{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a09d8b1b-ed12-4307-9e06-26afe636c2d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-16 22:58:01.062482: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-10-16 22:58:10.398192: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "from sklearn.cluster import KMeans\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "import numpy as np\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from tensorflow.keras.preprocessing.sequence import TimeseriesGenerator\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import r2_score\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.layers import  Dropout\n",
    "import networkx as nx\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from scipy.stats import chi2_contingency\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "32d8578c-470a-4bd2-b42e-88cf7c4e8674",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "adb9c8a3-7f8a-4782-9f99-9a73d2d767ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"cleaned_traffic_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a950f260-a67c-44b2-99ce-cf13e7808228",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the final selected columns\n",
    "selected_columns = [\n",
    "    \"Timestamp\", \"Station\", \"Route\", \"Direction of Travel\",\n",
    "    \"Total Flow\", \"Avg Speed\", \"% Observed\",\"Samples\",\"Lane Type\"\n",
    "]\n",
    "\n",
    "# Keep only the selected columns\n",
    "df = df[selected_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ec93adbc-a378-488b-94d0-f973efe2737e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=[\"Avg Speed\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d22e3ef3-4e06-4f66-90c6-98363b5b3dce",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['Total Flow'].notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2f2698a4-259f-4378-abb4-02ced930d3cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "duplicates: 0\n"
     ]
    }
   ],
   "source": [
    "duplicates = df.index.duplicated().sum() #check the number of duplicates \n",
    "print(\"duplicates:\", duplicates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "91bb5125-a46c-4cdf-97ed-0bc8d2216540",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Timestamp'] = pd.to_datetime(df['Timestamp'])\n",
    "df.set_index('Timestamp', inplace=True)\n",
    "df.sort_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ee65f5ff-9b12-4d6c-afa9-dc4900441794",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Station</th>\n",
       "      <th>Route</th>\n",
       "      <th>Direction of Travel</th>\n",
       "      <th>Total Flow</th>\n",
       "      <th>% Observed</th>\n",
       "      <th>Samples</th>\n",
       "      <th>Lane Type</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2024-10-01 00:00:00</th>\n",
       "      <td>308512</td>\n",
       "      <td>50</td>\n",
       "      <td>W</td>\n",
       "      <td>497.0</td>\n",
       "      <td>0</td>\n",
       "      <td>197</td>\n",
       "      <td>ML</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-10-01 00:00:00</th>\n",
       "      <td>311831</td>\n",
       "      <td>5</td>\n",
       "      <td>S</td>\n",
       "      <td>27.0</td>\n",
       "      <td>92</td>\n",
       "      <td>101</td>\n",
       "      <td>OR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-10-01 00:00:00</th>\n",
       "      <td>311832</td>\n",
       "      <td>5</td>\n",
       "      <td>S</td>\n",
       "      <td>78.0</td>\n",
       "      <td>92</td>\n",
       "      <td>101</td>\n",
       "      <td>FR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-10-01 00:00:00</th>\n",
       "      <td>311844</td>\n",
       "      <td>5</td>\n",
       "      <td>N</td>\n",
       "      <td>43.0</td>\n",
       "      <td>92</td>\n",
       "      <td>202</td>\n",
       "      <td>OR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-10-01 00:00:00</th>\n",
       "      <td>311847</td>\n",
       "      <td>5</td>\n",
       "      <td>N</td>\n",
       "      <td>73.0</td>\n",
       "      <td>92</td>\n",
       "      <td>303</td>\n",
       "      <td>OR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-12-31 23:00:00</th>\n",
       "      <td>3423094</td>\n",
       "      <td>99</td>\n",
       "      <td>S</td>\n",
       "      <td>68.0</td>\n",
       "      <td>96</td>\n",
       "      <td>118</td>\n",
       "      <td>ML</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-12-31 23:00:00</th>\n",
       "      <td>3900021</td>\n",
       "      <td>50</td>\n",
       "      <td>E</td>\n",
       "      <td>803.0</td>\n",
       "      <td>67</td>\n",
       "      <td>292</td>\n",
       "      <td>ML</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-12-31 23:00:00</th>\n",
       "      <td>3900022</td>\n",
       "      <td>50</td>\n",
       "      <td>E</td>\n",
       "      <td>509.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>HV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-12-31 23:00:00</th>\n",
       "      <td>3900023</td>\n",
       "      <td>50</td>\n",
       "      <td>W</td>\n",
       "      <td>881.0</td>\n",
       "      <td>67</td>\n",
       "      <td>289</td>\n",
       "      <td>ML</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-12-31 23:00:00</th>\n",
       "      <td>3900024</td>\n",
       "      <td>50</td>\n",
       "      <td>W</td>\n",
       "      <td>509.0</td>\n",
       "      <td>0</td>\n",
       "      <td>56</td>\n",
       "      <td>HV</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3810904 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Station  Route Direction of Travel  Total Flow  \\\n",
       "Timestamp                                                             \n",
       "2024-10-01 00:00:00   308512     50                   W       497.0   \n",
       "2024-10-01 00:00:00   311831      5                   S        27.0   \n",
       "2024-10-01 00:00:00   311832      5                   S        78.0   \n",
       "2024-10-01 00:00:00   311844      5                   N        43.0   \n",
       "2024-10-01 00:00:00   311847      5                   N        73.0   \n",
       "...                      ...    ...                 ...         ...   \n",
       "2024-12-31 23:00:00  3423094     99                   S        68.0   \n",
       "2024-12-31 23:00:00  3900021     50                   E       803.0   \n",
       "2024-12-31 23:00:00  3900022     50                   E       509.0   \n",
       "2024-12-31 23:00:00  3900023     50                   W       881.0   \n",
       "2024-12-31 23:00:00  3900024     50                   W       509.0   \n",
       "\n",
       "                     % Observed  Samples Lane Type  \n",
       "Timestamp                                           \n",
       "2024-10-01 00:00:00           0      197        ML  \n",
       "2024-10-01 00:00:00          92      101        OR  \n",
       "2024-10-01 00:00:00          92      101        FR  \n",
       "2024-10-01 00:00:00          92      202        OR  \n",
       "2024-10-01 00:00:00          92      303        OR  \n",
       "...                         ...      ...       ...  \n",
       "2024-12-31 23:00:00          96      118        ML  \n",
       "2024-12-31 23:00:00          67      292        ML  \n",
       "2024-12-31 23:00:00           0        0        HV  \n",
       "2024-12-31 23:00:00          67      289        ML  \n",
       "2024-12-31 23:00:00           0       56        HV  \n",
       "\n",
       "[3810904 rows x 7 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "febeafd9-2a6e-483a-aeb3-a3a12c57eca2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1806"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"Station\"].nunique() #There are 1,806 unique stations im the dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b62f259d-65c6-44d4-be61-f5e1fc7329fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Hour'] = df.index.hour\n",
    "df['Day'] = df.index.day\n",
    "df['Weekday'] = df.index.weekday\n",
    "df[\"Month\"] = df.index.month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e047f5e3-6ae7-4975-97bc-8b5932c453a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Station</th>\n",
       "      <th>Route</th>\n",
       "      <th>Direction of Travel</th>\n",
       "      <th>Total Flow</th>\n",
       "      <th>% Observed</th>\n",
       "      <th>Samples</th>\n",
       "      <th>Lane Type</th>\n",
       "      <th>Hour</th>\n",
       "      <th>Day</th>\n",
       "      <th>Weekday</th>\n",
       "      <th>Month</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2024-10-01 00:00:00</th>\n",
       "      <td>308512</td>\n",
       "      <td>50</td>\n",
       "      <td>W</td>\n",
       "      <td>497.0</td>\n",
       "      <td>0</td>\n",
       "      <td>197</td>\n",
       "      <td>ML</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-10-01 00:00:00</th>\n",
       "      <td>311831</td>\n",
       "      <td>5</td>\n",
       "      <td>S</td>\n",
       "      <td>27.0</td>\n",
       "      <td>92</td>\n",
       "      <td>101</td>\n",
       "      <td>OR</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-10-01 00:00:00</th>\n",
       "      <td>311832</td>\n",
       "      <td>5</td>\n",
       "      <td>S</td>\n",
       "      <td>78.0</td>\n",
       "      <td>92</td>\n",
       "      <td>101</td>\n",
       "      <td>FR</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-10-01 00:00:00</th>\n",
       "      <td>311844</td>\n",
       "      <td>5</td>\n",
       "      <td>N</td>\n",
       "      <td>43.0</td>\n",
       "      <td>92</td>\n",
       "      <td>202</td>\n",
       "      <td>OR</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-10-01 00:00:00</th>\n",
       "      <td>311847</td>\n",
       "      <td>5</td>\n",
       "      <td>N</td>\n",
       "      <td>73.0</td>\n",
       "      <td>92</td>\n",
       "      <td>303</td>\n",
       "      <td>OR</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-12-31 23:00:00</th>\n",
       "      <td>3423094</td>\n",
       "      <td>99</td>\n",
       "      <td>S</td>\n",
       "      <td>68.0</td>\n",
       "      <td>96</td>\n",
       "      <td>118</td>\n",
       "      <td>ML</td>\n",
       "      <td>23</td>\n",
       "      <td>31</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-12-31 23:00:00</th>\n",
       "      <td>3900021</td>\n",
       "      <td>50</td>\n",
       "      <td>E</td>\n",
       "      <td>803.0</td>\n",
       "      <td>67</td>\n",
       "      <td>292</td>\n",
       "      <td>ML</td>\n",
       "      <td>23</td>\n",
       "      <td>31</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-12-31 23:00:00</th>\n",
       "      <td>3900022</td>\n",
       "      <td>50</td>\n",
       "      <td>E</td>\n",
       "      <td>509.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>HV</td>\n",
       "      <td>23</td>\n",
       "      <td>31</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-12-31 23:00:00</th>\n",
       "      <td>3900023</td>\n",
       "      <td>50</td>\n",
       "      <td>W</td>\n",
       "      <td>881.0</td>\n",
       "      <td>67</td>\n",
       "      <td>289</td>\n",
       "      <td>ML</td>\n",
       "      <td>23</td>\n",
       "      <td>31</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-12-31 23:00:00</th>\n",
       "      <td>3900024</td>\n",
       "      <td>50</td>\n",
       "      <td>W</td>\n",
       "      <td>509.0</td>\n",
       "      <td>0</td>\n",
       "      <td>56</td>\n",
       "      <td>HV</td>\n",
       "      <td>23</td>\n",
       "      <td>31</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3810904 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Station  Route Direction of Travel  Total Flow  \\\n",
       "Timestamp                                                             \n",
       "2024-10-01 00:00:00   308512     50                   W       497.0   \n",
       "2024-10-01 00:00:00   311831      5                   S        27.0   \n",
       "2024-10-01 00:00:00   311832      5                   S        78.0   \n",
       "2024-10-01 00:00:00   311844      5                   N        43.0   \n",
       "2024-10-01 00:00:00   311847      5                   N        73.0   \n",
       "...                      ...    ...                 ...         ...   \n",
       "2024-12-31 23:00:00  3423094     99                   S        68.0   \n",
       "2024-12-31 23:00:00  3900021     50                   E       803.0   \n",
       "2024-12-31 23:00:00  3900022     50                   E       509.0   \n",
       "2024-12-31 23:00:00  3900023     50                   W       881.0   \n",
       "2024-12-31 23:00:00  3900024     50                   W       509.0   \n",
       "\n",
       "                     % Observed  Samples Lane Type  Hour  Day  Weekday  Month  \n",
       "Timestamp                                                                      \n",
       "2024-10-01 00:00:00           0      197        ML     0    1        1     10  \n",
       "2024-10-01 00:00:00          92      101        OR     0    1        1     10  \n",
       "2024-10-01 00:00:00          92      101        FR     0    1        1     10  \n",
       "2024-10-01 00:00:00          92      202        OR     0    1        1     10  \n",
       "2024-10-01 00:00:00          92      303        OR     0    1        1     10  \n",
       "...                         ...      ...       ...   ...  ...      ...    ...  \n",
       "2024-12-31 23:00:00          96      118        ML    23   31        1     12  \n",
       "2024-12-31 23:00:00          67      292        ML    23   31        1     12  \n",
       "2024-12-31 23:00:00           0        0        HV    23   31        1     12  \n",
       "2024-12-31 23:00:00          67      289        ML    23   31        1     12  \n",
       "2024-12-31 23:00:00           0       56        HV    23   31        1     12  \n",
       "\n",
       "[3810904 rows x 11 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bbfd51bb-177d-4a72-a5cf-7f4ed01830b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1000x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax = df['Total Flow'].plot(figsize=(10,3), title='Hourly series') #from the plot there is both a daily and weekly strudture in the traffic flow "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "21437d51-fde7-4fc7-ba37-c074a3165269",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: title={'center': 'Daily mean'}, xlabel='Timestamp'>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1000x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# daily average smooths noise so you see trend better\n",
    "df['Total Flow'].resample('D').mean().plot(figsize=(10,3), title='Daily mean')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "216f12c1-14f2-4a3b-931d-95c0e952b4dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_holidays = [   ##Beacuse of the drop in december it is great to include holiday so our model lears the behaviour of the flow over that time or periods\n",
    "    pd.to_datetime(\"2024-12-25\"),\n",
    "    pd.to_datetime(\"2024-12-31\"),\n",
    "    pd.to_datetime(\"2024-11-24\"),\n",
    "]\n",
    "df['IsHoliday'] = df.index.to_series().apply(lambda x: 1 if x in custom_holidays else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "084cbf35-5e62-4ae7-9034-4f558bba21d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "IsHoliday\n",
       "0    1000.285461\n",
       "1     293.691938\n",
       "Name: Total Flow, dtype: float64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('IsHoliday')['Total Flow'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e766ea66-0fa0-412e-bf31-d9bfb3d951a8",
   "metadata": {},
   "source": [
    "The average hourly Total Flow during non-holiday periods is approximately 1000, whereas it drops to about 294 during holidays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "20903ed7-027b-4068-ba01-2bb1e8ee9d18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: title={'center': 'Average Total Flow: Holidays vs Non-Holidays'}, xlabel='IsHoliday (0=No, 1=Yes)', ylabel='Average Flow'>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAdgAAAE1CAYAAABEA/HFAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy88F64QAAAACXBIWXMAAA9hAAAPYQGoP6dpAABCpklEQVR4nO3dd1RU1/428GekjAPCSBEGFJEoYgFL0KiY2AB7lHhjwxSi+dmNKCqW2COoUeRejBpzUaxgrrHFGK/YsCsSO2qaigQIFqQoUvf7hy/nOg4qgxwBeT5rzdLZZ58z3zPtYZ82CiGEABEREZWpauVdABER0ZuIAUtERCQDBiwREZEMGLBEREQyYMASERHJgAFLREQkAwYsERGRDBiwREREMmDAEhERyYABW8b+9a9/QaFQwNXVtbxLqTAiIiKgUCheeqtXr95LlxUfH485c+bg5s2br1zPy5bxoronTZok9atXrx78/PxKXY9cDh8+DIVCga1btxY7fezYsVAoFKVatp+fn87rVdLnoaiuw4cPl+qxKzM/Pz8oFAo0bdoUBQUFOtMVCgXGjh1bDpX97/1+9uzZYqf37t27RJ/R4nTq1AmdOnXSalMoFJgzZ06J63qVz3x5MSzvAt40a9asAQBcuXIFp0+fRps2bcq5ovLXq1cvnDx5UqutXbt2+PDDDxEQECC1KZXKly4rPj4ec+fORadOnUr9YdfX2rVr0ahRI602e3v71/LYlcn27dthbm5e3mVUCvHx8YiIiMCwYcPKu5Ryc/LkSdSpU6e8y5AVA7YMnT17FhcuXECvXr3w008/ITw8/LUHrBACjx8/hkqleq2P+yK1atVCrVq1dNptbW3Rtm3bcqhIP66urmjVqlV5l1HhtWzZsrxLqBRMTU3x9ttvY/bs2fD19a1Qn9XXqTJ89l8VNxGXofDwcADAwoUL4eHhgaioKDx69AgAkJeXBxsbG3z88cc68z148AAqlQoTJ06U2jIyMjBp0iQ4OTnB2NgYtWvXhr+/Px4+fKg1b9EmpVWrVqFx48ZQKpVYt24dAGDu3Llo06YNLC0tYW5ujrfffhvh4eF49vcdcnJyEBAQAI1GAxMTE3To0AFxcXHFbvJLSUnBiBEjUKdOHRgbG8PJyQlz585Ffn7+Kz9/x44dg6enJ8zMzGBiYgIPDw/89NNP0vSIiAj0798fANC5c2dpc21ERAQAIDo6Gn379kWdOnVQvXp1NGjQACNGjMDdu3dfuTZ9JSQk4KOPPoKNjQ2USiUaN26MpUuXorCwUOrTunVr9OrVS2s+Nzc3KBQKxMbGSm3btm2DQqHApUuXZK+7sLAQixcvRqNGjaBUKmFjY4NPPvkEiYmJL523uPfLtWvX0L17d5iYmMDa2hojR45EZmamzrwlee2OHj0KhUKByMhInfnXr1+v9bz9+eefGDRoEOzt7aFUKmFrawtPT0+cP3/+ufWHhoZCoVDg999/15kWGBgIY2NjqZ5z586hd+/e0utrb2+PXr16leh5AoBFixbhr7/+wj//+c+X9i3Je+nmzZtQKBRYsmQJQkJC4OTkhBo1aqBdu3Y4depUiWoqjcePH2PatGla31NjxozBgwcPXjpvcZuIT506hfbt26N69eqwt7fHtGnTkJeXpzPvli1b0LVrV9jZ2UGlUqFx48aYOnWq1vfjhg0boFAodLaeAcC8efNgZGSEpKQkAK/+ej6XoDLx6NEjoVarRevWrYUQQvz73/8WAERERITUZ8KECUKlUon09HSteVesWCEAiIsXLwohhHj48KFo0aKFsLa2FiEhIWL//v3in//8p1Cr1aJLly6isLBQmheAqF27tmjWrJnYvHmzOHjwoLh8+bIQQgg/Pz8RHh4uoqOjRXR0tJg/f75QqVRi7ty5Wo8/ePBgUa1aNTF16lSxb98+ERoaKhwcHIRarRaffvqp1C85OVk4ODgIR0dH8e2334r9+/eL+fPnC6VSKfz8/PR6vgCIMWPGSPcPHz4sjIyMhLu7u9iyZYvYsWOH6Nq1q1AoFCIqKkoIIURqaqoICgoSAMQ333wjTp48KU6ePClSU1OFEEKsXLlSBAcHi127domYmBixbt060bx5c+Hi4iJyc3Olx1q7dq0AIG7cuPHCGov6nTp1SuTl5Wndnubo6Kj1PKWmporatWuLWrVqiVWrVom9e/eKsWPHCgBi1KhRUr+pU6eKGjVqSLWlpKQIAEKlUokFCxZI/UaNGiVsbW21Hs/R0fGlz/GhQ4cEALFlyxad+vPy8sTo0aPFs18Bw4cPFwDE2LFjxd69e8WqVatErVq1hIODg7hz547U79NPP9Wp4dnnISUlRdjY2IjatWuLtWvXij179oghQ4aIunXrCgDi0KFDUt+SvnYtW7YU7du311nX1q1bS589IYRwcXERDRo0EBs2bBAxMTHihx9+EAEBAVqP+aw7d+4IY2NjMWPGDK32/Px8YW9vL/r16yeEECIrK0tYWVmJVq1aie+//17ExMSILVu2iJEjR4r4+PjnLr/oeTM1NRVCCPHBBx+ImjVrinv37knTn/1clPS9dOPGDQFA1KtXT3Tv3l3s2LFD7NixQ7i5uQkLCwvx4MGDF9YlxIvf73l5eaJnz55ar3lhYaHo1q2bMDQ0FDNnzhT79u0TS5YsEaampqJly5bi8ePHUt+OHTuKjh07aj0eADF79mzp/pUrV4SJiYlo0qSJiIyMFDt37hTdunWT3i9Pf17nz58vli1bJn766Sdx+PBhsWrVKuHk5CQ6d+4s9cnJyREajUYMGTJE63Hz8vKEvb296N+/vxDi1V7Pl2HAlpH169cLAGLVqlVCCCEyMzNFjRo1xHvvvSf1uXjxogAgVq9erTXvO++8I9zd3aX7wcHBolq1aiI2Nlar39atWwUAsWfPHqkNgFCr1eL+/fsvrK+goEDk5eWJefPmCSsrKymkr1y5IgCIwMBArf6RkZECgNYX5ogRI0SNGjXErVu3tPouWbJEABBXrlx5YQ1Pe/aLpG3btsLGxkZkZmZKbfn5+cLV1VXUqVNHqvc///mPzpdzcQoLC0VeXp64deuWACB27twpTdM3YIu7PR2yzwbL1KlTBQBx+vRpreWNGjVKKBQKcf36dSGEEPv37xcAxJEjR4QQQmzcuFGYmZmJ0aNHa31RODs7C19fX+l+/fr1Rf369V9YuxD/C9iX3YpcvXpVABCjR4/WWs7p06cFADF9+nSprSQBGxgYKBQKhTh//rxWP29v7xe+hiV57c6dOye1nTlzRgAQ69atE0IIcffuXQFAhIaGvvQ5ela/fv1EnTp1REFBgdS2Z88eAUD8+OOPQgghzp49KwCIHTt26L38pwP22rVrwsDAQAQEBEjTn/1clPS9VBSwbm5uIj8/X+pX9NxERka+tLYXvd+Lbk+/5nv37hUAxOLFi7WWs2XLFp3vuZIE7MCBA4VKpRIpKSlSW35+vmjUqNELP69F75eYmBgBQFy4cEGaNnv2bGFsbCz+/vtvnfpiYmKEEK/2er4MNxGXkfDwcKhUKgwaNAgAUKNGDfTv3x9Hjx7Fb7/9BuDJ5j93d3esXbtWmu/q1as4c+YMhg4dKrXt3r0brq6uaNGiBfLz86Vbt27dij36skuXLrCwsNCp6eDBg/Dy8oJarYaBgQGMjIwwa9Ys3Lt3D6mpqQCAmJgYAMCAAQO05v3www9haKi9i3737t3o3Lkz7O3tterq0aOH1rL09fDhQ5w+fRoffvghatSoIbUbGBjg448/RmJiIq5fv/7S5aSmpmLkyJFwcHCAoaEhjIyM4OjoCODJ81xa69evR2xsrNbt2efmaQcPHkSTJk3wzjvvaLX7+flBCIGDBw8CgLQpbP/+/QCebCbt1KkTunfvjhMnTuDRo0e4ffs2fvvtN3h5eUnL+f3334vdjPk8ixYt0qk/NjZW5zU/dOiQVOfT3nnnHTRu3BgHDhwo8WMWLa9p06Zo3ry5Vruvr69O35K+doMHD4aNjQ2++eYbqS0sLAy1atXCwIEDAQCWlpaoX78+vv76a4SEhODcuXNam1Nf5LPPPkNiYqL0mgBPDnLTaDTS+7xBgwawsLBAYGAgVq1ahfj4+BI+I9pcXFwwbNgwLF++HAkJCcX2Kel7qUivXr1gYGAg3W/WrBkA4NatWwCeHKPx9Ge3uF07xb3fY2Nj8e677+rUVlTL0/r37w9TU9NSvV88PT1ha2srtRkYGEiv69P+/PNP+Pr6QqPRSN9tHTt2BKD9fhk1ahQA4LvvvpPali9fDjc3N3To0AFA2b2exWHAloHff/8dR44cQa9evSCEwIMHD/DgwQN8+OGHAP53ZDEADB06FCdPnsS1a9cAPPnwKpVKDB48WOrz999/4+LFizAyMtK6mZmZQQihs0/Rzs5Op6YzZ86ga9euAJ68uY4fP47Y2FjMmDEDAJCdnQ0AuHfvHgBovakBwNDQEFZWVlptf//9N3788Uedupo2bQoApd7XmZaWBiFEsetRdLRuUZ3PU1hYiK5du2Lbtm2YMmUKDhw4gDNnzkj7n4rWtzQaN26MVq1aad1e5N69eyVal+rVq6N9+/bSl/mBAwfg7e2NTp06oaCgAEePHkV0dDQAaAWsvt566y2d+lu1aqVz4FlRXc+r/WWvwbPu3bsHjUaj0/5smz6vnVKpxIgRI7B582Y8ePAAd+7cwffff4/PP/9cOgpdoVDgwIED6NatGxYvXoy3334btWrVwhdffFHs/t+n9ejRA3Z2dtIfwWlpadi1axc++eQTKbjUajViYmLQokULTJ8+HU2bNoW9vT1mz55d7P7CF5kzZw4MDAwwc+bMYqeX9L1U5NnPbNFzUvQcxsTE6Hx+nz39pbj3e6tWraBWq3VqMzQ01HkfKRQKaDQa2d4vWVlZeO+993D69Gl89dVXOHz4MGJjY7Ft2zatdQWefK8NHDgQ3377LQoKCnDx4kUcPXpU61Sosnw9n8WjiMvAmjVrIITA1q1biz3ncN26dfjqq69gYGCAwYMHY+LEiYiIiMCCBQuwYcMG+Pj4aI1Ara2toVKptIL5adbW1lr3izuXMSoqCkZGRti9ezeqV68ute/YsUOrX9EH8u+//0bt2rWl9vz8fJ0PiLW1NZo1a4YFCxYUW1dpT12xsLBAtWrVkJycrDOt6CCEZ9f5WZcvX8aFCxcQERGBTz/9VGrXZ6RXVqysrEq8Lp6enpg1axbOnDmDxMREeHt7w8zMDK1bt0Z0dDSSkpLQsGFDODg4vJa6ASA5OVnn9ImkpKSXvgbFLS8lJUWn/dk2fV+7UaNGYeHChVizZg0eP36M/Px8jBw5UquPo6OjdNDhr7/+iu+//x5z5sxBbm4uVq1a9dyai7aa/Otf/8KDBw+wefNm5OTk4LPPPtPq5+bmhqioKAghcPHiRURERGDevHlQqVSYOnXqi5+Yp9jZ2cHf3x8LFy7UOmWtiD7vpZJwd3fXOoAOKP3n1srKCvn5+bhz545WyAohkJKSgtatW+u9vJK8Xw4ePIikpCQcPnxYGrUCeO6BVePHj8eGDRuwc+dO7N27FzVr1sSQIUO0+pTV6/ksjmBfUUFBAdatW4f69evj0KFDOreAgAAkJyfj559/BvAkTHx8fLB+/Xrs3r0bKSkpWpuHgScndP/xxx+wsrIq9i/Jkpz/qVAoYGhoqLW5KDs7Gxs2bNDqV7SZZMuWLVrtW7du1dl81Lt3b1y+fBn169cvtq7SflBNTU3Rpk0bbNu2Teuvz8LCQmzcuBF16tRBw4YNAej+Rf70+j49vci3335bqppehaenJ+Lj4/HLL79otRcd6dq5c2epzcvLC/n5+Zg5cybq1KkjnW/r5eWF/fv3S5v5X4cuXboAADZu3KjVHhsbi6tXr8LT01Ov5XXu3BlXrlzBhQsXtNo3b96sdV/f187Ozg79+/fHihUrsGrVKrz//vuoW7fuc+to2LAhvvzyS7i5uem8JsX57LPP8PjxY0RGRiIiIgLt2rXTOQ/66dqbN2+OZcuWoWbNmiVa/rMCAwNhaWlZ7Be5Pu+lkjAzM9P53BobG+tdc1FtgO775YcffsDDhw9L9X45cOAA/v77b6mtoKBA57tJ3/eLu7s7PDw8sGjRImzatAl+fn4wNTUttm9ZvJ5P4wj2Ff38889ISkrCokWLdK5UAjw5h3L58uUIDw9H7969ATzZTLxlyxaMHTsWderU0fkC9ff3xw8//IAOHTpgwoQJaNasGQoLC5GQkIB9+/YhICDgpefX9urVCyEhIfD19cXw4cNx7949LFmyROdN2bRpUwwePBhLly6FgYEBunTpgitXrmDp0qVQq9WoVu1/f4PNmzcP0dHR8PDwwBdffAEXFxc8fvwYN2/exJ49e7Bq1apSnzgeHBwMb29vdO7cGZMmTYKxsTFWrFiBy5cvIzIyUvpQFV0ha/Xq1TAzM0P16tXh5OSERo0aoX79+pg6dSqEELC0tMSPP/4obWJ9nSZMmID169ejV69emDdvHhwdHfHTTz9hxYoVGDVqlPTHAvDkw29hYYF9+/ZpjZK8vLwwf/586f9Pa9CgAYCyH527uLhg+PDhCAsLQ7Vq1dCjRw/cvHkTM2fOhIODAyZMmKDX8vz9/bFmzRr06tULX331FWxtbbFp0yZp90iR0rx248ePlz4DTx/TAAAXL17E2LFj0b9/fzg7O8PY2BgHDx7ExYsXSzQaadSoEdq1a4fg4GDcvn0bq1ev1pq+e/durFixAj4+PnjrrbcghMC2bdvw4MEDeHt7l/TpkZibm2PGjBnFPr/6vJdeN29vb3Tr1g2BgYHIyMhA+/btcfHiRcyePRstW7Ys9pTEF/nyyy+xa9cudOnSBbNmzYKJiQm++eYbnVMTPTw8YGFhgZEjR2L27NkwMjLCpk2bdP6Qe9r48eMxcOBAKBQKjB49WmtaWb+eWsr8sKkqxsfHRxgbG0unihRn0KBBwtDQUDo6rqCgQDg4OAgAOqcEFMnKyhJffvmlcHFxEcbGxkKtVgs3NzcxYcIEraPs8MxRh09bs2aNcHFxEUqlUrz11lsiODhYhIeH6xyR9/jxYzFx4kRhY2MjqlevLtq2bStOnjwp1Gq1mDBhgtYy79y5I7744gvh5OQkjIyMhKWlpXB3dxczZswQWVlZJX3aiq376NGjokuXLsLU1FSoVCrRtm1b6cjNp4WGhgonJydhYGAgAIi1a9cKIYSIj48X3t7ewszMTFhYWIj+/fuLhIQEnaMV9T2K+NmjuZ/17NGzQghx69Yt4evrK6ysrISRkZFwcXERX3/9tdbRqUU++OADAUBs2rRJasvNzRWmpqaiWrVqIi0tTefx9DlN5z//+U+x08eMGaNzmk5BQYFYtGiRaNiwoTAyMhLW1tbio48+Erdv39bqV5KjiIX432tSvXp1YWlpKYYNGyZ27typcxRxSV+7p9WrV080btxYp/3vv/8Wfn5+olGjRsLU1FTUqFFDNGvWTCxbtkzrCNsXWb16tXTK1LOn1V27dk0MHjxY1K9fX6hUKqFWq8U777yjdUre8zx9FPHTcnJyhJOTU7Gfi5K8l4qOIv766691lv2i5/BpL3u/9+rVS+c1z87OFoGBgcLR0VEYGRkJOzs7MWrUKJ33bEmOIhZCiOPHj4u2bdsKpVIpNBqNmDx5svRaPP15PXHihGjXrp0wMTERtWrVEp9//rn45ZdftL4PnpaTkyOUSqXo3r27zrRXeT1fRvH/V5RIy4kTJ9C+fXts2rSp2KM+icrTxYsX0bx5c3zzzTc6IxKiZ/3444/o06cPfvrpJ/Ts2fO1PS4DlhAdHY2TJ0/C3d0dKpUKFy5cwMKFC6FWq3Hx4kWtg6SIytMff/yBW7duYfr06UhISMDvv/8OExOT8i6LKqj4+HjcunUL48ePh6mpKX755ZdS/8BFaXAfLMHc3Bz79u1DaGgoMjMzYW1tjR49eiA4OJjhShXK/PnzsWHDBjRu3Bj/+c9/GK70QqNHj8bx48fx9ttvY926da81XAGOYImIiGTB03SIiIhkwIAlIiKSAQOWiIhIBjzIqYQKCwuRlJQEMzOz176jnIiIKgYhBDIzM2Fvb691IZ7iMGBLKCkp6bVcD5aIiCq+27dvv/TKdQzYEjIzMwPw5Ek1Nzcv52qIiKg8ZGRkwMHBQcqEF2HAllDRZmFzc3MGLBFRFVeSXYU8yImIiEgGDFgiIiIZMGCJiIhkwIAlIiKSQbkG7JEjR/D+++/D3t4eCoUCO3bs0JouhMCcOXNgb28PlUqFTp064cqVK1p9cnJyMG7cOFhbW8PU1BR9+vRBYmKiVp+0tDR8/PHHUKvVUKvV+Pjjj/HgwQOZ146IiKqycg3Yhw8fonnz5li+fHmx0xcvXoyQkBAsX74csbGx0Gg08Pb2RmZmptTH398f27dvR1RUFI4dO4asrCz07t0bBQUFUh9fX1+cP38ee/fuxd69e3H+/Hl8/PHHsq8fERFVYa/8k+1lBIDYvn27dL+wsFBoNBqxcOFCqe3x48dCrVaLVatWCSGEePDggTAyMhJRUVFSn7/++ktUq1ZN7N27VwghRHx8vAAgTp06JfU5efKkACCuXbtW4vrS09MFAJGenl7aVSQiokpOnyyosPtgb9y4gZSUFHTt2lVqUyqV6NixI06cOAEAiIuLQ15enlYfe3t7uLq6Sn1OnjwJtVqNNm3aSH3atm0LtVot9SlOTk4OMjIytG5EREQlVWEvNJGSkgIAsLW11Wq3tbXFrVu3pD7GxsawsLDQ6VM0f0pKCmxsbHSWb2NjI/UpTnBwMObOnftK61DRLDx3t7xLqPKmtrQu7xKI6DWpsCPYIs9eLUMI8dIraDzbp7j+L1vOtGnTkJ6eLt1u376tZ+VERFSVVdiA1Wg0AKAzykxNTZVGtRqNBrm5uUhLS3thn7///ltn+Xfu3NEZHT9NqVRKl0Xk5RGJiEhfFTZgnZycoNFoEB0dLbXl5uYiJiYGHh4eAAB3d3cYGRlp9UlOTsbly5elPu3atUN6ejrOnDkj9Tl9+jTS09OlPkRERGWtXPfBZmVl4ffff5fu37hxA+fPn4elpSXq1q0Lf39/BAUFwdnZGc7OzggKCoKJiQl8fX0BAGq1GsOGDUNAQACsrKxgaWmJSZMmwc3NDV5eXgCAxo0bo3v37vi///s/fPvttwCA4cOHo3fv3nBxcXn9K01ERFVCuQbs2bNn0blzZ+n+xIkTAQCffvopIiIiMGXKFGRnZ2P06NFIS0tDmzZtsG/fPq2fCVq2bBkMDQ0xYMAAZGdnw9PTExERETAwMJD6bNq0CV988YV0tHGfPn2ee+4tERFRWVAIIUR5F1EZZGRkQK1WIz09vdLuj+VRxOWPRxETVW76ZEGF3QdLRERUmTFgiYiIZMCAJSIikgEDloiISAYMWCIiIhkwYImIiGTAgCUiIpIBA5aIiEgGDFgiIiIZMGCJiIhkwIAlIiKSAQOWiIhIBgxYIiIiGTBgiYiIZMCAJSIikgEDloiISAYMWCIiIhkwYImIiGTAgCUiIpIBA5aIiEgGDFgiIiIZMGCJiIhkwIAlIiKSAQOWiIhIBgxYIiIiGTBgiYiIZMCAJSIikgEDloiISAYMWCIiIhkwYImIiGTAgCUiIpIBA5aIiEgGDFgiIiIZVOiAzc/Px5dffgknJyeoVCq89dZbmDdvHgoLC6U+QgjMmTMH9vb2UKlU6NSpE65cuaK1nJycHIwbNw7W1tYwNTVFnz59kJiY+LpXh4iIqpAKHbCLFi3CqlWrsHz5cly9ehWLFy/G119/jbCwMKnP4sWLERISguXLlyM2NhYajQbe3t7IzMyU+vj7+2P79u2IiorCsWPHkJWVhd69e6OgoKA8VouIiKoAw/Iu4EVOnjyJvn37olevXgCAevXqITIyEmfPngXwZPQaGhqKGTNmoF+/fgCAdevWwdbWFps3b8aIESOQnp6O8PBwbNiwAV5eXgCAjRs3wsHBAfv370e3bt3KZ+WIiOiNVqFHsO+++y4OHDiAX3/9FQBw4cIFHDt2DD179gQA3LhxAykpKejatas0j1KpRMeOHXHixAkAQFxcHPLy8rT62Nvbw9XVVepTnJycHGRkZGjdiIiISqpCj2ADAwORnp6ORo0awcDAAAUFBViwYAEGDx4MAEhJSQEA2Nraas1na2uLW7duSX2MjY1hYWGh06do/uIEBwdj7ty5Zbk6RERUhVToEeyWLVuwceNGbN68Gb/88gvWrVuHJUuWYN26dVr9FAqF1n0hhE7bs17WZ9q0aUhPT5dut2/fLv2KEBFRlVOhR7CTJ0/G1KlTMWjQIACAm5sbbt26heDgYHz66afQaDQAnoxS7ezspPlSU1OlUa1Go0Fubi7S0tK0RrGpqanw8PB47mMrlUoolUo5VouIiKqACj2CffToEapV0y7RwMBAOk3HyckJGo0G0dHR0vTc3FzExMRI4enu7g4jIyOtPsnJybh8+fILA5aIiOhVVOgR7Pvvv48FCxagbt26aNq0Kc6dO4eQkBAMHToUwJNNw/7+/ggKCoKzszOcnZ0RFBQEExMT+Pr6AgDUajWGDRuGgIAAWFlZwdLSEpMmTYKbm5t0VDEREVFZq9ABGxYWhpkzZ2L06NFITU2Fvb09RowYgVmzZkl9pkyZguzsbIwePRppaWlo06YN9u3bBzMzM6nPsmXLYGhoiAEDBiA7Oxuenp6IiIiAgYFBeawWERFVAQohhCjvIiqDjIwMqNVqpKenw9zcvLzLKZWF5+6WdwlV3tSW1uVdAhG9An2yoELvgyUiIqqsGLBEREQyYMASERHJgAFLREQkAwYsERGRDBiwREREMmDAEhERyYABS0REJAO9A3bGjBmIjo7Go0eP5KiHiIjojaB3wMbFxeEf//gHLCws0K5dO0ybNg179+5FVlaWHPURERFVSnoH7N69e5GWlobDhw+jb9++OHfuHAYOHAhLS0u0bdtWjhqJiIgqnVJd7N/AwADt2rWDpaUlLCwsYGZmhh07duCPP/4o6/qIiIgqJb1HsCtXrsSgQYNgZ2eH9957D/v27cN7772HuLg43LlzR44aiYiIKh29R7BjxoxBrVq1EBAQgJEjR1baX5YhIiKSk94j2G3btmHIkCGIioqCjY0N2rRpg8DAQPz888880ImIiOj/03sE6+PjAx8fHwBAeno6jh49iq1bt6Jv375QKBTIyckp6xqJiIgqnVId5HT//n3ExMTg8OHDOHz4MC5fvgwrKyt07NixrOsjIiKqlPQO2GbNmiE+Ph6Wlpbo0KED/u///g+dOnWCq6urHPURERFVSnoH7PDhwxmoREREL6F3wI4dO1b6vxACAKBQKMquIiIiojdAqS72v379eri5uUGlUkGlUqFZs2bYsGFDWddGRERUaek9gg0JCcHMmTMxduxYtG/fHkIIHD9+HCNHjsTdu3cxYcIEOeokIiKqVPQO2LCwMKxcuRKffPKJ1Na3b180bdoUc+bMYcASERGhFJuIk5OT4eHhodPu4eGB5OTkMimKiIiostM7YBs0aIDvv/9ep33Lli1wdnYuk6KIiIgqO703Ec+dOxcDBw7EkSNH0L59eygUChw7dgwHDhwoNniJiIiqIr1HsP/4xz9w+vRpWFtbY8eOHdi2bRusra1x5swZfPDBB3LUSEREVOmU6lKJ7u7u2LhxY1nXQkRE9MYoUcBmZGSUeIH8+ToiIqISBmzNmjVferUmIQQUCgUKCgrKpDAiIqLKrEQBe+jQIbnrICIieqOUKGD5M3RERET6KfFRxJ988gkyMzOl+xcuXEBeXp4sRREREVV2JQ7YTZs2ITs7W7r/3nvv4fbt27IU9bS//voLH330EaysrGBiYoIWLVogLi5Omi6EwJw5c2Bvbw+VSoVOnTrhypUrWsvIycnBuHHjYG1tDVNTU/Tp0weJiYmy105ERFVXiQO26KfpnndfDmlpaWjfvj2MjIzw888/Iz4+HkuXLkXNmjWlPosXL0ZISAiWL1+O2NhYaDQaeHt7a422/f39sX37dkRFReHYsWPIyspC7969eUAWERHJplTnwb4uixYtgoODA9auXSu11atXT/q/EAKhoaGYMWMG+vXrBwBYt24dbG1tsXnzZowYMQLp6ekIDw/Hhg0b4OXlBQDYuHEjHBwcsH//fnTr1u21rhMREVUNel3JKT4+HhcvXsTFixchhMC1a9ek+0W3srRr1y60atUK/fv3h42NDVq2bInvvvtOmn7jxg2kpKSga9euUptSqUTHjh1x4sQJAEBcXBzy8vK0+tjb28PV1VXqU5ycnBxkZGRo3YiIiEpKrxGsp6en1qbh3r17AwAUCoUs58H++eefWLlyJSZOnIjp06fjzJkz+OKLL6BUKvHJJ58gJSUFAGBra6s1n62tLW7dugUASElJgbGxMSwsLHT6FM1fnODgYMydO7fM1oWIiKqWEgfsjRs35KyjWIWFhWjVqhWCgoIAAC1btsSVK1d0fo/22YtgFIX9i7ysz7Rp0zBx4kTpfkZGBhwcHEqzGkREVAWVOGAdHR3lrKNYdnZ2aNKkiVZb48aN8cMPPwAANBoNgCejVDs7O6lPamqqNKrVaDTIzc1FWlqa1ig2NTW12N+1LaJUKqFUKstsXYiIqGrR+9d0Xqf27dvj+vXrWm2//vqrFPZOTk7QaDSIjo6Wpufm5iImJkYKT3d3dxgZGWn1SU5OxuXLl18YsERERK+iQh9FPGHCBHh4eCAoKAgDBgzAmTNnsHr1aqxevRrAk03D/v7+CAoKgrOzM5ydnREUFAQTExP4+voCANRqNYYNG4aAgABYWVnB0tISkyZNgpubm3RUMRERUVmr0AHbunVrbN++HdOmTcO8efPg5OSE0NBQDBkyROozZcoUZGdnY/To0UhLS0ObNm2wb98+mJmZSX2WLVsGQ0NDDBgwANnZ2fD09ERERAQMDAzKY7WIiKgKUIjXccWIN0BGRgbUajXS09Mr7U/yLTx3t7xLqPKmtrQu7xKI6BXokwWl2gebn5+P/fv349tvv5WumJSUlISsrKzSLI6IiOiNo/cm4lu3bqF79+5ISEhATk4OvL29YWZmhsWLF+Px48dYtWqVHHUSERFVKnqPYMePH49WrVohLS0NKpVKav/ggw9w4MCBMi2OiIiostJ7BHvs2DEcP34cxsbGWu2Ojo7466+/yqwwIiKiykzvEWxhYWGxl0NMTEzUOnKXiIioKtM7YL29vREaGirdVygUyMrKwuzZs9GzZ8+yrI2IiKjS0nsT8bJly9C5c2c0adIEjx8/hq+vL3777TdYW1sjMjJSjhqJiIgqHb0D1t7eHufPn0dkZCR++eUXFBYWYtiwYRgyZIjWQU9ERERVWamu5KRSqTB06FAMHTq0rOshIiJ6I+gdsLt27Sq2XaFQoHr16mjQoAGcnJxeuTAiIqLKTO+A9fHxkX5g/WlP/+j6u+++ix07duj8yDkREVFVofdRxNHR0WjdujWio6ORnp6O9PR0REdH45133sHu3btx5MgR3Lt3D5MmTZKjXiIiokpB7xHs+PHjsXr1aq3fUvX09ET16tUxfPhwXLlyBaGhodw/S0REVZreI9g//vij2F8QMDc3x59//gkAcHZ2xt27/OUWIiKquvQOWHd3d0yePBl37tyR2u7cuYMpU6agdevWAIDffvsNderUKbsqiYiIKhm9NxGHh4ejb9++qFOnDhwcHKBQKJCQkIC33noLO3fuBABkZWVh5syZZV4sERFRZaF3wLq4uODq1av473//i19//RVCCDRq1Aje3t6oVu3JgNjHx6es6yQiIqpUSnWhCYVCge7du6N79+5lXQ8REdEboVQB+/DhQ8TExCAhIQG5ubla07744osyKYyIiKgy0ztgz507h549e+LRo0d4+PAhLC0tcffuXZiYmMDGxoYBS0REhFIcRTxhwgS8//77uH//PlQqFU6dOoVbt27B3d0dS5YskaNGIiKiSkfvgD1//jwCAgJgYGAAAwMD5OTkwMHBAYsXL8b06dPlqJGIiKjS0TtgjYyMoFAoAAC2trZISEgAAKjVaun/REREVZ3e+2BbtmyJs2fPomHDhujcuTNmzZqFu3fvYsOGDXBzc5OjRiIiokpH7xFsUFAQ7OzsAADz58+HlZUVRo0ahdTUVKxevbrMCyQiIqqM9BrBCiFQq1YtNG3aFABQq1Yt7NmzR5bCiIiIKjO9RrBCCDg7OyMxMVGueoiIiN4IegVstWrV4OzsjHv37slVDxER0RtB732wixcvxuTJk3H58mU56iEiInoj6H0U8UcffYRHjx6hefPmMDY2hkql0pp+//79MiuOiIiostI7YENDQ2Uog4iI6M2id8B++umnctRBRET0RtF7HywA/PHHH/jyyy8xePBgpKamAgD27t2LK1eulGlxRERElZXeARsTEwM3NzecPn0a27ZtQ1ZWFgDg4sWLmD17dpkX+LTg4GAoFAr4+/tLbUIIzJkzB/b29lCpVOjUqZNO0Ofk5GDcuHGwtraGqakp+vTpw1ONiIhIVnoH7NSpU/HVV18hOjoaxsbGUnvnzp1x8uTJMi3uabGxsVi9ejWaNWum1b548WKEhIRg+fLliI2NhUajgbe3NzIzM6U+/v7+2L59O6KionDs2DFkZWWhd+/eKCgokK1eIiKq2vQO2EuXLuGDDz7Qaa9Vq5Zs58dmZWVhyJAh+O6772BhYSG1CyEQGhqKGTNmoF+/fnB1dcW6devw6NEjbN68GQCQnp6O8PBwLF26FF5eXmjZsiU2btyIS5cuYf/+/bLUS0REpHfA1qxZE8nJyTrt586dQ+3atcukqGeNGTMGvXr1gpeXl1b7jRs3kJKSgq5du0ptSqUSHTt2xIkTJwAAcXFxyMvL0+pjb28PV1dXqU9xcnJykJGRoXUjIiIqKb0D1tfXF4GBgUhJSYFCoUBhYSGOHz+OSZMm4ZNPPinzAqOiovDLL78gODhYZ1pKSgqAJz+b9zRbW1tpWkpKCoyNjbVGvs/2KU5wcDDUarV0c3BweNVVISKiKkTvgF2wYAHq1q2L2rVrIysrC02aNEGHDh3g4eGBL7/8skyLu337NsaPH4+NGzeievXqz+1X9Pu0RYQQOm3PelmfadOmIT09Xbrdvn1bv+KJiKhK0/s8WCMjI2zatAnz5s3DuXPnUFhYiJYtW8LZ2bnMi4uLi0Nqairc3d2ltoKCAhw5cgTLly/H9evXATwZpRb9hB4ApKamSqNajUaD3NxcpKWlaY1iU1NT4eHh8dzHViqVUCqVZb1KRERURZTqNB0AqF+/Pj788EMMGDBAlnAFAE9PT1y6dAnnz5+Xbq1atcKQIUNw/vx5vPXWW9BoNIiOjpbmyc3NRUxMjBSe7u7uMDIy0uqTnJyMy5cvvzBgiYiIXoXeI1hvb29oNBr4+vrio48+gqurqxx1AQDMzMx0lm9qagorKyup3d/fH0FBQXB2doazszOCgoJgYmICX19fAIBarcawYcMQEBAAKysrWFpaYtKkSXBzc9M5aIqIiKis6B2wSUlJiIqKQmRkJBYvXgxXV1d89NFH8PX1RZ06deSo8YWmTJmC7OxsjB49GmlpaWjTpg327dsHMzMzqc+yZctgaGiIAQMGIDs7G56enoiIiICBgcFrr5eIiKoGhRBClHbmGzduYPPmzYiMjMS1a9fQoUMHHDx4sCzrqzAyMjKgVquRnp4Oc3Pz8i6nVBaeu1veJVR5U1tal3cJRPQK9MmCUl2LuIiTkxOmTp2KhQsXws3NTdo/S0REVNWVOmCPHz+O0aNHw87ODr6+vmjatCl2795dlrURERFVWnrvg50+fToiIyORlJQELy8vhIaGwsfHByYmJnLUR0REVCnpHbCHDx/GpEmTMHDgQFhba+9POn/+PFq0aFFWtREREVVaegfss9fvTU9Px6ZNm/Dvf/8bFy5c4C/UEBER4RX2wR48eBAfffQR7OzsEBYWhp49e+Ls2bNlWRsREVGlpdcINjExEREREVizZg0ePnyIAQMGIC8vDz/88AOaNGkiV41ERESVTolHsD179kSTJk0QHx+PsLAwJCUlISwsTM7aiIiIKq0Sj2D37duHL774AqNGjZLt2sNERERvihKPYI8ePYrMzEy0atUKbdq0wfLly3Hnzh05ayMiIqq0Shyw7dq1w3fffYfk5GSMGDECUVFRqF27NgoLCxEdHY3MzEw56yQiIqpU9D6K2MTEBEOHDsWxY8dw6dIlBAQEYOHChbCxsUGfPn3kqJGIiKjSeaVrEbu4uGDx4sVITExEZGRkWdVERERU6b1SwBYxMDCAj48Pdu3aVRaLIyIiqvTKJGCJiIhIGwOWiIhIBnpfi5iIqDLLmxtQ3iVUeUazl5Z3Ca8FR7BEREQyYMASERHJgAFLREQkAwYsERGRDBiwREREMmDAEhERyYABS0REJAMGLBERkQwYsERERDJgwBIREcmAAUtERCQDBiwREZEMGLBEREQyYMASERHJgAFLREQkAwYsERGRDCp0wAYHB6N169YwMzODjY0NfHx8cP36da0+QgjMmTMH9vb2UKlU6NSpE65cuaLVJycnB+PGjYO1tTVMTU3Rp08fJCYmvs5VISKiKqZCB2xMTAzGjBmDU6dOITo6Gvn5+ejatSsePnwo9Vm8eDFCQkKwfPlyxMbGQqPRwNvbG5mZmVIff39/bN++HVFRUTh27BiysrLQu3dvFBQUlMdqERFRFWBY3gW8yN69e7Xur127FjY2NoiLi0OHDh0ghEBoaChmzJiBfv36AQDWrVsHW1tbbN68GSNGjEB6ejrCw8OxYcMGeHl5AQA2btwIBwcH7N+/H926dXvt60VERG++Cj2CfVZ6ejoAwNLSEgBw48YNpKSkoGvXrlIfpVKJjh074sSJEwCAuLg45OXlafWxt7eHq6ur1Kc4OTk5yMjI0LoRERGVVKUJWCEEJk6ciHfffReurq4AgJSUFACAra2tVl9bW1tpWkpKCoyNjWFhYfHcPsUJDg6GWq2Wbg4ODmW5OkRE9IarNAE7duxYXLx4EZGRkTrTFAqF1n0hhE7bs17WZ9q0aUhPT5dut2/fLl3hRERUJVWKgB03bhx27dqFQ4cOoU6dOlK7RqMBAJ2RaGpqqjSq1Wg0yM3NRVpa2nP7FEepVMLc3FzrRkREVFIVOmCFEBg7diy2bduGgwcPwsnJSWu6k5MTNBoNoqOjpbbc3FzExMTAw8MDAODu7g4jIyOtPsnJybh8+bLUh4iIqKxV6KOIx4wZg82bN2Pnzp0wMzOTRqpqtRoqlQoKhQL+/v4ICgqCs7MznJ2dERQUBBMTE/j6+kp9hw0bhoCAAFhZWcHS0hKTJk2Cm5ubdFQxERFRWavQAbty5UoAQKdOnbTa165dCz8/PwDAlClTkJ2djdGjRyMtLQ1t2rTBvn37YGZmJvVftmwZDA0NMWDAAGRnZ8PT0xMREREwMDB4XatCRERVjEIIIcq7iMogIyMDarUa6enplXZ/7MJzd8u7hCpvakvr8i6hysubG1DeJVR5RrOXlncJpaZPFlTofbBERESVFQOWiIhIBgxYIiIiGTBgiYiIZMCAJSIikgEDloiISAYMWCIiIhkwYImIiGTAgCUiIpIBA5aIiEgGDFgiIiIZMGCJiIhkwIAlIiKSAQOWiIhIBgxYIiIiGTBgiYiIZMCAJSIikgEDloiISAYMWCIiIhkwYImIiGTAgCUiIpIBA5aIiEgGDFgiIiIZMGCJiIhkwIAlIiKSAQOWiIhIBgxYIiIiGTBgiYiIZMCAJSIikgEDloiISAYMWCIiIhkwYImIiGTAgCUiIpJBlQrYFStWwMnJCdWrV4e7uzuOHj1a3iUREdEbqsoE7JYtW+Dv748ZM2bg3LlzeO+999CjRw8kJCSUd2lERPQGqjIBGxISgmHDhuHzzz9H48aNERoaCgcHB6xcubK8SyMiojeQYXkX8Drk5uYiLi4OU6dO1Wrv2rUrTpw4Uew8OTk5yMnJke6np6cDADIyMuQrVGaPszLLu4QqLyPDuLxLqPLyHue8vBPJyqgSf48WZYAQ4qV9q0TA3r17FwUFBbC1tdVqt7W1RUpKSrHzBAcHY+7cuTrtDg4OstRIVYPuO4qoClr4TXlX8MoyMzOhVqtf2KdKBGwRhUKhdV8IodNWZNq0aZg4caJ0v7CwEPfv34eVldVz5yF5ZWRkwMHBAbdv34a5uXl5l0P02vEzUP6EEMjMzIS9vf1L+1aJgLW2toaBgYHOaDU1NVVnVFtEqVRCqVRqtdWsWVOuEkkP5ubm/HKhKo2fgfL1spFrkSpxkJOxsTHc3d0RHR2t1R4dHQ0PD49yqoqIiN5kVWIECwATJ07Exx9/jFatWqFdu3ZYvXo1EhISMHLkyPIujYiI3kBVJmAHDhyIe/fuYd68eUhOToarqyv27NkDR0fH8i6NSkipVGL27Nk6m+6Jqgp+BioXhSjJscZERESklyqxD5aIiOh1Y8ASERHJgAFLREQkAwYsERGRDBiwREREMqgyp+lQ5ZOYmIiVK1fixIkTSElJgUKhgK2tLTw8PDBy5EheF5qIKjSepkMV0rFjx9CjRw84ODiga9eusLW1hRACqampiI6Oxu3bt/Hzzz+jffv25V0qUbm5ffs2Zs+ejTVr1pR3KVQMBixVSK1bt8a7776LZcuWFTt9woQJOHbsGGJjY19zZUQVx4ULF/D222+joKCgvEuhYjBgqUJSqVQ4f/48XFxcip1+7do1tGzZEtnZ2a+5MqLXZ9euXS+c/ueffyIgIIABW0FxHyxVSHZ2djhx4sRzA/bkyZOws7N7zVURvV4+Pj5QKBQv/HFv/nxmxcWApQpp0qRJGDlyJOLi4uDt7Q1bW1soFAqkpKQgOjoa//73vxEaGlreZRLJys7ODt988w18fHyKnX7+/Hm4u7u/3qKoxBiwVCGNHj0aVlZWWLZsGb799ltpE5iBgQHc3d2xfv16DBgwoJyrJJKXu7s7fvnll+cG7MtGt1S+uA+WKry8vDzcvXsXAGBtbQ0jI6Nyrojo9Th69CgePnyI7t27Fzv94cOHOHv2LDp27PiaK6OSYMASERHJgFdyIiIikgEDloiISAYMWCIiIhkwYIlk0qlTJ/j7+0v369Wr99JTixQKBXbs2CFrXQBw/fp1aDQaZGZmyv5YpG337t1o2bIlCgsLy7sUkhkDlt54fn5+zz3N4Vlz5sxBixYtdNpv3rwJhUKB8+fPl7qO2NhYDB8+vNTzl6UZM2ZgzJgxMDMzk9ouXbqEjh07QqVSoXbt2pg3b94rnQLi5+cHhUKBhQsXarXv2LFDlosjLFiwAB4eHjAxMUHNmjVfaVnz58+HnZ0d7t+/r9V+4cIFGBsbY+fOnaVedu/evaFQKLB58+ZXqpEqPgYs0WtSq1YtmJiYlHcZSExMxK5du/DZZ59JbRkZGfD29oa9vT1iY2MRFhaGJUuWICQk5JUeq3r16li0aBHS0tJeteyXys3NRf/+/TFq1KhXXta0adPg4OCAMWPGSG15eXnw8/ODr68v+vbt+0rL/+yzzxAWFvaqZVIFx4ClKmfr1q1wc3ODSqWClZUVvLy88PDhQ72XExMTg3feeQdKpRJ2dnaYOnUq8vPzn9v/2U3Ev/32Gzp06IDq1aujSZMmiI6O1pknMDAQDRs2hImJCd566y3MnDkTeXl5AJ6MqqtVq4azZ89qzRMWFgZHR8fnjj6///57NG/eHHXq1JHaNm3ahMePHyMiIgKurq7o168fpk+fjpCQkFcaxXp5eUGj0SA4OPiF/X744Qc0bdoUSqUS9erVw9KlS/V+rLlz52LChAlwc3MrbbkSQ0NDrF+/Hjt37sTWrVsBPBkh379/H//617+Qnp6O4cOHw8bGBubm5ujSpQsuXLggzX/hwgV07twZZmZmMDc3h7u7u9br1KdPH5w5cwZ//vnnK9dKFRcDlqqU5ORkDB48GEOHDsXVq1dx+PBh9OvXT+8Q+euvv9CzZ0+0bt0aFy5cwMqVKxEeHo6vvvqqRPMXFhaiX79+MDAwwKlTp7Bq1SoEBgbq9DMzM0NERATi4+Pxz3/+E9999530C0P16tWDl5cX1q5dqzXP2rVrpc2zxTly5AhatWql1Xby5El07NgRSqVSauvWrRuSkpJw8+ZNAE8uelCjRo0X3oKCgrSWa2BggKCgIISFhSExMbHYeuLi4jBgwAAMGjQIly5dwpw5czBz5kxERES88DksjZfV36NHD6lvo0aNEBQUhFGjRuG///0vgoODsXbtWpiZmaFXr15ISUnBnj17EBcXh7fffhuenp7SJuUhQ4agTp06iI2NRVxcHKZOnap1gRRHR0fY2Njg6NGjZb6OVHHwUolUpSQnJyM/Px/9+vWDo6MjAOiMeC5duoQaNWpotT0bwCtWrICDgwOWL18OhUKBRo0aISkpCYGBgZg1axaqVXvx36779+/H1atXcfPmTWkkGRQUpPUFDwBffvml9P969eohICAAW7ZswZQpUwAAn3/+OUaOHImQkBAolUpcuHAB58+fx7Zt25772Ddv3tS5fm1KSgrq1aun1WZraytNc3JyQqtWrV66D9rS0lKn7YMPPkCLFi0we/ZshIeH60wPCQmBp6cnZs6cCQBo2LAh4uPj8fXXX8PPz++Fj6evl9WvUqm07o8fPx47d+5Ez549MW7cOHTp0gUHDx7EpUuXkJqaKv1BsmTJEuzYsQNbt27F8OHDkZCQgMmTJ6NRo0YAAGdnZ53Hql27tvTHC72ZGLBUpTRv3hyenp5wc3NDt27d0LVrV3z44YewsLCQ+ri4uOj8TNhff/2FTp06SfevXr2Kdu3aaY0S27dvj6ysLCQmJqJu3bovrOPq1auoW7eu1mbadu3a6fTbunUrQkND8fvvvyMrKwv5+fkwNzeXpvv4+GDs2LHYvn07Bg0ahDVr1qBz5846Yfm07OxsVK9eXaf92RFv0R8VRe0qlQoNGjR44Xo9z6JFi9ClSxcEBAToTLt69arOPs327dsjNDQUBQUFMDAwKNVjFkff+hUKBWbMmIHDhw9Lf+zExcUhKysLVlZWWn2zs7Pxxx9/AAAmTpyIzz//HBs2bICXlxf69++P+vXra/VXqVR49OjRK6wNVXTcRExVioGBAaKjo/Hzzz+jSZMmCAsLg4uLC27cuCH1MTY2RoMGDbRuRaPdIkKIlwbSixS3SfrZ+U6dOoVBgwahR48e2L17N86dO4cZM2YgNzdXq9aPP/4Ya9euRW5uLjZv3oyhQ4e+8LGtra11DjrSaDRISUnRaktNTQXwv5FsaTYRF+nQoQO6deuG6dOnF/tcPO+5LGv6bCIuYmhoqPVvYWEh7OzscP78ea3b9evXMXnyZABPjka/cuUKevXqhYMHD6JJkybYvn271nLv37+PWrVqybKeVDFwBEtVjkKhQPv27dG+fXvMmjULjo6O2L59OyZOnFjiZTRp0gQ//PCDVjicOHECZmZmqF27donmT0hIQFJSEuzt7QE82Q/6tOPHj8PR0REzZsyQ2m7duqWzrM8//xyurq5YsWIF8vLy0K9fvxc+dsuWLREfH6/V1q5dO0yfPh25ubkwNjYGAOzbtw/29vbSaLi0m4iLLFy4EC1atEDDhg212ps0aYJjx45ptZ04cQINGzYs09EroP8m4uK8/fbbSElJgaGh4Qu3FDRs2BANGzbEhAkTMHjwYKxduxYffPABAODx48f4448/0LJlS33Kp0qGAUtVyunTp3HgwAF07doVNjY2OH36NO7cuYPGjRvrtZzRo0cjNDQU48aNw9ixY3H9+nXMnj0bEydOfOn+V+DJ0bUuLi745JNPsHTpUmRkZGgFKfBkc2ZCQgKioqLQunVr/PTTTzqjIABo3Lgx2rZti8DAQAwdOvSlIdGtWzd8/vnnWptffX19MXfuXPj5+WH69On47bffEBQUhFmzZpXJJmLgyb7uIUOG6JyeEhAQgNatW2P+/PkYOHAgTp48ieXLl2PFihV6LT8hIQH3799HQkICCgoKpDBt0KCBtE/9Veov4uXlhXbt2sHHxweLFi2Ci4sLkpKSsGfPHvj4+KBp06aYPHkyPvzwQzg5OSExMRGxsbH4xz/+IS3j1KlTUCqVxe4WoDeIIHrDffrpp6Jv375CCCHi4+NFt27dRK1atYRSqRQNGzYUYWFhUt/Zs2eL5s2b6yzjxo0bAoA4d+6c1Hb48GHRunVrYWxsLDQajQgMDBR5eXnS9I4dO4rx48dL9x0dHcWyZcuk+9evXxfvvvuuMDY2Fg0bNhR79+4VAMT27dulPpMnTxZWVlaiRo0aYuDAgWLZsmVCrVbr1BceHi4AiDNnzrz0+cjPzxe1a9cWe/fu1Wq/ePGieO+994RSqRQajUbMmTNHFBYWvnR5z/P0817k5s2bQqlUime/erZu3SqaNGkijIyMRN26dcXXX3+tNX327NnC0dHxpY8HQOd26NChUq+DEEIcOnRIABBpaWlSW0ZGhhg3bpywt7cXRkZGwsHBQQwZMkQkJCSInJwcMWjQIOHg4CCMjY2Fvb29GDt2rMjOzpbmHz58uBgxYsQr1UUVH3+ujugNsGDBAkRFReHSpUsl6r9ixQrs3LkT//3vf2WurGwUHU0sx6k7r9udO3fQqFEjnD17Fk5OTuVdDsmIm4iJKrGsrCxcvXoVYWFhmD9/fonnGz58ONLS0pCZmal1ucSKKiYmBkeOHCnvMsrEjRs3sGLFCoZrFcARLFEl5ufnh8jISPj4+GDz5s1lflAQEZUeA5aIiEgGPA+WiIhIBgxYIiIiGTBgiYiIZMCAJSIikgEDloiISAYMWCIiIhkwYImIiGTAgCUiIpIBA5aIiEgG/w/tNENlzKiHoAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 500x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.groupby('IsHoliday')['Total Flow'].mean().plot(\n",
    "    kind='bar',\n",
    "    color=['skyblue', 'salmon'],\n",
    "    title='Average Total Flow: Holidays vs Non-Holidays',\n",
    "    ylabel='Average Flow',\n",
    "    xlabel='IsHoliday (0=No, 1=Yes)',\n",
    "    figsize=(5,3)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "785d0229-0c4e-4711-8dfc-5bc556f73cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# average value by hour of day\n",
    "hour_profile = df.groupby('Hour')['Total Flow'].mean()\n",
    "# average value by day of week\n",
    "dow_profile  = df.groupby('Weekday')['Total Flow'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3c1382d3-9043-4c74-8739-f907ee6affbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Hour\n",
       "0      267.243212\n",
       "1      195.949000\n",
       "2      169.977573\n",
       "3      205.348161\n",
       "4      323.628788\n",
       "5      623.516306\n",
       "6     1009.907040\n",
       "7     1289.505955\n",
       "8     1316.575494\n",
       "9     1300.455276\n",
       "10    1360.537827\n",
       "11    1429.879912\n",
       "12    1499.280039\n",
       "13    1533.003386\n",
       "14    1614.258655\n",
       "15    1669.942609\n",
       "16    1657.396490\n",
       "17    1583.645661\n",
       "18    1330.434478\n",
       "19    1037.403310\n",
       "20     859.885616\n",
       "21     733.225761\n",
       "22     574.569621\n",
       "23     401.395380\n",
       "Name: Total Flow, dtype: float64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hour_profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fae66a1d-e775-4655-b8a8-d948022e9171",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 800x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8,4))\n",
    "plt.plot(hour_profile.index, hour_profile.values, marker='o')\n",
    "plt.title('Average Total Flow by Hour of Day')\n",
    "plt.xlabel('Hour of Day (0–23)')\n",
    "plt.ylabel('Average Total Flow')\n",
    "#plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c9af4d36-c9f0-4fe3-9377-f75babf82f1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Weekday\n",
       "0    1010.063746\n",
       "1    1027.432555\n",
       "2    1030.509575\n",
       "3    1032.143192\n",
       "4    1082.591190\n",
       "5     953.854524\n",
       "6     854.987151\n",
       "Name: Total Flow, dtype: float64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dow_profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d8ec13a3-c9bc-4ee7-8aab-2b8c8eafdefe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 700x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(7,4))\n",
    "dow_profile.plot(kind='bar', color='skyblue')\n",
    "plt.title('Average Total Flow by Day of Week')\n",
    "plt.xlabel('Day of Week (0=Mon, 6=Sun)')\n",
    "plt.ylabel('Average Total Flow')\n",
    "plt.grid(axis='y')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d861f711-2b41-42bc-8e59-242477869527",
   "metadata": {},
   "outputs": [],
   "source": [
    "for lag in range(1, 169):  # Lags 1 to 168\n",
    "    df[f'TotalFlow_lag_{lag}'] = df['Total Flow'].shift(lag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "52ef33a5-c10d-4a1f-8453-a3dd62f21517",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f6f2b189-6b97-403f-ae01-b0abecaec903",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Hour_sin'] = np.sin(2 * np.pi * df['Hour'] / 24)\n",
    "df['Hour_cos'] = np.cos(2 * np.pi * df['Hour'] / 24)\n",
    "df['Weekday_sin'] = np.sin(2 * np.pi * df['Weekday'] / 7)\n",
    "df['Weekday_cos'] = np.cos(2 * np.pi * df['Weekday'] / 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cacccc12-461a-4ed7-a7b7-9bb974e6aa1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=['Hour', 'Weekday'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "383d1ac4-8685-4131-9e97-c9975ba646f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for window in [6, 12, 24, 168]:\n",
    "    df[f'Flow_mean_{window}'] = df['Total Flow'].rolling(window=window).mean()\n",
    "    df[f'Flow_std_{window}'] = df['Total Flow'].rolling(window=window).std()\n",
    "    df[f'Flow_min_{window}'] = df['Total Flow'].rolling(window=window).min()\n",
    "    df[f'Flow_max_{window}'] = df['Total Flow'].rolling(window=window).max()\n",
    "    df[f'Flow_cv_{window}'] = df[f'Flow_std_{window}'] / df[f'Flow_mean_{window}']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "58ba1cbc-dd7d-4f7d-bf61-d3e50f9982a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define windows to visualize\n",
    "WINDOWS = [6, 12, 24, 168]\n",
    "eps = 1e-6\n",
    "\n",
    "# Compute rolling mean, std, and CV\n",
    "for w in WINDOWS:\n",
    "    m = df['Total Flow'].rolling(w).mean()\n",
    "    s = df['Total Flow'].rolling(w).std()\n",
    "    df[f'Flow_cv_{w}'] = s / m\n",
    "    df.loc[m < 1.0, f'Flow_cv_{w}'] = np.nan  # avoid inflating CV when mean ≈ 0\n",
    "\n",
    "# Plot CV over time\n",
    "plt.figure(figsize=(12,6))\n",
    "\n",
    "for w in [6, 24, 168]:  # show short, daily, and weekly\n",
    "    plt.plot(df.index, df[f'Flow_cv_{w}'], label=f'CV ({w}h window)', linewidth=2)\n",
    "\n",
    "plt.title('Coefficient of Variation (CV) over Time')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Coefficient of Variation (std/mean)')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.ylim(0, 2)  \n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "947c256c-42fb-4c9e-a45f-bd2505a08cc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weekday\n",
      "Monday       1.057653\n",
      "Tuesday      1.058653\n",
      "Wednesday    1.061878\n",
      "Thursday     1.058368\n",
      "Friday       1.036666\n",
      "Saturday     1.040663\n",
      "Sunday       1.062428\n",
      "Name: Flow_cv_24, dtype: float64\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 800x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Make sure 'Time' is your datetime index or column\n",
    "df['Weekday'] = df.index.day_name()  # e.g., Monday, Tuesday...\n",
    "\n",
    "# Choose the CV window you want to summarize (e.g., daily CV)\n",
    "cv_col = 'Flow_cv_24'\n",
    "\n",
    "weekday_cv = (\n",
    "    df.groupby('Weekday')[cv_col]\n",
    "      .mean()\n",
    "      .reindex(['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday'])\n",
    ")\n",
    "\n",
    "print(weekday_cv)\n",
    "\n",
    "# Plot it\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(8,4))\n",
    "weekday_cv.plot(kind='bar', color='skyblue')\n",
    "plt.title('Average Coefficient of Variation (24h) by Weekday')\n",
    "plt.ylabel('Average CV')\n",
    "plt.xlabel('Weekday')\n",
    "plt.grid(axis='y', alpha=0.3)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86d384fa-85a0-4f69-8a30-044b42a9c4d6",
   "metadata": {},
   "source": [
    "| CV Value  | Interpretation     | Meaning for EV Flow                                                     |\n",
    "| --------- | ------------------ | ----------------------------------------------------------------------- |\n",
    "| 0.0 – 0.3 | Very stable        | Regular, predictable station                                            |\n",
    "| 0.3 – 0.6 | Moderate variation | Normal daily cycles                                                     |\n",
    "| 0.6 – 1.0 | High variation     | Irregular demand or events                                              |\n",
    "| > 1.0     | Very unstable      | Flow fluctuates more than its mean\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "72aeb97c-13c7-418b-a82e-6fc1c6e3ed9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 800x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df['Hour'] = df.index.hour\n",
    "\n",
    "hourly_cv = df.groupby('Hour')[cv_col].mean()\n",
    "\n",
    "plt.figure(figsize=(8,4))\n",
    "hourly_cv.plot(kind='line', marker='o', color='tomato')\n",
    "plt.title('Average Coefficient of Variation (24h) by Hour of Day')\n",
    "plt.ylabel('Average CV')\n",
    "plt.xlabel('Hour of Day')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "47b6edf9-2340-4755-9343-4ec59427855d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Station\n",
       "3054057    2.061905\n",
       "3054056    2.033847\n",
       "3054055    2.005207\n",
       "3055025    1.984428\n",
       "3423066    1.980683\n",
       "3054053    1.962021\n",
       "3054052    1.958693\n",
       "3054054    1.909861\n",
       "3055011    1.904669\n",
       "3055015    1.902586\n",
       "Name: Flow_cv_24, dtype: float64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "station_cv = df.groupby('Station')[cv_col].mean().sort_values(ascending=False)\n",
    "\n",
    "station_cv.head(10)  # top 10 most variable stations\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ffad443-9226-47af-bdd5-2c0450739a4d",
   "metadata": {},
   "source": [
    "CV values were highest during early-morning hours (00:00 – 05:00) when flow levels were minimal, indicating greater relative volatility. Flow became more stable during daylight hours (10:00 – 15:00) with CV values dropping below 1.0, suggesting consistent daytime demand. Variability increased again in the late evening, reflecting irregular activity outside standard commuting periods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "03cd7314-ce32-4939-a250-e5cc78144571",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "17799930-8a35-4917-a104-418a72c0c6af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Station</th>\n",
       "      <th>Route</th>\n",
       "      <th>Direction of Travel</th>\n",
       "      <th>Total Flow</th>\n",
       "      <th>% Observed</th>\n",
       "      <th>Samples</th>\n",
       "      <th>Lane Type</th>\n",
       "      <th>Day</th>\n",
       "      <th>Month</th>\n",
       "      <th>IsHoliday</th>\n",
       "      <th>...</th>\n",
       "      <th>Flow_min_24</th>\n",
       "      <th>Flow_max_24</th>\n",
       "      <th>Flow_cv_24</th>\n",
       "      <th>Flow_mean_168</th>\n",
       "      <th>Flow_std_168</th>\n",
       "      <th>Flow_min_168</th>\n",
       "      <th>Flow_max_168</th>\n",
       "      <th>Flow_cv_168</th>\n",
       "      <th>Weekday</th>\n",
       "      <th>Hour</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2024-10-01 00:00:00</th>\n",
       "      <td>315053</td>\n",
       "      <td>5</td>\n",
       "      <td>N</td>\n",
       "      <td>44.0</td>\n",
       "      <td>92</td>\n",
       "      <td>99</td>\n",
       "      <td>OR</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1327.0</td>\n",
       "      <td>1.113435</td>\n",
       "      <td>362.797619</td>\n",
       "      <td>376.802170</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1381.0</td>\n",
       "      <td>1.038602</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-10-01 00:00:00</th>\n",
       "      <td>315054</td>\n",
       "      <td>5</td>\n",
       "      <td>N</td>\n",
       "      <td>1004.0</td>\n",
       "      <td>92</td>\n",
       "      <td>394</td>\n",
       "      <td>ML</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1327.0</td>\n",
       "      <td>1.029867</td>\n",
       "      <td>364.148810</td>\n",
       "      <td>378.698601</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1381.0</td>\n",
       "      <td>1.039956</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-10-01 00:00:00</th>\n",
       "      <td>315055</td>\n",
       "      <td>5</td>\n",
       "      <td>N</td>\n",
       "      <td>82.0</td>\n",
       "      <td>92</td>\n",
       "      <td>99</td>\n",
       "      <td>FR</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1327.0</td>\n",
       "      <td>1.024410</td>\n",
       "      <td>364.559524</td>\n",
       "      <td>378.352744</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1381.0</td>\n",
       "      <td>1.037835</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-10-01 00:00:00</th>\n",
       "      <td>315060</td>\n",
       "      <td>5</td>\n",
       "      <td>S</td>\n",
       "      <td>32.0</td>\n",
       "      <td>92</td>\n",
       "      <td>141</td>\n",
       "      <td>ML</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1327.0</td>\n",
       "      <td>1.098153</td>\n",
       "      <td>364.738095</td>\n",
       "      <td>378.187645</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1381.0</td>\n",
       "      <td>1.036875</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-10-01 00:00:00</th>\n",
       "      <td>315061</td>\n",
       "      <td>5</td>\n",
       "      <td>S</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>99</td>\n",
       "      <td>HV</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1327.0</td>\n",
       "      <td>1.101467</td>\n",
       "      <td>356.529762</td>\n",
       "      <td>370.937571</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1381.0</td>\n",
       "      <td>1.040411</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-12-31 23:00:00</th>\n",
       "      <td>3423094</td>\n",
       "      <td>99</td>\n",
       "      <td>S</td>\n",
       "      <td>68.0</td>\n",
       "      <td>96</td>\n",
       "      <td>118</td>\n",
       "      <td>ML</td>\n",
       "      <td>31</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>506.0</td>\n",
       "      <td>1.513366</td>\n",
       "      <td>223.714286</td>\n",
       "      <td>287.966027</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1422.0</td>\n",
       "      <td>1.287204</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-12-31 23:00:00</th>\n",
       "      <td>3900021</td>\n",
       "      <td>50</td>\n",
       "      <td>E</td>\n",
       "      <td>803.0</td>\n",
       "      <td>67</td>\n",
       "      <td>292</td>\n",
       "      <td>ML</td>\n",
       "      <td>31</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>803.0</td>\n",
       "      <td>1.810561</td>\n",
       "      <td>222.434524</td>\n",
       "      <td>284.876139</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1422.0</td>\n",
       "      <td>1.280719</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-12-31 23:00:00</th>\n",
       "      <td>3900022</td>\n",
       "      <td>50</td>\n",
       "      <td>E</td>\n",
       "      <td>509.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>HV</td>\n",
       "      <td>31</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>803.0</td>\n",
       "      <td>1.651651</td>\n",
       "      <td>219.404762</td>\n",
       "      <td>279.010661</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1422.0</td>\n",
       "      <td>1.271671</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-12-31 23:00:00</th>\n",
       "      <td>3900023</td>\n",
       "      <td>50</td>\n",
       "      <td>W</td>\n",
       "      <td>881.0</td>\n",
       "      <td>67</td>\n",
       "      <td>289</td>\n",
       "      <td>ML</td>\n",
       "      <td>31</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>881.0</td>\n",
       "      <td>1.599190</td>\n",
       "      <td>221.619048</td>\n",
       "      <td>282.773471</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1422.0</td>\n",
       "      <td>1.275944</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-12-31 23:00:00</th>\n",
       "      <td>3900024</td>\n",
       "      <td>50</td>\n",
       "      <td>W</td>\n",
       "      <td>509.0</td>\n",
       "      <td>0</td>\n",
       "      <td>56</td>\n",
       "      <td>HV</td>\n",
       "      <td>31</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>881.0</td>\n",
       "      <td>1.499371</td>\n",
       "      <td>221.619048</td>\n",
       "      <td>282.773471</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1422.0</td>\n",
       "      <td>1.275944</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3810551 rows × 204 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Station  Route Direction of Travel  Total Flow  \\\n",
       "Timestamp                                                             \n",
       "2024-10-01 00:00:00   315053      5                   N        44.0   \n",
       "2024-10-01 00:00:00   315054      5                   N      1004.0   \n",
       "2024-10-01 00:00:00   315055      5                   N        82.0   \n",
       "2024-10-01 00:00:00   315060      5                   S        32.0   \n",
       "2024-10-01 00:00:00   315061      5                   S         0.0   \n",
       "...                      ...    ...                 ...         ...   \n",
       "2024-12-31 23:00:00  3423094     99                   S        68.0   \n",
       "2024-12-31 23:00:00  3900021     50                   E       803.0   \n",
       "2024-12-31 23:00:00  3900022     50                   E       509.0   \n",
       "2024-12-31 23:00:00  3900023     50                   W       881.0   \n",
       "2024-12-31 23:00:00  3900024     50                   W       509.0   \n",
       "\n",
       "                     % Observed  Samples Lane Type  Day  Month  IsHoliday  \\\n",
       "Timestamp                                                                   \n",
       "2024-10-01 00:00:00          92       99        OR    1     10          0   \n",
       "2024-10-01 00:00:00          92      394        ML    1     10          0   \n",
       "2024-10-01 00:00:00          92       99        FR    1     10          0   \n",
       "2024-10-01 00:00:00          92      141        ML    1     10          0   \n",
       "2024-10-01 00:00:00           0       99        HV    1     10          0   \n",
       "...                         ...      ...       ...  ...    ...        ...   \n",
       "2024-12-31 23:00:00          96      118        ML   31     12          0   \n",
       "2024-12-31 23:00:00          67      292        ML   31     12          0   \n",
       "2024-12-31 23:00:00           0        0        HV   31     12          0   \n",
       "2024-12-31 23:00:00          67      289        ML   31     12          0   \n",
       "2024-12-31 23:00:00           0       56        HV   31     12          0   \n",
       "\n",
       "                     ...  Flow_min_24  Flow_max_24  Flow_cv_24  Flow_mean_168  \\\n",
       "Timestamp            ...                                                        \n",
       "2024-10-01 00:00:00  ...          0.0       1327.0    1.113435     362.797619   \n",
       "2024-10-01 00:00:00  ...          0.0       1327.0    1.029867     364.148810   \n",
       "2024-10-01 00:00:00  ...          0.0       1327.0    1.024410     364.559524   \n",
       "2024-10-01 00:00:00  ...          0.0       1327.0    1.098153     364.738095   \n",
       "2024-10-01 00:00:00  ...          0.0       1327.0    1.101467     356.529762   \n",
       "...                  ...          ...          ...         ...            ...   \n",
       "2024-12-31 23:00:00  ...          0.0        506.0    1.513366     223.714286   \n",
       "2024-12-31 23:00:00  ...          0.0        803.0    1.810561     222.434524   \n",
       "2024-12-31 23:00:00  ...          0.0        803.0    1.651651     219.404762   \n",
       "2024-12-31 23:00:00  ...          0.0        881.0    1.599190     221.619048   \n",
       "2024-12-31 23:00:00  ...          0.0        881.0    1.499371     221.619048   \n",
       "\n",
       "                     Flow_std_168  Flow_min_168  Flow_max_168  Flow_cv_168  \\\n",
       "Timestamp                                                                    \n",
       "2024-10-01 00:00:00    376.802170           0.0        1381.0     1.038602   \n",
       "2024-10-01 00:00:00    378.698601           0.0        1381.0     1.039956   \n",
       "2024-10-01 00:00:00    378.352744           0.0        1381.0     1.037835   \n",
       "2024-10-01 00:00:00    378.187645           0.0        1381.0     1.036875   \n",
       "2024-10-01 00:00:00    370.937571           0.0        1381.0     1.040411   \n",
       "...                           ...           ...           ...          ...   \n",
       "2024-12-31 23:00:00    287.966027           0.0        1422.0     1.287204   \n",
       "2024-12-31 23:00:00    284.876139           0.0        1422.0     1.280719   \n",
       "2024-12-31 23:00:00    279.010661           0.0        1422.0     1.271671   \n",
       "2024-12-31 23:00:00    282.773471           0.0        1422.0     1.275944   \n",
       "2024-12-31 23:00:00    282.773471           0.0        1422.0     1.275944   \n",
       "\n",
       "                     Weekday  Hour  \n",
       "Timestamp                           \n",
       "2024-10-01 00:00:00  Tuesday     0  \n",
       "2024-10-01 00:00:00  Tuesday     0  \n",
       "2024-10-01 00:00:00  Tuesday     0  \n",
       "2024-10-01 00:00:00  Tuesday     0  \n",
       "2024-10-01 00:00:00  Tuesday     0  \n",
       "...                      ...   ...  \n",
       "2024-12-31 23:00:00  Tuesday    23  \n",
       "2024-12-31 23:00:00  Tuesday    23  \n",
       "2024-12-31 23:00:00  Tuesday    23  \n",
       "2024-12-31 23:00:00  Tuesday    23  \n",
       "2024-12-31 23:00:00  Tuesday    23  \n",
       "\n",
       "[3810551 rows x 204 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1250aebf-4902-45e1-9f7a-cd56cf9694a3",
   "metadata": {},
   "source": [
    "## LSTM MODEL\n",
    "For each station, we build a LightGBM-selected LSTM model that uses lagged flows from other stations and contextual features to predict its own flow at multiple horizons, then average results across all stations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6c24628c-e444-4dd1-8497-62f77fc4f79e",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = pd.DataFrame({\n",
    "    'dtype': df.dtypes,\n",
    "    'num_unique': df.nunique(),\n",
    "    'example_values': df.apply(lambda x: list(x.unique()[:10]))  # show first 5 unique values\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "78c05d57-ae63-4ae1-b657-c7eeabe0c6e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dtype</th>\n",
       "      <th>num_unique</th>\n",
       "      <th>example_values</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>IsHoliday</th>\n",
       "      <td>int64</td>\n",
       "      <td>2</td>\n",
       "      <td>[0, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Month</th>\n",
       "      <td>int64</td>\n",
       "      <td>3</td>\n",
       "      <td>[10, 11, 12]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Direction of Travel</th>\n",
       "      <td>object</td>\n",
       "      <td>4</td>\n",
       "      <td>[N, S, E, W]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lane Type</th>\n",
       "      <td>object</td>\n",
       "      <td>5</td>\n",
       "      <td>[OR, ML, FR, HV, FF]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Weekday_cos</th>\n",
       "      <td>float64</td>\n",
       "      <td>6</td>\n",
       "      <td>[0.6234898018587335, -0.22252093395631437, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Weekday_sin</th>\n",
       "      <td>float64</td>\n",
       "      <td>7</td>\n",
       "      <td>[0.7818314824680299, 0.9749279121818238, 0.433...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Weekday</th>\n",
       "      <td>object</td>\n",
       "      <td>7</td>\n",
       "      <td>[Tuesday, Wednesday, Thursday, Friday, Saturda...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hour_cos</th>\n",
       "      <td>float64</td>\n",
       "      <td>22</td>\n",
       "      <td>[1.0, 0.9659258262890684, 0.8660254037844386, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Route</th>\n",
       "      <td>int64</td>\n",
       "      <td>23</td>\n",
       "      <td>[5, 80, 99, 51, 50, 113, 160, 89, 65, 70]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hour_sin</th>\n",
       "      <td>float64</td>\n",
       "      <td>23</td>\n",
       "      <td>[0.0, 0.2588190451025208, 0.4999999999999999, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hour</th>\n",
       "      <td>int64</td>\n",
       "      <td>24</td>\n",
       "      <td>[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Day</th>\n",
       "      <td>int64</td>\n",
       "      <td>31</td>\n",
       "      <td>[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>% Observed</th>\n",
       "      <td>int64</td>\n",
       "      <td>79</td>\n",
       "      <td>[92, 0, 75, 100, 83, 81, 85, 76, 46, 61]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Flow_min_168</th>\n",
       "      <td>float64</td>\n",
       "      <td>157</td>\n",
       "      <td>[0.0, 2.0, 1.0, 6.0, 9.0, 18.0, 14.0, 20.0, 25...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Samples</th>\n",
       "      <td>int64</td>\n",
       "      <td>809</td>\n",
       "      <td>[99, 394, 141, 129, 101, 23, 0, 90, 120, 73]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Station</th>\n",
       "      <td>int64</td>\n",
       "      <td>1806</td>\n",
       "      <td>[315053, 315054, 315055, 315060, 315061, 31580...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Flow_min_24</th>\n",
       "      <td>float64</td>\n",
       "      <td>2639</td>\n",
       "      <td>[0.0, 26.0, 36.0, 35.0, 31.0, 20.0, 18.0, 13.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Flow_min_12</th>\n",
       "      <td>float64</td>\n",
       "      <td>4585</td>\n",
       "      <td>[0.0, 1.0, 26.0, 36.0, 52.0, 54.0, 35.0, 31.0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Flow_min_6</th>\n",
       "      <td>float64</td>\n",
       "      <td>5217</td>\n",
       "      <td>[35.0, 32.0, 0.0, 26.0, 57.0, 36.0, 65.0, 52.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Flow_max_168</th>\n",
       "      <td>float64</td>\n",
       "      <td>7513</td>\n",
       "      <td>[1381.0, 1535.0, 1523.0, 1397.0, 1423.0, 1310....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Flow_max_24</th>\n",
       "      <td>float64</td>\n",
       "      <td>8065</td>\n",
       "      <td>[1327.0, 1004.0, 159.0, 233.0, 630.0, 736.0, 7...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Flow_max_12</th>\n",
       "      <td>float64</td>\n",
       "      <td>8131</td>\n",
       "      <td>[995.0, 1004.0, 101.0, 146.0, 159.0, 233.0, 63...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Flow_max_6</th>\n",
       "      <td>float64</td>\n",
       "      <td>8161</td>\n",
       "      <td>[883.0, 1004.0, 82.0, 101.0, 146.0, 159.0, 93....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TotalFlow_lag_7</th>\n",
       "      <td>float64</td>\n",
       "      <td>8165</td>\n",
       "      <td>[851.0, 995.0, 883.0, 54.0, 60.0, 836.0, 35.0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TotalFlow_lag_117</th>\n",
       "      <td>float64</td>\n",
       "      <td>8165</td>\n",
       "      <td>[430.0, 140.0, 5.0, 142.0, 56.0, 439.0, 181.0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TotalFlow_lag_118</th>\n",
       "      <td>float64</td>\n",
       "      <td>8165</td>\n",
       "      <td>[80.0, 430.0, 140.0, 5.0, 142.0, 56.0, 439.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TotalFlow_lag_119</th>\n",
       "      <td>float64</td>\n",
       "      <td>8165</td>\n",
       "      <td>[18.0, 80.0, 430.0, 140.0, 5.0, 142.0, 56.0, 4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TotalFlow_lag_120</th>\n",
       "      <td>float64</td>\n",
       "      <td>8165</td>\n",
       "      <td>[212.0, 18.0, 80.0, 430.0, 140.0, 5.0, 142.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TotalFlow_lag_121</th>\n",
       "      <td>float64</td>\n",
       "      <td>8165</td>\n",
       "      <td>[39.0, 212.0, 18.0, 80.0, 430.0, 140.0, 5.0, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TotalFlow_lag_122</th>\n",
       "      <td>float64</td>\n",
       "      <td>8165</td>\n",
       "      <td>[36.0, 39.0, 212.0, 18.0, 80.0, 430.0, 140.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TotalFlow_lag_123</th>\n",
       "      <td>float64</td>\n",
       "      <td>8165</td>\n",
       "      <td>[43.0, 36.0, 39.0, 212.0, 18.0, 80.0, 430.0, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TotalFlow_lag_124</th>\n",
       "      <td>float64</td>\n",
       "      <td>8165</td>\n",
       "      <td>[36.0, 43.0, 39.0, 212.0, 18.0, 80.0, 430.0, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TotalFlow_lag_128</th>\n",
       "      <td>float64</td>\n",
       "      <td>8165</td>\n",
       "      <td>[1223.0, 285.0, 10.0, 514.0, 36.0, 43.0, 39.0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TotalFlow_lag_126</th>\n",
       "      <td>float64</td>\n",
       "      <td>8165</td>\n",
       "      <td>[10.0, 514.0, 36.0, 43.0, 39.0, 212.0, 18.0, 8...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TotalFlow_lag_127</th>\n",
       "      <td>float64</td>\n",
       "      <td>8165</td>\n",
       "      <td>[285.0, 10.0, 514.0, 36.0, 43.0, 39.0, 212.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TotalFlow_lag_116</th>\n",
       "      <td>float64</td>\n",
       "      <td>8165</td>\n",
       "      <td>[140.0, 5.0, 142.0, 56.0, 439.0, 181.0, 199.0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TotalFlow_lag_129</th>\n",
       "      <td>float64</td>\n",
       "      <td>8165</td>\n",
       "      <td>[37.0, 1223.0, 285.0, 10.0, 514.0, 36.0, 43.0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TotalFlow_lag_130</th>\n",
       "      <td>float64</td>\n",
       "      <td>8165</td>\n",
       "      <td>[957.0, 37.0, 1223.0, 285.0, 10.0, 514.0, 36.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TotalFlow_lag_131</th>\n",
       "      <td>float64</td>\n",
       "      <td>8165</td>\n",
       "      <td>[31.0, 957.0, 37.0, 1223.0, 285.0, 10.0, 514.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TotalFlow_lag_132</th>\n",
       "      <td>float64</td>\n",
       "      <td>8165</td>\n",
       "      <td>[66.0, 31.0, 957.0, 37.0, 1223.0, 285.0, 10.0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TotalFlow_lag_125</th>\n",
       "      <td>float64</td>\n",
       "      <td>8165</td>\n",
       "      <td>[514.0, 36.0, 43.0, 39.0, 212.0, 18.0, 80.0, 4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TotalFlow_lag_115</th>\n",
       "      <td>float64</td>\n",
       "      <td>8165</td>\n",
       "      <td>[5.0, 142.0, 56.0, 439.0, 181.0, 199.0, 35.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TotalFlow_lag_111</th>\n",
       "      <td>float64</td>\n",
       "      <td>8165</td>\n",
       "      <td>[181.0, 199.0, 35.0, 957.0, 211.0, 20.0, 194.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TotalFlow_lag_113</th>\n",
       "      <td>float64</td>\n",
       "      <td>8165</td>\n",
       "      <td>[56.0, 439.0, 181.0, 199.0, 35.0, 957.0, 211.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TotalFlow_lag_97</th>\n",
       "      <td>float64</td>\n",
       "      <td>8165</td>\n",
       "      <td>[29.0, 760.0, 90.0, 780.0, 32.0, 748.0, 58.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TotalFlow_lag_98</th>\n",
       "      <td>float64</td>\n",
       "      <td>8165</td>\n",
       "      <td>[570.0, 29.0, 760.0, 90.0, 780.0, 32.0, 748.0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TotalFlow_lag_99</th>\n",
       "      <td>float64</td>\n",
       "      <td>8165</td>\n",
       "      <td>[18.0, 570.0, 29.0, 760.0, 90.0, 780.0, 32.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TotalFlow_lag_6</th>\n",
       "      <td>float64</td>\n",
       "      <td>8165</td>\n",
       "      <td>[995.0, 883.0, 54.0, 60.0, 836.0, 35.0, 44.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TotalFlow_lag_101</th>\n",
       "      <td>float64</td>\n",
       "      <td>8165</td>\n",
       "      <td>[957.0, 279.0, 18.0, 570.0, 29.0, 760.0, 90.0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TotalFlow_lag_102</th>\n",
       "      <td>float64</td>\n",
       "      <td>8165</td>\n",
       "      <td>[227.0, 957.0, 279.0, 18.0, 570.0, 29.0, 760.0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       dtype  num_unique  \\\n",
       "IsHoliday              int64           2   \n",
       "Month                  int64           3   \n",
       "Direction of Travel   object           4   \n",
       "Lane Type             object           5   \n",
       "Weekday_cos          float64           6   \n",
       "Weekday_sin          float64           7   \n",
       "Weekday               object           7   \n",
       "Hour_cos             float64          22   \n",
       "Route                  int64          23   \n",
       "Hour_sin             float64          23   \n",
       "Hour                   int64          24   \n",
       "Day                    int64          31   \n",
       "% Observed             int64          79   \n",
       "Flow_min_168         float64         157   \n",
       "Samples                int64         809   \n",
       "Station                int64        1806   \n",
       "Flow_min_24          float64        2639   \n",
       "Flow_min_12          float64        4585   \n",
       "Flow_min_6           float64        5217   \n",
       "Flow_max_168         float64        7513   \n",
       "Flow_max_24          float64        8065   \n",
       "Flow_max_12          float64        8131   \n",
       "Flow_max_6           float64        8161   \n",
       "TotalFlow_lag_7      float64        8165   \n",
       "TotalFlow_lag_117    float64        8165   \n",
       "TotalFlow_lag_118    float64        8165   \n",
       "TotalFlow_lag_119    float64        8165   \n",
       "TotalFlow_lag_120    float64        8165   \n",
       "TotalFlow_lag_121    float64        8165   \n",
       "TotalFlow_lag_122    float64        8165   \n",
       "TotalFlow_lag_123    float64        8165   \n",
       "TotalFlow_lag_124    float64        8165   \n",
       "TotalFlow_lag_128    float64        8165   \n",
       "TotalFlow_lag_126    float64        8165   \n",
       "TotalFlow_lag_127    float64        8165   \n",
       "TotalFlow_lag_116    float64        8165   \n",
       "TotalFlow_lag_129    float64        8165   \n",
       "TotalFlow_lag_130    float64        8165   \n",
       "TotalFlow_lag_131    float64        8165   \n",
       "TotalFlow_lag_132    float64        8165   \n",
       "TotalFlow_lag_125    float64        8165   \n",
       "TotalFlow_lag_115    float64        8165   \n",
       "TotalFlow_lag_111    float64        8165   \n",
       "TotalFlow_lag_113    float64        8165   \n",
       "TotalFlow_lag_97     float64        8165   \n",
       "TotalFlow_lag_98     float64        8165   \n",
       "TotalFlow_lag_99     float64        8165   \n",
       "TotalFlow_lag_6      float64        8165   \n",
       "TotalFlow_lag_101    float64        8165   \n",
       "TotalFlow_lag_102    float64        8165   \n",
       "\n",
       "                                                        example_values  \n",
       "IsHoliday                                                       [0, 1]  \n",
       "Month                                                     [10, 11, 12]  \n",
       "Direction of Travel                                       [N, S, E, W]  \n",
       "Lane Type                                         [OR, ML, FR, HV, FF]  \n",
       "Weekday_cos          [0.6234898018587335, -0.22252093395631437, -0....  \n",
       "Weekday_sin          [0.7818314824680299, 0.9749279121818238, 0.433...  \n",
       "Weekday              [Tuesday, Wednesday, Thursday, Friday, Saturda...  \n",
       "Hour_cos             [1.0, 0.9659258262890684, 0.8660254037844386, ...  \n",
       "Route                        [5, 80, 99, 51, 50, 113, 160, 89, 65, 70]  \n",
       "Hour_sin             [0.0, 0.2588190451025208, 0.4999999999999999, ...  \n",
       "Hour                                    [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]  \n",
       "Day                                    [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]  \n",
       "% Observed                    [92, 0, 75, 100, 83, 81, 85, 76, 46, 61]  \n",
       "Flow_min_168         [0.0, 2.0, 1.0, 6.0, 9.0, 18.0, 14.0, 20.0, 25...  \n",
       "Samples                   [99, 394, 141, 129, 101, 23, 0, 90, 120, 73]  \n",
       "Station              [315053, 315054, 315055, 315060, 315061, 31580...  \n",
       "Flow_min_24          [0.0, 26.0, 36.0, 35.0, 31.0, 20.0, 18.0, 13.0...  \n",
       "Flow_min_12          [0.0, 1.0, 26.0, 36.0, 52.0, 54.0, 35.0, 31.0,...  \n",
       "Flow_min_6           [35.0, 32.0, 0.0, 26.0, 57.0, 36.0, 65.0, 52.0...  \n",
       "Flow_max_168         [1381.0, 1535.0, 1523.0, 1397.0, 1423.0, 1310....  \n",
       "Flow_max_24          [1327.0, 1004.0, 159.0, 233.0, 630.0, 736.0, 7...  \n",
       "Flow_max_12          [995.0, 1004.0, 101.0, 146.0, 159.0, 233.0, 63...  \n",
       "Flow_max_6           [883.0, 1004.0, 82.0, 101.0, 146.0, 159.0, 93....  \n",
       "TotalFlow_lag_7      [851.0, 995.0, 883.0, 54.0, 60.0, 836.0, 35.0,...  \n",
       "TotalFlow_lag_117    [430.0, 140.0, 5.0, 142.0, 56.0, 439.0, 181.0,...  \n",
       "TotalFlow_lag_118    [80.0, 430.0, 140.0, 5.0, 142.0, 56.0, 439.0, ...  \n",
       "TotalFlow_lag_119    [18.0, 80.0, 430.0, 140.0, 5.0, 142.0, 56.0, 4...  \n",
       "TotalFlow_lag_120    [212.0, 18.0, 80.0, 430.0, 140.0, 5.0, 142.0, ...  \n",
       "TotalFlow_lag_121    [39.0, 212.0, 18.0, 80.0, 430.0, 140.0, 5.0, 1...  \n",
       "TotalFlow_lag_122    [36.0, 39.0, 212.0, 18.0, 80.0, 430.0, 140.0, ...  \n",
       "TotalFlow_lag_123    [43.0, 36.0, 39.0, 212.0, 18.0, 80.0, 430.0, 1...  \n",
       "TotalFlow_lag_124    [36.0, 43.0, 39.0, 212.0, 18.0, 80.0, 430.0, 1...  \n",
       "TotalFlow_lag_128    [1223.0, 285.0, 10.0, 514.0, 36.0, 43.0, 39.0,...  \n",
       "TotalFlow_lag_126    [10.0, 514.0, 36.0, 43.0, 39.0, 212.0, 18.0, 8...  \n",
       "TotalFlow_lag_127    [285.0, 10.0, 514.0, 36.0, 43.0, 39.0, 212.0, ...  \n",
       "TotalFlow_lag_116    [140.0, 5.0, 142.0, 56.0, 439.0, 181.0, 199.0,...  \n",
       "TotalFlow_lag_129    [37.0, 1223.0, 285.0, 10.0, 514.0, 36.0, 43.0,...  \n",
       "TotalFlow_lag_130    [957.0, 37.0, 1223.0, 285.0, 10.0, 514.0, 36.0...  \n",
       "TotalFlow_lag_131    [31.0, 957.0, 37.0, 1223.0, 285.0, 10.0, 514.0...  \n",
       "TotalFlow_lag_132    [66.0, 31.0, 957.0, 37.0, 1223.0, 285.0, 10.0,...  \n",
       "TotalFlow_lag_125    [514.0, 36.0, 43.0, 39.0, 212.0, 18.0, 80.0, 4...  \n",
       "TotalFlow_lag_115    [5.0, 142.0, 56.0, 439.0, 181.0, 199.0, 35.0, ...  \n",
       "TotalFlow_lag_111    [181.0, 199.0, 35.0, 957.0, 211.0, 20.0, 194.0...  \n",
       "TotalFlow_lag_113    [56.0, 439.0, 181.0, 199.0, 35.0, 957.0, 211.0...  \n",
       "TotalFlow_lag_97     [29.0, 760.0, 90.0, 780.0, 32.0, 748.0, 58.0, ...  \n",
       "TotalFlow_lag_98     [570.0, 29.0, 760.0, 90.0, 780.0, 32.0, 748.0,...  \n",
       "TotalFlow_lag_99     [18.0, 570.0, 29.0, 760.0, 90.0, 780.0, 32.0, ...  \n",
       "TotalFlow_lag_6      [995.0, 883.0, 54.0, 60.0, 836.0, 35.0, 44.0, ...  \n",
       "TotalFlow_lag_101    [957.0, 279.0, 18.0, 570.0, 29.0, 760.0, 90.0,...  \n",
       "TotalFlow_lag_102    [227.0, 957.0, 279.0, 18.0, 570.0, 29.0, 760.0...  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary.sort_values('num_unique').head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "89ae4191-8099-4a73-a1a5-6e5cc6889dbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.get_dummies(df, columns=['Lane Type'], prefix='Lane', drop_first=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8d56ec7b-4075-4d29-9145-56c8ed2e6928",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.get_dummies(df, columns=['Direction of Travel'], prefix='Dir', drop_first=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2718b01f-844e-441f-87e9-d4c348021677",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Station</th>\n",
       "      <th>Route</th>\n",
       "      <th>Total Flow</th>\n",
       "      <th>% Observed</th>\n",
       "      <th>Samples</th>\n",
       "      <th>Day</th>\n",
       "      <th>Month</th>\n",
       "      <th>IsHoliday</th>\n",
       "      <th>TotalFlow_lag_1</th>\n",
       "      <th>TotalFlow_lag_2</th>\n",
       "      <th>...</th>\n",
       "      <th>Hour</th>\n",
       "      <th>Lane_FF</th>\n",
       "      <th>Lane_FR</th>\n",
       "      <th>Lane_HV</th>\n",
       "      <th>Lane_ML</th>\n",
       "      <th>Lane_OR</th>\n",
       "      <th>Dir_E</th>\n",
       "      <th>Dir_N</th>\n",
       "      <th>Dir_S</th>\n",
       "      <th>Dir_W</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2024-10-01 00:00:00</th>\n",
       "      <td>315053</td>\n",
       "      <td>5</td>\n",
       "      <td>44.0</td>\n",
       "      <td>92</td>\n",
       "      <td>99</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>836.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-10-01 00:00:00</th>\n",
       "      <td>315054</td>\n",
       "      <td>5</td>\n",
       "      <td>1004.0</td>\n",
       "      <td>92</td>\n",
       "      <td>394</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-10-01 00:00:00</th>\n",
       "      <td>315055</td>\n",
       "      <td>5</td>\n",
       "      <td>82.0</td>\n",
       "      <td>92</td>\n",
       "      <td>99</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>1004.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-10-01 00:00:00</th>\n",
       "      <td>315060</td>\n",
       "      <td>5</td>\n",
       "      <td>32.0</td>\n",
       "      <td>92</td>\n",
       "      <td>141</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>1004.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-10-01 00:00:00</th>\n",
       "      <td>315061</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>99</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-12-31 23:00:00</th>\n",
       "      <td>3423094</td>\n",
       "      <td>99</td>\n",
       "      <td>68.0</td>\n",
       "      <td>96</td>\n",
       "      <td>118</td>\n",
       "      <td>31</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>184.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-12-31 23:00:00</th>\n",
       "      <td>3900021</td>\n",
       "      <td>50</td>\n",
       "      <td>803.0</td>\n",
       "      <td>67</td>\n",
       "      <td>292</td>\n",
       "      <td>31</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>184.0</td>\n",
       "      <td>...</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-12-31 23:00:00</th>\n",
       "      <td>3900022</td>\n",
       "      <td>50</td>\n",
       "      <td>509.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>803.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>...</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-12-31 23:00:00</th>\n",
       "      <td>3900023</td>\n",
       "      <td>50</td>\n",
       "      <td>881.0</td>\n",
       "      <td>67</td>\n",
       "      <td>289</td>\n",
       "      <td>31</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>509.0</td>\n",
       "      <td>803.0</td>\n",
       "      <td>...</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-12-31 23:00:00</th>\n",
       "      <td>3900024</td>\n",
       "      <td>50</td>\n",
       "      <td>509.0</td>\n",
       "      <td>0</td>\n",
       "      <td>56</td>\n",
       "      <td>31</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>881.0</td>\n",
       "      <td>509.0</td>\n",
       "      <td>...</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3810551 rows × 211 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Station  Route  Total Flow  % Observed  Samples  Day  \\\n",
       "Timestamp                                                                   \n",
       "2024-10-01 00:00:00   315053      5        44.0          92       99    1   \n",
       "2024-10-01 00:00:00   315054      5      1004.0          92      394    1   \n",
       "2024-10-01 00:00:00   315055      5        82.0          92       99    1   \n",
       "2024-10-01 00:00:00   315060      5        32.0          92      141    1   \n",
       "2024-10-01 00:00:00   315061      5         0.0           0       99    1   \n",
       "...                      ...    ...         ...         ...      ...  ...   \n",
       "2024-12-31 23:00:00  3423094     99        68.0          96      118   31   \n",
       "2024-12-31 23:00:00  3900021     50       803.0          67      292   31   \n",
       "2024-12-31 23:00:00  3900022     50       509.0           0        0   31   \n",
       "2024-12-31 23:00:00  3900023     50       881.0          67      289   31   \n",
       "2024-12-31 23:00:00  3900024     50       509.0           0       56   31   \n",
       "\n",
       "                     Month  IsHoliday  TotalFlow_lag_1  TotalFlow_lag_2  ...  \\\n",
       "Timestamp                                                                ...   \n",
       "2024-10-01 00:00:00     10          0             35.0            836.0  ...   \n",
       "2024-10-01 00:00:00     10          0             44.0             35.0  ...   \n",
       "2024-10-01 00:00:00     10          0           1004.0             44.0  ...   \n",
       "2024-10-01 00:00:00     10          0             82.0           1004.0  ...   \n",
       "2024-10-01 00:00:00     10          0             32.0             82.0  ...   \n",
       "...                    ...        ...              ...              ...  ...   \n",
       "2024-12-31 23:00:00     12          0            184.0              5.0  ...   \n",
       "2024-12-31 23:00:00     12          0             68.0            184.0  ...   \n",
       "2024-12-31 23:00:00     12          0            803.0             68.0  ...   \n",
       "2024-12-31 23:00:00     12          0            509.0            803.0  ...   \n",
       "2024-12-31 23:00:00     12          0            881.0            509.0  ...   \n",
       "\n",
       "                     Hour  Lane_FF  Lane_FR  Lane_HV  Lane_ML  Lane_OR  Dir_E  \\\n",
       "Timestamp                                                                       \n",
       "2024-10-01 00:00:00     0        0        0        0        0        1      0   \n",
       "2024-10-01 00:00:00     0        0        0        0        1        0      0   \n",
       "2024-10-01 00:00:00     0        0        1        0        0        0      0   \n",
       "2024-10-01 00:00:00     0        0        0        0        1        0      0   \n",
       "2024-10-01 00:00:00     0        0        0        1        0        0      0   \n",
       "...                   ...      ...      ...      ...      ...      ...    ...   \n",
       "2024-12-31 23:00:00    23        0        0        0        1        0      0   \n",
       "2024-12-31 23:00:00    23        0        0        0        1        0      1   \n",
       "2024-12-31 23:00:00    23        0        0        1        0        0      1   \n",
       "2024-12-31 23:00:00    23        0        0        0        1        0      0   \n",
       "2024-12-31 23:00:00    23        0        0        1        0        0      0   \n",
       "\n",
       "                     Dir_N  Dir_S  Dir_W  \n",
       "Timestamp                                 \n",
       "2024-10-01 00:00:00      1      0      0  \n",
       "2024-10-01 00:00:00      1      0      0  \n",
       "2024-10-01 00:00:00      1      0      0  \n",
       "2024-10-01 00:00:00      0      1      0  \n",
       "2024-10-01 00:00:00      0      1      0  \n",
       "...                    ...    ...    ...  \n",
       "2024-12-31 23:00:00      0      1      0  \n",
       "2024-12-31 23:00:00      0      0      0  \n",
       "2024-12-31 23:00:00      0      0      0  \n",
       "2024-12-31 23:00:00      0      0      1  \n",
       "2024-12-31 23:00:00      0      0      1  \n",
       "\n",
       "[3810551 rows x 211 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "10b00e8f-2f60-4396-abae-21e7ff909add",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Station</th>\n",
       "      <th>StationName</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2024-10-01</th>\n",
       "      <td>315053</td>\n",
       "      <td>S315053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-10-01</th>\n",
       "      <td>315054</td>\n",
       "      <td>S315054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-10-01</th>\n",
       "      <td>315055</td>\n",
       "      <td>S315055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-10-01</th>\n",
       "      <td>315060</td>\n",
       "      <td>S315060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-10-01</th>\n",
       "      <td>315061</td>\n",
       "      <td>S315061</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Station StationName\n",
       "Timestamp                      \n",
       "2024-10-01   315053     S315053\n",
       "2024-10-01   315054     S315054\n",
       "2024-10-01   315055     S315055\n",
       "2024-10-01   315060     S315060\n",
       "2024-10-01   315061     S315061"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make a safe copy (optional)\n",
    "df = df.copy()\n",
    "\n",
    "# create readable station codes like S315053\n",
    "df['StationName'] = 'S' + df['Station'].astype(str)\n",
    "\n",
    "# quick check\n",
    "df[['Station','StationName']].head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "63ba2f2d-64e5-4f65-a298-e8d7ea8c28af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert all True/False columns to 0/1 (int)\n",
    "df = df.astype({c: int for c in df.columns if df[c].dtype == 'bool'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "10096191-a7e1-480f-8428-938e54f951bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Station</th>\n",
       "      <th>Route</th>\n",
       "      <th>Total Flow</th>\n",
       "      <th>% Observed</th>\n",
       "      <th>Samples</th>\n",
       "      <th>Day</th>\n",
       "      <th>Month</th>\n",
       "      <th>IsHoliday</th>\n",
       "      <th>TotalFlow_lag_1</th>\n",
       "      <th>TotalFlow_lag_2</th>\n",
       "      <th>...</th>\n",
       "      <th>Lane_FF</th>\n",
       "      <th>Lane_FR</th>\n",
       "      <th>Lane_HV</th>\n",
       "      <th>Lane_ML</th>\n",
       "      <th>Lane_OR</th>\n",
       "      <th>Dir_E</th>\n",
       "      <th>Dir_N</th>\n",
       "      <th>Dir_S</th>\n",
       "      <th>Dir_W</th>\n",
       "      <th>StationName</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2024-10-01 00:00:00</th>\n",
       "      <td>315053</td>\n",
       "      <td>5</td>\n",
       "      <td>44.0</td>\n",
       "      <td>92</td>\n",
       "      <td>99</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>836.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>S315053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-10-01 00:00:00</th>\n",
       "      <td>315054</td>\n",
       "      <td>5</td>\n",
       "      <td>1004.0</td>\n",
       "      <td>92</td>\n",
       "      <td>394</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>S315054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-10-01 00:00:00</th>\n",
       "      <td>315055</td>\n",
       "      <td>5</td>\n",
       "      <td>82.0</td>\n",
       "      <td>92</td>\n",
       "      <td>99</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>1004.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>S315055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-10-01 00:00:00</th>\n",
       "      <td>315060</td>\n",
       "      <td>5</td>\n",
       "      <td>32.0</td>\n",
       "      <td>92</td>\n",
       "      <td>141</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>1004.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>S315060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-10-01 00:00:00</th>\n",
       "      <td>315061</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>99</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>S315061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-12-31 23:00:00</th>\n",
       "      <td>3423094</td>\n",
       "      <td>99</td>\n",
       "      <td>68.0</td>\n",
       "      <td>96</td>\n",
       "      <td>118</td>\n",
       "      <td>31</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>184.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>S3423094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-12-31 23:00:00</th>\n",
       "      <td>3900021</td>\n",
       "      <td>50</td>\n",
       "      <td>803.0</td>\n",
       "      <td>67</td>\n",
       "      <td>292</td>\n",
       "      <td>31</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>184.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>S3900021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-12-31 23:00:00</th>\n",
       "      <td>3900022</td>\n",
       "      <td>50</td>\n",
       "      <td>509.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>803.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>S3900022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-12-31 23:00:00</th>\n",
       "      <td>3900023</td>\n",
       "      <td>50</td>\n",
       "      <td>881.0</td>\n",
       "      <td>67</td>\n",
       "      <td>289</td>\n",
       "      <td>31</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>509.0</td>\n",
       "      <td>803.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>S3900023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-12-31 23:00:00</th>\n",
       "      <td>3900024</td>\n",
       "      <td>50</td>\n",
       "      <td>509.0</td>\n",
       "      <td>0</td>\n",
       "      <td>56</td>\n",
       "      <td>31</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>881.0</td>\n",
       "      <td>509.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>S3900024</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3810551 rows × 212 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Station  Route  Total Flow  % Observed  Samples  Day  \\\n",
       "Timestamp                                                                   \n",
       "2024-10-01 00:00:00   315053      5        44.0          92       99    1   \n",
       "2024-10-01 00:00:00   315054      5      1004.0          92      394    1   \n",
       "2024-10-01 00:00:00   315055      5        82.0          92       99    1   \n",
       "2024-10-01 00:00:00   315060      5        32.0          92      141    1   \n",
       "2024-10-01 00:00:00   315061      5         0.0           0       99    1   \n",
       "...                      ...    ...         ...         ...      ...  ...   \n",
       "2024-12-31 23:00:00  3423094     99        68.0          96      118   31   \n",
       "2024-12-31 23:00:00  3900021     50       803.0          67      292   31   \n",
       "2024-12-31 23:00:00  3900022     50       509.0           0        0   31   \n",
       "2024-12-31 23:00:00  3900023     50       881.0          67      289   31   \n",
       "2024-12-31 23:00:00  3900024     50       509.0           0       56   31   \n",
       "\n",
       "                     Month  IsHoliday  TotalFlow_lag_1  TotalFlow_lag_2  ...  \\\n",
       "Timestamp                                                                ...   \n",
       "2024-10-01 00:00:00     10          0             35.0            836.0  ...   \n",
       "2024-10-01 00:00:00     10          0             44.0             35.0  ...   \n",
       "2024-10-01 00:00:00     10          0           1004.0             44.0  ...   \n",
       "2024-10-01 00:00:00     10          0             82.0           1004.0  ...   \n",
       "2024-10-01 00:00:00     10          0             32.0             82.0  ...   \n",
       "...                    ...        ...              ...              ...  ...   \n",
       "2024-12-31 23:00:00     12          0            184.0              5.0  ...   \n",
       "2024-12-31 23:00:00     12          0             68.0            184.0  ...   \n",
       "2024-12-31 23:00:00     12          0            803.0             68.0  ...   \n",
       "2024-12-31 23:00:00     12          0            509.0            803.0  ...   \n",
       "2024-12-31 23:00:00     12          0            881.0            509.0  ...   \n",
       "\n",
       "                     Lane_FF  Lane_FR  Lane_HV  Lane_ML  Lane_OR  Dir_E  \\\n",
       "Timestamp                                                                 \n",
       "2024-10-01 00:00:00        0        0        0        0        1      0   \n",
       "2024-10-01 00:00:00        0        0        0        1        0      0   \n",
       "2024-10-01 00:00:00        0        1        0        0        0      0   \n",
       "2024-10-01 00:00:00        0        0        0        1        0      0   \n",
       "2024-10-01 00:00:00        0        0        1        0        0      0   \n",
       "...                      ...      ...      ...      ...      ...    ...   \n",
       "2024-12-31 23:00:00        0        0        0        1        0      0   \n",
       "2024-12-31 23:00:00        0        0        0        1        0      1   \n",
       "2024-12-31 23:00:00        0        0        1        0        0      1   \n",
       "2024-12-31 23:00:00        0        0        0        1        0      0   \n",
       "2024-12-31 23:00:00        0        0        1        0        0      0   \n",
       "\n",
       "                     Dir_N  Dir_S  Dir_W  StationName  \n",
       "Timestamp                                              \n",
       "2024-10-01 00:00:00      1      0      0      S315053  \n",
       "2024-10-01 00:00:00      1      0      0      S315054  \n",
       "2024-10-01 00:00:00      1      0      0      S315055  \n",
       "2024-10-01 00:00:00      0      1      0      S315060  \n",
       "2024-10-01 00:00:00      0      1      0      S315061  \n",
       "...                    ...    ...    ...          ...  \n",
       "2024-12-31 23:00:00      0      1      0     S3423094  \n",
       "2024-12-31 23:00:00      0      0      0     S3900021  \n",
       "2024-12-31 23:00:00      0      0      0     S3900022  \n",
       "2024-12-31 23:00:00      0      0      1     S3900023  \n",
       "2024-12-31 23:00:00      0      0      1     S3900024  \n",
       "\n",
       "[3810551 rows x 212 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f433b39b-ca94-4c1c-91b6-db8eb63c9864",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2208, 1806), (2208, 303408))"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FLOW_COL = 'Total Flow'\n",
    "LAGS = range(1, 169)  # 1..168 hours\n",
    "\n",
    "# df already has Timestamp as index in your screenshot\n",
    "flow_wide = df.pivot_table(index=df.index, columns='StationName', values=FLOW_COL, aggfunc='mean')\n",
    "flow_wide = flow_wide.reindex(sorted(flow_wide.columns), axis=1)\n",
    "\n",
    "# all lags for all stations\n",
    "flow_lags_all = pd.concat(\n",
    "    [flow_wide.shift(L).add_suffix(f'_lag_{L}') for L in LAGS],\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "flow_wide.shape, flow_lags_all.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "654e941f-5a80-49c8-b7f2-0e664ba1d57d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1967, 303281), (1967, 4))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target = df['StationName'].iloc[0]  # or pick any target like 'S315053'\n",
    "\n",
    "# lags of OTHER stations\n",
    "X_cross = flow_lags_all.drop(\n",
    "    columns=[c for c in flow_lags_all.columns if c.startswith(f'{target}_lag_')],\n",
    "    errors='ignore'\n",
    ")\n",
    "\n",
    "# ALL non-flow, non-lag features for the target station\n",
    "X_target_feats = df[df['StationName'] == target].drop(\n",
    "    columns=['Station', 'StationName', FLOW_COL] + \n",
    "            [c for c in df.columns if c.startswith('TotalFlow_lag_')],\n",
    "    errors='ignore'\n",
    ")\n",
    "\n",
    "# combine and align on time\n",
    "X = pd.concat([X_cross, X_target_feats], axis=1).sort_index()\n",
    "\n",
    "# multi-horizon Y\n",
    "HORIZONS = [12, 24, 48, 72]\n",
    "Y = pd.concat(\n",
    "    {h: df.loc[df['StationName'] == target, FLOW_COL].shift(-h) for h in HORIZONS},\n",
    "    axis=1\n",
    ")\n",
    "Y.columns = [f'y_{h}h' for h in HORIZONS]\n",
    "\n",
    "# ---------------- burn-in & cleaning ----------------\n",
    "burn_in = max(LAGS)  # e.g., 168\n",
    "# align indexes\n",
    "common_idx = X.index.intersection(Y.index)\n",
    "X = X.loc[common_idx]\n",
    "Y = Y.loc[common_idx]\n",
    "\n",
    "# drop first 'burn_in' rows (lags not fully available)\n",
    "X = X.iloc[burn_in:]\n",
    "Y = Y.iloc[burn_in:]\n",
    "\n",
    "# drop rows with NaN in Y only (due to forward shifts at the end)\n",
    "mask = ~Y.isna().any(axis=1)\n",
    "X = X.loc[mask]\n",
    "Y = Y.loc[mask]\n",
    "\n",
    "# impute residual NaNs in X (rare after the steps above)\n",
    "X = X.replace([np.inf, -np.inf], np.nan).fillna(0.0)\n",
    "\n",
    "X.shape, Y.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "837fd74b-44d7-4524-95d0-4bced1d875f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Gradient Boosting for feature importance ...\n",
      "Kept top-120 features.\n",
      "Shapes: \n",
      "  Xtr3: (1353, 24, 120) Ytr2: (1353, 4) \n",
      "  Xva3: (173, 24, 120) Yva2: (173, 4) \n",
      "  Xte3: (372, 24, 120) Yte2: (372, 4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-11 16:45:29.935413: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 14784 MB memory:  -> device: 0, name: Tesla V100-PCIE-16GB, pci bus id: 0000:5e:00.0, compute capability: 7.0\n",
      "2025-10-11 16:45:29.936576: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 14784 MB memory:  -> device: 1, name: Tesla V100-PCIE-16GB, pci bus id: 0000:af:00.0, compute capability: 7.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-11 16:45:34.167979: W tensorflow/core/common_runtime/type_inference.cc:339] Type inference failed. This indicates an invalid graph that escaped type checking. Error message: INVALID_ARGUMENT: expected compatible input types, but input 1:\n",
      "type_id: TFT_OPTIONAL\n",
      "args {\n",
      "  type_id: TFT_PRODUCT\n",
      "  args {\n",
      "    type_id: TFT_TENSOR\n",
      "    args {\n",
      "      type_id: TFT_INT32\n",
      "    }\n",
      "  }\n",
      "}\n",
      " is neither a subtype nor a supertype of the combined inputs preceding it:\n",
      "type_id: TFT_OPTIONAL\n",
      "args {\n",
      "  type_id: TFT_PRODUCT\n",
      "  args {\n",
      "    type_id: TFT_TENSOR\n",
      "    args {\n",
      "      type_id: TFT_FLOAT\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "\tfor Tuple type infernce function 0\n",
      "\twhile inferring type of node 'cond_40/output/_23'\n",
      "2025-10-11 16:45:34.439755: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8907\n",
      "2025-10-11 16:45:34.571506: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f094808ab90 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2025-10-11 16:45:34.571552: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla V100-PCIE-16GB, Compute Capability 7.0\n",
      "2025-10-11 16:45:34.571561: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (1): Tesla V100-PCIE-16GB, Compute Capability 7.0\n",
      "2025-10-11 16:45:34.580497: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:255] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2025-10-11 16:45:38.003118: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 12s 128ms/step - loss: 211.6065 - mae: 211.6065 - val_loss: 214.1326 - val_mae: 214.1326 - lr: 0.0010\n",
      "Epoch 2/25\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 210.4077 - mae: 210.4077 - val_loss: 212.6218 - val_mae: 212.6218 - lr: 0.0010\n",
      "Epoch 3/25\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 208.6242 - mae: 208.6242 - val_loss: 210.1237 - val_mae: 210.1237 - lr: 0.0010\n",
      "Epoch 4/25\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 205.4270 - mae: 205.4270 - val_loss: 205.0807 - val_mae: 205.0807 - lr: 0.0010\n",
      "Epoch 5/25\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 199.4483 - mae: 199.4483 - val_loss: 197.4776 - val_mae: 197.4776 - lr: 0.0010\n",
      "Epoch 6/25\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 192.1098 - mae: 192.1098 - val_loss: 189.4177 - val_mae: 189.4177 - lr: 0.0010\n",
      "Epoch 7/25\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 184.1064 - mae: 184.1064 - val_loss: 180.4220 - val_mae: 180.4220 - lr: 0.0010\n",
      "Epoch 8/25\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 175.5681 - mae: 175.5681 - val_loss: 170.7635 - val_mae: 170.7635 - lr: 0.0010\n",
      "Epoch 9/25\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 166.4242 - mae: 166.4242 - val_loss: 161.1195 - val_mae: 161.1195 - lr: 0.0010\n",
      "Epoch 10/25\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 157.5013 - mae: 157.5013 - val_loss: 151.9136 - val_mae: 151.9136 - lr: 0.0010\n",
      "Epoch 11/25\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 148.8870 - mae: 148.8870 - val_loss: 143.4982 - val_mae: 143.4982 - lr: 0.0010\n",
      "Epoch 12/25\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 141.5400 - mae: 141.5400 - val_loss: 135.8962 - val_mae: 135.8962 - lr: 0.0010\n",
      "Epoch 13/25\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 134.9278 - mae: 134.9278 - val_loss: 129.2517 - val_mae: 129.2517 - lr: 0.0010\n",
      "Epoch 14/25\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 129.2226 - mae: 129.2226 - val_loss: 123.3117 - val_mae: 123.3117 - lr: 0.0010\n",
      "Epoch 15/25\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 124.4097 - mae: 124.4097 - val_loss: 118.2363 - val_mae: 118.2363 - lr: 0.0010\n",
      "Epoch 16/25\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 120.9648 - mae: 120.9648 - val_loss: 114.5103 - val_mae: 114.5103 - lr: 0.0010\n",
      "Epoch 17/25\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 117.9228 - mae: 117.9228 - val_loss: 111.2313 - val_mae: 111.2313 - lr: 0.0010\n",
      "Epoch 18/25\n",
      "11/11 [==============================] - 0s 19ms/step - loss: 115.0694 - mae: 115.0694 - val_loss: 107.3561 - val_mae: 107.3561 - lr: 0.0010\n",
      "Epoch 19/25\n",
      "11/11 [==============================] - 0s 19ms/step - loss: 111.2980 - mae: 111.2980 - val_loss: 103.2630 - val_mae: 103.2630 - lr: 0.0010\n",
      "Epoch 20/25\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 106.2034 - mae: 106.2034 - val_loss: 99.2865 - val_mae: 99.2865 - lr: 0.0010\n",
      "Epoch 21/25\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 102.4220 - mae: 102.4220 - val_loss: 94.2227 - val_mae: 94.2227 - lr: 0.0010\n",
      "Epoch 22/25\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 98.4950 - mae: 98.4950 - val_loss: 90.9743 - val_mae: 90.9743 - lr: 0.0010\n",
      "Epoch 23/25\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 95.8973 - mae: 95.8973 - val_loss: 87.7491 - val_mae: 87.7491 - lr: 0.0010\n",
      "Epoch 24/25\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 93.8896 - mae: 93.8896 - val_loss: 85.4431 - val_mae: 85.4431 - lr: 0.0010\n",
      "Epoch 25/25\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 92.3834 - mae: 92.3834 - val_loss: 84.3026 - val_mae: 84.3026 - lr: 0.0010\n",
      "\n",
      "Test metrics:\n",
      "MAE_12h: 148.2002\n",
      "RMSE_12h: 181.0761\n",
      "MAE_24h: 64.5147\n",
      "RMSE_24h: 85.6758\n",
      "MAE_48h: 62.9149\n",
      "RMSE_48h: 85.1474\n",
      "MAE_72h: 66.0879\n",
      "RMSE_72h: 89.1096\n",
      "MAE_mean: 85.4294\n",
      "RMSE_mean: 110.2522\n"
     ]
    }
   ],
   "source": [
    "# ========================= CLEAN + SKLEARN GB → top-K → LSTM (single station) =========================\n",
    "import numpy as np, pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "# --------- CONFIG\n",
    "LOOKBACK   = 24\n",
    "HORIZONS   = [12, 24, 48, 72]\n",
    "TOP_K      = 120\n",
    "EPOCHS     = 25\n",
    "BATCH_SIZE = 128\n",
    "LR         = 1e-3\n",
    "PATIENCE   = 5\n",
    "\n",
    "# --------- helpers\n",
    "def time_split_index(idx, train_ratio=0.7, val_ratio=0.1):\n",
    "    n = len(idx); n_tr = int(n*train_ratio); n_va = int(n*val_ratio)\n",
    "    return idx[:n_tr], idx[n_tr:n_tr+n_va], idx[n_tr+n_va:]\n",
    "\n",
    "def make_windows(X2d, lookback):\n",
    "    T, F = X2d.shape\n",
    "    N = T - lookback + 1\n",
    "    out = np.empty((N, lookback, F), dtype=np.float32)\n",
    "    for i in range(N): out[i] = X2d[i:i+lookback]\n",
    "    return out\n",
    "\n",
    "def align_windows_with_targets(X_df, Y_df, lookback):\n",
    "    X_df = X_df.sort_index(); Y_df = Y_df.sort_index()\n",
    "    common = X_df.index.intersection(Y_df.index)\n",
    "    X2 = X_df.loc[common].to_numpy(dtype=float)\n",
    "    Y2 = Y_df.loc[common].to_numpy(dtype=float)\n",
    "    X3 = make_windows(X2, lookback)\n",
    "    Y_al = Y2[lookback-1:]\n",
    "    idx_al = common[lookback-1:]\n",
    "    return X3, Y_al, idx_al\n",
    "\n",
    "def build_lstm(n_features, n_outputs):\n",
    "    inp = keras.Input(shape=(LOOKBACK, n_features))\n",
    "    x = keras.layers.Masking(mask_value=0.0)(inp)\n",
    "    x = keras.layers.LSTM(64, return_sequences=False)(x)\n",
    "    x = keras.layers.Dense(64, activation='relu')(x)\n",
    "    x = keras.layers.Dropout(0.2)(x)\n",
    "    out = keras.layers.Dense(n_outputs)(x)\n",
    "    m = keras.Model(inp, out)\n",
    "    m.compile(optimizer=keras.optimizers.Adam(LR), loss='mae', metrics=['mae'])\n",
    "    return m\n",
    "\n",
    "def metrics_by_horizon(y_true, y_pred, horizons):\n",
    "    res, maes, rmses = {}, [], []\n",
    "    for j, h in enumerate(horizons):\n",
    "        mae  = mean_absolute_error(y_true[:, j], y_pred[:, j])\n",
    "        rmse = mean_squared_error(y_true[:, j], y_pred[:, j], squared=False)\n",
    "        res[f\"MAE_{h}h\"] = mae; res[f\"RMSE_{h}h\"] = rmse\n",
    "        maes.append(mae); rmses.append(rmse)\n",
    "    res[\"MAE_mean\"]  = float(np.mean(maes)); res[\"RMSE_mean\"] = float(np.mean(rmses))\n",
    "    return res\n",
    "\n",
    "# --------- CLEAN FEATURES (handles 'Tuesday' etc.)\n",
    "def clean_features(X):\n",
    "    X = X.copy()\n",
    "    # booleans -> ints\n",
    "    bcols = X.select_dtypes(include=['bool']).columns\n",
    "    if len(bcols): X[bcols] = X[bcols].astype(int)\n",
    "    # object -> numeric where possible, else drop\n",
    "    ocols = X.select_dtypes(include=['object']).columns\n",
    "    for c in ocols: X[c] = pd.to_numeric(X[c], errors='coerce')\n",
    "    non_num = [c for c in X.columns if not np.issubdtype(X[c].dtype, np.number)]\n",
    "    if non_num:\n",
    "        print(\"Dropping non-numeric columns:\", non_num)\n",
    "        X = X.drop(columns=non_num)\n",
    "    # clean infinities/NaN\n",
    "    X = X.replace([np.inf, -np.inf], np.nan).fillna(0.0)\n",
    "    return X.astype(float)\n",
    "\n",
    "# --------- 1) CLEAN DATA\n",
    "X = clean_features(X)\n",
    "Y = Y.replace([np.inf, -np.inf], np.nan).dropna().astype(float)\n",
    "common_idx = X.index.intersection(Y.index)\n",
    "X = X.loc[common_idx]; Y = Y.loc[common_idx]\n",
    "\n",
    "# --------- 2) time split\n",
    "tr_idx, va_idx, te_idx = time_split_index(X.index, train_ratio=0.7, val_ratio=0.1)\n",
    "X_tr, X_va, X_te = X.loc[tr_idx], X.loc[va_idx], X.loc[te_idx]\n",
    "Y_tr, Y_va, Y_te = Y.loc[tr_idx], Y.loc[va_idx], Y.loc[te_idx]\n",
    "\n",
    "# --------- 3) Feature selection with GradientBoostingRegressor (12h proxy)\n",
    "print(\"Running Gradient Boosting for feature importance ...\")\n",
    "gbr = GradientBoostingRegressor(n_estimators=600, learning_rate=0.05, max_depth=5, random_state=42)\n",
    "gbr.fit(X_tr, Y_tr['y_12h'])\n",
    "imp = pd.Series(gbr.feature_importances_, index=X_tr.columns).sort_values(ascending=False)\n",
    "keep_cols = imp.head(TOP_K).index.tolist()\n",
    "print(f\"Kept top-{TOP_K} features.\")\n",
    "\n",
    "# --------- 4) Scale & window\n",
    "scaler = StandardScaler()\n",
    "Xtr2 = scaler.fit_transform(X_tr[keep_cols])\n",
    "Xva2 = scaler.transform(X_va[keep_cols])\n",
    "Xte2 = scaler.transform(X_te[keep_cols])\n",
    "\n",
    "Xtr3, Ytr2, _ = align_windows_with_targets(pd.DataFrame(Xtr2, index=X_tr.index, columns=keep_cols), Y_tr, LOOKBACK)\n",
    "Xva3, Yva2, _ = align_windows_with_targets(pd.DataFrame(Xva2, index=X_va.index, columns=keep_cols), Y_va, LOOKBACK)\n",
    "Xte3, Yte2, _ = align_windows_with_targets(pd.DataFrame(Xte2, index=X_te.index, columns=keep_cols), Y_te, LOOKBACK)\n",
    "\n",
    "print(\"Shapes:\",\n",
    "      \"\\n  Xtr3:\", Xtr3.shape, \"Ytr2:\", Ytr2.shape,\n",
    "      \"\\n  Xva3:\", Xva3.shape, \"Yva2:\", Yva2.shape,\n",
    "      \"\\n  Xte3:\", Xte3.shape, \"Yte2:\", Yte2.shape)\n",
    "\n",
    "# --------- 5) LSTM training\n",
    "tf.keras.backend.clear_session()\n",
    "model = build_lstm(n_features=Xtr3.shape[-1], n_outputs=len(HORIZONS))\n",
    "cbs = [\n",
    "    keras.callbacks.EarlyStopping(monitor='val_loss', patience=PATIENCE, restore_best_weights=True),\n",
    "    keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, min_lr=1e-5),\n",
    "]\n",
    "history = model.fit(Xtr3, Ytr2, validation_data=(Xva3, Yva2),\n",
    "                    epochs=EPOCHS, batch_size=BATCH_SIZE, verbose=1, callbacks=cbs)\n",
    "\n",
    "# --------- 6) Evaluate\n",
    "Yhat_te = model.predict(Xte3, verbose=0)\n",
    "results = metrics_by_horizon(Yte2, Yhat_te, HORIZONS)\n",
    "print(\"\\nTest metrics:\")\n",
    "for k, v in results.items():\n",
    "    print(f\"{k}: {v:.4f}\")\n",
    "\n",
    "# --------- 7) Save artifacts (optional)\n",
    "pd.DataFrame({'feature': imp.index, 'importance': imp.values}).to_csv(\"gb_importance.csv\", index=False)\n",
    "pd.Series(keep_cols, name=\"kept_features\").to_csv(\"kept_features.csv\", index=False)\n",
    "model.save(\"lstm_per_station_cleaned.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "681d1dd0-7cbe-4f3e-a2e0-7f3200ac1449",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Gradient Boosting for feature importance ...\n",
      "Kept top-120 features.\n",
      "Shapes: \n",
      "  Xtr3: (1353, 24, 120) Ytr2: (1353, 4) \n",
      "  Xva3: (173, 24, 120) Yva2: (173, 4) \n",
      "  Xte3: (372, 24, 120) Yte2: (372, 4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-14 06:17:03.386793: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:47] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
      "2025-10-14 06:17:03.387193: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 14728 MB memory:  -> device: 0, name: Tesla V100-PCIE-16GB, pci bus id: 0000:5e:00.0, compute capability: 7.0\n",
      "2025-10-14 06:17:03.387813: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:47] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
      "2025-10-14 06:17:03.387842: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 14728 MB memory:  -> device: 1, name: Tesla V100-PCIE-16GB, pci bus id: 0000:af:00.0, compute capability: 7.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-14 06:17:05.734911: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8907\n",
      "2025-10-14 06:17:10.811154: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f4989946620 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2025-10-14 06:17:10.811217: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla V100-PCIE-16GB, Compute Capability 7.0\n",
      "2025-10-14 06:17:10.811232: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (1): Tesla V100-PCIE-16GB, Compute Capability 7.0\n",
      "2025-10-14 06:17:10.820818: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:255] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2025-10-14 06:17:13.609688: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 17s 59ms/step - loss: 210.0976 - mae: 210.0849 - val_loss: 209.4288 - val_mae: 209.4161 - lr: 0.0010\n",
      "Epoch 2/25\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 202.4714 - mae: 202.4585 - val_loss: 198.7004 - val_mae: 198.6874 - lr: 0.0010\n",
      "Epoch 3/25\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 190.8520 - mae: 190.8387 - val_loss: 184.5775 - val_mae: 184.5639 - lr: 0.0010\n",
      "Epoch 4/25\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 176.9049 - mae: 176.8909 - val_loss: 168.2063 - val_mae: 168.1918 - lr: 0.0010\n",
      "Epoch 5/25\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 160.9404 - mae: 160.9254 - val_loss: 151.4746 - val_mae: 151.4589 - lr: 0.0010\n",
      "Epoch 6/25\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 145.6216 - mae: 145.6052 - val_loss: 136.2987 - val_mae: 136.2815 - lr: 0.0010\n",
      "Epoch 7/25\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 132.6124 - mae: 132.5945 - val_loss: 123.4572 - val_mae: 123.4384 - lr: 0.0010\n",
      "Epoch 8/25\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 123.4292 - mae: 123.4096 - val_loss: 114.2318 - val_mae: 114.2114 - lr: 0.0010\n",
      "Epoch 9/25\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 117.0214 - mae: 117.0004 - val_loss: 109.2290 - val_mae: 109.2073 - lr: 0.0010\n",
      "Epoch 10/25\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 113.8334 - mae: 113.8113 - val_loss: 106.4458 - val_mae: 106.4231 - lr: 0.0010\n",
      "Epoch 11/25\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 112.8351 - mae: 112.8121 - val_loss: 105.1082 - val_mae: 105.0849 - lr: 0.0010\n",
      "Epoch 12/25\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 111.6744 - mae: 111.6509 - val_loss: 104.5444 - val_mae: 104.5208 - lr: 0.0010\n",
      "Epoch 13/25\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 111.6971 - mae: 111.6734 - val_loss: 104.3277 - val_mae: 104.3040 - lr: 0.0010\n",
      "Epoch 14/25\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 111.8718 - mae: 111.8483 - val_loss: 104.3068 - val_mae: 104.2833 - lr: 0.0010\n",
      "Epoch 15/25\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 112.0011 - mae: 111.9777 - val_loss: 104.3972 - val_mae: 104.3739 - lr: 0.0010\n",
      "Epoch 16/25\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 111.5630 - mae: 111.5398 - val_loss: 104.2836 - val_mae: 104.2604 - lr: 0.0010\n",
      "Epoch 17/25\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 111.7806 - mae: 111.7575 - val_loss: 104.0284 - val_mae: 104.0053 - lr: 0.0010\n",
      "Epoch 18/25\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 111.3123 - mae: 111.2892 - val_loss: 102.4362 - val_mae: 102.4132 - lr: 0.0010\n",
      "Epoch 19/25\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 107.6991 - mae: 107.6760 - val_loss: 98.0167 - val_mae: 97.9934 - lr: 0.0010\n",
      "Epoch 20/25\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 103.2256 - mae: 103.2021 - val_loss: 92.3315 - val_mae: 92.3076 - lr: 0.0010\n",
      "Epoch 21/25\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 96.6271 - mae: 96.6028 - val_loss: 86.3582 - val_mae: 86.3334 - lr: 0.0010\n",
      "Epoch 22/25\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 93.8471 - mae: 93.8220 - val_loss: 83.6142 - val_mae: 83.5886 - lr: 0.0010\n",
      "Epoch 23/25\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 90.2884 - mae: 90.2625 - val_loss: 79.5639 - val_mae: 79.5376 - lr: 0.0010\n",
      "Epoch 24/25\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 90.2345 - mae: 90.2080 - val_loss: 77.2667 - val_mae: 77.2398 - lr: 0.0010\n",
      "Epoch 25/25\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 87.9386 - mae: 87.9116 - val_loss: 75.2782 - val_mae: 75.2510 - lr: 0.0010\n",
      "\n",
      "[Info] REF_COL not found in X or disabled; skipping LV baseline.\n",
      "\n",
      "LSTM Test metrics:\n",
      "MAE_12h: 142.8584\n",
      "RMSE_12h: 175.4022\n",
      "MAE_24h: 59.9042\n",
      "RMSE_24h: 78.8636\n",
      "MAE_48h: 57.7086\n",
      "RMSE_48h: 77.5148\n",
      "MAE_72h: 59.0106\n",
      "RMSE_72h: 78.7884\n",
      "MAE_mean: 79.8705\n",
      "RMSE_mean: 102.6423\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE by decile for 12h: [(1, 139.29118909333883), (2, 115.53777433696546), (3, 87.49750819959138), (4, 37.43319867108319), (5, 37.62316864415219), (6, 69.58255186080933), (7, 128.32027826811137), (8, 201.68957220541463), (9, 259.9010966532939), (10, 347.5810183474892)]\n",
      "MAE by decile for 24h: [(1, 38.588213896140076), (2, 29.11128469613882), (3, 43.46708517074585), (4, 66.51105720118473), (5, 59.47081013729698), (6, 45.852974339535365), (7, 38.671404587595084), (8, 41.64359881426837), (9, 77.1701557056324), (10, 156.8309286017167)]\n",
      "MAE by decile for 48h: [(1, 37.88441025583368), (2, 26.36030528419896), (3, 32.229135513305664), (4, 60.63041948017321), (5, 59.849271001042545), (6, 45.03081058811497), (7, 35.79257684004934), (8, 38.77974901701275), (9, 75.42889115617082), (10, 159.69597103721216)]\n",
      "MAE by decile for 72h: [(1, 39.75990706995914), (2, 29.493891947978252), (3, 34.55565323700776), (4, 61.81848726774517), (5, 62.38962755705181), (6, 43.177603025694154), (7, 36.37256642934438), (8, 41.75284761995883), (9, 78.51530126623206), (10, 160.16016588712992)]\n",
      "\n",
      "Saved: per_station_metrics.csv, per_station_preds_test.csv, gb_importance.csv, kept_features.csv, lstm_per_station_cleaned.h5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "29473"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ========================= FINAL: GB → top-K → Scale → Window → Conv1D+LSTM (single station) =========================\n",
    "import os, gc, warnings, logging\n",
    "import numpy as np, pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
    "os.environ.setdefault(\"TF_FORCE_GPU_ALLOW_GROWTH\", \"true\")\n",
    "tf.get_logger().setLevel(logging.ERROR)\n",
    "\n",
    "# ---------------- CONFIG ----------------\n",
    "LOOKBACK    = 24           # try 168 later for weekly context\n",
    "HORIZONS    = [12, 24, 48, 72]\n",
    "ORDERED_COLS = [f\"y_{h}h\" for h in HORIZONS]\n",
    "TOP_K       = 120\n",
    "EPOCHS      = 25\n",
    "BATCH_SIZE  = 128\n",
    "LR          = 1e-3\n",
    "PATIENCE    = 5\n",
    "REF_COL     = \"Total Flow\" # used for LV baseline; set to None to skip or rename to match your X\n",
    "PLOT_DIAGNOSTICS = True    # set False to skip plots\n",
    "\n",
    "# ------------- helpers -------------\n",
    "def time_split_index(idx, train_ratio=0.7, val_ratio=0.1):\n",
    "    n = len(idx); n_tr = int(n*train_ratio); n_va = int(n*val_ratio)\n",
    "    return idx[:n_tr], idx[n_tr:n_tr+n_va], idx[n_tr+n_va:]\n",
    "\n",
    "def make_windows(X2d, lookback):\n",
    "    T, F = X2d.shape\n",
    "    N = T - lookback + 1\n",
    "    out = np.empty((N, lookback, F), dtype=np.float32)\n",
    "    for i in range(N):\n",
    "        out[i] = X2d[i:i+lookback]\n",
    "    return out\n",
    "\n",
    "def align_windows_with_targets(X_df, Y_df, lookback):\n",
    "    X_df = X_df.sort_index(); Y_df = Y_df.sort_index()\n",
    "    common = X_df.index.intersection(Y_df.index)\n",
    "    X2 = X_df.loc[common].to_numpy(dtype=float)\n",
    "    Y2 = Y_df.loc[common].to_numpy(dtype=float)\n",
    "    X3 = make_windows(X2, lookback)\n",
    "    Y_al = Y2[lookback-1:]\n",
    "    idx_al = common[lookback-1:]\n",
    "    return X3, Y_al, idx_al\n",
    "\n",
    "def build_model(n_features, n_outputs):\n",
    "    inp = keras.Input(shape=(LOOKBACK, n_features))\n",
    "    x = keras.layers.Conv1D(32, 3, padding=\"causal\", activation=\"relu\")(inp)\n",
    "    x = keras.layers.LSTM(128)(x)\n",
    "    x = keras.layers.Dense(128, activation='relu', kernel_regularizer=keras.regularizers.l2(1e-4))(x)\n",
    "    x = keras.layers.Dropout(0.3)(x)\n",
    "    out = keras.layers.Dense(n_outputs)(x)\n",
    "    m = keras.Model(inp, out)\n",
    "    m.compile(optimizer=keras.optimizers.Adam(LR), loss='mae', metrics=['mae'])\n",
    "    return m\n",
    "\n",
    "def metrics_by_horizon(y_true, y_pred, horizons):\n",
    "    res, maes, rmses = {}, [], []\n",
    "    for j, h in enumerate(horizons):\n",
    "        mae  = mean_absolute_error(y_true[:, j], y_pred[:, j])\n",
    "        rmse = mean_squared_error(y_true[:, j], y_pred[:, j], squared=False)\n",
    "        res[f\"MAE_{h}h\"] = float(mae); res[f\"RMSE_{h}h\"] = float(rmse)\n",
    "        maes.append(mae); rmses.append(rmse)\n",
    "    res[\"MAE_mean\"]  = float(np.mean(maes)); res[\"RMSE_mean\"] = float(np.mean(rmses))\n",
    "    return res\n",
    "\n",
    "def lv_baseline_metrics(y_true_df, ref_series, horizons):\n",
    "    \"\"\"Last-value (LV) baseline: predict all horizons as the most recent observed value at window end.\"\"\"\n",
    "    y_true = y_true_df.to_numpy()\n",
    "    # Use the aligned ref_series values (same index as y_true_df)\n",
    "    ref_vals = ref_series.loc[y_true_df.index].values.reshape(-1, 1)\n",
    "    preds_lv = np.repeat(ref_vals, repeats=len(horizons), axis=1)\n",
    "    res, maes, rmses = {}, [], []\n",
    "    for j, h in enumerate(horizons):\n",
    "        mae  = mean_absolute_error(y_true[:, j], preds_lv[:, j])\n",
    "        rmse = mean_squared_error(y_true[:, j], preds_lv[:, j], squared=False)\n",
    "        res[f\"LV_MAE_{h}h\"] = float(mae); res[f\"LV_RMSE_{h}h\"] = float(rmse)\n",
    "        maes.append(mae); rmses.append(rmse)\n",
    "    res[\"LV_MAE_mean\"]  = float(np.mean(maes)); res[\"LV_RMSE_mean\"] = float(np.mean(rmses))\n",
    "    return res\n",
    "\n",
    "def clean_features(X):\n",
    "    X = X.copy()\n",
    "    # booleans -> ints\n",
    "    bcols = X.select_dtypes(include=['bool']).columns\n",
    "    if len(bcols): X[bcols] = X[bcols].astype(int)\n",
    "    # object -> numeric where possible, else drop\n",
    "    ocols = X.select_dtypes(include=['object']).columns\n",
    "    for c in ocols: X[c] = pd.to_numeric(X[c], errors='coerce')\n",
    "    non_num = [c for c in X.columns if not np.issubdtype(X[c].dtype, np.number)]\n",
    "    if non_num:\n",
    "        print(\"Dropping non-numeric columns:\", non_num)\n",
    "        X = X.drop(columns=non_num)\n",
    "    # clean infinities/NaN\n",
    "    X = X.replace([np.inf, -np.inf], np.nan).fillna(0.0)\n",
    "    return X.astype(float)\n",
    "\n",
    "def mae_by_quantile(y, yhat, q=10):\n",
    "    qs = np.linspace(0, 1, q+1)\n",
    "    cuts = np.quantile(y, qs)\n",
    "    out = []\n",
    "    for i in range(q):\n",
    "        mask = (y >= cuts[i]) & (y <= cuts[i+1] if i < q-1 else y <= cuts[i+1])\n",
    "        if mask.sum():\n",
    "            out.append((i+1, float(np.mean(np.abs(yhat[mask]-y[mask])))))\n",
    "    return out\n",
    "\n",
    "# ============================= MAIN (single-station) =============================\n",
    "# Expect X, Y already defined (DataFrames with DateTime index). Y must contain y_12h,y_24h,y_48h,y_72h.\n",
    "assert isinstance(X, pd.DataFrame) and isinstance(Y, pd.DataFrame), \"Please provide X and Y as pandas DataFrames.\"\n",
    "X = clean_features(X)\n",
    "\n",
    "# Strict target order\n",
    "for c in ORDERED_COLS:\n",
    "    assert c in Y.columns, f\"Missing target column {c} in Y\"\n",
    "Y = Y[ORDERED_COLS].replace([np.inf, -np.inf], np.nan).dropna().astype(float)\n",
    "\n",
    "# Align X and Y on common timestamps\n",
    "common_idx = X.index.intersection(Y.index)\n",
    "X = X.loc[common_idx]\n",
    "Y = Y.loc[common_idx]\n",
    "\n",
    "# Split by time\n",
    "tr_idx, va_idx, te_idx = time_split_index(X.index, train_ratio=0.7, val_ratio=0.1)\n",
    "X_tr, X_va, X_te = X.loc[tr_idx], X.loc[va_idx], X.loc[te_idx]\n",
    "Y_tr, Y_va, Y_te = Y.loc[tr_idx], Y.loc[va_idx], Y.loc[te_idx]\n",
    "\n",
    "# Gradient Boosting feature selection using 12h as proxy\n",
    "print(\"Running Gradient Boosting for feature importance ...\")\n",
    "gbr = GradientBoostingRegressor(n_estimators=600, learning_rate=0.05, max_depth=5, random_state=42)\n",
    "gbr.fit(X_tr, Y_tr['y_12h'])\n",
    "imp = pd.Series(gbr.feature_importances_, index=X_tr.columns).sort_values(ascending=False)\n",
    "keep_cols = imp.head(TOP_K).index.tolist()\n",
    "print(f\"Kept top-{TOP_K} features.\")\n",
    "\n",
    "# Scale on train only\n",
    "scaler = StandardScaler()\n",
    "Xtr2 = scaler.fit_transform(X_tr[keep_cols])\n",
    "Xva2 = scaler.transform(X_va[keep_cols])\n",
    "Xte2 = scaler.transform(X_te[keep_cols])\n",
    "\n",
    "# Window + align\n",
    "Xtr3, Ytr2, tr_al_idx = align_windows_with_targets(pd.DataFrame(Xtr2, index=X_tr.index, columns=keep_cols), Y_tr, LOOKBACK)\n",
    "Xva3, Yva2, va_al_idx = align_windows_with_targets(pd.DataFrame(Xva2, index=X_va.index, columns=keep_cols), Y_va, LOOKBACK)\n",
    "Xte3, Yte2, te_al_idx = align_windows_with_targets(pd.DataFrame(Xte2, index=X_te.index, columns=keep_cols), Y_te, LOOKBACK)\n",
    "\n",
    "print(\"Shapes:\",\n",
    "      \"\\n  Xtr3:\", Xtr3.shape, \"Ytr2:\", Ytr2.shape,\n",
    "      \"\\n  Xva3:\", Xva3.shape, \"Yva2:\", Yva2.shape,\n",
    "      \"\\n  Xte3:\", Xte3.shape, \"Yte2:\", Yte2.shape)\n",
    "\n",
    "# Train\n",
    "tf.keras.backend.clear_session()\n",
    "model = build_model(n_features=Xtr3.shape[-1], n_outputs=len(HORIZONS))\n",
    "cbs = [\n",
    "    keras.callbacks.EarlyStopping(monitor='val_loss', patience=PATIENCE, restore_best_weights=True),\n",
    "    keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, min_lr=1e-5),\n",
    "]\n",
    "history = model.fit(\n",
    "    Xtr3, Ytr2,\n",
    "    validation_data=(Xva3, Yva2),\n",
    "    epochs=EPOCHS, batch_size=BATCH_SIZE, verbose=1, callbacks=cbs\n",
    ")\n",
    "\n",
    "# Evaluate\n",
    "Yhat_te = model.predict(Xte3, verbose=0)\n",
    "results = metrics_by_horizon(Yte2, Yhat_te, HORIZONS)\n",
    "\n",
    "# Build aligned DataFrames for export/plots\n",
    "Yte_df   = pd.DataFrame(Yte2, index=te_al_idx, columns=ORDERED_COLS)\n",
    "Yhat_df  = pd.DataFrame(Yhat_te, index=te_al_idx, columns=ORDERED_COLS)\n",
    "\n",
    "# Baseline (Last-Value) if reference column exists\n",
    "baseline_res = {}\n",
    "if REF_COL is not None and REF_COL in X.columns:\n",
    "    # Use raw (unscaled) REF_COL aligned to the end of each window\n",
    "    ref_series = X[REF_COL]\n",
    "    baseline_res = lv_baseline_metrics(Yte_df, ref_series, HORIZONS)\n",
    "    print(\"\\nBaseline (LV) metrics:\")\n",
    "    for k, v in baseline_res.items():\n",
    "        print(f\"{k}: {v:.4f}\")\n",
    "else:\n",
    "    print(\"\\n[Info] REF_COL not found in X or disabled; skipping LV baseline.\")\n",
    "\n",
    "print(\"\\nLSTM Test metrics:\")\n",
    "for k, v in results.items():\n",
    "    print(f\"{k}: {v:.4f}\")\n",
    "\n",
    "# --------- Diagnostics (optional) ---------\n",
    "if PLOT_DIAGNOSTICS:\n",
    "    for col in ORDERED_COLS:\n",
    "        plt.figure()\n",
    "        plt.scatter(Yte_df[col].values, Yhat_df[col].values, s=6, alpha=0.5)\n",
    "        plt.xlabel(f\"Actual {col}\"); plt.ylabel(f\"Predicted {col}\")\n",
    "        plt.title(f\"Pred vs Actual — {col}\"); plt.grid(True); plt.show()\n",
    "\n",
    "    for col in ORDERED_COLS:\n",
    "        res = (Yhat_df[col] - Yte_df[col]).values\n",
    "        plt.figure()\n",
    "        plt.hist(res, bins=40)\n",
    "        plt.title(f\"Residuals — {col}\")\n",
    "        plt.xlabel(\"Error\"); plt.ylabel(\"Count\"); plt.grid(True); plt.show()\n",
    "\n",
    "    for h in HORIZONS:\n",
    "        y = Yte_df[f'y_{h}h'].values; yhat = Yhat_df[f'y_{h}h'].values\n",
    "        print(f\"MAE by decile for {h}h:\", mae_by_quantile(y, yhat))\n",
    "\n",
    "# --------- Exports ---------\n",
    "# Metrics table (model + baseline if available)\n",
    "final_metrics = {**{k: float(v) for k, v in results.items()}, **{k: float(v) for k, v in baseline_res.items()}}\n",
    "metrics_df = pd.DataFrame(list(final_metrics.items()), columns=[\"metric\", \"value\"])\n",
    "metrics_df.to_csv(\"per_station_metrics.csv\", index=False)\n",
    "\n",
    "# Predictions vs actuals\n",
    "out = pd.concat([Yte_df.add_prefix(\"ytrue_\"), Yhat_df.add_prefix(\"ypred_\")], axis=1)\n",
    "out.to_csv(\"per_station_preds_test.csv\")\n",
    "\n",
    "# Feature importance + kept features\n",
    "pd.DataFrame({'feature': imp.index, 'importance': imp.values}).to_csv(\"gb_importance.csv\", index=False)\n",
    "pd.Series(keep_cols, name=\"kept_features\").to_csv(\"kept_features.csv\", index=False)\n",
    "\n",
    "# Save model\n",
    "model.save(\"lstm_per_station_cleaned.h5\")\n",
    "\n",
    "print(\"\\nSaved: per_station_metrics.csv, per_station_preds_test.csv, gb_importance.csv, kept_features.csv, lstm_per_station_cleaned.h5\")\n",
    "gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85e22934-af60-4c6a-80c0-313d4c6175cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Station S3001021 ===\n",
      "[GB] Computing feature importances on y_12h ...\n",
      "[GB] Kept top-120 features\n",
      "Shapes: \n",
      "  Xtr3: (1354, 24, 120) Ytr2: (1354, 4) \n",
      "  Xva3: (173, 24, 120) Yva2: (173, 4) \n",
      "  Xte3: (372, 24, 120) Yte2: (372, 4)\n",
      "Epoch 1/25\n",
      "11/11 [==============================] - 3s 53ms/step - loss: 986.3527 - mae: 986.3400 - val_loss: 994.8376 - val_mae: 994.8248 - lr: 0.0010\n",
      "Epoch 2/25\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 982.1848 - mae: 982.1718 - val_loss: 987.8970 - val_mae: 987.8839 - lr: 0.0010\n",
      "Epoch 3/25\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 973.1365 - mae: 973.1232 - val_loss: 976.4744 - val_mae: 976.4610 - lr: 0.0010\n",
      "Epoch 4/25\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 960.2292 - mae: 960.2153 - val_loss: 961.5973 - val_mae: 961.5829 - lr: 0.0010\n",
      "Epoch 5/25\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 943.4097 - mae: 943.3948 - val_loss: 942.7943 - val_mae: 942.7786 - lr: 0.0010\n",
      "Epoch 6/25\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 923.2496 - mae: 923.2334 - val_loss: 920.4710 - val_mae: 920.4539 - lr: 0.0010\n",
      "Epoch 7/25\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 900.3981 - mae: 900.3800 - val_loss: 896.9878 - val_mae: 896.9686 - lr: 0.0010\n",
      "Epoch 8/25\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 877.6153 - mae: 877.5950 - val_loss: 875.2086 - val_mae: 875.1873 - lr: 0.0010\n",
      "Epoch 9/25\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 856.2147 - mae: 856.1923 - val_loss: 855.0621 - val_mae: 855.0383 - lr: 0.0010\n",
      "Epoch 10/25\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 836.0505 - mae: 836.0256 - val_loss: 835.7173 - val_mae: 835.6910 - lr: 0.0010\n",
      "Epoch 11/25\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 816.9108 - mae: 816.8833 - val_loss: 817.5968 - val_mae: 817.5677 - lr: 0.0010\n",
      "Epoch 12/25\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 799.2180 - mae: 799.1876 - val_loss: 799.6847 - val_mae: 799.6527 - lr: 0.0010\n",
      "Epoch 13/25\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 781.9618 - mae: 781.9285 - val_loss: 781.8085 - val_mae: 781.7735 - lr: 0.0010\n",
      "Epoch 14/25\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 764.0643 - mae: 764.0280 - val_loss: 765.1716 - val_mae: 765.1335 - lr: 0.0010\n",
      "Epoch 15/25\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 748.5089 - mae: 748.4692 - val_loss: 749.4657 - val_mae: 749.4242 - lr: 0.0010\n",
      "Epoch 16/25\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 734.5889 - mae: 734.5459 - val_loss: 734.5095 - val_mae: 734.4647 - lr: 0.0010\n",
      "Epoch 17/25\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 720.9517 - mae: 720.9053 - val_loss: 720.5795 - val_mae: 720.5312 - lr: 0.0010\n",
      "Epoch 18/25\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 706.6024 - mae: 706.5528 - val_loss: 708.8233 - val_mae: 708.7717 - lr: 0.0010\n",
      "Epoch 19/25\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 698.1567 - mae: 698.1039 - val_loss: 698.7973 - val_mae: 698.7426 - lr: 0.0010\n",
      "Epoch 20/25\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 689.2432 - mae: 689.1871 - val_loss: 690.3975 - val_mae: 690.3397 - lr: 0.0010\n",
      "Epoch 21/25\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 684.2637 - mae: 684.2047 - val_loss: 683.4186 - val_mae: 683.3580 - lr: 0.0010\n",
      "Epoch 22/25\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 675.9213 - mae: 675.8595 - val_loss: 677.7390 - val_mae: 677.6756 - lr: 0.0010\n",
      "Epoch 23/25\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 671.5225 - mae: 671.4579 - val_loss: 672.4820 - val_mae: 672.4160 - lr: 0.0010\n",
      "Epoch 24/25\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 666.1866 - mae: 666.1196 - val_loss: 666.5579 - val_mae: 666.4894 - lr: 0.0010\n",
      "Epoch 25/25\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 660.3726 - mae: 660.3033 - val_loss: 657.8513 - val_mae: 657.7806 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 1095.4785\n",
      "LV_RMSE_12h: 1236.7085\n",
      "LV_MAE_24h: 197.7177\n",
      "LV_RMSE_24h: 308.6893\n",
      "LV_MAE_48h: 281.8468\n",
      "LV_RMSE_48h: 422.9302\n",
      "LV_MAE_72h: 239.5134\n",
      "LV_RMSE_72h: 369.2577\n",
      "LV_MAE_mean: 453.6391\n",
      "LV_RMSE_mean: 584.3964\n",
      "\n",
      "LSTM Test metrics:\n",
      "MAE_12h: 577.2119\n",
      "RMSE_12h: 690.1813\n",
      "MAE_24h: 535.2682\n",
      "RMSE_24h: 638.1290\n",
      "MAE_48h: 551.8069\n",
      "RMSE_48h: 665.9410\n",
      "MAE_72h: 549.4716\n",
      "RMSE_72h: 661.0326\n",
      "MAE_mean: 553.4396\n",
      "RMSE_mean: 663.8210\n",
      "\n",
      "=== Station S3001022 ===\n",
      "[GB] Computing feature importances on y_12h ...\n",
      "[GB] Kept top-120 features\n",
      "Shapes: \n",
      "  Xtr3: (1353, 24, 120) Ytr2: (1353, 4) \n",
      "  Xva3: (173, 24, 120) Yva2: (173, 4) \n",
      "  Xte3: (371, 24, 120) Yte2: (371, 4)\n",
      "Epoch 1/25\n",
      "11/11 [==============================] - 3s 54ms/step - loss: 571.4599 - mae: 571.4471 - val_loss: 593.9089 - val_mae: 593.8961 - lr: 0.0010\n",
      "Epoch 2/25\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 564.5804 - mae: 564.5676 - val_loss: 584.0643 - val_mae: 584.0514 - lr: 0.0010\n",
      "Epoch 3/25\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 553.1651 - mae: 553.1520 - val_loss: 571.7697 - val_mae: 571.7562 - lr: 0.0010\n",
      "Epoch 4/25\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 540.3482 - mae: 540.3344 - val_loss: 558.3544 - val_mae: 558.3402 - lr: 0.0010\n",
      "Epoch 5/25\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 527.4862 - mae: 527.4716 - val_loss: 544.3944 - val_mae: 544.3791 - lr: 0.0010\n",
      "Epoch 6/25\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 514.1174 - mae: 514.1016 - val_loss: 530.8625 - val_mae: 530.8459 - lr: 0.0010\n",
      "Epoch 7/25\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 501.3977 - mae: 501.3805 - val_loss: 517.6822 - val_mae: 517.6640 - lr: 0.0010\n",
      "Epoch 8/25\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 488.6094 - mae: 488.5905 - val_loss: 504.8436 - val_mae: 504.8237 - lr: 0.0010\n",
      "Epoch 9/25\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 477.9560 - mae: 477.9352 - val_loss: 492.5977 - val_mae: 492.5759 - lr: 0.0010\n",
      "Epoch 10/25\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 465.5172 - mae: 465.4945 - val_loss: 481.2325 - val_mae: 481.2086 - lr: 0.0010\n",
      "Epoch 11/25\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 455.5812 - mae: 455.5563 - val_loss: 470.2237 - val_mae: 470.1974 - lr: 0.0010\n",
      "Epoch 12/25\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 445.7124 - mae: 445.6852 - val_loss: 460.5776 - val_mae: 460.5491 - lr: 0.0010\n",
      "Epoch 13/25\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 436.3605 - mae: 436.3309 - val_loss: 450.0516 - val_mae: 450.0208 - lr: 0.0010\n",
      "Epoch 14/25\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 426.1956 - mae: 426.1637 - val_loss: 436.9964 - val_mae: 436.9631 - lr: 0.0010\n",
      "Epoch 15/25\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 413.2190 - mae: 413.1846 - val_loss: 423.2785 - val_mae: 423.2426 - lr: 0.0010\n",
      "Epoch 16/25\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 399.7531 - mae: 399.7159 - val_loss: 406.6449 - val_mae: 406.6061 - lr: 0.0010\n",
      "Epoch 17/25\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 382.9555 - mae: 382.9154 - val_loss: 386.6578 - val_mae: 386.6160 - lr: 0.0010\n",
      "Epoch 18/25\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 363.7285 - mae: 363.6852 - val_loss: 364.5816 - val_mae: 364.5364 - lr: 0.0010\n",
      "Epoch 19/25\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 341.6777 - mae: 341.6308 - val_loss: 343.9602 - val_mae: 343.9112 - lr: 0.0010\n",
      "Epoch 20/25\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 322.4031 - mae: 322.3524 - val_loss: 326.0135 - val_mae: 325.9603 - lr: 0.0010\n",
      "Epoch 21/25\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 306.6502 - mae: 306.5953 - val_loss: 305.6750 - val_mae: 305.6177 - lr: 0.0010\n",
      "Epoch 22/25\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 286.5564 - mae: 286.4972 - val_loss: 287.5429 - val_mae: 287.4812 - lr: 0.0010\n",
      "Epoch 23/25\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 268.1508 - mae: 268.0869 - val_loss: 268.0056 - val_mae: 267.9389 - lr: 0.0010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/25\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 247.8840 - mae: 247.8151 - val_loss: 248.4766 - val_mae: 248.4047 - lr: 0.0010\n",
      "Epoch 25/25\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 229.0035 - mae: 228.9292 - val_loss: 230.0577 - val_mae: 229.9802 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 777.8275\n",
      "LV_RMSE_12h: 868.8057\n",
      "LV_MAE_24h: 124.5822\n",
      "LV_RMSE_24h: 234.7035\n",
      "LV_MAE_48h: 150.4124\n",
      "LV_RMSE_48h: 258.4712\n",
      "LV_MAE_72h: 140.6280\n",
      "LV_RMSE_72h: 233.7331\n",
      "LV_MAE_mean: 298.3625\n",
      "LV_RMSE_mean: 398.9284\n",
      "\n",
      "LSTM Test metrics:\n",
      "MAE_12h: 523.1557\n",
      "RMSE_12h: 645.0999\n",
      "MAE_24h: 145.7836\n",
      "RMSE_24h: 207.7283\n",
      "MAE_48h: 135.1052\n",
      "RMSE_48h: 198.9211\n",
      "MAE_72h: 142.1749\n",
      "RMSE_72h: 207.3020\n",
      "MAE_mean: 236.5549\n",
      "RMSE_mean: 314.7628\n",
      "\n",
      "=== Station S3001101 ===\n",
      "[GB] Computing feature importances on y_12h ...\n"
     ]
    }
   ],
   "source": [
    "# ========================= PER-STATION: Cross-lags → Top-K → Scale → Window → Conv1D+LSTM =========================\n",
    "# - For each station:\n",
    "#   X = lags of all OTHER stations + target station's non-flow features (no self lags)\n",
    "#   Y = multi-horizon targets (12h, 24h, 48h, 72h) of the target station\n",
    "# - Feature selection with Gradient Boosting (on y_12h)\n",
    "# - Train Conv1D+LSTM\n",
    "# - Metrics per horizon and averaged; optional LV baseline using raw target series\n",
    "# - Saves per-station outputs under ./per_station/<station> and a combined summary CSV\n",
    "\n",
    "import os, gc, warnings, logging\n",
    "import numpy as np, pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "# ---------------- CONFIG ----------------\n",
    "FLOW_COL       = \"Total Flow\"    # column in df with flow values\n",
    "STATION_COL    = \"StationName\"   # column in df that identifies station\n",
    "LAGS           = range(1, 169)   # 1..168 hours of lags\n",
    "LOOKBACK       = 24              # try 168 for weekly context\n",
    "HORIZONS       = [12, 24, 48, 72]\n",
    "ORDERED_COLS   = [f\"y_{h}h\" for h in HORIZONS]\n",
    "TOP_K          = 120\n",
    "EPOCHS         = 25\n",
    "BATCH_SIZE     = 128\n",
    "LR             = 1e-3\n",
    "PATIENCE       = 5\n",
    "PLOT_DIAGNOSTICS = False         # set True to see plots per horizon\n",
    "\n",
    "# TensorFlow hygiene\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
    "os.environ.setdefault(\"TF_FORCE_GPU_ALLOW_GROWTH\", \"true\")\n",
    "tf.get_logger().setLevel(logging.ERROR)\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# ---------------- helpers ----------------\n",
    "def time_split_index(idx, train_ratio=0.7, val_ratio=0.1):\n",
    "    n = len(idx); n_tr = int(n*train_ratio); n_va = int(n*val_ratio)\n",
    "    return idx[:n_tr], idx[n_tr:n_tr+n_va], idx[n_tr+n_va:]\n",
    "\n",
    "def make_windows(X2d, lookback):\n",
    "    T, F = X2d.shape\n",
    "    N = T - lookback + 1\n",
    "    out = np.empty((N, lookback, F), dtype=np.float32)\n",
    "    for i in range(N):\n",
    "        out[i] = X2d[i:i+lookback]\n",
    "    return out\n",
    "\n",
    "def align_windows_with_targets(X_df, Y_df, lookback):\n",
    "    X_df = X_df.sort_index(); Y_df = Y_df.sort_index()\n",
    "    common = X_df.index.intersection(Y_df.index)\n",
    "    X2 = X_df.loc[common].to_numpy(dtype=float)\n",
    "    Y2 = Y_df.loc[common].to_numpy(dtype=float)\n",
    "    X3 = make_windows(X2, lookback)\n",
    "    Y_al = Y2[lookback-1:]\n",
    "    idx_al = common[lookback-1:]\n",
    "    return X3, Y_al, idx_al\n",
    "\n",
    "def build_model(n_features, n_outputs):\n",
    "    inp = keras.Input(shape=(LOOKBACK, n_features))\n",
    "    x = keras.layers.Conv1D(32, 3, padding=\"causal\", activation=\"relu\")(inp)\n",
    "    x = keras.layers.LSTM(128)(x)\n",
    "    x = keras.layers.Dense(128, activation='relu', kernel_regularizer=keras.regularizers.l2(1e-4))(x)\n",
    "    x = keras.layers.Dropout(0.3)(x)\n",
    "    out = keras.layers.Dense(n_outputs)(x)\n",
    "    m = keras.Model(inp, out)\n",
    "    m.compile(optimizer=keras.optimizers.Adam(LR), loss='mae', metrics=['mae'])\n",
    "    return m\n",
    "\n",
    "def metrics_by_horizon(y_true, y_pred, horizons):\n",
    "    res, maes, rmses = {}, [], []\n",
    "    for j, h in enumerate(horizons):\n",
    "        mae  = mean_absolute_error(y_true[:, j], y_pred[:, j])\n",
    "        rmse = mean_squared_error(y_true[:, j], y_pred[:, j], squared=False)\n",
    "        res[f\"MAE_{h}h\"] = float(mae); res[f\"RMSE_{h}h\"] = float(rmse)\n",
    "        maes.append(mae); rmses.append(rmse)\n",
    "    res[\"MAE_mean\"]  = float(np.mean(maes)); res[\"RMSE_mean\"] = float(np.mean(rmses))\n",
    "    return res\n",
    "\n",
    "def lv_baseline_metrics(y_true_df, ref_series, horizons):\n",
    "    \"\"\"Last-value baseline at window end: predict all horizons as the most recent observed ref value.\"\"\"\n",
    "    y_true = y_true_df.to_numpy()\n",
    "    ref_vals = ref_series.loc[y_true_df.index].values.reshape(-1, 1)\n",
    "    preds_lv = np.repeat(ref_vals, repeats=len(horizons), axis=1)\n",
    "    res, maes, rmses = {}, [], []\n",
    "    for j, h in enumerate(horizons):\n",
    "        mae  = mean_absolute_error(y_true[:, j], preds_lv[:, j])\n",
    "        rmse = mean_squared_error(y_true[:, j], preds_lv[:, j], squared=False)\n",
    "        res[f\"LV_MAE_{h}h\"] = float(mae); res[f\"LV_RMSE_{h}h\"] = float(rmse)\n",
    "        maes.append(mae); rmses.append(rmse)\n",
    "    res[\"LV_MAE_mean\"]  = float(np.mean(maes)); res[\"LV_RMSE_mean\"] = float(np.mean(rmses))\n",
    "    return res\n",
    "\n",
    "def clean_features(X):\n",
    "    X = X.copy()\n",
    "    bcols = X.select_dtypes(include=['bool']).columns\n",
    "    if len(bcols): X[bcols] = X[bcols].astype(int)\n",
    "    ocols = X.select_dtypes(include=['object']).columns\n",
    "    for c in ocols: X[c] = pd.to_numeric(X[c], errors='coerce')\n",
    "    non_num = [c for c in X.columns if not np.issubdtype(X[c].dtype, np.number)]\n",
    "    if non_num:\n",
    "        print(\"Dropping non-numeric columns:\", non_num)\n",
    "        X = X.drop(columns=non_num)\n",
    "    X = X.replace([np.inf, -np.inf], np.nan).fillna(0.0)\n",
    "    return X.astype(float)\n",
    "\n",
    "def mae_by_quantile(y, yhat, q=10):\n",
    "    qs = np.linspace(0, 1, q+1)\n",
    "    cuts = np.quantile(y, qs)\n",
    "    out = []\n",
    "    for i in range(q):\n",
    "        mask = (y >= cuts[i]) & (y <= cuts[i+1] if i < q-1 else y <= cuts[i+1])\n",
    "        if mask.sum():\n",
    "            out.append((i+1, float(np.mean(np.abs(yhat[mask]-y[mask])))))\n",
    "    return out\n",
    "\n",
    "# ---------------- data builders ----------------\n",
    "def build_XY_for_target(df, target):\n",
    "    \"\"\"\n",
    "    For a given target station:\n",
    "      X = lags of all OTHER stations + target station's non-flow features (no self-lags)\n",
    "      Y = multi-horizon targets of the target station\n",
    "    \"\"\"\n",
    "    # wide table of flows per station\n",
    "    flow_wide = df.pivot_table(index=df.index, columns=STATION_COL, values=FLOW_COL, aggfunc='mean')\n",
    "    flow_wide = flow_wide.reindex(sorted(flow_wide.columns), axis=1)\n",
    "\n",
    "    # lags for all stations\n",
    "    flow_lags_all = pd.concat(\n",
    "        [flow_wide.shift(L).add_suffix(f'_lag_{L}') for L in LAGS],\n",
    "        axis=1\n",
    "    )\n",
    "\n",
    "    # keep only other stations' lags (exclude self)\n",
    "    X_cross = flow_lags_all.drop(\n",
    "        columns=[c for c in flow_lags_all.columns if c.startswith(f'{target}_lag_')],\n",
    "        errors='ignore'\n",
    "    )\n",
    "\n",
    "    # non-flow features for this target station\n",
    "    X_target_feats = df[df[STATION_COL] == target].drop(\n",
    "        columns=[col for col in ['Station', STATION_COL, FLOW_COL] if col in df.columns] +\n",
    "                [c for c in df.columns if c.startswith('TotalFlow_lag_')],\n",
    "        errors='ignore'\n",
    "    )\n",
    "\n",
    "    # combine and align\n",
    "    X = pd.concat([X_cross, X_target_feats], axis=1).sort_index()\n",
    "\n",
    "    # multi-horizon Y\n",
    "    Y = pd.concat(\n",
    "        {h: df.loc[df[STATION_COL] == target, FLOW_COL].shift(-h) for h in HORIZONS},\n",
    "        axis=1\n",
    "    )\n",
    "    Y.columns = ORDERED_COLS\n",
    "\n",
    "    # burn-in and cleaning\n",
    "    burn_in = max(LAGS)\n",
    "    common_idx = X.index.intersection(Y.index)\n",
    "    X = X.loc[common_idx].iloc[burn_in:]\n",
    "    Y = Y.loc[common_idx].iloc[burn_in:]\n",
    "    mask = ~Y.isna().any(axis=1)\n",
    "    X = X.loc[mask].replace([np.inf, -np.inf], np.nan).fillna(0.0)\n",
    "    Y = Y.loc[mask]\n",
    "\n",
    "    return X, Y\n",
    "\n",
    "# ---------------- per-station runner ----------------\n",
    "def run_one_station(df, target, plot=PLOT_DIAGNOSTICS):\n",
    "    \"\"\"\n",
    "    Build X,Y for `target`, feature-select, scale, window, train, evaluate, save artifacts.\n",
    "    Returns a summary dict with averaged metrics.\n",
    "    \"\"\"\n",
    "    print(f\"\\n=== Station {target} ===\")\n",
    "    station_dir = f\"per_station/{target}\"\n",
    "    os.makedirs(station_dir, exist_ok=True)\n",
    "\n",
    "    # 1) Build X, Y\n",
    "    X, Y = build_XY_for_target(df, target)\n",
    "    X = clean_features(X)\n",
    "\n",
    "    # 2) Split by time\n",
    "    tr_idx, va_idx, te_idx = time_split_index(X.index, train_ratio=0.7, val_ratio=0.1)\n",
    "    X_tr, X_va, X_te = X.loc[tr_idx], X.loc[va_idx], X.loc[te_idx]\n",
    "    Y_tr, Y_va, Y_te = Y.loc[tr_idx], Y.loc[va_idx], Y.loc[te_idx]\n",
    "\n",
    "    # 3) Gradient Boosting feature selection using 12h as proxy\n",
    "    print(\"[GB] Computing feature importances on y_12h ...\")\n",
    "    gbr = GradientBoostingRegressor(n_estimators=600, learning_rate=0.05, max_depth=5, random_state=42)\n",
    "    gbr.fit(X_tr, Y_tr['y_12h'])\n",
    "    imp = pd.Series(gbr.feature_importances_, index=X_tr.columns).sort_values(ascending=False)\n",
    "    keep_cols = imp.head(TOP_K).index.tolist()\n",
    "    print(f\"[GB] Kept top-{TOP_K} features\")\n",
    "\n",
    "    # 4) Scale on train only\n",
    "    scaler = StandardScaler()\n",
    "    Xtr2 = scaler.fit_transform(X_tr[keep_cols])\n",
    "    Xva2 = scaler.transform(X_va[keep_cols])\n",
    "    Xte2 = scaler.transform(X_te[keep_cols])\n",
    "\n",
    "    # 5) Window + align\n",
    "    Xtr3, Ytr2, tr_al_idx = align_windows_with_targets(pd.DataFrame(Xtr2, index=X_tr.index, columns=keep_cols), Y_tr, LOOKBACK)\n",
    "    Xva3, Yva2, va_al_idx = align_windows_with_targets(pd.DataFrame(Xva2, index=X_va.index, columns=keep_cols), Y_va, LOOKBACK)\n",
    "    Xte3, Yte2, te_al_idx = align_windows_with_targets(pd.DataFrame(Xte2, index=X_te.index, columns=keep_cols), Y_te, LOOKBACK)\n",
    "\n",
    "    print(\"Shapes:\",\n",
    "          \"\\n  Xtr3:\", Xtr3.shape, \"Ytr2:\", Ytr2.shape,\n",
    "          \"\\n  Xva3:\", Xva3.shape, \"Yva2:\", Yva2.shape,\n",
    "          \"\\n  Xte3:\", Xte3.shape, \"Yte2:\", Yte2.shape)\n",
    "\n",
    "    # 6) Train\n",
    "    tf.keras.backend.clear_session()\n",
    "    model = build_model(n_features=Xtr3.shape[-1], n_outputs=len(HORIZONS))\n",
    "    cbs = [\n",
    "        keras.callbacks.EarlyStopping(monitor='val_loss', patience=PATIENCE, restore_best_weights=True),\n",
    "        keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, min_lr=1e-5),\n",
    "    ]\n",
    "    _ = model.fit(\n",
    "        Xtr3, Ytr2,\n",
    "        validation_data=(Xva3, Yva2),\n",
    "        epochs=EPOCHS, batch_size=BATCH_SIZE, verbose=1, callbacks=cbs\n",
    "    )\n",
    "\n",
    "    # 7) Evaluate\n",
    "    Yhat_te = model.predict(Xte3, verbose=0)\n",
    "    results = metrics_by_horizon(Yte2, Yhat_te, HORIZONS)\n",
    "\n",
    "    # 8) Build aligned DataFrames\n",
    "    Yte_df  = pd.DataFrame(Yte2, index=te_al_idx, columns=ORDERED_COLS)\n",
    "    Yhat_df = pd.DataFrame(Yhat_te, index=te_al_idx, columns=ORDERED_COLS)\n",
    "\n",
    "    # 9) Baseline using raw target series aligned to window ends\n",
    "    target_series = df.loc[df[STATION_COL] == target, FLOW_COL].sort_index()\n",
    "    baseline_res = lv_baseline_metrics(Yte_df, target_series, HORIZONS)\n",
    "\n",
    "    print(\"\\nBaseline (LV) metrics:\")\n",
    "    for k, v in baseline_res.items():\n",
    "        print(f\"{k}: {v:.4f}\")\n",
    "\n",
    "    print(\"\\nLSTM Test metrics:\")\n",
    "    for k, v in results.items():\n",
    "        print(f\"{k}: {v:.4f}\")\n",
    "\n",
    "    # 10) Diagnostics\n",
    "    if plot:\n",
    "        for col in ORDERED_COLS:\n",
    "            plt.figure()\n",
    "            plt.scatter(Yte_df[col].values, Yhat_df[col].values, s=6, alpha=0.5)\n",
    "            plt.xlabel(f\"Actual {col}\"); plt.ylabel(f\"Predicted {col}\")\n",
    "            plt.title(f\"Pred vs Actual — {col}\"); plt.grid(True); plt.show()\n",
    "\n",
    "        for col in ORDERED_COLS:\n",
    "            res = (Yhat_df[col] - Yte_df[col]).values\n",
    "            plt.figure()\n",
    "            plt.hist(res, bins=40)\n",
    "            plt.title(f\"Residuals — {col}\")\n",
    "            plt.xlabel(\"Error\"); plt.ylabel(\"Count\"); plt.grid(True); plt.show()\n",
    "\n",
    "        for h in HORIZONS:\n",
    "            y = Yte_df[f'y_{h}h'].values; yhat = Yhat_df[f'y_{h}h'].values\n",
    "            print(f\"MAE by decile for {h}h:\", mae_by_quantile(y, yhat))\n",
    "\n",
    "    # 11) Save artifacts\n",
    "    # metrics table (model + baseline)\n",
    "    final_metrics = {**{k: float(v) for k, v in results.items()},\n",
    "                     **{k: float(v) for k, v in baseline_res.items()}}\n",
    "    pd.DataFrame(list(final_metrics.items()), columns=[\"metric\", \"value\"]).to_csv(f\"{station_dir}/metrics.csv\", index=False)\n",
    "\n",
    "    # predictions vs actuals\n",
    "    pd.concat([Yte_df.add_prefix(\"ytrue_\"), Yhat_df.add_prefix(\"ypred_\")], axis=1).to_csv(f\"{station_dir}/preds_test.csv\")\n",
    "\n",
    "    # feature importance + kept features\n",
    "    pd.DataFrame({'feature': imp.index, 'importance': imp.values}).to_csv(f\"{station_dir}/gb_importance.csv\", index=False)\n",
    "    pd.Series(keep_cols, name=\"kept_features\").to_csv(f\"{station_dir}/kept_features.csv\", index=False)\n",
    "\n",
    "    # model\n",
    "    model.save(f\"{station_dir}/model.h5\")\n",
    "\n",
    "    gc.collect()\n",
    "\n",
    "    # return a summary row\n",
    "    row = {\"station\": target}\n",
    "    row.update(final_metrics)\n",
    "    return row\n",
    "\n",
    "# ---------------- main: run all stations ----------------\n",
    "# Expect: a DataFrame `df` in memory with:\n",
    "# - DateTimeIndex\n",
    "# - columns: STATION_COL, FLOW_COL, plus non-flow features\n",
    "# Example: df = ...  (load/prepare your DataFrame before running this script)\n",
    "\n",
    "def run_all_stations(df):\n",
    "    stations = sorted(df[STATION_COL].dropna().unique())\n",
    "    os.makedirs(\"per_station\", exist_ok=True)\n",
    "\n",
    "    summary_rows = []\n",
    "    for s in stations:\n",
    "        try:\n",
    "            row = run_one_station(df, s, plot=PLOT_DIAGNOSTICS)\n",
    "            summary_rows.append(row)\n",
    "        except Exception as e:\n",
    "            print(f\"[{s}] ERROR: {e}\")\n",
    "\n",
    "    if summary_rows:\n",
    "        summary_df = pd.DataFrame(summary_rows).sort_values(by=\"MAE_mean\")\n",
    "        summary_df.to_csv(\"summary_all_stations.csv\", index=False)\n",
    "        print(\"\\nSaved combined summary: summary_all_stations.csv\")\n",
    "    else:\n",
    "        print(\"No station results produced. Check inputs and schema.\")\n",
    "\n",
    "# ---------------- run ----------------\n",
    "# Uncomment the next line after you have `df` ready in memory:\n",
    "run_all_stations(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "06025df6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[prep] computing flow_wide...\n",
      "\n",
      "=== Station S3001021 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1377 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1354, 24, 400) Ytr2: (1354, 4) \n",
      "  Xva3: (197, 24, 400) Yva2: (197, 4) \n",
      "  Xte3: (348, 24, 400) Yte2: (348, 4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-16 23:04:38.977689: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:47] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
      "2025-10-16 23:04:38.978084: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 14728 MB memory:  -> device: 0, name: Tesla V100-PCIE-16GB, pci bus id: 0000:5e:00.0, compute capability: 7.0\n",
      "2025-10-16 23:04:38.978847: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:47] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
      "2025-10-16 23:04:38.978876: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 14728 MB memory:  -> device: 1, name: Tesla V100-PCIE-16GB, pci bus id: 0000:af:00.0, compute capability: 7.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-16 23:04:43.635157: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8907\n",
      "2025-10-16 23:04:49.928899: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f4d97e82430 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2025-10-16 23:04:49.928969: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla V100-PCIE-16GB, Compute Capability 7.0\n",
      "2025-10-16 23:04:49.928986: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (1): Tesla V100-PCIE-16GB, Compute Capability 7.0\n",
      "2025-10-16 23:04:50.441208: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:255] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2025-10-16 23:04:53.311798: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 19s 73ms/step - loss: 985.5366 - mae: 985.5238 - val_loss: 976.9126 - val_mae: 976.8997 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 980.0068 - mae: 979.9939 - val_loss: 968.9565 - val_mae: 968.9434 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 0s 19ms/step - loss: 970.0600 - mae: 970.0467 - val_loss: 956.7532 - val_mae: 956.7397 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 0s 17ms/step - loss: 956.5344 - mae: 956.5205 - val_loss: 941.2291 - val_mae: 941.2146 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 938.8848 - mae: 938.8698 - val_loss: 921.5512 - val_mae: 921.5356 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 0s 18ms/step - loss: 917.8792 - mae: 917.8629 - val_loss: 898.7141 - val_mae: 898.6968 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 0s 18ms/step - loss: 895.0976 - mae: 895.0796 - val_loss: 875.6142 - val_mae: 875.5949 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 0s 17ms/step - loss: 872.4076 - mae: 872.3875 - val_loss: 854.3829 - val_mae: 854.3615 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 0s 17ms/step - loss: 851.2010 - mae: 851.1786 - val_loss: 834.1849 - val_mae: 834.1612 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 0s 17ms/step - loss: 831.0132 - mae: 830.9883 - val_loss: 815.3167 - val_mae: 815.2905 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 0s 17ms/step - loss: 812.4380 - mae: 812.4105 - val_loss: 797.2193 - val_mae: 797.1904 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 794.7532 - mae: 794.7230 - val_loss: 779.0733 - val_mae: 779.0414 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 776.9380 - mae: 776.9047 - val_loss: 761.3025 - val_mae: 761.2676 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 0s 17ms/step - loss: 759.9416 - mae: 759.9052 - val_loss: 744.9100 - val_mae: 744.8718 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 0s 17ms/step - loss: 743.9672 - mae: 743.9276 - val_loss: 729.4244 - val_mae: 729.3830 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 729.7424 - mae: 729.6996 - val_loss: 714.6870 - val_mae: 714.6423 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 0s 17ms/step - loss: 716.3920 - mae: 716.3458 - val_loss: 701.5037 - val_mae: 701.4557 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 0s 17ms/step - loss: 705.5551 - mae: 705.5056 - val_loss: 690.6356 - val_mae: 690.5844 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 0s 18ms/step - loss: 694.8741 - mae: 694.8215 - val_loss: 680.4855 - val_mae: 680.4312 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 0s 17ms/step - loss: 686.8795 - mae: 686.8237 - val_loss: 669.0792 - val_mae: 669.0218 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 1103.4281\n",
      "LV_RMSE_12h: 1243.6606\n",
      "LV_MAE_24h: 199.2816\n",
      "LV_RMSE_24h: 310.0421\n",
      "LV_MAE_48h: 275.3017\n",
      "LV_RMSE_48h: 416.9476\n",
      "LV_MAE_72h: 235.5575\n",
      "LV_RMSE_72h: 361.5775\n",
      "LV_MAE_mean: 453.3922\n",
      "LV_RMSE_mean: 583.0570\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 586.9324\n",
      "RMSE_12h: 718.3947\n",
      "MAE_24h: 570.1031\n",
      "RMSE_24h: 715.7684\n",
      "MAE_48h: 565.3077\n",
      "RMSE_48h: 701.0273\n",
      "MAE_72h: 564.2121\n",
      "RMSE_72h: 712.1713\n",
      "MAE_mean: 571.6389\n",
      "RMSE_mean: 711.8405\n",
      "\n",
      "=== Station S3001022 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1376 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1353, 24, 400) Ytr2: (1353, 4) \n",
      "  Xva3: (197, 24, 400) Yva2: (197, 4) \n",
      "  Xte3: (347, 24, 400) Yte2: (347, 4)\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 3s 57ms/step - loss: 571.4417 - mae: 571.4289 - val_loss: 591.3988 - val_mae: 591.3859 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 564.7551 - mae: 564.7421 - val_loss: 581.6603 - val_mae: 581.6470 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 553.4002 - mae: 553.3868 - val_loss: 569.2940 - val_mae: 569.2803 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 540.4207 - mae: 540.4066 - val_loss: 556.1044 - val_mae: 556.0898 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 527.7010 - mae: 527.6859 - val_loss: 542.2751 - val_mae: 542.2593 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 514.5703 - mae: 514.5539 - val_loss: 528.8766 - val_mae: 528.8594 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 501.9684 - mae: 501.9505 - val_loss: 515.8701 - val_mae: 515.8512 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 0s 18ms/step - loss: 489.0290 - mae: 489.0093 - val_loss: 502.8322 - val_mae: 502.8115 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 477.6432 - mae: 477.6217 - val_loss: 489.4514 - val_mae: 489.4286 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 463.2288 - mae: 463.2051 - val_loss: 475.0002 - val_mae: 474.9752 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 447.8050 - mae: 447.7789 - val_loss: 456.5233 - val_mae: 456.4957 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 428.5181 - mae: 428.4893 - val_loss: 437.4786 - val_mae: 437.4481 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 409.7938 - mae: 409.7620 - val_loss: 417.7873 - val_mae: 417.7536 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 390.0651 - mae: 390.0298 - val_loss: 396.5147 - val_mae: 396.4774 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 368.8302 - mae: 368.7910 - val_loss: 375.6659 - val_mae: 375.6245 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 350.2578 - mae: 350.2145 - val_loss: 355.3408 - val_mae: 355.2951 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 331.0534 - mae: 331.0057 - val_loss: 336.9455 - val_mae: 336.8952 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 313.7485 - mae: 313.6962 - val_loss: 318.3492 - val_mae: 318.2943 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 296.2271 - mae: 296.1701 - val_loss: 300.4231 - val_mae: 300.3636 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 279.5337 - mae: 279.4720 - val_loss: 282.3626 - val_mae: 282.2982 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 773.9280\n",
      "LV_RMSE_12h: 866.3762\n",
      "LV_MAE_24h: 130.0836\n",
      "LV_RMSE_24h: 241.9860\n",
      "LV_MAE_48h: 153.4438\n",
      "LV_RMSE_48h: 264.7818\n",
      "LV_MAE_72h: 142.5043\n",
      "LV_RMSE_72h: 238.4465\n",
      "LV_MAE_mean: 299.9899\n",
      "LV_RMSE_mean: 402.8976\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 503.8270\n",
      "RMSE_12h: 627.3729\n",
      "MAE_24h: 203.5502\n",
      "RMSE_24h: 272.9403\n",
      "MAE_48h: 209.1046\n",
      "RMSE_48h: 281.8736\n",
      "MAE_72h: 212.4967\n",
      "RMSE_72h: 286.0321\n",
      "MAE_mean: 282.2446\n",
      "RMSE_mean: 367.0547\n",
      "\n",
      "=== Station S3001101 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1376 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1353, 24, 400) Ytr2: (1353, 4) \n",
      "  Xva3: (197, 24, 400) Yva2: (197, 4) \n",
      "  Xte3: (347, 24, 400) Yte2: (347, 4)\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 3s 52ms/step - loss: 145.0117 - mae: 144.9991 - val_loss: 147.3092 - val_mae: 147.2966 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 139.1828 - mae: 139.1701 - val_loss: 140.3589 - val_mae: 140.3461 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 131.8140 - mae: 131.8011 - val_loss: 133.3484 - val_mae: 133.3352 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 124.8806 - mae: 124.8672 - val_loss: 127.0189 - val_mae: 127.0051 - lr: 0.0010\n",
      "Epoch 5/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 11ms/step - loss: 119.1143 - mae: 119.1002 - val_loss: 120.8455 - val_mae: 120.8309 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 113.4181 - mae: 113.4031 - val_loss: 114.5063 - val_mae: 114.4908 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 107.4211 - mae: 107.4052 - val_loss: 108.0918 - val_mae: 108.0752 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 101.1675 - mae: 101.1505 - val_loss: 101.5423 - val_mae: 101.5247 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 94.5794 - mae: 94.5612 - val_loss: 94.3277 - val_mae: 94.3087 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 87.5987 - mae: 87.5791 - val_loss: 87.6815 - val_mae: 87.6611 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 80.8885 - mae: 80.8674 - val_loss: 80.6949 - val_mae: 80.6729 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 74.2028 - mae: 74.1800 - val_loss: 73.7759 - val_mae: 73.7521 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 68.7734 - mae: 68.7488 - val_loss: 68.3025 - val_mae: 68.2769 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 65.0685 - mae: 65.0421 - val_loss: 65.3722 - val_mae: 65.3451 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 62.7151 - mae: 62.6873 - val_loss: 62.1542 - val_mae: 62.1257 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 60.1508 - mae: 60.1217 - val_loss: 60.0321 - val_mae: 60.0024 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 57.7515 - mae: 57.7213 - val_loss: 57.6427 - val_mae: 57.6119 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 55.8895 - mae: 55.8581 - val_loss: 55.9709 - val_mae: 55.9388 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 54.2407 - mae: 54.2080 - val_loss: 53.9253 - val_mae: 53.8918 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 52.2456 - mae: 52.2117 - val_loss: 51.7797 - val_mae: 51.7452 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 198.2161\n",
      "LV_RMSE_12h: 235.2897\n",
      "LV_MAE_24h: 50.1210\n",
      "LV_RMSE_24h: 78.7415\n",
      "LV_MAE_48h: 64.3285\n",
      "LV_RMSE_48h: 98.8229\n",
      "LV_MAE_72h: 54.2277\n",
      "LV_RMSE_72h: 82.2271\n",
      "LV_MAE_mean: 91.7233\n",
      "LV_RMSE_mean: 123.7703\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 90.6535\n",
      "RMSE_12h: 138.1106\n",
      "MAE_24h: 48.5198\n",
      "RMSE_24h: 74.7884\n",
      "MAE_48h: 45.6718\n",
      "RMSE_48h: 71.7773\n",
      "MAE_72h: 45.6777\n",
      "RMSE_72h: 71.6417\n",
      "MAE_mean: 57.6307\n",
      "RMSE_mean: 89.0795\n",
      "\n",
      "=== Station S3001102 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1377 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1354, 24, 400) Ytr2: (1354, 4) \n",
      "  Xva3: (197, 24, 400) Yva2: (197, 4) \n",
      "  Xte3: (348, 24, 400) Yte2: (348, 4)\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 3s 55ms/step - loss: 630.5553 - mae: 630.5427 - val_loss: 611.4765 - val_mae: 611.4638 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 625.6551 - mae: 625.6424 - val_loss: 604.2990 - val_mae: 604.2861 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 616.7013 - mae: 616.6883 - val_loss: 593.3917 - val_mae: 593.3785 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 604.6357 - mae: 604.6221 - val_loss: 579.4864 - val_mae: 579.4724 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 588.9603 - mae: 588.9458 - val_loss: 561.9504 - val_mae: 561.9354 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 570.2305 - mae: 570.2148 - val_loss: 542.0879 - val_mae: 542.0714 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 550.4247 - mae: 550.4075 - val_loss: 522.1654 - val_mae: 522.1472 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 530.9744 - mae: 530.9553 - val_loss: 503.8257 - val_mae: 503.8055 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 512.6829 - mae: 512.6617 - val_loss: 487.1559 - val_mae: 487.1336 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 495.7164 - mae: 495.6932 - val_loss: 471.5496 - val_mae: 471.5251 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 480.6073 - mae: 480.5817 - val_loss: 456.3294 - val_mae: 456.3025 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 465.7601 - mae: 465.7321 - val_loss: 442.1900 - val_mae: 442.1606 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 452.4890 - mae: 452.4584 - val_loss: 429.1705 - val_mae: 429.1385 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 440.0339 - mae: 440.0008 - val_loss: 417.6963 - val_mae: 417.6617 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 428.3041 - mae: 428.2684 - val_loss: 403.8533 - val_mae: 403.8161 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 411.8858 - mae: 411.8474 - val_loss: 379.0126 - val_mae: 378.9727 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 386.3543 - mae: 386.3130 - val_loss: 354.8897 - val_mae: 354.8466 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 365.3249 - mae: 365.2803 - val_loss: 335.7921 - val_mae: 335.7455 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 346.9485 - mae: 346.9002 - val_loss: 317.9269 - val_mae: 317.8764 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 328.5368 - mae: 328.4844 - val_loss: 300.9833 - val_mae: 300.9286 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 649.6063\n",
      "LV_RMSE_12h: 722.7619\n",
      "LV_MAE_24h: 111.7069\n",
      "LV_RMSE_24h: 169.7435\n",
      "LV_MAE_48h: 155.3592\n",
      "LV_RMSE_48h: 230.7145\n",
      "LV_MAE_72h: 135.9713\n",
      "LV_RMSE_72h: 210.3003\n",
      "LV_MAE_mean: 263.1609\n",
      "LV_RMSE_mean: 333.3800\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 442.9883\n",
      "RMSE_12h: 541.1794\n",
      "MAE_24h: 184.7844\n",
      "RMSE_24h: 269.5723\n",
      "MAE_48h: 193.4891\n",
      "RMSE_48h: 283.6526\n",
      "MAE_72h: 184.6539\n",
      "RMSE_72h: 269.9467\n",
      "MAE_mean: 251.4789\n",
      "RMSE_mean: 341.0878\n",
      "\n",
      "=== Station S3001111 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1377 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1354, 24, 400) Ytr2: (1354, 4) \n",
      "  Xva3: (197, 24, 400) Yva2: (197, 4) \n",
      "  Xte3: (348, 24, 400) Yte2: (348, 4)\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 3s 50ms/step - loss: 557.3853 - mae: 557.3728 - val_loss: 533.8544 - val_mae: 533.8418 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 554.6143 - mae: 554.6016 - val_loss: 530.0018 - val_mae: 529.9890 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 549.9397 - mae: 549.9266 - val_loss: 524.6816 - val_mae: 524.6682 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 543.7466 - mae: 543.7330 - val_loss: 517.9097 - val_mae: 517.8957 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 535.9002 - mae: 535.8857 - val_loss: 509.8031 - val_mae: 509.7878 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 526.7878 - mae: 526.7720 - val_loss: 500.1459 - val_mae: 500.1291 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 516.0063 - mae: 515.9888 - val_loss: 489.0060 - val_mae: 488.9872 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 503.5448 - mae: 503.5251 - val_loss: 476.1609 - val_mae: 476.1398 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 489.9727 - mae: 489.9505 - val_loss: 461.9853 - val_mae: 461.9614 - lr: 0.0010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/20\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 474.6621 - mae: 474.6369 - val_loss: 445.9778 - val_mae: 445.9507 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 457.2721 - mae: 457.2434 - val_loss: 429.2408 - val_mae: 429.2100 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 439.4339 - mae: 439.4013 - val_loss: 411.0964 - val_mae: 411.0614 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 419.9505 - mae: 419.9136 - val_loss: 392.4302 - val_mae: 392.3907 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 399.8652 - mae: 399.8235 - val_loss: 372.3402 - val_mae: 372.2956 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 376.4096 - mae: 376.3627 - val_loss: 350.5841 - val_mae: 350.5340 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 355.4102 - mae: 355.3577 - val_loss: 328.3774 - val_mae: 328.3214 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 334.2172 - mae: 334.1587 - val_loss: 307.3880 - val_mae: 307.3260 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 310.6751 - mae: 310.6104 - val_loss: 288.0137 - val_mae: 287.9454 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 0s 18ms/step - loss: 291.4514 - mae: 291.3802 - val_loss: 269.2114 - val_mae: 269.1365 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 270.1375 - mae: 270.0598 - val_loss: 252.5691 - val_mae: 252.4878 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 734.7845\n",
      "LV_RMSE_12h: 810.7036\n",
      "LV_MAE_24h: 175.8477\n",
      "LV_RMSE_24h: 269.8237\n",
      "LV_MAE_48h: 248.7672\n",
      "LV_RMSE_48h: 354.0738\n",
      "LV_MAE_72h: 223.4598\n",
      "LV_RMSE_72h: 337.8562\n",
      "LV_MAE_mean: 345.7148\n",
      "LV_RMSE_mean: 443.1143\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 422.8245\n",
      "RMSE_12h: 553.1801\n",
      "MAE_24h: 175.1078\n",
      "RMSE_24h: 265.3482\n",
      "MAE_48h: 188.9575\n",
      "RMSE_48h: 271.4648\n",
      "MAE_72h: 192.8911\n",
      "RMSE_72h: 272.3186\n",
      "MAE_mean: 244.9452\n",
      "RMSE_mean: 340.5779\n",
      "\n",
      "=== Station S3001121 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1377 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1354, 24, 400) Ytr2: (1354, 4) \n",
      "  Xva3: (197, 24, 400) Yva2: (197, 4) \n",
      "  Xte3: (348, 24, 400) Yte2: (348, 4)\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 3s 49ms/step - loss: 555.7132 - mae: 555.7003 - val_loss: 537.2418 - val_mae: 537.2289 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 551.8130 - mae: 551.7999 - val_loss: 532.1101 - val_mae: 532.0970 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 545.8024 - mae: 545.7890 - val_loss: 525.1703 - val_mae: 525.1566 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 538.1701 - mae: 538.1560 - val_loss: 516.4054 - val_mae: 516.3908 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 528.7565 - mae: 528.7414 - val_loss: 506.3483 - val_mae: 506.3325 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 518.0460 - mae: 518.0295 - val_loss: 494.4148 - val_mae: 494.3975 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 505.9709 - mae: 505.9526 - val_loss: 480.9610 - val_mae: 480.9416 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 491.5013 - mae: 491.4809 - val_loss: 465.4493 - val_mae: 465.4274 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 476.4048 - mae: 476.3817 - val_loss: 448.5847 - val_mae: 448.5599 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 458.9284 - mae: 458.9023 - val_loss: 430.7460 - val_mae: 430.7180 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 441.1299 - mae: 441.1003 - val_loss: 412.6355 - val_mae: 412.6037 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 422.6498 - mae: 422.6162 - val_loss: 393.3018 - val_mae: 393.2659 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 402.4958 - mae: 402.4578 - val_loss: 373.1213 - val_mae: 373.0808 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 379.9078 - mae: 379.8651 - val_loss: 351.7321 - val_mae: 351.6866 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 357.2576 - mae: 357.2096 - val_loss: 330.2854 - val_mae: 330.2344 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 335.1898 - mae: 335.1363 - val_loss: 307.3935 - val_mae: 307.3366 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 312.2537 - mae: 312.1942 - val_loss: 289.6043 - val_mae: 289.5415 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 292.2363 - mae: 292.1708 - val_loss: 269.1677 - val_mae: 269.0988 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 272.9170 - mae: 272.8453 - val_loss: 250.8265 - val_mae: 250.7512 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 254.2464 - mae: 254.1684 - val_loss: 240.2198 - val_mae: 240.1385 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 746.5345\n",
      "LV_RMSE_12h: 820.7906\n",
      "LV_MAE_24h: 193.3678\n",
      "LV_RMSE_24h: 305.6234\n",
      "LV_MAE_48h: 284.2328\n",
      "LV_RMSE_48h: 405.5431\n",
      "LV_MAE_72h: 253.4425\n",
      "LV_RMSE_72h: 377.6442\n",
      "LV_MAE_mean: 369.3944\n",
      "LV_RMSE_mean: 477.4003\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 442.4054\n",
      "RMSE_12h: 595.1324\n",
      "MAE_24h: 172.5347\n",
      "RMSE_24h: 261.7139\n",
      "MAE_48h: 201.0678\n",
      "RMSE_48h: 294.3688\n",
      "MAE_72h: 205.2743\n",
      "RMSE_72h: 296.4235\n",
      "MAE_mean: 255.3206\n",
      "RMSE_mean: 361.9096\n",
      "\n",
      "=== Station S3003011 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1376 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1353, 24, 400) Ytr2: (1353, 4) \n",
      "  Xva3: (197, 24, 400) Yva2: (197, 4) \n",
      "  Xte3: (348, 24, 400) Yte2: (348, 4)\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 3s 51ms/step - loss: 298.1839 - mae: 298.1712 - val_loss: 297.1418 - val_mae: 297.1291 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 291.4260 - mae: 291.4132 - val_loss: 287.4224 - val_mae: 287.4094 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 280.0817 - mae: 280.0686 - val_loss: 274.4910 - val_mae: 274.4775 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 266.7976 - mae: 266.7838 - val_loss: 262.0335 - val_mae: 262.0190 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 254.0182 - mae: 254.0032 - val_loss: 249.5340 - val_mae: 249.5183 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 241.0590 - mae: 241.0427 - val_loss: 236.7634 - val_mae: 236.7462 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 228.7613 - mae: 228.7434 - val_loss: 224.5378 - val_mae: 224.5189 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 216.9949 - mae: 216.9751 - val_loss: 213.5719 - val_mae: 213.5510 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 207.2746 - mae: 207.2528 - val_loss: 203.8367 - val_mae: 203.8138 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 197.7880 - mae: 197.7642 - val_loss: 193.7757 - val_mae: 193.7507 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 187.1315 - mae: 187.1057 - val_loss: 180.2626 - val_mae: 180.2355 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 173.5880 - mae: 173.5598 - val_loss: 166.1156 - val_mae: 166.0861 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 157.9634 - mae: 157.9329 - val_loss: 151.3685 - val_mae: 151.3365 - lr: 0.0010\n",
      "Epoch 14/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 12ms/step - loss: 143.4149 - mae: 143.3817 - val_loss: 134.8854 - val_mae: 134.8506 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 128.6983 - mae: 128.6622 - val_loss: 120.0221 - val_mae: 119.9843 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 116.1434 - mae: 116.1041 - val_loss: 106.6910 - val_mae: 106.6499 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 105.9926 - mae: 105.9501 - val_loss: 97.8176 - val_mae: 97.7735 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 100.7543 - mae: 100.7094 - val_loss: 93.0014 - val_mae: 92.9554 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 97.7191 - mae: 97.6727 - val_loss: 91.3330 - val_mae: 91.2861 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 95.8898 - mae: 95.8426 - val_loss: 89.4787 - val_mae: 89.4312 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 333.6322\n",
      "LV_RMSE_12h: 367.3687\n",
      "LV_MAE_24h: 57.9713\n",
      "LV_RMSE_24h: 84.1679\n",
      "LV_MAE_48h: 67.3822\n",
      "LV_RMSE_48h: 99.0183\n",
      "LV_MAE_72h: 59.8046\n",
      "LV_RMSE_72h: 87.1699\n",
      "LV_MAE_mean: 129.6975\n",
      "LV_RMSE_mean: 159.4312\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 224.9242\n",
      "RMSE_12h: 272.4496\n",
      "MAE_24h: 56.1017\n",
      "RMSE_24h: 86.8044\n",
      "MAE_48h: 57.1952\n",
      "RMSE_48h: 88.2759\n",
      "MAE_72h: 59.7978\n",
      "RMSE_72h: 90.7279\n",
      "MAE_mean: 99.5047\n",
      "RMSE_mean: 134.5645\n",
      "\n",
      "=== Station S3003041 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1269 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1246, 24, 400) Ytr2: (1246, 4) \n",
      "  Xva3: (182, 24, 400) Yva2: (182, 4) \n",
      "  Xte3: (316, 24, 400) Yte2: (316, 4)\n",
      "Epoch 1/20\n",
      "10/10 [==============================] - 3s 62ms/step - loss: 106.1706 - mae: 106.1579 - val_loss: 102.8364 - val_mae: 102.8236 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 101.0594 - mae: 101.0466 - val_loss: 96.0232 - val_mae: 96.0103 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 93.1970 - mae: 93.1839 - val_loss: 87.4289 - val_mae: 87.4156 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 84.6892 - mae: 84.6757 - val_loss: 79.4909 - val_mae: 79.4770 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 76.8701 - mae: 76.8559 - val_loss: 71.8425 - val_mae: 71.8278 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 69.5031 - mae: 69.4880 - val_loss: 64.5455 - val_mae: 64.5298 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 63.3263 - mae: 63.3102 - val_loss: 58.5716 - val_mae: 58.5549 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 58.6190 - mae: 58.6018 - val_loss: 54.5836 - val_mae: 54.5659 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 54.7586 - mae: 54.7405 - val_loss: 51.3903 - val_mae: 51.3718 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 51.6784 - mae: 51.6595 - val_loss: 47.7750 - val_mae: 47.7558 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 47.8815 - mae: 47.8621 - val_loss: 42.6817 - val_mae: 42.6619 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 43.9323 - mae: 43.9123 - val_loss: 38.5927 - val_mae: 38.5723 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 40.6678 - mae: 40.6471 - val_loss: 35.1219 - val_mae: 35.1009 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 38.6815 - mae: 38.6602 - val_loss: 33.0431 - val_mae: 33.0216 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 37.5680 - mae: 37.5464 - val_loss: 31.9868 - val_mae: 31.9649 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 36.7110 - mae: 36.6890 - val_loss: 31.2310 - val_mae: 31.2088 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 35.5091 - mae: 35.4868 - val_loss: 29.7696 - val_mae: 29.7471 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 34.5336 - mae: 34.5110 - val_loss: 28.7053 - val_mae: 28.6824 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 33.5980 - mae: 33.5750 - val_loss: 27.5071 - val_mae: 27.4838 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 32.4974 - mae: 32.4738 - val_loss: 26.4155 - val_mae: 26.3917 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 110.7848\n",
      "LV_RMSE_12h: 138.4122\n",
      "LV_MAE_24h: 28.6456\n",
      "LV_RMSE_24h: 68.6527\n",
      "LV_MAE_48h: 30.9335\n",
      "LV_RMSE_48h: 69.0873\n",
      "LV_MAE_72h: 28.8449\n",
      "LV_RMSE_72h: 68.3152\n",
      "LV_MAE_mean: 49.8022\n",
      "LV_RMSE_mean: 86.1169\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 60.2526\n",
      "RMSE_12h: 84.3532\n",
      "MAE_24h: 22.3760\n",
      "RMSE_24h: 51.3075\n",
      "MAE_48h: 22.4998\n",
      "RMSE_48h: 51.5108\n",
      "MAE_72h: 22.5922\n",
      "RMSE_72h: 51.3625\n",
      "MAE_mean: 31.9302\n",
      "RMSE_mean: 59.6335\n",
      "\n",
      "=== Station S3003044 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 285 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (262, 24, 400) Ytr2: (262, 4) \n",
      "  Xva3: (41, 24, 400) Yva2: (41, 4) \n",
      "  Xte3: (36, 24, 400) Yte2: (36, 4)\n",
      "Epoch 1/20\n",
      "3/3 [==============================] - 3s 243ms/step - loss: 42.6141 - mae: 42.6014 - val_loss: 52.4837 - val_mae: 52.4710 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 42.0491 - mae: 42.0364 - val_loss: 51.8781 - val_mae: 51.8654 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 41.3664 - mae: 41.3537 - val_loss: 51.2105 - val_mae: 51.1978 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 40.6209 - mae: 40.6083 - val_loss: 50.5486 - val_mae: 50.5359 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 39.8979 - mae: 39.8852 - val_loss: 49.8049 - val_mae: 49.7922 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 39.1124 - mae: 39.0997 - val_loss: 48.9442 - val_mae: 48.9315 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 38.1762 - mae: 38.1635 - val_loss: 48.0448 - val_mae: 48.0320 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 37.1301 - mae: 37.1173 - val_loss: 47.0814 - val_mae: 47.0685 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 36.2683 - mae: 36.2555 - val_loss: 46.0844 - val_mae: 46.0715 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 35.1956 - mae: 35.1827 - val_loss: 45.0490 - val_mae: 45.0360 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 34.1609 - mae: 34.1479 - val_loss: 43.9478 - val_mae: 43.9346 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 33.2863 - mae: 33.2732 - val_loss: 42.7696 - val_mae: 42.7564 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 32.2001 - mae: 32.1868 - val_loss: 41.5596 - val_mae: 41.5462 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 31.3742 - mae: 31.3609 - val_loss: 40.2753 - val_mae: 40.2618 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 30.4811 - mae: 30.4675 - val_loss: 38.9706 - val_mae: 38.9570 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 29.7132 - mae: 29.6996 - val_loss: 37.7704 - val_mae: 37.7566 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 28.9630 - mae: 28.9492 - val_loss: 36.7361 - val_mae: 36.7221 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 28.4469 - mae: 28.4329 - val_loss: 35.7053 - val_mae: 35.6912 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 27.9884 - mae: 27.9742 - val_loss: 34.7460 - val_mae: 34.7318 - lr: 0.0010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/20\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 27.3802 - mae: 27.3659 - val_loss: 33.7308 - val_mae: 33.7163 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 93.3889\n",
      "LV_RMSE_12h: 101.9147\n",
      "LV_MAE_24h: 11.1944\n",
      "LV_RMSE_24h: 19.8935\n",
      "LV_MAE_48h: 33.4444\n",
      "LV_RMSE_48h: 52.4569\n",
      "LV_MAE_72h: 45.3333\n",
      "LV_RMSE_72h: 64.9675\n",
      "LV_MAE_mean: 45.8403\n",
      "LV_RMSE_mean: 59.8081\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 47.1591\n",
      "RMSE_12h: 66.2330\n",
      "MAE_24h: 32.1192\n",
      "RMSE_24h: 47.7857\n",
      "MAE_48h: 19.6767\n",
      "RMSE_48h: 32.4799\n",
      "MAE_72h: 9.4818\n",
      "RMSE_72h: 12.3423\n",
      "MAE_mean: 27.1092\n",
      "RMSE_mean: 39.7102\n",
      "\n",
      "=== Station S3003054 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 218 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (195, 24, 400) Ytr2: (195, 4) \n",
      "  Xva3: (32, 24, 400) Yva2: (32, 4) \n",
      "  Xte3: (16, 24, 400) Yte2: (16, 4)\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 3s 429ms/step - loss: 4.2114 - mae: 4.1986 - val_loss: 4.4426 - val_mae: 4.4298 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 3.8218 - mae: 3.8090 - val_loss: 4.0800 - val_mae: 4.0673 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 3.4590 - mae: 3.4462 - val_loss: 3.7640 - val_mae: 3.7512 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 3.1648 - mae: 3.1520 - val_loss: 3.4776 - val_mae: 3.4648 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 2.8673 - mae: 2.8545 - val_loss: 3.2041 - val_mae: 3.1912 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 2.6716 - mae: 2.6587 - val_loss: 2.8969 - val_mae: 2.8840 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 2.4920 - mae: 2.4791 - val_loss: 2.6905 - val_mae: 2.6777 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 2.4032 - mae: 2.3903 - val_loss: 2.5639 - val_mae: 2.5510 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 2.3281 - mae: 2.3152 - val_loss: 2.4841 - val_mae: 2.4712 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 2.3264 - mae: 2.3135 - val_loss: 2.4269 - val_mae: 2.4140 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 2.3137 - mae: 2.3008 - val_loss: 2.3814 - val_mae: 2.3685 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 2.2897 - mae: 2.2768 - val_loss: 2.3526 - val_mae: 2.3397 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 2.1783 - mae: 2.1654 - val_loss: 2.3404 - val_mae: 2.3275 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 2.1349 - mae: 2.1220 - val_loss: 2.3492 - val_mae: 2.3363 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 2.1792 - mae: 2.1664 - val_loss: 2.3605 - val_mae: 2.3476 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 2.1383 - mae: 2.1254 - val_loss: 2.3564 - val_mae: 2.3436 - lr: 5.0000e-04\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 2.1019 - mae: 2.0890 - val_loss: 2.3580 - val_mae: 2.3452 - lr: 5.0000e-04\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 2.0759 - mae: 2.0631 - val_loss: 2.3582 - val_mae: 2.3453 - lr: 2.5000e-04\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 7.3750\n",
      "LV_RMSE_12h: 8.3141\n",
      "LV_MAE_24h: 2.4375\n",
      "LV_RMSE_24h: 3.1125\n",
      "LV_MAE_48h: 1.4375\n",
      "LV_RMSE_48h: 1.8200\n",
      "LV_MAE_72h: 2.8750\n",
      "LV_RMSE_72h: 3.5707\n",
      "LV_MAE_mean: 3.5312\n",
      "LV_RMSE_mean: 4.2043\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 1.5717\n",
      "RMSE_12h: 2.6017\n",
      "MAE_24h: 1.5233\n",
      "RMSE_24h: 2.0340\n",
      "MAE_48h: 1.8953\n",
      "RMSE_48h: 3.4154\n",
      "MAE_72h: 2.0679\n",
      "RMSE_72h: 2.6494\n",
      "MAE_mean: 1.7645\n",
      "RMSE_mean: 2.6751\n",
      "\n",
      "=== Station S3004071 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1377 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1354, 24, 400) Ytr2: (1354, 4) \n",
      "  Xva3: (197, 24, 400) Yva2: (197, 4) \n",
      "  Xte3: (348, 24, 400) Yte2: (348, 4)\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 3s 55ms/step - loss: 1430.1903 - mae: 1430.1775 - val_loss: 1387.0652 - val_mae: 1387.0524 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1423.9568 - mae: 1423.9438 - val_loss: 1378.2738 - val_mae: 1378.2606 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1413.3551 - mae: 1413.3419 - val_loss: 1365.6233 - val_mae: 1365.6097 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1399.0315 - mae: 1399.0176 - val_loss: 1348.7130 - val_mae: 1348.6986 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1379.7838 - mae: 1379.7689 - val_loss: 1327.2521 - val_mae: 1327.2362 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1356.0420 - mae: 1356.0253 - val_loss: 1300.6317 - val_mae: 1300.6140 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1327.1964 - mae: 1327.1779 - val_loss: 1268.3810 - val_mae: 1268.3610 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1292.6116 - mae: 1292.5903 - val_loss: 1231.3622 - val_mae: 1231.3394 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1254.7606 - mae: 1254.7362 - val_loss: 1190.5984 - val_mae: 1190.5721 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1212.9529 - mae: 1212.9250 - val_loss: 1148.8210 - val_mae: 1148.7913 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1171.0204 - mae: 1170.9888 - val_loss: 1107.3601 - val_mae: 1107.3262 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1132.4753 - mae: 1132.4396 - val_loss: 1068.7094 - val_mae: 1068.6711 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1096.4315 - mae: 1096.3915 - val_loss: 1031.4958 - val_mae: 1031.4532 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1063.3607 - mae: 1063.3160 - val_loss: 995.4407 - val_mae: 995.3936 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1029.5718 - mae: 1029.5226 - val_loss: 959.4962 - val_mae: 959.4444 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 999.8616 - mae: 999.8078 - val_loss: 923.9576 - val_mae: 923.9010 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 969.7300 - mae: 969.6713 - val_loss: 889.2359 - val_mae: 889.1743 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 940.9935 - mae: 940.9296 - val_loss: 856.7751 - val_mae: 856.7084 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 915.0132 - mae: 914.9442 - val_loss: 825.7749 - val_mae: 825.7031 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 889.5762 - mae: 889.5022 - val_loss: 794.7990 - val_mae: 794.7219 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 862.4023\n",
      "LV_RMSE_12h: 958.7578\n",
      "LV_MAE_24h: 176.7874\n",
      "LV_RMSE_24h: 260.5841\n",
      "LV_MAE_48h: 231.3247\n",
      "LV_RMSE_48h: 335.9868\n",
      "LV_MAE_72h: 210.6667\n",
      "LV_RMSE_72h: 286.8635\n",
      "LV_MAE_mean: 370.2953\n",
      "LV_RMSE_mean: 460.5480\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 512.5065\n",
      "RMSE_12h: 582.7156\n",
      "MAE_24h: 483.8515\n",
      "RMSE_24h: 567.4374\n",
      "MAE_48h: 482.4119\n",
      "RMSE_48h: 567.1819\n",
      "MAE_72h: 471.3751\n",
      "RMSE_72h: 557.0814\n",
      "MAE_mean: 487.5363\n",
      "RMSE_mean: 568.6041\n",
      "\n",
      "=== Station S3004072 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1318 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1295, 24, 400) Ytr2: (1295, 4) \n",
      "  Xva3: (189, 24, 400) Yva2: (189, 4) \n",
      "  Xte3: (330, 24, 400) Yte2: (330, 4)\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 3s 56ms/step - loss: 399.9219 - mae: 399.9091 - val_loss: 394.3567 - val_mae: 394.3439 - lr: 0.0010\n",
      "Epoch 2/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 15ms/step - loss: 394.9550 - mae: 394.9422 - val_loss: 387.3235 - val_mae: 387.3105 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 386.2955 - mae: 386.2823 - val_loss: 376.9463 - val_mae: 376.9328 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 374.3442 - mae: 374.3305 - val_loss: 363.0272 - val_mae: 363.0129 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 358.5531 - mae: 358.5385 - val_loss: 345.2370 - val_mae: 345.2216 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 338.6836 - mae: 338.6677 - val_loss: 323.3181 - val_mae: 323.3013 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 315.1564 - mae: 315.1387 - val_loss: 297.5742 - val_mae: 297.5554 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 288.1996 - mae: 288.1799 - val_loss: 270.0026 - val_mae: 269.9815 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 261.5858 - mae: 261.5638 - val_loss: 246.1502 - val_mae: 246.1267 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 239.6886 - mae: 239.6641 - val_loss: 226.9790 - val_mae: 226.9530 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 220.1945 - mae: 220.1674 - val_loss: 210.4850 - val_mae: 210.4564 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 204.5947 - mae: 204.5651 - val_loss: 196.5753 - val_mae: 196.5442 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 190.9127 - mae: 190.8805 - val_loss: 184.6379 - val_mae: 184.6043 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 179.6985 - mae: 179.6638 - val_loss: 176.2306 - val_mae: 176.1946 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 171.5257 - mae: 171.4889 - val_loss: 171.0713 - val_mae: 171.0332 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 167.9091 - mae: 167.8703 - val_loss: 167.7699 - val_mae: 167.7301 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 164.7607 - mae: 164.7204 - val_loss: 165.6884 - val_mae: 165.6472 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 162.8023 - mae: 162.7607 - val_loss: 164.6376 - val_mae: 164.5954 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 158.2949 - mae: 158.2524 - val_loss: 150.7172 - val_mae: 150.6743 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 142.0492 - mae: 142.0058 - val_loss: 131.3131 - val_mae: 131.2688 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 50.9727\n",
      "LV_RMSE_12h: 117.5282\n",
      "LV_MAE_24h: 34.4364\n",
      "LV_RMSE_24h: 108.5993\n",
      "LV_MAE_48h: 50.4970\n",
      "LV_RMSE_48h: 144.5493\n",
      "LV_MAE_72h: 50.3788\n",
      "LV_RMSE_72h: 144.2696\n",
      "LV_MAE_mean: 46.5712\n",
      "LV_RMSE_mean: 128.7366\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 333.6603\n",
      "RMSE_12h: 351.1949\n",
      "MAE_24h: 332.6428\n",
      "RMSE_24h: 351.5270\n",
      "MAE_48h: 337.4602\n",
      "RMSE_48h: 350.5028\n",
      "MAE_72h: 338.1591\n",
      "RMSE_72h: 351.2381\n",
      "MAE_mean: 335.4806\n",
      "RMSE_mean: 351.1157\n",
      "\n",
      "=== Station S3005031 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1377 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1354, 24, 400) Ytr2: (1354, 4) \n",
      "  Xva3: (197, 24, 400) Yva2: (197, 4) \n",
      "  Xte3: (348, 24, 400) Yte2: (348, 4)\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 3s 52ms/step - loss: 439.4796 - mae: 439.4669 - val_loss: 442.3498 - val_mae: 442.3370 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 433.2351 - mae: 433.2222 - val_loss: 433.8969 - val_mae: 433.8839 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 423.4335 - mae: 423.4203 - val_loss: 422.7760 - val_mae: 422.7625 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 411.8579 - mae: 411.8441 - val_loss: 410.5128 - val_mae: 410.4985 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 398.8503 - mae: 398.8356 - val_loss: 397.5253 - val_mae: 397.5100 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 385.4832 - mae: 385.4673 - val_loss: 383.4658 - val_mae: 383.4492 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 370.6119 - mae: 370.5946 - val_loss: 368.3381 - val_mae: 368.3197 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 355.4223 - mae: 355.4031 - val_loss: 352.3608 - val_mae: 352.3405 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 339.2910 - mae: 339.2698 - val_loss: 336.4624 - val_mae: 336.4400 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 324.8294 - mae: 324.8059 - val_loss: 321.8514 - val_mae: 321.8266 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 311.8013 - mae: 311.7754 - val_loss: 308.6070 - val_mae: 308.5796 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 298.2943 - mae: 298.2659 - val_loss: 295.4057 - val_mae: 295.3758 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 283.2795 - mae: 283.2484 - val_loss: 277.2876 - val_mae: 277.2551 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 263.0579 - mae: 263.0240 - val_loss: 257.0846 - val_mae: 257.0490 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 241.5341 - mae: 241.4970 - val_loss: 237.5670 - val_mae: 237.5280 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 223.2639 - mae: 223.2233 - val_loss: 219.5774 - val_mae: 219.5347 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 205.2403 - mae: 205.1959 - val_loss: 204.1194 - val_mae: 204.0729 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 192.5224 - mae: 192.4743 - val_loss: 192.6667 - val_mae: 192.6166 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 183.3124 - mae: 183.2609 - val_loss: 183.9700 - val_mae: 183.9167 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 176.6690 - mae: 176.6146 - val_loss: 181.0537 - val_mae: 180.9979 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 493.0575\n",
      "LV_RMSE_12h: 551.1769\n",
      "LV_MAE_24h: 115.2730\n",
      "LV_RMSE_24h: 173.7391\n",
      "LV_MAE_48h: 135.9368\n",
      "LV_RMSE_48h: 202.6941\n",
      "LV_MAE_72h: 118.8075\n",
      "LV_RMSE_72h: 182.4264\n",
      "LV_MAE_mean: 215.7687\n",
      "LV_RMSE_mean: 277.5091\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 373.4036\n",
      "RMSE_12h: 435.2077\n",
      "MAE_24h: 141.1663\n",
      "RMSE_24h: 192.3637\n",
      "MAE_48h: 135.5415\n",
      "RMSE_48h: 188.6625\n",
      "MAE_72h: 135.1649\n",
      "RMSE_72h: 188.2318\n",
      "MAE_mean: 196.3191\n",
      "RMSE_mean: 251.1164\n",
      "\n",
      "=== Station S3005041 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1377 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1354, 24, 400) Ytr2: (1354, 4) \n",
      "  Xva3: (197, 24, 400) Yva2: (197, 4) \n",
      "  Xte3: (348, 24, 400) Yte2: (348, 4)\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 3s 54ms/step - loss: 422.8123 - mae: 422.7997 - val_loss: 426.0958 - val_mae: 426.0831 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 416.9192 - mae: 416.9064 - val_loss: 417.5972 - val_mae: 417.5844 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 406.8096 - mae: 406.7966 - val_loss: 406.0808 - val_mae: 406.0674 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 394.9460 - mae: 394.9323 - val_loss: 393.4424 - val_mae: 393.4283 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 381.6189 - mae: 381.6043 - val_loss: 380.2966 - val_mae: 380.2813 - lr: 0.0010\n",
      "Epoch 6/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 13ms/step - loss: 368.0064 - mae: 367.9906 - val_loss: 366.0332 - val_mae: 366.0166 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 353.1338 - mae: 353.1165 - val_loss: 350.9934 - val_mae: 350.9751 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 337.9823 - mae: 337.9632 - val_loss: 335.2435 - val_mae: 335.2232 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 322.3757 - mae: 322.3545 - val_loss: 319.3669 - val_mae: 319.3445 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 307.3185 - mae: 307.2951 - val_loss: 304.9641 - val_mae: 304.9393 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 294.8313 - mae: 294.8055 - val_loss: 292.4502 - val_mae: 292.4230 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 283.1244 - mae: 283.0961 - val_loss: 281.5165 - val_mae: 281.4868 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 273.6744 - mae: 273.6437 - val_loss: 272.7477 - val_mae: 272.7156 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 263.8405 - mae: 263.8073 - val_loss: 262.2502 - val_mae: 262.2156 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 250.8736 - mae: 250.8379 - val_loss: 245.2768 - val_mae: 245.2397 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 232.4343 - mae: 232.3960 - val_loss: 227.5328 - val_mae: 227.4929 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 214.7333 - mae: 214.6921 - val_loss: 213.3044 - val_mae: 213.2614 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 200.0829 - mae: 200.0385 - val_loss: 198.3376 - val_mae: 198.2915 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 186.9732 - mae: 186.9256 - val_loss: 187.1246 - val_mae: 187.0752 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 178.2448 - mae: 178.1942 - val_loss: 178.7171 - val_mae: 178.6651 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 478.2644\n",
      "LV_RMSE_12h: 536.2821\n",
      "LV_MAE_24h: 110.3678\n",
      "LV_RMSE_24h: 164.0532\n",
      "LV_MAE_48h: 129.0632\n",
      "LV_RMSE_48h: 190.7968\n",
      "LV_MAE_72h: 114.6695\n",
      "LV_RMSE_72h: 174.4779\n",
      "LV_MAE_mean: 208.0912\n",
      "LV_RMSE_mean: 266.4025\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 363.5181\n",
      "RMSE_12h: 418.6731\n",
      "MAE_24h: 142.2352\n",
      "RMSE_24h: 189.4726\n",
      "MAE_48h: 139.7120\n",
      "RMSE_48h: 189.2095\n",
      "MAE_72h: 139.6630\n",
      "RMSE_72h: 189.5571\n",
      "MAE_mean: 196.2821\n",
      "RMSE_mean: 246.7281\n",
      "\n",
      "=== Station S3005052 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1377 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1354, 24, 400) Ytr2: (1354, 4) \n",
      "  Xva3: (197, 24, 400) Yva2: (197, 4) \n",
      "  Xte3: (348, 24, 400) Yte2: (348, 4)\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 3s 55ms/step - loss: 125.5655 - mae: 125.5526 - val_loss: 128.7170 - val_mae: 128.7040 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 120.5924 - mae: 120.5793 - val_loss: 123.2742 - val_mae: 123.2608 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 114.9584 - mae: 114.9449 - val_loss: 116.8702 - val_mae: 116.8563 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 108.4241 - mae: 108.4098 - val_loss: 109.3379 - val_mae: 109.3230 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 100.9072 - mae: 100.8918 - val_loss: 101.5952 - val_mae: 101.5792 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 93.5965 - mae: 93.5798 - val_loss: 93.6922 - val_mae: 93.6746 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 86.6146 - mae: 86.5963 - val_loss: 86.6041 - val_mae: 86.5850 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 79.5833 - mae: 79.5634 - val_loss: 79.5915 - val_mae: 79.5707 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 72.7698 - mae: 72.7483 - val_loss: 73.5201 - val_mae: 73.4975 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 66.4997 - mae: 66.4762 - val_loss: 67.7229 - val_mae: 67.6984 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 61.0011 - mae: 60.9757 - val_loss: 62.9067 - val_mae: 62.8801 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 57.1505 - mae: 57.1230 - val_loss: 59.5419 - val_mae: 59.5133 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 53.9585 - mae: 53.9292 - val_loss: 56.7111 - val_mae: 56.6809 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 51.8880 - mae: 51.8570 - val_loss: 54.4316 - val_mae: 54.3998 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 48.8323 - mae: 48.7997 - val_loss: 52.2696 - val_mae: 52.2360 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 47.6749 - mae: 47.6406 - val_loss: 50.6633 - val_mae: 50.6281 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 45.9509 - mae: 45.9151 - val_loss: 48.3841 - val_mae: 48.3474 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 44.2975 - mae: 44.2603 - val_loss: 46.4438 - val_mae: 46.4058 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 43.2863 - mae: 43.2476 - val_loss: 45.1654 - val_mae: 45.1260 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 41.6168 - mae: 41.5768 - val_loss: 44.5606 - val_mae: 44.5198 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 219.6782\n",
      "LV_RMSE_12h: 265.3233\n",
      "LV_MAE_24h: 47.9569\n",
      "LV_RMSE_24h: 75.3731\n",
      "LV_MAE_48h: 59.9397\n",
      "LV_RMSE_48h: 96.7290\n",
      "LV_MAE_72h: 55.2816\n",
      "LV_RMSE_72h: 92.5641\n",
      "LV_MAE_mean: 95.7141\n",
      "LV_RMSE_mean: 132.4974\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 70.1239\n",
      "RMSE_12h: 118.7268\n",
      "MAE_24h: 51.3847\n",
      "RMSE_24h: 78.5451\n",
      "MAE_48h: 50.8617\n",
      "RMSE_48h: 76.5942\n",
      "MAE_72h: 51.1964\n",
      "RMSE_72h: 77.0735\n",
      "MAE_mean: 55.8917\n",
      "RMSE_mean: 87.7349\n",
      "\n",
      "=== Station S3007011 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1376 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1353, 24, 400) Ytr2: (1353, 4) \n",
      "  Xva3: (197, 24, 400) Yva2: (197, 4) \n",
      "  Xte3: (348, 24, 400) Yte2: (348, 4)\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 3s 53ms/step - loss: 649.1005 - mae: 649.0876 - val_loss: 550.3238 - val_mae: 550.3109 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 643.0658 - mae: 643.0528 - val_loss: 541.8255 - val_mae: 541.8123 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 632.6652 - mae: 632.6519 - val_loss: 529.6904 - val_mae: 529.6766 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 618.6520 - mae: 618.6378 - val_loss: 514.4186 - val_mae: 514.4039 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 601.5002 - mae: 601.4849 - val_loss: 496.3545 - val_mae: 496.3384 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 582.3420 - mae: 582.3253 - val_loss: 477.1772 - val_mae: 477.1595 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 562.5591 - mae: 562.5405 - val_loss: 458.0365 - val_mae: 458.0168 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 543.5436 - mae: 543.5229 - val_loss: 438.8626 - val_mae: 438.8407 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 0s 18ms/step - loss: 525.0902 - mae: 525.0671 - val_loss: 419.4737 - val_mae: 419.4492 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 505.3920 - mae: 505.3664 - val_loss: 399.3221 - val_mae: 399.2950 - lr: 0.0010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/20\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 485.1271 - mae: 485.0987 - val_loss: 378.5773 - val_mae: 378.5471 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 465.3056 - mae: 465.2740 - val_loss: 357.8253 - val_mae: 357.7918 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 444.5544 - mae: 444.5195 - val_loss: 337.6149 - val_mae: 337.5780 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 421.7241 - mae: 421.6856 - val_loss: 313.7363 - val_mae: 313.6957 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 396.9133 - mae: 396.8710 - val_loss: 289.6983 - val_mae: 289.6538 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 371.1140 - mae: 371.0677 - val_loss: 266.5661 - val_mae: 266.5172 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 346.8447 - mae: 346.7940 - val_loss: 242.4589 - val_mae: 242.4055 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 320.9938 - mae: 320.9383 - val_loss: 222.5482 - val_mae: 222.4901 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 299.0755 - mae: 299.0152 - val_loss: 207.0105 - val_mae: 206.9474 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 278.8081 - mae: 278.7427 - val_loss: 197.0771 - val_mae: 197.0089 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 568.3822\n",
      "LV_RMSE_12h: 640.4166\n",
      "LV_MAE_24h: 109.5632\n",
      "LV_RMSE_24h: 163.3494\n",
      "LV_MAE_48h: 124.9310\n",
      "LV_RMSE_48h: 177.4468\n",
      "LV_MAE_72h: 107.7902\n",
      "LV_RMSE_72h: 158.0545\n",
      "LV_MAE_mean: 227.6667\n",
      "LV_RMSE_mean: 284.8168\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 427.0233\n",
      "RMSE_12h: 501.2280\n",
      "MAE_24h: 125.2912\n",
      "RMSE_24h: 170.4026\n",
      "MAE_48h: 127.1178\n",
      "RMSE_48h: 173.9911\n",
      "MAE_72h: 124.9737\n",
      "RMSE_72h: 173.9200\n",
      "MAE_mean: 201.1015\n",
      "RMSE_mean: 254.8854\n",
      "\n",
      "=== Station S3007031 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1377 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1354, 24, 400) Ytr2: (1354, 4) \n",
      "  Xva3: (197, 24, 400) Yva2: (197, 4) \n",
      "  Xte3: (348, 24, 400) Yte2: (348, 4)\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 3s 56ms/step - loss: 322.1564 - mae: 322.1436 - val_loss: 304.0995 - val_mae: 304.0866 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 316.1194 - mae: 316.1065 - val_loss: 295.6707 - val_mae: 295.6576 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 305.8395 - mae: 305.8263 - val_loss: 283.4220 - val_mae: 283.4085 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 292.5767 - mae: 292.5628 - val_loss: 268.8084 - val_mae: 268.7941 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 277.3217 - mae: 277.3069 - val_loss: 254.2722 - val_mae: 254.2567 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 262.9083 - mae: 262.8922 - val_loss: 240.2280 - val_mae: 240.2111 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 249.1575 - mae: 249.1399 - val_loss: 226.9739 - val_mae: 226.9554 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 236.4446 - mae: 236.4254 - val_loss: 214.9377 - val_mae: 214.9176 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 225.1604 - mae: 225.1394 - val_loss: 203.8487 - val_mae: 203.8267 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 214.8877 - mae: 214.8649 - val_loss: 193.7519 - val_mae: 193.7280 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 204.6191 - mae: 204.5943 - val_loss: 181.9658 - val_mae: 181.9400 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 192.1797 - mae: 192.1529 - val_loss: 169.8328 - val_mae: 169.8048 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 178.0125 - mae: 177.9835 - val_loss: 156.7147 - val_mae: 156.6844 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 164.3749 - mae: 164.3433 - val_loss: 143.4507 - val_mae: 143.4176 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 151.1942 - mae: 151.1597 - val_loss: 131.7741 - val_mae: 131.7379 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 137.6409 - mae: 137.6033 - val_loss: 120.3446 - val_mae: 120.3052 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 127.0266 - mae: 126.9858 - val_loss: 110.3034 - val_mae: 110.2609 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 117.8680 - mae: 117.8243 - val_loss: 105.1518 - val_mae: 105.1067 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 112.5427 - mae: 112.4967 - val_loss: 101.9344 - val_mae: 101.8875 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 109.3384 - mae: 109.2908 - val_loss: 98.5633 - val_mae: 98.5149 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 346.4167\n",
      "LV_RMSE_12h: 377.4511\n",
      "LV_MAE_24h: 53.7989\n",
      "LV_RMSE_24h: 76.8770\n",
      "LV_MAE_48h: 69.7414\n",
      "LV_RMSE_48h: 99.2591\n",
      "LV_MAE_72h: 63.5747\n",
      "LV_RMSE_72h: 92.8536\n",
      "LV_MAE_mean: 133.3829\n",
      "LV_RMSE_mean: 161.6102\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 240.6712\n",
      "RMSE_12h: 277.7329\n",
      "MAE_24h: 62.0537\n",
      "RMSE_24h: 88.5680\n",
      "MAE_48h: 58.4206\n",
      "RMSE_48h: 83.8375\n",
      "MAE_72h: 59.3696\n",
      "RMSE_72h: 85.3261\n",
      "MAE_mean: 105.1288\n",
      "RMSE_mean: 133.8661\n",
      "\n",
      "=== Station S3007033 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1377 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1354, 24, 400) Ytr2: (1354, 4) \n",
      "  Xva3: (197, 24, 400) Yva2: (197, 4) \n",
      "  Xte3: (348, 24, 400) Yte2: (348, 4)\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 3s 52ms/step - loss: 298.1885 - mae: 298.1757 - val_loss: 275.3252 - val_mae: 275.3124 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 292.1594 - mae: 292.1465 - val_loss: 266.7762 - val_mae: 266.7631 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 281.9126 - mae: 281.8993 - val_loss: 254.6426 - val_mae: 254.6290 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 268.6642 - mae: 268.6502 - val_loss: 239.6237 - val_mae: 239.6092 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 253.4430 - mae: 253.4280 - val_loss: 224.9634 - val_mae: 224.9478 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 238.9507 - mae: 238.9344 - val_loss: 210.9174 - val_mae: 210.9003 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 224.5940 - mae: 224.5762 - val_loss: 197.7439 - val_mae: 197.7252 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 211.4207 - mae: 211.4012 - val_loss: 185.7972 - val_mae: 185.7767 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 199.3075 - mae: 199.2861 - val_loss: 174.6417 - val_mae: 174.6192 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 187.9535 - mae: 187.9301 - val_loss: 165.0389 - val_mae: 165.0143 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 179.0342 - mae: 179.0087 - val_loss: 156.3155 - val_mae: 156.2889 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 169.3386 - mae: 169.3111 - val_loss: 147.5605 - val_mae: 147.5318 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 158.1915 - mae: 158.1619 - val_loss: 134.6256 - val_mae: 134.5947 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 143.2467 - mae: 143.2149 - val_loss: 121.3484 - val_mae: 121.3153 - lr: 0.0010\n",
      "Epoch 15/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 13ms/step - loss: 128.4222 - mae: 128.3879 - val_loss: 108.5471 - val_mae: 108.5114 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 116.5164 - mae: 116.4795 - val_loss: 101.4167 - val_mae: 101.3783 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 109.0453 - mae: 109.0060 - val_loss: 97.8981 - val_mae: 97.8577 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 105.2052 - mae: 105.1641 - val_loss: 95.7819 - val_mae: 95.7402 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 103.8472 - mae: 103.8052 - val_loss: 93.9556 - val_mae: 93.9131 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 100.5890 - mae: 100.5462 - val_loss: 91.5461 - val_mae: 91.5027 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 274.5115\n",
      "LV_RMSE_12h: 305.0841\n",
      "LV_MAE_24h: 48.4655\n",
      "LV_RMSE_24h: 71.2501\n",
      "LV_MAE_48h: 61.1034\n",
      "LV_RMSE_48h: 89.6115\n",
      "LV_MAE_72h: 54.2356\n",
      "LV_RMSE_72h: 82.4579\n",
      "LV_MAE_mean: 109.5790\n",
      "LV_RMSE_mean: 137.1009\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 209.0001\n",
      "RMSE_12h: 239.6166\n",
      "MAE_24h: 52.9011\n",
      "RMSE_24h: 81.2115\n",
      "MAE_48h: 50.3205\n",
      "RMSE_48h: 78.1588\n",
      "MAE_72h: 52.0844\n",
      "RMSE_72h: 78.7216\n",
      "MAE_mean: 91.0765\n",
      "RMSE_mean: 119.4271\n",
      "\n",
      "=== Station S3007041 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1377 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1354, 24, 400) Ytr2: (1354, 4) \n",
      "  Xva3: (197, 24, 400) Yva2: (197, 4) \n",
      "  Xte3: (348, 24, 400) Yte2: (348, 4)\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 3s 54ms/step - loss: 308.4526 - mae: 308.4399 - val_loss: 285.3441 - val_mae: 285.3314 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 301.1039 - mae: 301.0912 - val_loss: 275.0933 - val_mae: 275.0804 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 289.1738 - mae: 289.1606 - val_loss: 261.3671 - val_mae: 261.3536 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 274.6591 - mae: 274.6453 - val_loss: 245.6125 - val_mae: 245.5982 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 258.6596 - mae: 258.6448 - val_loss: 230.4860 - val_mae: 230.4705 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 243.4772 - mae: 243.4610 - val_loss: 215.7370 - val_mae: 215.7200 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 228.9605 - mae: 228.9428 - val_loss: 201.8377 - val_mae: 201.8190 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 214.7695 - mae: 214.7500 - val_loss: 189.2754 - val_mae: 189.2548 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 202.1730 - mae: 202.1515 - val_loss: 178.1686 - val_mae: 178.1460 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 190.8101 - mae: 190.7865 - val_loss: 168.1985 - val_mae: 168.1737 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 180.9824 - mae: 180.9567 - val_loss: 158.2260 - val_mae: 158.1991 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 169.3514 - mae: 169.3236 - val_loss: 145.6024 - val_mae: 145.5733 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 154.9875 - mae: 154.9575 - val_loss: 132.6078 - val_mae: 132.5765 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 142.1131 - mae: 142.0807 - val_loss: 122.5344 - val_mae: 122.5006 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 131.3793 - mae: 131.3443 - val_loss: 115.3432 - val_mae: 115.3068 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 122.0864 - mae: 122.0490 - val_loss: 108.4295 - val_mae: 108.3909 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 116.7868 - mae: 116.7475 - val_loss: 105.1991 - val_mae: 105.1589 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 111.4663 - mae: 111.4256 - val_loss: 100.1457 - val_mae: 100.1043 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 106.6510 - mae: 106.6091 - val_loss: 95.5526 - val_mae: 95.5100 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 103.5182 - mae: 103.4751 - val_loss: 92.9673 - val_mae: 92.9235 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 283.7500\n",
      "LV_RMSE_12h: 315.9319\n",
      "LV_MAE_24h: 48.7184\n",
      "LV_RMSE_24h: 72.1611\n",
      "LV_MAE_48h: 63.9971\n",
      "LV_RMSE_48h: 93.9189\n",
      "LV_MAE_72h: 57.7730\n",
      "LV_RMSE_72h: 88.5771\n",
      "LV_MAE_mean: 113.5596\n",
      "LV_RMSE_mean: 142.6472\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 215.7865\n",
      "RMSE_12h: 248.3632\n",
      "MAE_24h: 54.3580\n",
      "RMSE_24h: 83.7800\n",
      "MAE_48h: 52.5657\n",
      "RMSE_48h: 81.6698\n",
      "MAE_72h: 53.4276\n",
      "RMSE_72h: 82.0383\n",
      "MAE_mean: 94.0345\n",
      "RMSE_mean: 123.9628\n",
      "\n",
      "=== Station S3007043 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1377 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1354, 24, 400) Ytr2: (1354, 4) \n",
      "  Xva3: (197, 24, 400) Yva2: (197, 4) \n",
      "  Xte3: (348, 24, 400) Yte2: (348, 4)\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 3s 53ms/step - loss: 334.1981 - mae: 334.1855 - val_loss: 315.0982 - val_mae: 315.0856 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 327.1764 - mae: 327.1637 - val_loss: 305.6921 - val_mae: 305.6792 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 316.0609 - mae: 316.0478 - val_loss: 293.2110 - val_mae: 293.1976 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 302.9482 - mae: 302.9345 - val_loss: 279.1041 - val_mae: 279.0899 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 288.5250 - mae: 288.5103 - val_loss: 265.3070 - val_mae: 265.2917 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 274.9146 - mae: 274.8988 - val_loss: 251.7190 - val_mae: 251.7025 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 261.9731 - mae: 261.9560 - val_loss: 238.8809 - val_mae: 238.8629 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 249.7092 - mae: 249.6905 - val_loss: 227.0948 - val_mae: 227.0751 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 238.3813 - mae: 238.3609 - val_loss: 215.8839 - val_mae: 215.8625 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 227.8538 - mae: 227.8317 - val_loss: 206.2591 - val_mae: 206.2359 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 217.5538 - mae: 217.5298 - val_loss: 195.1028 - val_mae: 195.0778 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 206.0545 - mae: 206.0286 - val_loss: 183.0909 - val_mae: 183.0639 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 194.3418 - mae: 194.3139 - val_loss: 171.4061 - val_mae: 171.3770 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 181.0615 - mae: 181.0314 - val_loss: 159.7399 - val_mae: 159.7083 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 168.1270 - mae: 168.0943 - val_loss: 146.7379 - val_mae: 146.7037 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 154.6541 - mae: 154.6187 - val_loss: 134.7419 - val_mae: 134.7048 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 140.7129 - mae: 140.6745 - val_loss: 125.0500 - val_mae: 125.0098 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 130.0731 - mae: 130.0316 - val_loss: 115.8835 - val_mae: 115.8405 - lr: 0.0010\n",
      "Epoch 19/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 13ms/step - loss: 122.8416 - mae: 122.7974 - val_loss: 112.2784 - val_mae: 112.2329 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 118.6838 - mae: 118.6375 - val_loss: 107.0257 - val_mae: 106.9784 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 360.3649\n",
      "LV_RMSE_12h: 392.0441\n",
      "LV_MAE_24h: 57.4741\n",
      "LV_RMSE_24h: 88.2010\n",
      "LV_MAE_48h: 73.7730\n",
      "LV_RMSE_48h: 108.6018\n",
      "LV_MAE_72h: 67.1580\n",
      "LV_RMSE_72h: 101.1993\n",
      "LV_MAE_mean: 139.6925\n",
      "LV_RMSE_mean: 172.5116\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 261.0175\n",
      "RMSE_12h: 302.4560\n",
      "MAE_24h: 66.6032\n",
      "RMSE_24h: 97.5104\n",
      "MAE_48h: 65.6088\n",
      "RMSE_48h: 96.3658\n",
      "MAE_72h: 67.0490\n",
      "RMSE_72h: 98.1115\n",
      "MAE_mean: 115.0696\n",
      "RMSE_mean: 148.6109\n",
      "\n",
      "=== Station S3008011 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1377 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1354, 24, 400) Ytr2: (1354, 4) \n",
      "  Xva3: (197, 24, 400) Yva2: (197, 4) \n",
      "  Xte3: (348, 24, 400) Yte2: (348, 4)\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 3s 53ms/step - loss: 1080.1874 - mae: 1080.1746 - val_loss: 1038.6677 - val_mae: 1038.6547 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1073.4666 - mae: 1073.4536 - val_loss: 1029.2942 - val_mae: 1029.2810 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1062.4525 - mae: 1062.4391 - val_loss: 1016.5095 - val_mae: 1016.4957 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1048.3403 - mae: 1048.3263 - val_loss: 1000.1327 - val_mae: 1000.1180 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1029.7437 - mae: 1029.7283 - val_loss: 979.3438 - val_mae: 979.3278 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1006.8932 - mae: 1006.8766 - val_loss: 953.9294 - val_mae: 953.9117 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 979.5626 - mae: 979.5440 - val_loss: 923.8046 - val_mae: 923.7848 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 947.3997 - mae: 947.3789 - val_loss: 888.9373 - val_mae: 888.9150 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 910.7292 - mae: 910.7056 - val_loss: 850.0226 - val_mae: 849.9971 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 870.8741 - mae: 870.8472 - val_loss: 811.0442 - val_mae: 811.0154 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 832.2089 - mae: 832.1786 - val_loss: 775.4246 - val_mae: 775.3923 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 797.5881 - mae: 797.5541 - val_loss: 742.8295 - val_mae: 742.7932 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 766.4105 - mae: 766.3726 - val_loss: 712.7057 - val_mae: 712.6658 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 736.2477 - mae: 736.2061 - val_loss: 685.5630 - val_mae: 685.5190 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 708.3064 - mae: 708.2607 - val_loss: 659.6333 - val_mae: 659.5853 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 684.0886 - mae: 684.0389 - val_loss: 635.3618 - val_mae: 635.3098 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 660.6496 - mae: 660.5956 - val_loss: 611.1389 - val_mae: 611.0825 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 633.8200 - mae: 633.7618 - val_loss: 588.9924 - val_mae: 588.9318 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 615.3321 - mae: 615.2696 - val_loss: 568.6539 - val_mae: 568.5889 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 592.8432 - mae: 592.7764 - val_loss: 546.6872 - val_mae: 546.6179 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 893.3247\n",
      "LV_RMSE_12h: 977.6022\n",
      "LV_MAE_24h: 168.2385\n",
      "LV_RMSE_24h: 262.3089\n",
      "LV_MAE_48h: 213.4914\n",
      "LV_RMSE_48h: 331.6276\n",
      "LV_MAE_72h: 189.5172\n",
      "LV_RMSE_72h: 278.4824\n",
      "LV_MAE_mean: 366.1429\n",
      "LV_RMSE_mean: 462.5053\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 509.6195\n",
      "RMSE_12h: 592.9160\n",
      "MAE_24h: 486.8039\n",
      "RMSE_24h: 575.5739\n",
      "MAE_48h: 489.1495\n",
      "RMSE_48h: 579.2270\n",
      "MAE_72h: 480.5098\n",
      "RMSE_72h: 567.8959\n",
      "MAE_mean: 491.5207\n",
      "RMSE_mean: 578.9032\n",
      "\n",
      "=== Station S3008012 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1375 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1352, 24, 400) Ytr2: (1352, 4) \n",
      "  Xva3: (197, 24, 400) Yva2: (197, 4) \n",
      "  Xte3: (347, 24, 400) Yte2: (347, 4)\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 4s 64ms/step - loss: 2.7867 - mae: 2.7741 - val_loss: 2.3766 - val_mae: 2.3639 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 2.4708 - mae: 2.4582 - val_loss: 2.3979 - val_mae: 2.3853 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 2.4156 - mae: 2.4031 - val_loss: 2.3305 - val_mae: 2.3180 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 0s 21ms/step - loss: 2.4008 - mae: 2.3884 - val_loss: 2.3310 - val_mae: 2.3186 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 2.3944 - mae: 2.3821 - val_loss: 2.3037 - val_mae: 2.2914 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 0s 17ms/step - loss: 2.3872 - mae: 2.3749 - val_loss: 2.3032 - val_mae: 2.2911 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 0s 17ms/step - loss: 2.3683 - mae: 2.3562 - val_loss: 2.2975 - val_mae: 2.2855 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 2.3651 - mae: 2.3530 - val_loss: 2.2926 - val_mae: 2.2807 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 0s 19ms/step - loss: 2.3500 - mae: 2.3380 - val_loss: 2.3073 - val_mae: 2.2954 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 0s 17ms/step - loss: 2.3336 - mae: 2.3218 - val_loss: 2.2845 - val_mae: 2.2727 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 0s 17ms/step - loss: 2.3416 - mae: 2.3298 - val_loss: 2.3068 - val_mae: 2.2950 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 2.3316 - mae: 2.3199 - val_loss: 2.2970 - val_mae: 2.2853 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 2.3105 - mae: 2.2988 - val_loss: 2.2763 - val_mae: 2.2647 - lr: 5.0000e-04\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 0s 19ms/step - loss: 2.3145 - mae: 2.3029 - val_loss: 2.2928 - val_mae: 2.2813 - lr: 5.0000e-04\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 2.3096 - mae: 2.2980 - val_loss: 2.2881 - val_mae: 2.2765 - lr: 5.0000e-04\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 2.2945 - mae: 2.2829 - val_loss: 2.2878 - val_mae: 2.2763 - lr: 2.5000e-04\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 0s 18ms/step - loss: 2.2828 - mae: 2.2713 - val_loss: 2.2772 - val_mae: 2.2657 - lr: 2.5000e-04\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 0s 18ms/step - loss: 2.2813 - mae: 2.2698 - val_loss: 2.2832 - val_mae: 2.2717 - lr: 1.2500e-04\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 3.6196\n",
      "LV_RMSE_12h: 8.1996\n",
      "LV_MAE_24h: 2.7839\n",
      "LV_RMSE_24h: 6.8124\n",
      "LV_MAE_48h: 2.7954\n",
      "LV_RMSE_48h: 6.1826\n",
      "LV_MAE_72h: 3.1671\n",
      "LV_RMSE_72h: 7.4115\n",
      "LV_MAE_mean: 3.0915\n",
      "LV_RMSE_mean: 7.1515\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 2.2205\n",
      "RMSE_12h: 5.8267\n",
      "MAE_24h: 2.0745\n",
      "RMSE_24h: 4.7899\n",
      "MAE_48h: 2.2435\n",
      "RMSE_48h: 5.1345\n",
      "MAE_72h: 2.1664\n",
      "RMSE_72h: 5.0180\n",
      "MAE_mean: 2.1762\n",
      "RMSE_mean: 5.1922\n",
      "\n",
      "=== Station S3008013 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1375 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1352, 24, 400) Ytr2: (1352, 4) \n",
      "  Xva3: (197, 24, 400) Yva2: (197, 4) \n",
      "  Xte3: (347, 24, 400) Yte2: (347, 4)\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 3s 57ms/step - loss: 143.6930 - mae: 143.6802 - val_loss: 133.0915 - val_mae: 133.0787 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 138.7061 - mae: 138.6933 - val_loss: 125.8449 - val_mae: 125.8320 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 129.9410 - mae: 129.9279 - val_loss: 116.1225 - val_mae: 116.1092 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 119.7045 - mae: 119.6910 - val_loss: 105.3881 - val_mae: 105.3742 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 107.9742 - mae: 107.9600 - val_loss: 93.4505 - val_mae: 93.4357 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 95.0544 - mae: 95.0391 - val_loss: 80.9423 - val_mae: 80.9263 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 83.2570 - mae: 83.2404 - val_loss: 70.1151 - val_mae: 70.0977 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 73.2994 - mae: 73.2814 - val_loss: 62.0748 - val_mae: 62.0561 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 66.4904 - mae: 66.4711 - val_loss: 57.0923 - val_mae: 57.0723 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 61.1898 - mae: 61.1694 - val_loss: 53.2967 - val_mae: 53.2758 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 56.4651 - mae: 56.4439 - val_loss: 49.1975 - val_mae: 49.1759 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 52.5572 - mae: 52.5353 - val_loss: 47.2444 - val_mae: 47.2222 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 51.1526 - mae: 51.1303 - val_loss: 46.3845 - val_mae: 46.3621 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 50.5304 - mae: 50.5078 - val_loss: 45.5984 - val_mae: 45.5758 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 49.5508 - mae: 49.5281 - val_loss: 44.3756 - val_mae: 44.3527 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 48.8725 - mae: 48.8494 - val_loss: 43.7849 - val_mae: 43.7617 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 47.4865 - mae: 47.4630 - val_loss: 42.6136 - val_mae: 42.5898 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 46.7149 - mae: 46.6910 - val_loss: 41.2345 - val_mae: 41.2102 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 44.9400 - mae: 44.9155 - val_loss: 40.9131 - val_mae: 40.8882 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 44.1776 - mae: 44.1524 - val_loss: 38.6668 - val_mae: 38.6412 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 94.7089\n",
      "LV_RMSE_12h: 109.0344\n",
      "LV_MAE_24h: 32.5331\n",
      "LV_RMSE_24h: 43.5101\n",
      "LV_MAE_48h: 38.6916\n",
      "LV_RMSE_48h: 50.3406\n",
      "LV_MAE_72h: 38.7896\n",
      "LV_RMSE_72h: 50.9412\n",
      "LV_MAE_mean: 51.1808\n",
      "LV_RMSE_mean: 63.4566\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 62.9033\n",
      "RMSE_12h: 74.4042\n",
      "MAE_24h: 29.9427\n",
      "RMSE_24h: 37.5842\n",
      "MAE_48h: 29.9744\n",
      "RMSE_48h: 37.7684\n",
      "MAE_72h: 31.7655\n",
      "RMSE_72h: 39.6926\n",
      "MAE_mean: 38.6465\n",
      "RMSE_mean: 47.3623\n",
      "\n",
      "=== Station S3008021 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1377 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1354, 24, 400) Ytr2: (1354, 4) \n",
      "  Xva3: (197, 24, 400) Yva2: (197, 4) \n",
      "  Xte3: (348, 24, 400) Yte2: (348, 4)\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 3s 57ms/step - loss: 1147.3623 - mae: 1147.3495 - val_loss: 1164.5513 - val_mae: 1164.5383 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1141.5942 - mae: 1141.5813 - val_loss: 1156.8092 - val_mae: 1156.7961 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1132.2931 - mae: 1132.2798 - val_loss: 1145.8577 - val_mae: 1145.8444 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1120.1316 - mae: 1120.1180 - val_loss: 1131.5657 - val_mae: 1131.5515 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1103.8220 - mae: 1103.8074 - val_loss: 1113.3923 - val_mae: 1113.3771 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1083.9999 - mae: 1083.9839 - val_loss: 1090.9327 - val_mae: 1090.9159 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1059.5900 - mae: 1059.5723 - val_loss: 1064.0801 - val_mae: 1064.0614 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1030.3358 - mae: 1030.3162 - val_loss: 1032.7130 - val_mae: 1032.6921 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 997.7488 - mae: 997.7266 - val_loss: 997.4082 - val_mae: 997.3845 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 960.5899 - mae: 960.5648 - val_loss: 959.8562 - val_mae: 959.8293 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 921.7946 - mae: 921.7662 - val_loss: 920.9579 - val_mae: 920.9277 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 882.6249 - mae: 882.5931 - val_loss: 881.5111 - val_mae: 881.4771 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 846.0153 - mae: 845.9795 - val_loss: 842.9824 - val_mae: 842.9444 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 810.4713 - mae: 810.4316 - val_loss: 806.3932 - val_mae: 806.3512 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 779.4090 - mae: 779.3652 - val_loss: 770.3160 - val_mae: 770.2701 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 751.8394 - mae: 751.7916 - val_loss: 734.9724 - val_mae: 734.9224 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 0s 19ms/step - loss: 724.5340 - mae: 724.4821 - val_loss: 699.8887 - val_mae: 699.8344 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 695.2145 - mae: 695.1583 - val_loss: 665.5170 - val_mae: 665.4584 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 671.0414 - mae: 670.9808 - val_loss: 633.2051 - val_mae: 633.1420 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 645.0255 - mae: 644.9603 - val_loss: 603.9175 - val_mae: 603.8499 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 902.0575\n",
      "LV_RMSE_12h: 1056.4493\n",
      "LV_MAE_24h: 187.2414\n",
      "LV_RMSE_24h: 265.6225\n",
      "LV_MAE_48h: 239.3879\n",
      "LV_RMSE_48h: 340.4774\n",
      "LV_MAE_72h: 240.1552\n",
      "LV_RMSE_72h: 326.1664\n",
      "LV_MAE_mean: 392.2105\n",
      "LV_RMSE_mean: 497.1789\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 600.3159\n",
      "RMSE_12h: 727.3261\n",
      "MAE_24h: 578.2762\n",
      "RMSE_24h: 697.8038\n",
      "MAE_48h: 595.7797\n",
      "RMSE_48h: 725.8766\n",
      "MAE_72h: 586.2006\n",
      "RMSE_72h: 716.8809\n",
      "MAE_mean: 590.1431\n",
      "RMSE_mean: 716.9718\n",
      "\n",
      "=== Station S3008022 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1019 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (996, 24, 400) Ytr2: (996, 4) \n",
      "  Xva3: (146, 24, 400) Yva2: (146, 4) \n",
      "  Xte3: (245, 24, 400) Yte2: (245, 4)\n",
      "Epoch 1/20\n",
      "8/8 [==============================] - 3s 82ms/step - loss: 88.1117 - mae: 88.0989 - val_loss: 91.9113 - val_mae: 91.8985 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 83.8566 - mae: 83.8438 - val_loss: 86.3450 - val_mae: 86.3321 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 77.3470 - mae: 77.3340 - val_loss: 78.8772 - val_mae: 78.8640 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 69.6217 - mae: 69.6083 - val_loss: 71.0792 - val_mae: 71.0656 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 62.0617 - mae: 62.0479 - val_loss: 64.0313 - val_mae: 64.0171 - lr: 0.0010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/20\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 55.3154 - mae: 55.3009 - val_loss: 58.0320 - val_mae: 58.0172 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 51.0695 - mae: 51.0544 - val_loss: 54.0886 - val_mae: 54.0731 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 49.1273 - mae: 49.1116 - val_loss: 52.2430 - val_mae: 52.2271 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 48.7426 - mae: 48.7266 - val_loss: 51.7769 - val_mae: 51.7607 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 48.6663 - mae: 48.6501 - val_loss: 51.6547 - val_mae: 51.6385 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 48.5658 - mae: 48.5497 - val_loss: 51.6220 - val_mae: 51.6060 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 48.1224 - mae: 48.1064 - val_loss: 51.3708 - val_mae: 51.3549 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 47.1735 - mae: 47.1576 - val_loss: 51.2467 - val_mae: 51.2308 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 46.1702 - mae: 46.1543 - val_loss: 50.7548 - val_mae: 50.7388 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 45.5867 - mae: 45.5706 - val_loss: 50.0660 - val_mae: 50.0498 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 44.9235 - mae: 44.9072 - val_loss: 49.4867 - val_mae: 49.4702 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 44.3891 - mae: 44.3726 - val_loss: 49.1586 - val_mae: 49.1420 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 44.0727 - mae: 44.0560 - val_loss: 48.6766 - val_mae: 48.6598 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 43.4268 - mae: 43.4100 - val_loss: 48.1639 - val_mae: 48.1470 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 43.0726 - mae: 43.0556 - val_loss: 47.9137 - val_mae: 47.8966 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 91.2286\n",
      "LV_RMSE_12h: 138.9588\n",
      "LV_MAE_24h: 54.8653\n",
      "LV_RMSE_24h: 99.4397\n",
      "LV_MAE_48h: 56.8327\n",
      "LV_RMSE_48h: 102.2367\n",
      "LV_MAE_72h: 48.7673\n",
      "LV_RMSE_72h: 87.3048\n",
      "LV_MAE_mean: 62.9235\n",
      "LV_RMSE_mean: 106.9850\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 53.8619\n",
      "RMSE_12h: 95.6812\n",
      "MAE_24h: 35.6632\n",
      "RMSE_24h: 69.7779\n",
      "MAE_48h: 37.0961\n",
      "RMSE_48h: 72.2509\n",
      "MAE_72h: 35.4518\n",
      "RMSE_72h: 69.3542\n",
      "MAE_mean: 40.5183\n",
      "RMSE_mean: 76.7660\n",
      "\n",
      "=== Station S3008023 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1019 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (996, 24, 400) Ytr2: (996, 4) \n",
      "  Xva3: (146, 24, 400) Yva2: (146, 4) \n",
      "  Xte3: (245, 24, 400) Yte2: (245, 4)\n",
      "Epoch 1/20\n",
      "8/8 [==============================] - 3s 75ms/step - loss: 638.9471 - mae: 638.9343 - val_loss: 596.2844 - val_mae: 596.2715 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 634.9931 - mae: 634.9803 - val_loss: 590.8539 - val_mae: 590.8409 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 628.4512 - mae: 628.4381 - val_loss: 583.0931 - val_mae: 583.0800 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 619.9982 - mae: 619.9849 - val_loss: 573.8765 - val_mae: 573.8628 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 609.9814 - mae: 609.9675 - val_loss: 562.8235 - val_mae: 562.8093 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 598.0989 - mae: 598.0843 - val_loss: 549.7081 - val_mae: 549.6929 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 584.1940 - mae: 584.1784 - val_loss: 534.4759 - val_mae: 534.4597 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 568.4542 - mae: 568.4374 - val_loss: 517.2714 - val_mae: 517.2540 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 550.0883 - mae: 550.0701 - val_loss: 498.0899 - val_mae: 498.0710 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 530.6710 - mae: 530.6513 - val_loss: 477.1347 - val_mae: 477.1141 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 510.0792 - mae: 510.0578 - val_loss: 455.2386 - val_mae: 455.2161 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 487.4047 - mae: 487.3812 - val_loss: 432.9450 - val_mae: 432.9203 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 463.9033 - mae: 463.8776 - val_loss: 410.3801 - val_mae: 410.3531 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 438.7012 - mae: 438.6731 - val_loss: 386.9377 - val_mae: 386.9081 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 414.7237 - mae: 414.6930 - val_loss: 362.0086 - val_mae: 361.9763 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 387.1518 - mae: 387.1182 - val_loss: 336.3425 - val_mae: 336.3072 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 359.8610 - mae: 359.8244 - val_loss: 311.4537 - val_mae: 311.4153 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 333.9465 - mae: 333.9067 - val_loss: 288.4689 - val_mae: 288.4272 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 309.2571 - mae: 309.2140 - val_loss: 270.3716 - val_mae: 270.3267 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 288.0119 - mae: 287.9656 - val_loss: 256.8752 - val_mae: 256.8271 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 303.4653\n",
      "LV_RMSE_12h: 374.1877\n",
      "LV_MAE_24h: 155.2122\n",
      "LV_RMSE_24h: 217.7590\n",
      "LV_MAE_48h: 172.4939\n",
      "LV_RMSE_48h: 232.9674\n",
      "LV_MAE_72h: 181.2286\n",
      "LV_RMSE_72h: 248.5119\n",
      "LV_MAE_mean: 203.1000\n",
      "LV_RMSE_mean: 268.3565\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 236.0363\n",
      "RMSE_12h: 285.5978\n",
      "MAE_24h: 254.9967\n",
      "RMSE_24h: 305.5008\n",
      "MAE_48h: 243.1791\n",
      "RMSE_48h: 292.0760\n",
      "MAE_72h: 244.9783\n",
      "RMSE_72h: 296.6079\n",
      "MAE_mean: 244.7976\n",
      "RMSE_mean: 294.9456\n",
      "\n",
      "=== Station S3009021 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1377 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1354, 24, 400) Ytr2: (1354, 4) \n",
      "  Xva3: (197, 24, 400) Yva2: (197, 4) \n",
      "  Xte3: (348, 24, 400) Yte2: (348, 4)\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 3s 57ms/step - loss: 879.6753 - mae: 879.6625 - val_loss: 817.3376 - val_mae: 817.3249 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 873.4146 - mae: 873.4016 - val_loss: 808.0364 - val_mae: 808.0233 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 861.9543 - mae: 861.9411 - val_loss: 794.4171 - val_mae: 794.4035 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 847.1715 - mae: 847.1575 - val_loss: 777.7047 - val_mae: 777.6901 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 829.7463 - mae: 829.7311 - val_loss: 759.8859 - val_mae: 759.8701 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 812.1050 - mae: 812.0884 - val_loss: 741.9754 - val_mae: 741.9579 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 794.4499 - mae: 794.4315 - val_loss: 723.9827 - val_mae: 723.9632 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 776.7004 - mae: 776.6800 - val_loss: 705.8590 - val_mae: 705.8373 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 758.6604 - mae: 758.6378 - val_loss: 687.2352 - val_mae: 687.2111 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 740.7014 - mae: 740.6762 - val_loss: 668.4539 - val_mae: 668.4272 - lr: 0.0010\n",
      "Epoch 11/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 15ms/step - loss: 721.8358 - mae: 721.8077 - val_loss: 648.1454 - val_mae: 648.1157 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 701.8834 - mae: 701.8524 - val_loss: 628.8172 - val_mae: 628.7842 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 682.0870 - mae: 682.0526 - val_loss: 607.4455 - val_mae: 607.4089 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 658.7230 - mae: 658.6849 - val_loss: 577.0577 - val_mae: 577.0175 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 628.9181 - mae: 628.8760 - val_loss: 546.0535 - val_mae: 546.0090 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 600.2278 - mae: 600.1814 - val_loss: 518.4769 - val_mae: 518.4278 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 573.1603 - mae: 573.1090 - val_loss: 492.1025 - val_mae: 492.0483 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 546.6536 - mae: 546.5970 - val_loss: 465.6785 - val_mae: 465.6189 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 523.4785 - mae: 523.4166 - val_loss: 444.5339 - val_mae: 444.4688 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 500.1055 - mae: 500.0380 - val_loss: 421.3747 - val_mae: 421.3040 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 1085.2529\n",
      "LV_RMSE_12h: 1222.7469\n",
      "LV_MAE_24h: 147.8132\n",
      "LV_RMSE_24h: 224.1303\n",
      "LV_MAE_48h: 194.7126\n",
      "LV_RMSE_48h: 288.2400\n",
      "LV_MAE_72h: 170.6092\n",
      "LV_RMSE_72h: 245.3565\n",
      "LV_MAE_mean: 399.5970\n",
      "LV_RMSE_mean: 495.1184\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 720.9861\n",
      "RMSE_12h: 907.5850\n",
      "MAE_24h: 351.3585\n",
      "RMSE_24h: 520.4703\n",
      "MAE_48h: 349.7011\n",
      "RMSE_48h: 515.1672\n",
      "MAE_72h: 365.2022\n",
      "RMSE_72h: 545.8259\n",
      "MAE_mean: 446.8120\n",
      "RMSE_mean: 622.2621\n",
      "\n",
      "=== Station S3009022 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1377 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1354, 24, 400) Ytr2: (1354, 4) \n",
      "  Xva3: (197, 24, 400) Yva2: (197, 4) \n",
      "  Xte3: (348, 24, 400) Yte2: (348, 4)\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 3s 59ms/step - loss: 839.0414 - mae: 839.0287 - val_loss: 727.8284 - val_mae: 727.8157 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 834.2558 - mae: 834.2431 - val_loss: 722.5199 - val_mae: 722.5070 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 826.9303 - mae: 826.9171 - val_loss: 715.6841 - val_mae: 715.6706 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 818.1077 - mae: 818.0939 - val_loss: 707.7778 - val_mae: 707.7635 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 807.2222 - mae: 807.2073 - val_loss: 698.8506 - val_mae: 698.8350 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 794.8847 - mae: 794.8683 - val_loss: 688.5403 - val_mae: 688.5230 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 0s 20ms/step - loss: 781.2609 - mae: 781.2426 - val_loss: 677.1490 - val_mae: 677.1296 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 766.2575 - mae: 766.2370 - val_loss: 666.2878 - val_mae: 666.2658 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 750.6815 - mae: 750.6583 - val_loss: 654.5607 - val_mae: 654.5358 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 733.5324 - mae: 733.5062 - val_loss: 642.2903 - val_mae: 642.2623 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 716.7478 - mae: 716.7183 - val_loss: 628.6193 - val_mae: 628.5876 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 697.9547 - mae: 697.9213 - val_loss: 613.3284 - val_mae: 613.2928 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 677.7174 - mae: 677.6799 - val_loss: 594.6934 - val_mae: 594.6537 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 654.5526 - mae: 654.5107 - val_loss: 570.9386 - val_mae: 570.8940 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 629.6789 - mae: 629.6321 - val_loss: 546.6318 - val_mae: 546.5820 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 604.9868 - mae: 604.9346 - val_loss: 521.5476 - val_mae: 521.4921 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 579.2737 - mae: 579.2156 - val_loss: 496.3172 - val_mae: 496.2556 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 553.0120 - mae: 552.9475 - val_loss: 471.6315 - val_mae: 471.5634 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 526.1877 - mae: 526.1167 - val_loss: 449.2174 - val_mae: 449.1424 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 500.1136 - mae: 500.0354 - val_loss: 419.7009 - val_mae: 419.6183 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 1243.7271\n",
      "LV_RMSE_12h: 1332.9900\n",
      "LV_MAE_24h: 182.9799\n",
      "LV_RMSE_24h: 296.2064\n",
      "LV_MAE_48h: 208.1264\n",
      "LV_RMSE_48h: 335.0122\n",
      "LV_MAE_72h: 177.4138\n",
      "LV_RMSE_72h: 287.2978\n",
      "LV_MAE_mean: 453.0618\n",
      "LV_RMSE_mean: 562.8766\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 796.5118\n",
      "RMSE_12h: 974.9644\n",
      "MAE_24h: 314.6678\n",
      "RMSE_24h: 438.4390\n",
      "MAE_48h: 325.6207\n",
      "RMSE_48h: 457.7106\n",
      "MAE_72h: 325.4077\n",
      "RMSE_72h: 458.8395\n",
      "MAE_mean: 440.5520\n",
      "RMSE_mean: 582.4884\n",
      "\n",
      "=== Station S3009025 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1376 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1353, 24, 400) Ytr2: (1353, 4) \n",
      "  Xva3: (197, 24, 400) Yva2: (197, 4) \n",
      "  Xte3: (348, 24, 400) Yte2: (348, 4)\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 3s 57ms/step - loss: 102.1183 - mae: 102.1055 - val_loss: 98.3454 - val_mae: 98.3327 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 97.5361 - mae: 97.5234 - val_loss: 93.3644 - val_mae: 93.3516 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 92.7315 - mae: 92.7186 - val_loss: 88.7222 - val_mae: 88.7092 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 88.1213 - mae: 88.1081 - val_loss: 84.1883 - val_mae: 84.1748 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 83.9113 - mae: 83.8974 - val_loss: 79.8517 - val_mae: 79.8374 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 80.1253 - mae: 80.1108 - val_loss: 76.0941 - val_mae: 76.0791 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 76.7738 - mae: 76.7585 - val_loss: 72.7584 - val_mae: 72.7426 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 73.1115 - mae: 73.0955 - val_loss: 68.7861 - val_mae: 68.7696 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 68.9890 - mae: 68.9721 - val_loss: 63.8341 - val_mae: 63.8167 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 63.1015 - mae: 63.0836 - val_loss: 58.0071 - val_mae: 57.9886 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 56.6247 - mae: 56.6056 - val_loss: 51.1012 - val_mae: 51.0813 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 49.5157 - mae: 49.4951 - val_loss: 44.9684 - val_mae: 44.9469 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 44.3927 - mae: 44.3705 - val_loss: 40.4787 - val_mae: 40.4556 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 40.1630 - mae: 40.1394 - val_loss: 37.5125 - val_mae: 37.4881 - lr: 0.0010\n",
      "Epoch 15/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 13ms/step - loss: 37.7087 - mae: 37.6839 - val_loss: 35.8543 - val_mae: 35.8289 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 36.5181 - mae: 36.4923 - val_loss: 34.0380 - val_mae: 34.0117 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 34.9961 - mae: 34.9693 - val_loss: 32.4868 - val_mae: 32.4596 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 33.5854 - mae: 33.5578 - val_loss: 31.0004 - val_mae: 30.9722 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 31.8036 - mae: 31.7751 - val_loss: 29.2093 - val_mae: 29.1803 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 30.7696 - mae: 30.7402 - val_loss: 27.8180 - val_mae: 27.7880 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 141.3736\n",
      "LV_RMSE_12h: 161.9939\n",
      "LV_MAE_24h: 26.6868\n",
      "LV_RMSE_24h: 42.5782\n",
      "LV_MAE_48h: 32.7500\n",
      "LV_RMSE_48h: 53.0427\n",
      "LV_MAE_72h: 28.2960\n",
      "LV_RMSE_72h: 43.2306\n",
      "LV_MAE_mean: 57.2766\n",
      "LV_RMSE_mean: 75.2113\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 50.1873\n",
      "RMSE_12h: 75.8283\n",
      "MAE_24h: 24.4422\n",
      "RMSE_24h: 39.4071\n",
      "MAE_48h: 23.1668\n",
      "RMSE_48h: 37.9373\n",
      "MAE_72h: 23.7306\n",
      "RMSE_72h: 37.4844\n",
      "MAE_mean: 30.3817\n",
      "RMSE_mean: 47.6643\n",
      "\n",
      "=== Station S3009026 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1358 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1335, 24, 400) Ytr2: (1335, 4) \n",
      "  Xva3: (195, 24, 400) Yva2: (195, 4) \n",
      "  Xte3: (341, 24, 400) Yte2: (341, 4)\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 3s 57ms/step - loss: 114.6039 - mae: 114.5910 - val_loss: 99.3606 - val_mae: 99.3477 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 109.4675 - mae: 109.4545 - val_loss: 93.8526 - val_mae: 93.8395 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 102.7592 - mae: 102.7459 - val_loss: 88.8039 - val_mae: 88.7904 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 95.8869 - mae: 95.8731 - val_loss: 84.2972 - val_mae: 84.2829 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 89.8417 - mae: 89.8270 - val_loss: 80.8737 - val_mae: 80.8586 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 85.3019 - mae: 85.2864 - val_loss: 79.0550 - val_mae: 79.0389 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 82.3659 - mae: 82.3495 - val_loss: 77.6986 - val_mae: 77.6817 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 80.4312 - mae: 80.4141 - val_loss: 75.0808 - val_mae: 75.0634 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 78.7628 - mae: 78.7452 - val_loss: 71.1896 - val_mae: 71.1717 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 76.6233 - mae: 76.6052 - val_loss: 67.2303 - val_mae: 67.2119 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 74.6134 - mae: 74.5948 - val_loss: 61.5751 - val_mae: 61.5560 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 72.3394 - mae: 72.3200 - val_loss: 56.2133 - val_mae: 56.1935 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 69.3458 - mae: 69.3255 - val_loss: 50.8242 - val_mae: 50.8034 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 66.8717 - mae: 66.8504 - val_loss: 46.8429 - val_mae: 46.8211 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 64.3655 - mae: 64.3432 - val_loss: 43.0136 - val_mae: 42.9907 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 62.5427 - mae: 62.5193 - val_loss: 41.0860 - val_mae: 41.0620 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 60.6211 - mae: 60.5966 - val_loss: 39.2924 - val_mae: 39.2673 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 59.0821 - mae: 59.0565 - val_loss: 37.2612 - val_mae: 37.2351 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 57.4503 - mae: 57.4238 - val_loss: 34.9727 - val_mae: 34.9456 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 56.2847 - mae: 56.2572 - val_loss: 32.2983 - val_mae: 32.2702 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 150.2141\n",
      "LV_RMSE_12h: 168.2391\n",
      "LV_MAE_24h: 26.9560\n",
      "LV_RMSE_24h: 41.3424\n",
      "LV_MAE_48h: 32.2405\n",
      "LV_RMSE_48h: 50.2844\n",
      "LV_MAE_72h: 26.9062\n",
      "LV_RMSE_72h: 40.5726\n",
      "LV_MAE_mean: 59.0792\n",
      "LV_RMSE_mean: 75.1096\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 65.1107\n",
      "RMSE_12h: 83.2274\n",
      "MAE_24h: 24.3325\n",
      "RMSE_24h: 38.1427\n",
      "MAE_48h: 23.1623\n",
      "RMSE_48h: 37.1096\n",
      "MAE_72h: 22.4720\n",
      "RMSE_72h: 35.1990\n",
      "MAE_mean: 33.7694\n",
      "RMSE_mean: 48.4197\n",
      "\n",
      "=== Station S3009051 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1377 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1354, 24, 400) Ytr2: (1354, 4) \n",
      "  Xva3: (197, 24, 400) Yva2: (197, 4) \n",
      "  Xte3: (348, 24, 400) Yte2: (348, 4)\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 3s 57ms/step - loss: 710.9726 - mae: 710.9598 - val_loss: 640.3884 - val_mae: 640.3757 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 705.6878 - mae: 705.6750 - val_loss: 632.2831 - val_mae: 632.2701 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 695.4099 - mae: 695.3967 - val_loss: 619.7872 - val_mae: 619.7736 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 681.8494 - mae: 681.8354 - val_loss: 604.2358 - val_mae: 604.2213 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 665.2352 - mae: 665.2200 - val_loss: 587.0155 - val_mae: 586.9996 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 647.9643 - mae: 647.9475 - val_loss: 569.5491 - val_mae: 569.5314 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 630.9193 - mae: 630.9006 - val_loss: 552.3304 - val_mae: 552.3107 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 613.3228 - mae: 613.3021 - val_loss: 535.0912 - val_mae: 535.0692 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 596.6232 - mae: 596.6000 - val_loss: 517.7234 - val_mae: 517.6987 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 579.1599 - mae: 579.1341 - val_loss: 500.2278 - val_mae: 500.2002 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 562.5807 - mae: 562.5518 - val_loss: 482.7896 - val_mae: 482.7589 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 546.3160 - mae: 546.2839 - val_loss: 466.6179 - val_mae: 466.5838 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 530.6711 - mae: 530.6356 - val_loss: 451.9808 - val_mae: 451.9434 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 517.0511 - mae: 517.0121 - val_loss: 435.2595 - val_mae: 435.2186 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 500.1735 - mae: 500.1311 - val_loss: 416.9342 - val_mae: 416.8898 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 482.1091 - mae: 482.0631 - val_loss: 395.7009 - val_mae: 395.6528 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 459.4315 - mae: 459.3816 - val_loss: 373.5984 - val_mae: 373.5462 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 437.4119 - mae: 437.3580 - val_loss: 353.5245 - val_mae: 353.4680 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 417.9892 - mae: 417.9307 - val_loss: 334.3391 - val_mae: 334.2781 - lr: 0.0010\n",
      "Epoch 20/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 12ms/step - loss: 398.5829 - mae: 398.5198 - val_loss: 315.0693 - val_mae: 315.0034 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 843.1149\n",
      "LV_RMSE_12h: 941.3256\n",
      "LV_MAE_24h: 126.8218\n",
      "LV_RMSE_24h: 185.3798\n",
      "LV_MAE_48h: 156.1782\n",
      "LV_RMSE_48h: 227.7178\n",
      "LV_MAE_72h: 145.0000\n",
      "LV_RMSE_72h: 204.6921\n",
      "LV_MAE_mean: 317.7787\n",
      "LV_RMSE_mean: 389.7788\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 577.2919\n",
      "RMSE_12h: 701.3964\n",
      "MAE_24h: 267.6742\n",
      "RMSE_24h: 384.1423\n",
      "MAE_48h: 258.8642\n",
      "RMSE_48h: 366.1582\n",
      "MAE_72h: 274.2297\n",
      "RMSE_72h: 394.4073\n",
      "MAE_mean: 344.5150\n",
      "RMSE_mean: 461.5261\n",
      "\n",
      "=== Station S3009052 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1376 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1353, 24, 400) Ytr2: (1353, 4) \n",
      "  Xva3: (197, 24, 400) Yva2: (197, 4) \n",
      "  Xte3: (348, 24, 400) Yte2: (348, 4)\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 3s 62ms/step - loss: 400.0663 - mae: 400.0536 - val_loss: 414.4231 - val_mae: 414.4103 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 393.0477 - mae: 393.0348 - val_loss: 405.0323 - val_mae: 405.0193 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 382.8590 - mae: 382.8458 - val_loss: 393.6931 - val_mae: 393.6796 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 372.2642 - mae: 372.2504 - val_loss: 382.8829 - val_mae: 382.8687 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 361.5309 - mae: 361.5161 - val_loss: 371.5692 - val_mae: 371.5538 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 350.5222 - mae: 350.5063 - val_loss: 361.3211 - val_mae: 361.3044 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 340.6516 - mae: 340.6342 - val_loss: 351.2789 - val_mae: 351.2607 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 330.6711 - mae: 330.6521 - val_loss: 341.1920 - val_mae: 341.1720 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 321.6682 - mae: 321.6474 - val_loss: 332.0103 - val_mae: 331.9885 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 312.7170 - mae: 312.6943 - val_loss: 323.6026 - val_mae: 323.5788 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 304.9946 - mae: 304.9701 - val_loss: 315.6444 - val_mae: 315.6187 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 295.3481 - mae: 295.3215 - val_loss: 302.7530 - val_mae: 302.7253 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 280.4061 - mae: 280.3775 - val_loss: 284.4843 - val_mae: 284.4543 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 261.7188 - mae: 261.6877 - val_loss: 266.1328 - val_mae: 266.1000 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 244.8089 - mae: 244.7748 - val_loss: 248.2735 - val_mae: 248.2375 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 226.8578 - mae: 226.8203 - val_loss: 230.3499 - val_mae: 230.3101 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 209.9960 - mae: 209.9544 - val_loss: 211.7842 - val_mae: 211.7402 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 193.9242 - mae: 193.8783 - val_loss: 194.9489 - val_mae: 194.9005 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 178.5481 - mae: 178.4976 - val_loss: 177.6512 - val_mae: 177.5981 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 165.7078 - mae: 165.6528 - val_loss: 164.2369 - val_mae: 164.1794 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 576.8879\n",
      "LV_RMSE_12h: 643.5761\n",
      "LV_MAE_24h: 96.4569\n",
      "LV_RMSE_24h: 154.5797\n",
      "LV_MAE_48h: 122.7155\n",
      "LV_RMSE_48h: 195.2334\n",
      "LV_MAE_72h: 102.9167\n",
      "LV_RMSE_72h: 155.4776\n",
      "LV_MAE_mean: 224.7443\n",
      "LV_RMSE_mean: 287.2167\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 363.5867\n",
      "RMSE_12h: 471.1833\n",
      "MAE_24h: 106.7452\n",
      "RMSE_24h: 159.8737\n",
      "MAE_48h: 107.9750\n",
      "RMSE_48h: 160.3647\n",
      "MAE_72h: 109.8944\n",
      "RMSE_72h: 163.7803\n",
      "MAE_mean: 172.0503\n",
      "RMSE_mean: 238.8005\n",
      "\n",
      "=== Station S3009053 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1376 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1353, 24, 400) Ytr2: (1353, 4) \n",
      "  Xva3: (197, 24, 400) Yva2: (197, 4) \n",
      "  Xte3: (348, 24, 400) Yte2: (348, 4)\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 3s 58ms/step - loss: 414.7186 - mae: 414.7057 - val_loss: 424.3324 - val_mae: 424.3194 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 408.6157 - mae: 408.6026 - val_loss: 415.4288 - val_mae: 415.4155 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 399.0234 - mae: 399.0098 - val_loss: 405.3063 - val_mae: 405.2924 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 388.7326 - mae: 388.7184 - val_loss: 394.4323 - val_mae: 394.4175 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 377.9809 - mae: 377.9656 - val_loss: 382.8641 - val_mae: 382.8481 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 366.9566 - mae: 366.9399 - val_loss: 370.9967 - val_mae: 370.9791 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 355.5049 - mae: 355.4866 - val_loss: 359.0239 - val_mae: 359.0045 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 343.7646 - mae: 343.7444 - val_loss: 347.2198 - val_mae: 347.1985 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 333.2983 - mae: 333.2760 - val_loss: 335.2565 - val_mae: 335.2329 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 321.4852 - mae: 321.4607 - val_loss: 322.9434 - val_mae: 322.9176 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 309.7021 - mae: 309.6753 - val_loss: 309.2791 - val_mae: 309.2508 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 295.5052 - mae: 295.4757 - val_loss: 295.1187 - val_mae: 295.0878 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 281.6452 - mae: 281.6131 - val_loss: 281.3307 - val_mae: 281.2969 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 267.6674 - mae: 267.6322 - val_loss: 266.7119 - val_mae: 266.6748 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 253.8778 - mae: 253.8393 - val_loss: 250.5480 - val_mae: 250.5075 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 237.8283 - mae: 237.7863 - val_loss: 234.4082 - val_mae: 234.3641 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 222.1135 - mae: 222.0676 - val_loss: 217.1988 - val_mae: 217.1506 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 207.4102 - mae: 207.3602 - val_loss: 202.8297 - val_mae: 202.7774 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 194.5246 - mae: 194.4706 - val_loss: 190.1321 - val_mae: 190.0758 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 182.7516 - mae: 182.6938 - val_loss: 178.6429 - val_mae: 178.5830 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 575.0374\n",
      "LV_RMSE_12h: 647.0372\n",
      "LV_MAE_24h: 95.8736\n",
      "LV_RMSE_24h: 153.8176\n",
      "LV_MAE_48h: 121.9454\n",
      "LV_RMSE_48h: 192.3773\n",
      "LV_MAE_72h: 106.2615\n",
      "LV_RMSE_72h: 157.7893\n",
      "LV_MAE_mean: 224.7794\n",
      "LV_RMSE_mean: 287.7554\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 362.9293\n",
      "RMSE_12h: 468.1269\n",
      "MAE_24h: 121.5527\n",
      "RMSE_24h: 168.4531\n",
      "MAE_48h: 118.1007\n",
      "RMSE_48h: 164.8289\n",
      "MAE_72h: 121.3439\n",
      "RMSE_72h: 170.7027\n",
      "MAE_mean: 180.9817\n",
      "RMSE_mean: 243.0279\n",
      "\n",
      "=== Station S3009071 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1376 rows, 1631 features...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1353, 24, 400) Ytr2: (1353, 4) \n",
      "  Xva3: (197, 24, 400) Yva2: (197, 4) \n",
      "  Xte3: (347, 24, 400) Yte2: (347, 4)\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 3s 57ms/step - loss: 40.1714 - mae: 40.1587 - val_loss: 40.4291 - val_mae: 40.4164 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 37.2294 - mae: 37.2165 - val_loss: 36.6234 - val_mae: 36.6104 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 33.6062 - mae: 33.5930 - val_loss: 32.6255 - val_mae: 32.6120 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 29.6762 - mae: 29.6623 - val_loss: 28.7892 - val_mae: 28.7748 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 26.2523 - mae: 26.2375 - val_loss: 26.4464 - val_mae: 26.4311 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 24.2581 - mae: 24.2424 - val_loss: 25.3423 - val_mae: 25.3262 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 23.5952 - mae: 23.5788 - val_loss: 24.6541 - val_mae: 24.6375 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 23.1883 - mae: 23.1716 - val_loss: 24.1672 - val_mae: 24.1504 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 22.6310 - mae: 22.6141 - val_loss: 23.8845 - val_mae: 23.8675 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 22.2910 - mae: 22.2739 - val_loss: 23.1751 - val_mae: 23.1579 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 21.9949 - mae: 21.9775 - val_loss: 22.7812 - val_mae: 22.7637 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 21.4041 - mae: 21.3864 - val_loss: 22.2960 - val_mae: 22.2781 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 21.1158 - mae: 21.0978 - val_loss: 21.9091 - val_mae: 21.8908 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 20.5483 - mae: 20.5299 - val_loss: 21.5276 - val_mae: 21.5089 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 20.0488 - mae: 20.0300 - val_loss: 21.0712 - val_mae: 21.0521 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 19.5958 - mae: 19.5765 - val_loss: 20.8365 - val_mae: 20.8169 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 19.0180 - mae: 18.9982 - val_loss: 20.2662 - val_mae: 20.2461 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 18.8326 - mae: 18.8122 - val_loss: 20.0672 - val_mae: 20.0465 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 18.0772 - mae: 18.0562 - val_loss: 20.4190 - val_mae: 20.3976 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 17.5442 - mae: 17.5226 - val_loss: 20.1711 - val_mae: 20.1491 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 58.0144\n",
      "LV_RMSE_12h: 79.4313\n",
      "LV_MAE_24h: 15.4352\n",
      "LV_RMSE_24h: 29.1567\n",
      "LV_MAE_48h: 20.8732\n",
      "LV_RMSE_48h: 39.7197\n",
      "LV_MAE_72h: 22.2075\n",
      "LV_RMSE_72h: 45.0400\n",
      "LV_MAE_mean: 29.1326\n",
      "LV_RMSE_mean: 48.3369\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 17.1489\n",
      "RMSE_12h: 33.4581\n",
      "MAE_24h: 19.2018\n",
      "RMSE_24h: 34.3633\n",
      "MAE_48h: 17.8944\n",
      "RMSE_48h: 31.1694\n",
      "MAE_72h: 18.1122\n",
      "RMSE_72h: 31.2435\n",
      "MAE_mean: 18.0893\n",
      "RMSE_mean: 32.5586\n",
      "\n",
      "=== Station S3009081 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1376 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1353, 24, 400) Ytr2: (1353, 4) \n",
      "  Xva3: (197, 24, 400) Yva2: (197, 4) \n",
      "  Xte3: (347, 24, 400) Yte2: (347, 4)\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 3s 56ms/step - loss: 12.7944 - mae: 12.7816 - val_loss: 13.4932 - val_mae: 13.4803 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 10.3017 - mae: 10.2887 - val_loss: 11.0779 - val_mae: 11.0648 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 8.1577 - mae: 8.1445 - val_loss: 9.6879 - val_mae: 9.6745 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 7.2852 - mae: 7.2717 - val_loss: 9.3636 - val_mae: 9.3500 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 7.1209 - mae: 7.1074 - val_loss: 9.3865 - val_mae: 9.3730 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 6.9987 - mae: 6.9852 - val_loss: 9.3346 - val_mae: 9.3211 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 6.9862 - mae: 6.9728 - val_loss: 9.2966 - val_mae: 9.2832 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 6.8730 - mae: 6.8597 - val_loss: 9.2531 - val_mae: 9.2398 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 6.7504 - mae: 6.7371 - val_loss: 9.2735 - val_mae: 9.2602 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 6.7475 - mae: 6.7342 - val_loss: 9.2579 - val_mae: 9.2447 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 6.6266 - mae: 6.6133 - val_loss: 9.2289 - val_mae: 9.2156 - lr: 5.0000e-04\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 6.6379 - mae: 6.6247 - val_loss: 9.2297 - val_mae: 9.2164 - lr: 5.0000e-04\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 6.4766 - mae: 6.4634 - val_loss: 9.1673 - val_mae: 9.1540 - lr: 5.0000e-04\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 6.4667 - mae: 6.4534 - val_loss: 9.1803 - val_mae: 9.1670 - lr: 5.0000e-04\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 6.4883 - mae: 6.4750 - val_loss: 9.1722 - val_mae: 9.1589 - lr: 5.0000e-04\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 6.4073 - mae: 6.3940 - val_loss: 9.1423 - val_mae: 9.1290 - lr: 2.5000e-04\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 6.3417 - mae: 6.3283 - val_loss: 9.1267 - val_mae: 9.1134 - lr: 2.5000e-04\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 6.3606 - mae: 6.3472 - val_loss: 9.1420 - val_mae: 9.1287 - lr: 2.5000e-04\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 6.2468 - mae: 6.2334 - val_loss: 9.0636 - val_mae: 9.0503 - lr: 2.5000e-04\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 6.2506 - mae: 6.2372 - val_loss: 9.0882 - val_mae: 9.0749 - lr: 2.5000e-04\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 14.0519\n",
      "LV_RMSE_12h: 20.6470\n",
      "LV_MAE_24h: 6.1614\n",
      "LV_RMSE_24h: 12.9314\n",
      "LV_MAE_48h: 6.4438\n",
      "LV_RMSE_48h: 13.2895\n",
      "LV_MAE_72h: 6.6369\n",
      "LV_RMSE_72h: 12.9840\n",
      "LV_MAE_mean: 8.3235\n",
      "LV_RMSE_mean: 14.9630\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 6.4513\n",
      "RMSE_12h: 11.7691\n",
      "MAE_24h: 6.5601\n",
      "RMSE_24h: 11.5792\n",
      "MAE_48h: 6.2736\n",
      "RMSE_48h: 11.4923\n",
      "MAE_72h: 6.2926\n",
      "RMSE_72h: 11.2814\n",
      "MAE_mean: 6.3944\n",
      "RMSE_mean: 11.5305\n",
      "\n",
      "=== Station S3009082 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1376 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1353, 24, 400) Ytr2: (1353, 4) \n",
      "  Xva3: (197, 24, 400) Yva2: (197, 4) \n",
      "  Xte3: (347, 24, 400) Yte2: (347, 4)\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 3s 58ms/step - loss: 554.0995 - mae: 554.0868 - val_loss: 588.1703 - val_mae: 588.1576 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 548.2666 - mae: 548.2537 - val_loss: 579.5786 - val_mae: 579.5655 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 537.9177 - mae: 537.9044 - val_loss: 567.3556 - val_mae: 567.3419 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 524.6222 - mae: 524.6082 - val_loss: 552.8551 - val_mae: 552.8405 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 510.0172 - mae: 510.0021 - val_loss: 537.3090 - val_mae: 537.2932 - lr: 0.0010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 494.5866 - mae: 494.5701 - val_loss: 521.3638 - val_mae: 521.3464 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 478.9731 - mae: 478.9550 - val_loss: 505.4125 - val_mae: 505.3932 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 463.0375 - mae: 463.0174 - val_loss: 489.8036 - val_mae: 489.7823 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 448.3214 - mae: 448.2992 - val_loss: 474.1823 - val_mae: 474.1587 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 432.4506 - mae: 432.4260 - val_loss: 456.2227 - val_mae: 456.1966 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 411.9919 - mae: 411.9646 - val_loss: 430.6536 - val_mae: 430.6247 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 386.0659 - mae: 386.0356 - val_loss: 402.9981 - val_mae: 402.9659 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 360.8729 - mae: 360.8390 - val_loss: 378.0645 - val_mae: 378.0284 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 338.5681 - mae: 338.5304 - val_loss: 355.2880 - val_mae: 355.2479 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 317.2910 - mae: 317.2489 - val_loss: 334.6516 - val_mae: 334.6072 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 298.3628 - mae: 298.3165 - val_loss: 316.1622 - val_mae: 316.1135 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 281.5127 - mae: 281.4621 - val_loss: 298.6067 - val_mae: 298.5536 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 265.0203 - mae: 264.9653 - val_loss: 281.9326 - val_mae: 281.8751 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 248.8312 - mae: 248.7717 - val_loss: 265.0542 - val_mae: 264.9921 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 232.5411 - mae: 232.4771 - val_loss: 248.6014 - val_mae: 248.5349 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 699.9106\n",
      "LV_RMSE_12h: 771.5171\n",
      "LV_MAE_24h: 125.0144\n",
      "LV_RMSE_24h: 192.3319\n",
      "LV_MAE_48h: 153.6282\n",
      "LV_RMSE_48h: 234.9022\n",
      "LV_MAE_72h: 138.8473\n",
      "LV_RMSE_72h: 208.2756\n",
      "LV_MAE_mean: 279.3501\n",
      "LV_RMSE_mean: 351.7567\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 474.3065\n",
      "RMSE_12h: 584.4278\n",
      "MAE_24h: 157.6995\n",
      "RMSE_24h: 227.0692\n",
      "MAE_48h: 164.4643\n",
      "RMSE_48h: 237.8463\n",
      "MAE_72h: 152.0648\n",
      "RMSE_72h: 218.8634\n",
      "MAE_mean: 237.1338\n",
      "RMSE_mean: 317.0517\n",
      "\n",
      "=== Station S3010011 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1377 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1354, 24, 400) Ytr2: (1354, 4) \n",
      "  Xva3: (197, 24, 400) Yva2: (197, 4) \n",
      "  Xte3: (348, 24, 400) Yte2: (348, 4)\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 3s 58ms/step - loss: 427.8388 - mae: 427.8260 - val_loss: 430.4895 - val_mae: 430.4767 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 421.3328 - mae: 421.3199 - val_loss: 421.3426 - val_mae: 421.3297 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 410.7484 - mae: 410.7353 - val_loss: 408.7197 - val_mae: 408.7063 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 396.9271 - mae: 396.9133 - val_loss: 391.8503 - val_mae: 391.8360 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 378.5185 - mae: 378.5036 - val_loss: 370.3561 - val_mae: 370.3405 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 356.4005 - mae: 356.3842 - val_loss: 344.2170 - val_mae: 344.1996 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 331.5583 - mae: 331.5400 - val_loss: 316.0363 - val_mae: 316.0169 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 308.7033 - mae: 308.6828 - val_loss: 296.8962 - val_mae: 296.8745 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 293.7558 - mae: 293.7331 - val_loss: 281.8228 - val_mae: 281.7990 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 280.2732 - mae: 280.2484 - val_loss: 269.0809 - val_mae: 269.0549 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 270.2233 - mae: 270.1963 - val_loss: 258.5660 - val_mae: 258.5379 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 261.2929 - mae: 261.2638 - val_loss: 250.6638 - val_mae: 250.6335 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 254.6246 - mae: 254.5934 - val_loss: 242.7002 - val_mae: 242.6680 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 245.5858 - mae: 245.5527 - val_loss: 231.9164 - val_mae: 231.8822 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 234.3789 - mae: 234.3438 - val_loss: 220.4960 - val_mae: 220.4598 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 220.7143 - mae: 220.6771 - val_loss: 205.9744 - val_mae: 205.9358 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 206.1547 - mae: 206.1150 - val_loss: 190.5408 - val_mae: 190.4997 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 192.9598 - mae: 192.9173 - val_loss: 178.8403 - val_mae: 178.7961 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 181.6974 - mae: 181.6518 - val_loss: 167.5295 - val_mae: 167.4821 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 171.4403 - mae: 171.3916 - val_loss: 158.4348 - val_mae: 158.3844 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 412.9167\n",
      "LV_RMSE_12h: 468.8948\n",
      "LV_MAE_24h: 103.3678\n",
      "LV_RMSE_24h: 172.8542\n",
      "LV_MAE_48h: 118.8362\n",
      "LV_RMSE_48h: 180.3412\n",
      "LV_MAE_72h: 99.2299\n",
      "LV_RMSE_72h: 167.1341\n",
      "LV_MAE_mean: 183.5876\n",
      "LV_RMSE_mean: 247.3061\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 306.3592\n",
      "RMSE_12h: 367.2516\n",
      "MAE_24h: 99.8637\n",
      "RMSE_24h: 156.5650\n",
      "MAE_48h: 105.0778\n",
      "RMSE_48h: 161.8221\n",
      "MAE_72h: 105.2262\n",
      "RMSE_72h: 160.1247\n",
      "MAE_mean: 154.1317\n",
      "RMSE_mean: 211.4408\n",
      "\n",
      "=== Station S3010012 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1377 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1354, 24, 400) Ytr2: (1354, 4) \n",
      "  Xva3: (197, 24, 400) Yva2: (197, 4) \n",
      "  Xte3: (348, 24, 400) Yte2: (348, 4)\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 3s 59ms/step - loss: 432.1916 - mae: 432.1788 - val_loss: 431.4794 - val_mae: 431.4665 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 426.0076 - mae: 425.9946 - val_loss: 422.4751 - val_mae: 422.4619 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 415.4615 - mae: 415.4481 - val_loss: 409.7863 - val_mae: 409.7726 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 401.9848 - mae: 401.9707 - val_loss: 393.6015 - val_mae: 393.5869 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 384.3685 - mae: 384.3535 - val_loss: 373.2253 - val_mae: 373.2095 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 363.3431 - mae: 363.3267 - val_loss: 348.2802 - val_mae: 348.2626 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 338.5691 - mae: 338.5507 - val_loss: 318.9492 - val_mae: 318.9295 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 313.8335 - mae: 313.8129 - val_loss: 295.6212 - val_mae: 295.5992 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 295.2871 - mae: 295.2642 - val_loss: 277.7498 - val_mae: 277.7255 - lr: 0.0010\n",
      "Epoch 10/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 12ms/step - loss: 280.2887 - mae: 280.2635 - val_loss: 261.8971 - val_mae: 261.8706 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 267.8306 - mae: 267.8031 - val_loss: 247.8049 - val_mae: 247.7762 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 256.4848 - mae: 256.4551 - val_loss: 235.6608 - val_mae: 235.6298 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 247.0053 - mae: 246.9732 - val_loss: 225.5205 - val_mae: 225.4872 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 239.8172 - mae: 239.7829 - val_loss: 218.1774 - val_mae: 218.1419 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 234.1427 - mae: 234.1064 - val_loss: 211.9312 - val_mae: 211.8939 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 226.1449 - mae: 226.1068 - val_loss: 198.5796 - val_mae: 198.5405 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 209.9933 - mae: 209.9533 - val_loss: 183.2063 - val_mae: 183.1651 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 193.9780 - mae: 193.9357 - val_loss: 169.3440 - val_mae: 169.3002 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 180.8091 - mae: 180.7640 - val_loss: 154.5259 - val_mae: 154.4791 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 169.3011 - mae: 169.2529 - val_loss: 144.0916 - val_mae: 144.0417 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 357.6149\n",
      "LV_RMSE_12h: 397.7694\n",
      "LV_MAE_24h: 87.4368\n",
      "LV_RMSE_24h: 151.2567\n",
      "LV_MAE_48h: 107.0718\n",
      "LV_RMSE_48h: 173.2249\n",
      "LV_MAE_72h: 93.0057\n",
      "LV_RMSE_72h: 161.5581\n",
      "LV_MAE_mean: 161.2823\n",
      "LV_RMSE_mean: 220.9523\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 285.6791\n",
      "RMSE_12h: 327.5153\n",
      "MAE_24h: 92.7727\n",
      "RMSE_24h: 138.1338\n",
      "MAE_48h: 91.6026\n",
      "RMSE_48h: 136.8504\n",
      "MAE_72h: 90.3532\n",
      "RMSE_72h: 134.5675\n",
      "MAE_mean: 140.1019\n",
      "RMSE_mean: 184.2668\n",
      "\n",
      "=== Station S3010091 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1377 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1354, 24, 400) Ytr2: (1354, 4) \n",
      "  Xva3: (197, 24, 400) Yva2: (197, 4) \n",
      "  Xte3: (348, 24, 400) Yte2: (348, 4)\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 3s 59ms/step - loss: 4201.3037 - mae: 4201.2915 - val_loss: 4252.9424 - val_mae: 4252.9297 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 4195.7568 - mae: 4195.7441 - val_loss: 4245.1846 - val_mae: 4245.1714 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 4186.1938 - mae: 4186.1812 - val_loss: 4233.6445 - val_mae: 4233.6309 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 4173.3555 - mae: 4173.3413 - val_loss: 4218.7378 - val_mae: 4218.7231 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 4156.5083 - mae: 4156.4941 - val_loss: 4199.9922 - val_mae: 4199.9766 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 4136.0312 - mae: 4136.0146 - val_loss: 4176.8525 - val_mae: 4176.8354 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 4110.9541 - mae: 4110.9355 - val_loss: 4148.9771 - val_mae: 4148.9580 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 4080.7542 - mae: 4080.7334 - val_loss: 4116.5674 - val_mae: 4116.5459 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 4047.1382 - mae: 4047.1152 - val_loss: 4079.4968 - val_mae: 4079.4724 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 4007.7822 - mae: 4007.7563 - val_loss: 4037.6533 - val_mae: 4037.6257 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 3963.6997 - mae: 3963.6707 - val_loss: 3990.9453 - val_mae: 3990.9143 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 3914.8247 - mae: 3914.7917 - val_loss: 3939.3201 - val_mae: 3939.2842 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 3861.5217 - mae: 3861.4841 - val_loss: 3882.7734 - val_mae: 3882.7329 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 3802.1240 - mae: 3802.0813 - val_loss: 3821.3005 - val_mae: 3821.2551 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 3737.5330 - mae: 3737.4849 - val_loss: 3754.7583 - val_mae: 3754.7075 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 3669.9360 - mae: 3669.8818 - val_loss: 3683.3110 - val_mae: 3683.2539 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 3595.4700 - mae: 3595.4099 - val_loss: 3606.9282 - val_mae: 3606.8647 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 3517.3682 - mae: 3517.3018 - val_loss: 3526.2815 - val_mae: 3526.2107 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 3436.1299 - mae: 3436.0562 - val_loss: 3444.8210 - val_mae: 3444.7429 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 3354.0510 - mae: 3353.9705 - val_loss: 3366.3325 - val_mae: 3366.2471 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 3753.3735\n",
      "LV_RMSE_12h: 4240.5249\n",
      "LV_MAE_24h: 605.5862\n",
      "LV_RMSE_24h: 852.5417\n",
      "LV_MAE_48h: 740.1523\n",
      "LV_RMSE_48h: 1070.9780\n",
      "LV_MAE_72h: 604.0402\n",
      "LV_RMSE_72h: 840.7997\n",
      "LV_MAE_mean: 1425.7881\n",
      "LV_RMSE_mean: 1751.2111\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 3156.5710\n",
      "RMSE_12h: 3837.4504\n",
      "MAE_24h: 3198.5071\n",
      "RMSE_24h: 3855.8669\n",
      "MAE_48h: 3329.9495\n",
      "RMSE_48h: 3986.1255\n",
      "MAE_72h: 3247.2141\n",
      "RMSE_72h: 3908.3032\n",
      "MAE_mean: 3233.0603\n",
      "RMSE_mean: 3896.9365\n",
      "\n",
      "=== Station S3010092 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1377 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1354, 24, 400) Ytr2: (1354, 4) \n",
      "  Xva3: (197, 24, 400) Yva2: (197, 4) \n",
      "  Xte3: (348, 24, 400) Yte2: (348, 4)\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 3s 60ms/step - loss: 590.6856 - mae: 590.6729 - val_loss: 616.3078 - val_mae: 616.2950 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 584.8529 - mae: 584.8402 - val_loss: 607.7436 - val_mae: 607.7307 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 574.2662 - mae: 574.2531 - val_loss: 595.3262 - val_mae: 595.3127 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 560.5257 - mae: 560.5118 - val_loss: 579.3009 - val_mae: 579.2866 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 542.8255 - mae: 542.8107 - val_loss: 559.6904 - val_mae: 559.6748 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 521.4970 - mae: 521.4808 - val_loss: 536.8727 - val_mae: 536.8554 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 499.0901 - mae: 499.0720 - val_loss: 514.1855 - val_mae: 514.1663 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 478.2923 - mae: 478.2722 - val_loss: 496.2595 - val_mae: 496.2382 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 461.3200 - mae: 461.2978 - val_loss: 481.2803 - val_mae: 481.2568 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 446.6315 - mae: 446.6071 - val_loss: 467.1185 - val_mae: 467.0927 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 433.7180 - mae: 433.6913 - val_loss: 452.7066 - val_mae: 452.6785 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 419.5735 - mae: 419.5442 - val_loss: 438.7279 - val_mae: 438.6972 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 405.5994 - mae: 405.5674 - val_loss: 425.2163 - val_mae: 425.1827 - lr: 0.0010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 392.2271 - mae: 392.1923 - val_loss: 412.2957 - val_mae: 412.2593 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 379.5414 - mae: 379.5037 - val_loss: 399.0808 - val_mae: 399.0416 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 367.8873 - mae: 367.8467 - val_loss: 384.6654 - val_mae: 384.6233 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 351.7764 - mae: 351.7330 - val_loss: 370.5031 - val_mae: 370.4580 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 337.2185 - mae: 337.1722 - val_loss: 352.6913 - val_mae: 352.6433 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 317.5811 - mae: 317.5318 - val_loss: 330.0074 - val_mae: 329.9561 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 295.0580 - mae: 295.0053 - val_loss: 308.8887 - val_mae: 308.8340 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 803.3104\n",
      "LV_RMSE_12h: 930.7462\n",
      "LV_MAE_24h: 137.6925\n",
      "LV_RMSE_24h: 194.8804\n",
      "LV_MAE_48h: 170.4626\n",
      "LV_RMSE_48h: 246.4020\n",
      "LV_MAE_72h: 168.4713\n",
      "LV_RMSE_72h: 235.3125\n",
      "LV_MAE_mean: 319.9842\n",
      "LV_RMSE_mean: 401.8352\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 525.9733\n",
      "RMSE_12h: 681.0717\n",
      "MAE_24h: 282.0561\n",
      "RMSE_24h: 430.2336\n",
      "MAE_48h: 290.8054\n",
      "RMSE_48h: 437.4895\n",
      "MAE_72h: 294.3429\n",
      "RMSE_72h: 444.8855\n",
      "MAE_mean: 348.2944\n",
      "RMSE_mean: 498.4201\n",
      "\n",
      "=== Station S3011011 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1377 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1354, 24, 400) Ytr2: (1354, 4) \n",
      "  Xva3: (197, 24, 400) Yva2: (197, 4) \n",
      "  Xte3: (348, 24, 400) Yte2: (348, 4)\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 3s 60ms/step - loss: 713.8323 - mae: 713.8196 - val_loss: 702.8828 - val_mae: 702.8699 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 706.0461 - mae: 706.0334 - val_loss: 692.4366 - val_mae: 692.4235 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 693.9209 - mae: 693.9077 - val_loss: 678.3740 - val_mae: 678.3604 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 678.3054 - mae: 678.2913 - val_loss: 660.3032 - val_mae: 660.2886 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 657.8584 - mae: 657.8433 - val_loss: 638.7914 - val_mae: 638.7753 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 635.5568 - mae: 635.5399 - val_loss: 616.4966 - val_mae: 616.4787 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 612.9545 - mae: 612.9357 - val_loss: 594.5922 - val_mae: 594.5722 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 591.0923 - mae: 591.0712 - val_loss: 573.7269 - val_mae: 573.7045 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 571.4363 - mae: 571.4128 - val_loss: 554.7657 - val_mae: 554.7408 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 552.1905 - mae: 552.1644 - val_loss: 537.5448 - val_mae: 537.5172 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 536.3469 - mae: 536.3181 - val_loss: 521.2177 - val_mae: 521.1872 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 521.1194 - mae: 521.0876 - val_loss: 505.6580 - val_mae: 505.6246 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 507.4354 - mae: 507.4007 - val_loss: 491.2443 - val_mae: 491.2079 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 494.6300 - mae: 494.5924 - val_loss: 477.7171 - val_mae: 477.6777 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 479.3876 - mae: 479.3468 - val_loss: 459.6647 - val_mae: 459.6221 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 460.0832 - mae: 460.0392 - val_loss: 435.9529 - val_mae: 435.9070 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 434.2356 - mae: 434.1880 - val_loss: 409.6087 - val_mae: 409.5591 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 409.4514 - mae: 409.4000 - val_loss: 385.4956 - val_mae: 385.4420 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 386.2683 - mae: 386.2127 - val_loss: 364.9705 - val_mae: 364.9124 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 366.9216 - mae: 366.8615 - val_loss: 346.1266 - val_mae: 346.0639 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 757.8247\n",
      "LV_RMSE_12h: 855.3196\n",
      "LV_MAE_24h: 134.5460\n",
      "LV_RMSE_24h: 208.0577\n",
      "LV_MAE_48h: 187.3908\n",
      "LV_RMSE_48h: 283.4328\n",
      "LV_MAE_72h: 165.1494\n",
      "LV_RMSE_72h: 257.8993\n",
      "LV_MAE_mean: 311.2277\n",
      "LV_RMSE_mean: 401.1773\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 535.1972\n",
      "RMSE_12h: 650.2625\n",
      "MAE_24h: 224.1109\n",
      "RMSE_24h: 337.7333\n",
      "MAE_48h: 216.6658\n",
      "RMSE_48h: 320.1923\n",
      "MAE_72h: 225.0985\n",
      "RMSE_72h: 339.0358\n",
      "MAE_mean: 300.2681\n",
      "RMSE_mean: 411.8059\n",
      "\n",
      "=== Station S3011012 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1377 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1354, 24, 400) Ytr2: (1354, 4) \n",
      "  Xva3: (197, 24, 400) Yva2: (197, 4) \n",
      "  Xte3: (348, 24, 400) Yte2: (348, 4)\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 3s 57ms/step - loss: 735.7623 - mae: 735.7494 - val_loss: 721.3867 - val_mae: 721.3740 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 731.1338 - mae: 731.1208 - val_loss: 714.5733 - val_mae: 714.5603 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 722.2380 - mae: 722.2249 - val_loss: 703.0807 - val_mae: 703.0672 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 708.9034 - mae: 708.8895 - val_loss: 687.1385 - val_mae: 687.1241 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 690.9109 - mae: 690.8961 - val_loss: 666.9307 - val_mae: 666.9150 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 668.9096 - mae: 668.8932 - val_loss: 642.8290 - val_mae: 642.8115 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 644.5798 - mae: 644.5615 - val_loss: 617.7757 - val_mae: 617.7561 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 619.4272 - mae: 619.4066 - val_loss: 594.3020 - val_mae: 594.2800 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 595.8509 - mae: 595.8276 - val_loss: 573.1622 - val_mae: 573.1375 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 574.1506 - mae: 574.1247 - val_loss: 553.9376 - val_mae: 553.9100 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 555.6094 - mae: 555.5807 - val_loss: 536.6906 - val_mae: 536.6602 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 538.3477 - mae: 538.3160 - val_loss: 521.3034 - val_mae: 521.2701 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 524.0895 - mae: 524.0548 - val_loss: 507.4963 - val_mae: 507.4600 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 510.8344 - mae: 510.7968 - val_loss: 495.0374 - val_mae: 494.9981 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 499.1209 - mae: 499.0804 - val_loss: 484.5827 - val_mae: 484.5405 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 489.3253 - mae: 489.2819 - val_loss: 474.6935 - val_mae: 474.6484 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 477.8415 - mae: 477.7953 - val_loss: 461.6826 - val_mae: 461.6347 - lr: 0.0010\n",
      "Epoch 18/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 13ms/step - loss: 462.2185 - mae: 462.1695 - val_loss: 440.3464 - val_mae: 440.2957 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 437.1815 - mae: 437.1293 - val_loss: 415.7219 - val_mae: 415.6678 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 414.5038 - mae: 414.4479 - val_loss: 396.3438 - val_mae: 396.2857 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 761.2098\n",
      "LV_RMSE_12h: 843.4914\n",
      "LV_MAE_24h: 139.7442\n",
      "LV_RMSE_24h: 214.7833\n",
      "LV_MAE_48h: 197.0460\n",
      "LV_RMSE_48h: 293.0738\n",
      "LV_MAE_72h: 170.8879\n",
      "LV_RMSE_72h: 259.5251\n",
      "LV_MAE_mean: 317.2220\n",
      "LV_RMSE_mean: 402.7184\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 512.2098\n",
      "RMSE_12h: 613.6382\n",
      "MAE_24h: 267.9079\n",
      "RMSE_24h: 378.7099\n",
      "MAE_48h: 268.7242\n",
      "RMSE_48h: 377.6322\n",
      "MAE_72h: 262.4106\n",
      "RMSE_72h: 367.7912\n",
      "MAE_mean: 327.8131\n",
      "RMSE_mean: 434.4429\n",
      "\n",
      "=== Station S3011031 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1377 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1354, 24, 400) Ytr2: (1354, 4) \n",
      "  Xva3: (197, 24, 400) Yva2: (197, 4) \n",
      "  Xte3: (348, 24, 400) Yte2: (348, 4)\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 3s 57ms/step - loss: 3611.0676 - mae: 3611.0549 - val_loss: 3622.3591 - val_mae: 3622.3464 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 3604.9070 - mae: 3604.8943 - val_loss: 3613.3943 - val_mae: 3613.3813 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 3594.1182 - mae: 3594.1050 - val_loss: 3600.7681 - val_mae: 3600.7544 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 3580.1809 - mae: 3580.1670 - val_loss: 3584.7944 - val_mae: 3584.7798 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 3562.2910 - mae: 3562.2759 - val_loss: 3564.8064 - val_mae: 3564.7905 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 3540.2854 - mae: 3540.2693 - val_loss: 3540.4800 - val_mae: 3540.4626 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 3514.2046 - mae: 3514.1858 - val_loss: 3511.5891 - val_mae: 3511.5698 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 3483.1414 - mae: 3483.1211 - val_loss: 3477.9629 - val_mae: 3477.9409 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 3446.8701 - mae: 3446.8459 - val_loss: 3439.4661 - val_mae: 3439.4409 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 3406.9395 - mae: 3406.9133 - val_loss: 3396.0879 - val_mae: 3396.0596 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 3361.0979 - mae: 3361.0679 - val_loss: 3347.7437 - val_mae: 3347.7117 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 3310.2219 - mae: 3310.1880 - val_loss: 3294.3313 - val_mae: 3294.2947 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 3254.7056 - mae: 3254.6670 - val_loss: 3236.1492 - val_mae: 3236.1079 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 3196.9731 - mae: 3196.9294 - val_loss: 3175.2490 - val_mae: 3175.2024 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 3134.0586 - mae: 3134.0095 - val_loss: 3114.7104 - val_mae: 3114.6582 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 3076.2512 - mae: 3076.1968 - val_loss: 3056.5813 - val_mae: 3056.5237 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 3019.7998 - mae: 3019.7397 - val_loss: 3000.1577 - val_mae: 3000.0942 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 2963.6914 - mae: 2963.6252 - val_loss: 2946.8499 - val_mae: 2946.7805 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 2911.5798 - mae: 2911.5081 - val_loss: 2895.6265 - val_mae: 2895.5508 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 2862.7959 - mae: 2862.7173 - val_loss: 2846.0061 - val_mae: 2845.9238 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 3419.1350\n",
      "LV_RMSE_12h: 3809.0474\n",
      "LV_MAE_24h: 614.9138\n",
      "LV_RMSE_24h: 844.3270\n",
      "LV_MAE_48h: 752.7701\n",
      "LV_RMSE_48h: 1052.5898\n",
      "LV_MAE_72h: 586.4052\n",
      "LV_RMSE_72h: 811.5103\n",
      "LV_MAE_mean: 1343.3060\n",
      "LV_RMSE_mean: 1629.3687\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 2633.8223\n",
      "RMSE_12h: 3239.7561\n",
      "MAE_24h: 2648.5449\n",
      "RMSE_24h: 3234.8545\n",
      "MAE_48h: 2663.5471\n",
      "RMSE_48h: 3254.5137\n",
      "MAE_72h: 2691.8513\n",
      "RMSE_72h: 3286.1506\n",
      "MAE_mean: 2659.4414\n",
      "RMSE_mean: 3253.8186\n",
      "\n",
      "=== Station S3011032 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1377 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1354, 24, 400) Ytr2: (1354, 4) \n",
      "  Xva3: (197, 24, 400) Yva2: (197, 4) \n",
      "  Xte3: (348, 24, 400) Yte2: (348, 4)\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 3s 57ms/step - loss: 618.0993 - mae: 618.0865 - val_loss: 641.9417 - val_mae: 641.9288 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 611.8412 - mae: 611.8283 - val_loss: 632.7340 - val_mae: 632.7208 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 601.5432 - mae: 601.5298 - val_loss: 621.0418 - val_mae: 621.0280 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 589.6432 - mae: 589.6291 - val_loss: 608.2586 - val_mae: 608.2438 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 576.1772 - mae: 576.1619 - val_loss: 593.7490 - val_mae: 593.7327 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 561.8022 - mae: 561.7852 - val_loss: 578.4046 - val_mae: 578.3865 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 546.8082 - mae: 546.7893 - val_loss: 563.2238 - val_mae: 563.2036 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 531.2454 - mae: 531.2241 - val_loss: 547.5822 - val_mae: 547.5595 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 515.5974 - mae: 515.5735 - val_loss: 531.5786 - val_mae: 531.5532 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 498.9871 - mae: 498.9603 - val_loss: 515.4537 - val_mae: 515.4252 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 483.6668 - mae: 483.6368 - val_loss: 498.5902 - val_mae: 498.5583 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 466.9305 - mae: 466.8970 - val_loss: 481.9655 - val_mae: 481.9299 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 451.4836 - mae: 451.4464 - val_loss: 464.6683 - val_mae: 464.6290 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 434.1872 - mae: 434.1462 - val_loss: 443.7033 - val_mae: 443.6601 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 411.3241 - mae: 411.2790 - val_loss: 418.1176 - val_mae: 418.0703 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 389.1706 - mae: 389.1214 - val_loss: 394.1307 - val_mae: 394.0790 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 364.5489 - mae: 364.4953 - val_loss: 373.4289 - val_mae: 373.3728 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 346.0778 - mae: 346.0197 - val_loss: 355.0673 - val_mae: 355.0067 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 327.5870 - mae: 327.5246 - val_loss: 337.6448 - val_mae: 337.5800 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 312.6901 - mae: 312.6235 - val_loss: 322.5944 - val_mae: 322.5255 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 911.6207\n",
      "LV_RMSE_12h: 1052.0923\n",
      "LV_MAE_24h: 160.3879\n",
      "LV_RMSE_24h: 226.8398\n",
      "LV_MAE_48h: 198.8075\n",
      "LV_RMSE_48h: 285.0629\n",
      "LV_MAE_72h: 192.7615\n",
      "LV_RMSE_72h: 263.7797\n",
      "LV_MAE_mean: 365.8944\n",
      "LV_RMSE_mean: 456.9437\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 615.7283\n",
      "RMSE_12h: 773.8620\n",
      "MAE_24h: 279.6444\n",
      "RMSE_24h: 405.6046\n",
      "MAE_48h: 287.2498\n",
      "RMSE_48h: 413.2979\n",
      "MAE_72h: 295.8352\n",
      "RMSE_72h: 424.2002\n",
      "MAE_mean: 369.6144\n",
      "RMSE_mean: 504.2412\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Station S3011041 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1377 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1354, 24, 400) Ytr2: (1354, 4) \n",
      "  Xva3: (197, 24, 400) Yva2: (197, 4) \n",
      "  Xte3: (348, 24, 400) Yte2: (348, 4)\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 3s 59ms/step - loss: 3440.3696 - mae: 3440.3564 - val_loss: 3457.4016 - val_mae: 3457.3887 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 3433.5139 - mae: 3433.5012 - val_loss: 3447.9417 - val_mae: 3447.9282 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 3422.4382 - mae: 3422.4250 - val_loss: 3435.1675 - val_mae: 3435.1538 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 3408.4387 - mae: 3408.4246 - val_loss: 3418.9524 - val_mae: 3418.9382 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 3389.9819 - mae: 3389.9663 - val_loss: 3398.4309 - val_mae: 3398.4150 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 3367.5376 - mae: 3367.5210 - val_loss: 3373.3181 - val_mae: 3373.3008 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 3340.5247 - mae: 3340.5059 - val_loss: 3343.4387 - val_mae: 3343.4187 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 3308.1018 - mae: 3308.0813 - val_loss: 3308.5540 - val_mae: 3308.5317 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 3271.6377 - mae: 3271.6147 - val_loss: 3268.6155 - val_mae: 3268.5901 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 3229.0557 - mae: 3229.0288 - val_loss: 3223.5464 - val_mae: 3223.5178 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 3181.4727 - mae: 3181.4424 - val_loss: 3173.1777 - val_mae: 3173.1448 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 3129.8005 - mae: 3129.7659 - val_loss: 3117.6348 - val_mae: 3117.5974 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 3071.8132 - mae: 3071.7739 - val_loss: 3056.7913 - val_mae: 3056.7488 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 3008.1394 - mae: 3008.0945 - val_loss: 2990.8091 - val_mae: 2990.7607 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 2940.9109 - mae: 2940.8601 - val_loss: 2920.7524 - val_mae: 2920.6985 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 2873.2866 - mae: 2873.2302 - val_loss: 2850.0732 - val_mae: 2850.0129 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 2808.5557 - mae: 2808.4927 - val_loss: 2783.5750 - val_mae: 2783.5083 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 2742.9880 - mae: 2742.9185 - val_loss: 2721.4905 - val_mae: 2721.4172 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 2686.7791 - mae: 2686.7029 - val_loss: 2664.1941 - val_mae: 2664.1145 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 2629.0496 - mae: 2628.9670 - val_loss: 2609.6284 - val_mae: 2609.5420 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 2944.6379\n",
      "LV_RMSE_12h: 3295.3254\n",
      "LV_MAE_24h: 628.2759\n",
      "LV_RMSE_24h: 951.0422\n",
      "LV_MAE_48h: 829.3046\n",
      "LV_RMSE_48h: 1165.5623\n",
      "LV_MAE_72h: 600.3448\n",
      "LV_RMSE_72h: 832.6835\n",
      "LV_MAE_mean: 1250.6407\n",
      "LV_RMSE_mean: 1561.1533\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 2475.3018\n",
      "RMSE_12h: 3007.9983\n",
      "MAE_24h: 2505.2524\n",
      "RMSE_24h: 3016.4138\n",
      "MAE_48h: 2517.4907\n",
      "RMSE_48h: 3033.9844\n",
      "MAE_72h: 2479.0981\n",
      "RMSE_72h: 2992.5220\n",
      "MAE_mean: 2494.2856\n",
      "RMSE_mean: 3012.7295\n",
      "\n",
      "=== Station S3011042 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1377 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1354, 24, 400) Ytr2: (1354, 4) \n",
      "  Xva3: (197, 24, 400) Yva2: (197, 4) \n",
      "  Xte3: (348, 24, 400) Yte2: (348, 4)\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 3s 58ms/step - loss: 752.2922 - mae: 752.2795 - val_loss: 746.2367 - val_mae: 746.2238 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 746.4572 - mae: 746.4444 - val_loss: 737.8318 - val_mae: 737.8188 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 736.5167 - mae: 736.5035 - val_loss: 726.4248 - val_mae: 726.4114 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 724.2537 - mae: 724.2399 - val_loss: 712.4926 - val_mae: 712.4785 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 709.0847 - mae: 709.0700 - val_loss: 696.8607 - val_mae: 696.8454 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 692.8020 - mae: 692.7863 - val_loss: 680.3225 - val_mae: 680.3058 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 675.6078 - mae: 675.5905 - val_loss: 663.1339 - val_mae: 663.1155 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 657.5391 - mae: 657.5200 - val_loss: 645.1421 - val_mae: 645.1218 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 639.4855 - mae: 639.4642 - val_loss: 626.4613 - val_mae: 626.4387 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 619.9253 - mae: 619.9016 - val_loss: 607.4114 - val_mae: 607.3863 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 601.7389 - mae: 601.7126 - val_loss: 587.6323 - val_mae: 587.6044 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 581.7662 - mae: 581.7369 - val_loss: 568.4838 - val_mae: 568.4529 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 562.7634 - mae: 562.7311 - val_loss: 550.4122 - val_mae: 550.3782 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 545.8275 - mae: 545.7920 - val_loss: 532.7428 - val_mae: 532.7054 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 527.7987 - mae: 527.7599 - val_loss: 514.0112 - val_mae: 513.9704 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 511.3506 - mae: 511.3084 - val_loss: 493.8239 - val_mae: 493.7796 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 490.4676 - mae: 490.4216 - val_loss: 473.7618 - val_mae: 473.7138 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 470.9319 - mae: 470.8821 - val_loss: 452.1706 - val_mae: 452.1187 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 452.6128 - mae: 452.5592 - val_loss: 431.9766 - val_mae: 431.9206 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 433.2788 - mae: 433.2209 - val_loss: 412.9391 - val_mae: 412.8789 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 913.5287\n",
      "LV_RMSE_12h: 1032.1180\n",
      "LV_MAE_24h: 164.9425\n",
      "LV_RMSE_24h: 231.0628\n",
      "LV_MAE_48h: 192.9454\n",
      "LV_RMSE_48h: 271.5794\n",
      "LV_MAE_72h: 198.7500\n",
      "LV_RMSE_72h: 274.3658\n",
      "LV_MAE_mean: 367.5417\n",
      "LV_RMSE_mean: 452.2815\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 563.6667\n",
      "RMSE_12h: 661.2152\n",
      "MAE_24h: 423.1311\n",
      "RMSE_24h: 522.4496\n",
      "MAE_48h: 402.7574\n",
      "RMSE_48h: 499.4348\n",
      "MAE_72h: 412.2979\n",
      "RMSE_72h: 514.8573\n",
      "MAE_mean: 450.4633\n",
      "RMSE_mean: 549.4893\n",
      "\n",
      "=== Station S3013021 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1377 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1354, 24, 400) Ytr2: (1354, 4) \n",
      "  Xva3: (197, 24, 400) Yva2: (197, 4) \n",
      "  Xte3: (348, 24, 400) Yte2: (348, 4)\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 3s 63ms/step - loss: 507.9112 - mae: 507.8987 - val_loss: 477.7133 - val_mae: 477.7007 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 503.0195 - mae: 503.0069 - val_loss: 470.3615 - val_mae: 470.3487 - lr: 0.0010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 494.0902 - mae: 494.0772 - val_loss: 459.6328 - val_mae: 459.6195 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 482.3297 - mae: 482.3159 - val_loss: 446.7622 - val_mae: 446.7480 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 467.9652 - mae: 467.9505 - val_loss: 432.6321 - val_mae: 432.6167 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 452.6772 - mae: 452.6611 - val_loss: 417.7058 - val_mae: 417.6888 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 436.0802 - mae: 436.0624 - val_loss: 401.7531 - val_mae: 401.7341 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 418.5363 - mae: 418.5165 - val_loss: 385.1023 - val_mae: 385.0812 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 400.6818 - mae: 400.6597 - val_loss: 368.5039 - val_mae: 368.4804 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 381.5485 - mae: 381.5238 - val_loss: 352.0918 - val_mae: 352.0655 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 364.5510 - mae: 364.5235 - val_loss: 335.8447 - val_mae: 335.8156 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 346.7791 - mae: 346.7486 - val_loss: 320.7218 - val_mae: 320.6896 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 331.1199 - mae: 331.0862 - val_loss: 305.9445 - val_mae: 305.9090 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 315.8912 - mae: 315.8543 - val_loss: 291.7984 - val_mae: 291.7596 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 302.4993 - mae: 302.4590 - val_loss: 279.4198 - val_mae: 279.3777 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 289.3449 - mae: 289.3014 - val_loss: 261.3285 - val_mae: 261.2833 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 266.5010 - mae: 266.4544 - val_loss: 240.7283 - val_mae: 240.6801 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 249.7234 - mae: 249.6741 - val_loss: 227.0820 - val_mae: 227.0311 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 236.1564 - mae: 236.1043 - val_loss: 216.0310 - val_mae: 215.9773 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 225.4655 - mae: 225.4107 - val_loss: 205.1661 - val_mae: 205.1098 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 559.2471\n",
      "LV_RMSE_12h: 646.5081\n",
      "LV_MAE_24h: 89.0517\n",
      "LV_RMSE_24h: 120.5408\n",
      "LV_MAE_48h: 110.8563\n",
      "LV_RMSE_48h: 141.6590\n",
      "LV_MAE_72h: 103.0805\n",
      "LV_RMSE_72h: 137.9804\n",
      "LV_MAE_mean: 215.5589\n",
      "LV_RMSE_mean: 261.6721\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 388.3831\n",
      "RMSE_12h: 468.6010\n",
      "MAE_24h: 162.4222\n",
      "RMSE_24h: 216.9619\n",
      "MAE_48h: 163.7768\n",
      "RMSE_48h: 220.6583\n",
      "MAE_72h: 168.4524\n",
      "RMSE_72h: 223.1144\n",
      "MAE_mean: 220.7586\n",
      "RMSE_mean: 282.3339\n",
      "\n",
      "=== Station S3013022 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1377 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1354, 24, 400) Ytr2: (1354, 4) \n",
      "  Xva3: (197, 24, 400) Yva2: (197, 4) \n",
      "  Xte3: (348, 24, 400) Yte2: (348, 4)\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 3s 57ms/step - loss: 1260.2146 - mae: 1260.2019 - val_loss: 1105.9056 - val_mae: 1105.8929 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1253.4388 - mae: 1253.4259 - val_loss: 1096.3081 - val_mae: 1096.2949 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1241.9780 - mae: 1241.9647 - val_loss: 1083.0338 - val_mae: 1083.0201 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 1227.4269 - mae: 1227.4128 - val_loss: 1065.8896 - val_mae: 1065.8750 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1207.8846 - mae: 1207.8695 - val_loss: 1044.2480 - val_mae: 1044.2321 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1183.9460 - mae: 1183.9292 - val_loss: 1017.6391 - val_mae: 1017.6213 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 1155.5753 - mae: 1155.5565 - val_loss: 985.9646 - val_mae: 985.9446 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 1121.3013 - mae: 1121.2802 - val_loss: 948.9940 - val_mae: 948.9711 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1082.3448 - mae: 1082.3207 - val_loss: 906.6608 - val_mae: 906.6348 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 1037.2280 - mae: 1037.2003 - val_loss: 859.6149 - val_mae: 859.5850 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 989.2756 - mae: 989.2439 - val_loss: 810.5408 - val_mae: 810.5067 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 939.0592 - mae: 939.0232 - val_loss: 762.9441 - val_mae: 762.9054 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 890.2072 - mae: 890.1663 - val_loss: 718.8890 - val_mae: 718.8454 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 845.5177 - mae: 845.4722 - val_loss: 678.4719 - val_mae: 678.4235 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 798.8062 - mae: 798.7556 - val_loss: 639.7867 - val_mae: 639.7330 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 757.0764 - mae: 757.0205 - val_loss: 603.3961 - val_mae: 603.3371 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 715.6588 - mae: 715.5975 - val_loss: 570.5786 - val_mae: 570.5141 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 674.6277 - mae: 674.5609 - val_loss: 540.4653 - val_mae: 540.3952 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 642.6685 - mae: 642.5961 - val_loss: 511.5596 - val_mae: 511.4840 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 609.0489 - mae: 608.9709 - val_loss: 482.1208 - val_mae: 482.0397 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 783.1753\n",
      "LV_RMSE_12h: 883.9524\n",
      "LV_MAE_24h: 141.3506\n",
      "LV_RMSE_24h: 207.5185\n",
      "LV_MAE_48h: 178.1609\n",
      "LV_RMSE_48h: 256.4607\n",
      "LV_MAE_72h: 155.4167\n",
      "LV_RMSE_72h: 224.2756\n",
      "LV_MAE_mean: 314.5258\n",
      "LV_RMSE_mean: 393.0518\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 500.7122\n",
      "RMSE_12h: 563.7964\n",
      "MAE_24h: 436.8427\n",
      "RMSE_24h: 487.2310\n",
      "MAE_48h: 428.7204\n",
      "RMSE_48h: 478.4474\n",
      "MAE_72h: 464.1554\n",
      "RMSE_72h: 524.1625\n",
      "MAE_mean: 457.6077\n",
      "RMSE_mean: 513.4093\n",
      "\n",
      "=== Station S3013023 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[S3013023] ERROR: No training rows after alignment. Check the data index and feature build.\n",
      "\n",
      "=== Station S3013024 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1167 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1144, 24, 400) Ytr2: (1144, 4) \n",
      "  Xva3: (167, 24, 400) Yva2: (167, 4) \n",
      "  Xte3: (288, 24, 400) Yte2: (288, 4)\n",
      "Epoch 1/20\n",
      "9/9 [==============================] - 3s 78ms/step - loss: 191.7758 - mae: 191.7631 - val_loss: 194.3671 - val_mae: 194.3544 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 187.8090 - mae: 187.7963 - val_loss: 188.8011 - val_mae: 188.7883 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 180.9036 - mae: 180.8907 - val_loss: 180.3372 - val_mae: 180.3241 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 171.8374 - mae: 171.8241 - val_loss: 171.1547 - val_mae: 171.1411 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 162.5873 - mae: 162.5734 - val_loss: 162.3163 - val_mae: 162.3020 - lr: 0.0010\n",
      "Epoch 6/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 14ms/step - loss: 153.6513 - mae: 153.6366 - val_loss: 153.9397 - val_mae: 153.9245 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 145.5135 - mae: 145.4978 - val_loss: 145.8940 - val_mae: 145.8777 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 137.3890 - mae: 137.3722 - val_loss: 138.1185 - val_mae: 138.1011 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 130.2324 - mae: 130.2144 - val_loss: 131.1754 - val_mae: 131.1567 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 123.9763 - mae: 123.9570 - val_loss: 125.2802 - val_mae: 125.2602 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 118.4023 - mae: 118.3817 - val_loss: 119.1562 - val_mae: 119.1348 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 112.3341 - mae: 112.3122 - val_loss: 111.3149 - val_mae: 111.2923 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 104.9927 - mae: 104.9695 - val_loss: 103.1751 - val_mae: 103.1511 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 98.2907 - mae: 98.2661 - val_loss: 96.2454 - val_mae: 96.2200 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 93.3021 - mae: 93.2762 - val_loss: 90.0258 - val_mae: 89.9991 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 88.1204 - mae: 88.0931 - val_loss: 85.3585 - val_mae: 85.3306 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 84.7092 - mae: 84.6808 - val_loss: 80.8568 - val_mae: 80.8279 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 80.9590 - mae: 80.9296 - val_loss: 76.4325 - val_mae: 76.4025 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 77.0440 - mae: 77.0135 - val_loss: 71.9011 - val_mae: 71.8700 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 73.3412 - mae: 73.3097 - val_loss: 68.0916 - val_mae: 68.0595 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 212.2569\n",
      "LV_RMSE_12h: 238.2219\n",
      "LV_MAE_24h: 41.9722\n",
      "LV_RMSE_24h: 60.5239\n",
      "LV_MAE_48h: 46.1181\n",
      "LV_RMSE_48h: 64.8773\n",
      "LV_MAE_72h: 39.6910\n",
      "LV_RMSE_72h: 56.5456\n",
      "LV_MAE_mean: 85.0096\n",
      "LV_RMSE_mean: 105.0422\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 147.8076\n",
      "RMSE_12h: 172.0191\n",
      "MAE_24h: 42.9526\n",
      "RMSE_24h: 56.9164\n",
      "MAE_48h: 40.8507\n",
      "RMSE_48h: 55.3455\n",
      "MAE_72h: 41.2385\n",
      "RMSE_72h: 53.6841\n",
      "MAE_mean: 68.2123\n",
      "RMSE_mean: 84.4913\n",
      "\n",
      "=== Station S3013091 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1377 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1354, 24, 400) Ytr2: (1354, 4) \n",
      "  Xva3: (197, 24, 400) Yva2: (197, 4) \n",
      "  Xte3: (348, 24, 400) Yte2: (348, 4)\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 3s 62ms/step - loss: 374.7439 - mae: 374.7311 - val_loss: 350.0838 - val_mae: 350.0710 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 367.0817 - mae: 367.0687 - val_loss: 339.2177 - val_mae: 339.2045 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 354.3303 - mae: 354.3168 - val_loss: 324.4713 - val_mae: 324.4574 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 338.2241 - mae: 338.2099 - val_loss: 305.7879 - val_mae: 305.7729 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 316.9684 - mae: 316.9529 - val_loss: 282.4568 - val_mae: 282.4404 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 291.7206 - mae: 291.7034 - val_loss: 254.8332 - val_mae: 254.8149 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 262.3802 - mae: 262.3608 - val_loss: 225.0402 - val_mae: 225.0195 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 230.8857 - mae: 230.8639 - val_loss: 196.8445 - val_mae: 196.8212 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 202.9098 - mae: 202.8852 - val_loss: 174.3333 - val_mae: 174.3071 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 181.3387 - mae: 181.3113 - val_loss: 157.8442 - val_mae: 157.8152 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 166.3634 - mae: 166.3333 - val_loss: 146.6149 - val_mae: 146.5835 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 154.3053 - mae: 154.2728 - val_loss: 138.8181 - val_mae: 138.7844 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 147.0156 - mae: 146.9810 - val_loss: 133.1298 - val_mae: 133.0941 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 140.5228 - mae: 140.4863 - val_loss: 126.3844 - val_mae: 126.3470 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 132.1810 - mae: 132.1429 - val_loss: 115.9580 - val_mae: 115.9191 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 121.3043 - mae: 121.2646 - val_loss: 106.2683 - val_mae: 106.2276 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 111.6318 - mae: 111.5903 - val_loss: 98.7419 - val_mae: 98.6995 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 104.1231 - mae: 104.0799 - val_loss: 93.3258 - val_mae: 93.2817 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 100.6738 - mae: 100.6290 - val_loss: 91.2770 - val_mae: 91.2316 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 97.9408 - mae: 97.8949 - val_loss: 90.0276 - val_mae: 89.9813 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 248.6552\n",
      "LV_RMSE_12h: 274.1449\n",
      "LV_MAE_24h: 56.8793\n",
      "LV_RMSE_24h: 80.2500\n",
      "LV_MAE_48h: 70.1264\n",
      "LV_RMSE_48h: 99.8367\n",
      "LV_MAE_72h: 60.9397\n",
      "LV_RMSE_72h: 88.5109\n",
      "LV_MAE_mean: 109.1501\n",
      "LV_RMSE_mean: 135.6856\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 200.9794\n",
      "RMSE_12h: 227.6266\n",
      "MAE_24h: 57.4844\n",
      "RMSE_24h: 83.0117\n",
      "MAE_48h: 55.8669\n",
      "RMSE_48h: 82.4227\n",
      "MAE_72h: 55.6738\n",
      "RMSE_72h: 81.5856\n",
      "MAE_mean: 92.5011\n",
      "RMSE_mean: 118.6617\n",
      "\n",
      "=== Station S3013095 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1376 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1353, 24, 400) Ytr2: (1353, 4) \n",
      "  Xva3: (197, 24, 400) Yva2: (197, 4) \n",
      "  Xte3: (348, 24, 400) Yte2: (348, 4)\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 3s 58ms/step - loss: 81.1115 - mae: 81.0987 - val_loss: 78.5055 - val_mae: 78.4928 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 76.5632 - mae: 76.5504 - val_loss: 72.7945 - val_mae: 72.7816 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 71.4398 - mae: 71.4268 - val_loss: 67.4163 - val_mae: 67.4031 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 65.9768 - mae: 65.9632 - val_loss: 62.0906 - val_mae: 62.0766 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 60.7911 - mae: 60.7768 - val_loss: 56.9376 - val_mae: 56.9229 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 55.4796 - mae: 55.4645 - val_loss: 51.3689 - val_mae: 51.3532 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 50.1864 - mae: 50.1702 - val_loss: 45.0186 - val_mae: 45.0018 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 44.2723 - mae: 44.2550 - val_loss: 39.9070 - val_mae: 39.8891 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 40.7336 - mae: 40.7153 - val_loss: 37.2057 - val_mae: 37.1870 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 39.2598 - mae: 39.2410 - val_loss: 36.2947 - val_mae: 36.2757 - lr: 0.0010\n",
      "Epoch 11/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 13ms/step - loss: 38.1649 - mae: 38.1459 - val_loss: 35.2824 - val_mae: 35.2633 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 37.0798 - mae: 37.0606 - val_loss: 34.0111 - val_mae: 33.9916 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 36.0262 - mae: 36.0065 - val_loss: 32.6956 - val_mae: 32.6756 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 34.3338 - mae: 34.3134 - val_loss: 30.9571 - val_mae: 30.9363 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 33.0928 - mae: 33.0716 - val_loss: 28.8885 - val_mae: 28.8668 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 30.8521 - mae: 30.8299 - val_loss: 26.8166 - val_mae: 26.7937 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 29.0433 - mae: 29.0199 - val_loss: 24.7660 - val_mae: 24.7419 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 27.5104 - mae: 27.4857 - val_loss: 23.6027 - val_mae: 23.5774 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 26.9606 - mae: 26.9350 - val_loss: 22.5545 - val_mae: 22.5283 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 26.0560 - mae: 26.0295 - val_loss: 22.1211 - val_mae: 22.0942 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 99.7011\n",
      "LV_RMSE_12h: 112.3322\n",
      "LV_MAE_24h: 21.7931\n",
      "LV_RMSE_24h: 37.6311\n",
      "LV_MAE_48h: 27.8592\n",
      "LV_RMSE_48h: 49.8702\n",
      "LV_MAE_72h: 25.0833\n",
      "LV_RMSE_72h: 45.6302\n",
      "LV_MAE_mean: 43.6092\n",
      "LV_RMSE_mean: 61.3659\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 21.3341\n",
      "RMSE_12h: 38.6025\n",
      "MAE_24h: 22.1784\n",
      "RMSE_24h: 39.0051\n",
      "MAE_48h: 21.0027\n",
      "RMSE_48h: 36.0135\n",
      "MAE_72h: 20.0519\n",
      "RMSE_72h: 32.9959\n",
      "MAE_mean: 21.1418\n",
      "RMSE_mean: 36.6542\n",
      "\n",
      "=== Station S3013101 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1376 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1353, 24, 400) Ytr2: (1353, 4) \n",
      "  Xva3: (197, 24, 400) Yva2: (197, 4) \n",
      "  Xte3: (348, 24, 400) Yte2: (348, 4)\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 3s 58ms/step - loss: 444.4891 - mae: 444.4764 - val_loss: 452.4610 - val_mae: 452.4483 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 438.3622 - mae: 438.3495 - val_loss: 443.6492 - val_mae: 443.6363 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 427.8667 - mae: 427.8536 - val_loss: 431.5156 - val_mae: 431.5021 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 414.5420 - mae: 414.5281 - val_loss: 416.9363 - val_mae: 416.9219 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 399.8358 - mae: 399.8210 - val_loss: 400.8218 - val_mae: 400.8062 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 384.3173 - mae: 384.3011 - val_loss: 384.9789 - val_mae: 384.9618 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 368.9537 - mae: 368.9358 - val_loss: 369.7982 - val_mae: 369.7794 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 353.7585 - mae: 353.7387 - val_loss: 354.5995 - val_mae: 354.5786 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 339.1876 - mae: 339.1657 - val_loss: 339.7290 - val_mae: 339.7059 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 324.2895 - mae: 324.2654 - val_loss: 326.3603 - val_mae: 326.3348 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 311.4691 - mae: 311.4426 - val_loss: 313.9713 - val_mae: 313.9433 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 299.5626 - mae: 299.5335 - val_loss: 302.4278 - val_mae: 302.3973 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 287.2592 - mae: 287.2277 - val_loss: 288.1278 - val_mae: 288.0948 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 271.3744 - mae: 271.3402 - val_loss: 268.5067 - val_mae: 268.4710 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 253.1574 - mae: 253.1204 - val_loss: 251.6417 - val_mae: 251.6031 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 240.1826 - mae: 240.1427 - val_loss: 237.1658 - val_mae: 237.1242 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 227.5286 - mae: 227.4857 - val_loss: 224.5233 - val_mae: 224.4787 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 216.3952 - mae: 216.3494 - val_loss: 213.3045 - val_mae: 213.2572 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 206.3959 - mae: 206.3474 - val_loss: 205.3639 - val_mae: 205.3140 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 199.8084 - mae: 199.7574 - val_loss: 198.9983 - val_mae: 198.9459 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 495.8017\n",
      "LV_RMSE_12h: 593.3686\n",
      "LV_MAE_24h: 94.8563\n",
      "LV_RMSE_24h: 154.4742\n",
      "LV_MAE_48h: 126.4080\n",
      "LV_RMSE_48h: 199.3786\n",
      "LV_MAE_72h: 113.8908\n",
      "LV_RMSE_72h: 183.0628\n",
      "LV_MAE_mean: 207.7392\n",
      "LV_RMSE_mean: 282.5711\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 347.7384\n",
      "RMSE_12h: 450.2690\n",
      "MAE_24h: 128.4061\n",
      "RMSE_24h: 218.9229\n",
      "MAE_48h: 129.9080\n",
      "RMSE_48h: 217.8465\n",
      "MAE_72h: 127.4672\n",
      "RMSE_72h: 211.8955\n",
      "MAE_mean: 183.3799\n",
      "RMSE_mean: 274.7335\n",
      "\n",
      "=== Station S3013103 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1377 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1354, 24, 400) Ytr2: (1354, 4) \n",
      "  Xva3: (197, 24, 400) Yva2: (197, 4) \n",
      "  Xte3: (348, 24, 400) Yte2: (348, 4)\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 3s 57ms/step - loss: 395.9138 - mae: 395.9011 - val_loss: 358.1527 - val_mae: 358.1400 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 390.0183 - mae: 390.0056 - val_loss: 350.0227 - val_mae: 350.0098 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 380.1823 - mae: 380.1692 - val_loss: 338.8335 - val_mae: 338.8201 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 368.5676 - mae: 368.5538 - val_loss: 326.5993 - val_mae: 326.5851 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 355.7751 - mae: 355.7604 - val_loss: 314.1498 - val_mae: 314.1344 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 343.0268 - mae: 343.0108 - val_loss: 301.6140 - val_mae: 301.5971 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 329.7919 - mae: 329.7743 - val_loss: 288.6663 - val_mae: 288.6477 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 316.2064 - mae: 316.1869 - val_loss: 276.3553 - val_mae: 276.3347 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 302.9520 - mae: 302.9305 - val_loss: 264.8979 - val_mae: 264.8751 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 290.5150 - mae: 290.4912 - val_loss: 252.3422 - val_mae: 252.3171 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 276.5177 - mae: 276.4915 - val_loss: 236.6457 - val_mae: 236.6181 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 259.6057 - mae: 259.5768 - val_loss: 220.5902 - val_mae: 220.5598 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 243.4220 - mae: 243.3901 - val_loss: 204.1790 - val_mae: 204.1453 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 227.1718 - mae: 227.1367 - val_loss: 187.4979 - val_mae: 187.4608 - lr: 0.0010\n",
      "Epoch 15/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 13ms/step - loss: 210.2012 - mae: 210.1624 - val_loss: 172.2208 - val_mae: 172.1799 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 194.8342 - mae: 194.7916 - val_loss: 159.8686 - val_mae: 159.8238 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 184.1296 - mae: 184.0833 - val_loss: 151.7129 - val_mae: 151.6647 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 176.7869 - mae: 176.7375 - val_loss: 147.4967 - val_mae: 147.4458 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 172.4453 - mae: 172.3936 - val_loss: 144.0355 - val_mae: 143.9827 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 170.0093 - mae: 169.9557 - val_loss: 142.1296 - val_mae: 142.0752 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 498.1178\n",
      "LV_RMSE_12h: 568.1361\n",
      "LV_MAE_24h: 99.2644\n",
      "LV_RMSE_24h: 141.2429\n",
      "LV_MAE_48h: 138.0144\n",
      "LV_RMSE_48h: 189.2440\n",
      "LV_MAE_72h: 141.1006\n",
      "LV_RMSE_72h: 203.0443\n",
      "LV_MAE_mean: 219.1243\n",
      "LV_RMSE_mean: 275.4168\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 328.0172\n",
      "RMSE_12h: 407.6482\n",
      "MAE_24h: 130.3675\n",
      "RMSE_24h: 189.9490\n",
      "MAE_48h: 128.2733\n",
      "RMSE_48h: 186.8524\n",
      "MAE_72h: 131.2029\n",
      "RMSE_72h: 190.2252\n",
      "MAE_mean: 179.4653\n",
      "RMSE_mean: 243.6687\n",
      "\n",
      "=== Station S3015021 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1377 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1354, 24, 400) Ytr2: (1354, 4) \n",
      "  Xva3: (197, 24, 400) Yva2: (197, 4) \n",
      "  Xte3: (348, 24, 400) Yte2: (348, 4)\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 3s 57ms/step - loss: 5415.1997 - mae: 5415.1870 - val_loss: 5442.8438 - val_mae: 5442.8311 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 5408.7622 - mae: 5408.7490 - val_loss: 5433.7500 - val_mae: 5433.7373 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 5397.8633 - mae: 5397.8501 - val_loss: 5420.7124 - val_mae: 5420.6987 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 5383.4160 - mae: 5383.4019 - val_loss: 5403.8242 - val_mae: 5403.8096 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 5364.0356 - mae: 5364.0205 - val_loss: 5381.9634 - val_mae: 5381.9468 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 5339.9111 - mae: 5339.8940 - val_loss: 5354.6650 - val_mae: 5354.6465 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 5310.4077 - mae: 5310.3887 - val_loss: 5322.1406 - val_mae: 5322.1206 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 5275.6821 - mae: 5275.6602 - val_loss: 5284.0601 - val_mae: 5284.0376 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 5235.3906 - mae: 5235.3657 - val_loss: 5240.3789 - val_mae: 5240.3530 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 5188.8198 - mae: 5188.7915 - val_loss: 5190.9473 - val_mae: 5190.9165 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 5136.9287 - mae: 5136.8965 - val_loss: 5135.6772 - val_mae: 5135.6416 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 5078.9736 - mae: 5078.9365 - val_loss: 5074.5664 - val_mae: 5074.5269 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 0s 18ms/step - loss: 5015.4268 - mae: 5015.3843 - val_loss: 5007.5532 - val_mae: 5007.5078 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 0s 17ms/step - loss: 4946.1099 - mae: 4946.0615 - val_loss: 4934.7051 - val_mae: 4934.6533 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 4869.2266 - mae: 4869.1719 - val_loss: 4855.8398 - val_mae: 4855.7812 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 4788.5161 - mae: 4788.4541 - val_loss: 4771.1011 - val_mae: 4771.0347 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 4701.8423 - mae: 4701.7734 - val_loss: 4680.6958 - val_mae: 4680.6221 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 4606.6362 - mae: 4606.5586 - val_loss: 4587.4263 - val_mae: 4587.3447 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 4521.5044 - mae: 4521.4189 - val_loss: 4498.7456 - val_mae: 4498.6553 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 4436.4536 - mae: 4436.3589 - val_loss: 4416.6694 - val_mae: 4416.5703 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 4791.6064\n",
      "LV_RMSE_12h: 5205.9072\n",
      "LV_MAE_24h: 458.4511\n",
      "LV_RMSE_24h: 967.0130\n",
      "LV_MAE_48h: 727.1494\n",
      "LV_RMSE_48h: 1366.6345\n",
      "LV_MAE_72h: 779.1580\n",
      "LV_RMSE_72h: 1412.2401\n",
      "LV_MAE_mean: 1689.0913\n",
      "LV_RMSE_mean: 2237.9487\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 4315.2290\n",
      "RMSE_12h: 5125.8530\n",
      "MAE_24h: 4387.1250\n",
      "RMSE_24h: 5159.9976\n",
      "MAE_48h: 4405.7314\n",
      "RMSE_48h: 5183.4888\n",
      "MAE_72h: 4462.2505\n",
      "RMSE_72h: 5240.5366\n",
      "MAE_mean: 4392.5840\n",
      "RMSE_mean: 5177.4692\n",
      "\n",
      "=== Station S3015062 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1377 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1354, 24, 400) Ytr2: (1354, 4) \n",
      "  Xva3: (197, 24, 400) Yva2: (197, 4) \n",
      "  Xte3: (348, 24, 400) Yte2: (348, 4)\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 3s 60ms/step - loss: 4157.5942 - mae: 4157.5806 - val_loss: 4142.6636 - val_mae: 4142.6509 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 4151.8955 - mae: 4151.8828 - val_loss: 4134.0742 - val_mae: 4134.0610 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 4141.2544 - mae: 4141.2417 - val_loss: 4121.1445 - val_mae: 4121.1313 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 4126.7451 - mae: 4126.7314 - val_loss: 4104.1421 - val_mae: 4104.1274 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 4107.4229 - mae: 4107.4077 - val_loss: 4082.3848 - val_mae: 4082.3687 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 4083.3142 - mae: 4083.2981 - val_loss: 4055.4258 - val_mae: 4055.4080 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 4053.9280 - mae: 4053.9092 - val_loss: 4023.0034 - val_mae: 4022.9832 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 4018.6760 - mae: 4018.6548 - val_loss: 3984.8372 - val_mae: 3984.8140 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 0s 19ms/step - loss: 3979.0073 - mae: 3978.9827 - val_loss: 3940.8730 - val_mae: 3940.8464 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 3931.3350 - mae: 3931.3062 - val_loss: 3890.9734 - val_mae: 3890.9429 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 3879.3933 - mae: 3879.3604 - val_loss: 3835.0681 - val_mae: 3835.0330 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 3821.5784 - mae: 3821.5405 - val_loss: 3773.2017 - val_mae: 3773.1611 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 3756.9883 - mae: 3756.9458 - val_loss: 3705.2764 - val_mae: 3705.2302 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 3687.3638 - mae: 3687.3154 - val_loss: 3631.3687 - val_mae: 3631.3167 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 3607.3982 - mae: 3607.3430 - val_loss: 3551.2395 - val_mae: 3551.1804 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 3526.3459 - mae: 3526.2839 - val_loss: 3465.0024 - val_mae: 3464.9360 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 3438.8523 - mae: 3438.7825 - val_loss: 3372.8401 - val_mae: 3372.7656 - lr: 0.0010\n",
      "Epoch 18/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 15ms/step - loss: 3339.6484 - mae: 3339.5698 - val_loss: 3274.4067 - val_mae: 3274.3235 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 3242.5022 - mae: 3242.4148 - val_loss: 3170.0051 - val_mae: 3169.9128 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 3131.7769 - mae: 3131.6802 - val_loss: 3059.5254 - val_mae: 3059.4233 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 2761.0259\n",
      "LV_RMSE_12h: 3050.2507\n",
      "LV_MAE_24h: 571.2443\n",
      "LV_RMSE_24h: 895.9664\n",
      "LV_MAE_48h: 741.7040\n",
      "LV_RMSE_48h: 1124.2957\n",
      "LV_MAE_72h: 638.2500\n",
      "LV_RMSE_72h: 989.0118\n",
      "LV_MAE_mean: 1178.0560\n",
      "LV_RMSE_mean: 1514.8811\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 2794.6130\n",
      "RMSE_12h: 3261.2878\n",
      "MAE_24h: 2804.9475\n",
      "RMSE_24h: 3259.6179\n",
      "MAE_48h: 2790.8718\n",
      "RMSE_48h: 3249.1531\n",
      "MAE_72h: 2778.2517\n",
      "RMSE_72h: 3226.6804\n",
      "MAE_mean: 2792.1711\n",
      "RMSE_mean: 3249.1848\n",
      "\n",
      "=== Station S3016011 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1377 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1354, 24, 400) Ytr2: (1354, 4) \n",
      "  Xva3: (197, 24, 400) Yva2: (197, 4) \n",
      "  Xte3: (348, 24, 400) Yte2: (348, 4)\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 3s 56ms/step - loss: 795.7958 - mae: 795.7830 - val_loss: 792.7051 - val_mae: 792.6923 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 790.1473 - mae: 790.1343 - val_loss: 784.6953 - val_mae: 784.6822 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 780.1577 - mae: 780.1444 - val_loss: 772.5435 - val_mae: 772.5298 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 766.6651 - mae: 766.6512 - val_loss: 756.7256 - val_mae: 756.7111 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 748.7795 - mae: 748.7645 - val_loss: 736.8257 - val_mae: 736.8099 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 727.5005 - mae: 727.4841 - val_loss: 713.2788 - val_mae: 713.2614 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 703.9268 - mae: 703.9086 - val_loss: 688.9310 - val_mae: 688.9116 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 680.6702 - mae: 680.6499 - val_loss: 666.4036 - val_mae: 666.3821 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 659.0200 - mae: 658.9973 - val_loss: 645.9887 - val_mae: 645.9647 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 639.1201 - mae: 639.0950 - val_loss: 627.0447 - val_mae: 627.0182 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 620.7695 - mae: 620.7417 - val_loss: 609.3256 - val_mae: 609.2964 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 603.5547 - mae: 603.5243 - val_loss: 592.9615 - val_mae: 592.9295 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 588.8755 - mae: 588.8423 - val_loss: 577.7669 - val_mae: 577.7320 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 574.4545 - mae: 574.4184 - val_loss: 563.5940 - val_mae: 563.5562 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 562.2801 - mae: 562.2410 - val_loss: 551.3898 - val_mae: 551.3491 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 552.2598 - mae: 552.2177 - val_loss: 541.1337 - val_mae: 541.0901 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 542.9125 - mae: 542.8677 - val_loss: 532.1906 - val_mae: 532.1443 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 535.4844 - mae: 535.4371 - val_loss: 520.9366 - val_mae: 520.8879 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 519.7441 - mae: 519.6943 - val_loss: 500.9694 - val_mae: 500.9181 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 496.5184 - mae: 496.4657 - val_loss: 477.1068 - val_mae: 477.0523 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 856.4023\n",
      "LV_RMSE_12h: 951.0707\n",
      "LV_MAE_24h: 151.8506\n",
      "LV_RMSE_24h: 233.0634\n",
      "LV_MAE_48h: 212.0919\n",
      "LV_RMSE_48h: 316.2588\n",
      "LV_MAE_72h: 181.7644\n",
      "LV_RMSE_72h: 276.9463\n",
      "LV_MAE_mean: 350.5273\n",
      "LV_RMSE_mean: 444.3348\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 542.3835\n",
      "RMSE_12h: 653.5640\n",
      "MAE_24h: 343.9305\n",
      "RMSE_24h: 466.9654\n",
      "MAE_48h: 344.5192\n",
      "RMSE_48h: 465.9174\n",
      "MAE_72h: 347.9552\n",
      "RMSE_72h: 475.6639\n",
      "MAE_mean: 394.6971\n",
      "RMSE_mean: 515.5277\n",
      "\n",
      "=== Station S3016012 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1377 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1354, 24, 400) Ytr2: (1354, 4) \n",
      "  Xva3: (197, 24, 400) Yva2: (197, 4) \n",
      "  Xte3: (348, 24, 400) Yte2: (348, 4)\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 3s 57ms/step - loss: 799.7938 - mae: 799.7806 - val_loss: 800.7574 - val_mae: 800.7444 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 794.5007 - mae: 794.4877 - val_loss: 793.1784 - val_mae: 793.1652 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 785.2061 - mae: 785.1927 - val_loss: 782.0522 - val_mae: 782.0386 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 772.9285 - mae: 772.9146 - val_loss: 767.5336 - val_mae: 767.5193 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 756.3832 - mae: 756.3685 - val_loss: 749.3539 - val_mae: 749.3384 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 736.9080 - mae: 736.8918 - val_loss: 728.6093 - val_mae: 728.5923 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 715.8542 - mae: 715.8365 - val_loss: 708.3040 - val_mae: 708.2852 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 695.5350 - mae: 695.5154 - val_loss: 687.8859 - val_mae: 687.8652 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 676.2869 - mae: 676.2653 - val_loss: 668.3441 - val_mae: 668.3210 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 657.1758 - mae: 657.1519 - val_loss: 649.3442 - val_mae: 649.3189 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 639.6175 - mae: 639.5911 - val_loss: 630.3746 - val_mae: 630.3466 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 620.5439 - mae: 620.5148 - val_loss: 611.8420 - val_mae: 611.8113 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 602.7541 - mae: 602.7223 - val_loss: 592.4307 - val_mae: 592.3972 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 584.7333 - mae: 584.6984 - val_loss: 574.0833 - val_mae: 574.0467 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 566.9429 - mae: 566.9048 - val_loss: 553.5273 - val_mae: 553.4875 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 547.0443 - mae: 547.0029 - val_loss: 532.1940 - val_mae: 532.1508 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 524.5010 - mae: 524.4564 - val_loss: 507.4936 - val_mae: 507.4467 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 498.6281 - mae: 498.5794 - val_loss: 484.3917 - val_mae: 484.3407 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 477.1604 - mae: 477.1075 - val_loss: 463.5434 - val_mae: 463.4880 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 457.3768 - mae: 457.3194 - val_loss: 442.6356 - val_mae: 442.5756 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 868.0833\n",
      "LV_RMSE_12h: 976.0392\n",
      "LV_MAE_24h: 154.4828\n",
      "LV_RMSE_24h: 236.8228\n",
      "LV_MAE_48h: 216.6408\n",
      "LV_RMSE_48h: 323.3203\n",
      "LV_MAE_72h: 191.0977\n",
      "LV_RMSE_72h: 295.4587\n",
      "LV_MAE_mean: 357.5761\n",
      "LV_RMSE_mean: 457.9103\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 570.5044\n",
      "RMSE_12h: 717.4724\n",
      "MAE_24h: 315.0292\n",
      "RMSE_24h: 459.0660\n",
      "MAE_48h: 307.1941\n",
      "RMSE_48h: 445.0070\n",
      "MAE_72h: 293.1368\n",
      "RMSE_72h: 419.1967\n",
      "MAE_mean: 371.4661\n",
      "RMSE_mean: 510.1855\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Station S3016021 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1377 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1354, 24, 400) Ytr2: (1354, 4) \n",
      "  Xva3: (197, 24, 400) Yva2: (197, 4) \n",
      "  Xte3: (348, 24, 400) Yte2: (348, 4)\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 3s 58ms/step - loss: 862.6227 - mae: 862.6099 - val_loss: 857.6685 - val_mae: 857.6557 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 857.5364 - mae: 857.5234 - val_loss: 850.3199 - val_mae: 850.3069 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 848.5578 - mae: 848.5445 - val_loss: 839.6671 - val_mae: 839.6536 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 836.6122 - mae: 836.5984 - val_loss: 825.5389 - val_mae: 825.5246 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 820.3575 - mae: 820.3429 - val_loss: 807.1232 - val_mae: 807.1078 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 799.9094 - mae: 799.8935 - val_loss: 784.1318 - val_mae: 784.1149 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 776.4478 - mae: 776.4300 - val_loss: 758.6576 - val_mae: 758.6387 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 751.3218 - mae: 751.3019 - val_loss: 732.8563 - val_mae: 732.8350 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 725.7482 - mae: 725.7258 - val_loss: 707.1582 - val_mae: 707.1345 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 699.9180 - mae: 699.8931 - val_loss: 681.0616 - val_mae: 681.0350 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 675.3243 - mae: 675.2963 - val_loss: 654.2230 - val_mae: 654.1932 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 650.4004 - mae: 650.3692 - val_loss: 628.6495 - val_mae: 628.6165 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 626.0015 - mae: 625.9670 - val_loss: 604.7471 - val_mae: 604.7106 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 603.8870 - mae: 603.8489 - val_loss: 583.8298 - val_mae: 583.7897 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 584.8062 - mae: 584.7646 - val_loss: 566.3171 - val_mae: 566.2736 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 569.9014 - mae: 569.8564 - val_loss: 551.3321 - val_mae: 551.2852 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 554.5166 - mae: 554.4683 - val_loss: 536.6787 - val_mae: 536.6287 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 537.9192 - mae: 537.8677 - val_loss: 516.0089 - val_mae: 515.9557 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 513.8270 - mae: 513.7723 - val_loss: 494.1986 - val_mae: 494.1418 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 494.3131 - mae: 494.2546 - val_loss: 476.5095 - val_mae: 476.4488 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 888.5057\n",
      "LV_RMSE_12h: 990.5192\n",
      "LV_MAE_24h: 215.0805\n",
      "LV_RMSE_24h: 302.9925\n",
      "LV_MAE_48h: 275.0805\n",
      "LV_RMSE_48h: 368.7918\n",
      "LV_MAE_72h: 214.4109\n",
      "LV_RMSE_72h: 277.2259\n",
      "LV_MAE_mean: 398.2694\n",
      "LV_RMSE_mean: 484.8823\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 575.5960\n",
      "RMSE_12h: 724.3119\n",
      "MAE_24h: 401.8205\n",
      "RMSE_24h: 539.2359\n",
      "MAE_48h: 406.5062\n",
      "RMSE_48h: 543.0225\n",
      "MAE_72h: 386.0934\n",
      "RMSE_72h: 513.9788\n",
      "MAE_mean: 442.5040\n",
      "RMSE_mean: 580.1373\n",
      "\n",
      "=== Station S3016022 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1377 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1354, 24, 400) Ytr2: (1354, 4) \n",
      "  Xva3: (197, 24, 400) Yva2: (197, 4) \n",
      "  Xte3: (348, 24, 400) Yte2: (348, 4)\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 3s 58ms/step - loss: 804.9335 - mae: 804.9209 - val_loss: 791.2963 - val_mae: 791.2836 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 799.1752 - mae: 799.1625 - val_loss: 783.2731 - val_mae: 783.2603 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 789.4725 - mae: 789.4595 - val_loss: 771.6647 - val_mae: 771.6514 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 776.4031 - mae: 776.3895 - val_loss: 756.5731 - val_mae: 756.5590 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 759.4041 - mae: 759.3895 - val_loss: 737.8334 - val_mae: 737.8181 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 739.3730 - mae: 739.3570 - val_loss: 716.3046 - val_mae: 716.2876 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 718.2734 - mae: 718.2556 - val_loss: 695.8621 - val_mae: 695.8434 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 698.1302 - mae: 698.1107 - val_loss: 675.9711 - val_mae: 675.9504 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 679.0471 - mae: 679.0253 - val_loss: 657.4462 - val_mae: 657.4230 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 660.4160 - mae: 660.3920 - val_loss: 639.4050 - val_mae: 639.3795 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 643.2466 - mae: 643.2200 - val_loss: 622.7023 - val_mae: 622.6743 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 626.5132 - mae: 626.4839 - val_loss: 606.9449 - val_mae: 606.9140 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 611.5299 - mae: 611.4979 - val_loss: 592.1110 - val_mae: 592.0773 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 597.9855 - mae: 597.9507 - val_loss: 577.1357 - val_mae: 577.0992 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 582.2418 - mae: 582.2040 - val_loss: 559.1907 - val_mae: 559.1512 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 564.6841 - mae: 564.6432 - val_loss: 538.8391 - val_mae: 538.7964 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 542.0941 - mae: 542.0500 - val_loss: 515.9736 - val_mae: 515.9275 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 517.4330 - mae: 517.3853 - val_loss: 489.5154 - val_mae: 489.4654 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 494.2404 - mae: 494.1886 - val_loss: 465.5573 - val_mae: 465.5029 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 470.3736 - mae: 470.3172 - val_loss: 443.0023 - val_mae: 442.9432 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 872.1839\n",
      "LV_RMSE_12h: 981.4343\n",
      "LV_MAE_24h: 153.6581\n",
      "LV_RMSE_24h: 236.8529\n",
      "LV_MAE_48h: 217.3276\n",
      "LV_RMSE_48h: 325.6159\n",
      "LV_MAE_72h: 193.8333\n",
      "LV_RMSE_72h: 301.6636\n",
      "LV_MAE_mean: 359.2507\n",
      "LV_RMSE_mean: 461.3917\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 581.4638\n",
      "RMSE_12h: 723.5754\n",
      "MAE_24h: 314.4496\n",
      "RMSE_24h: 467.3629\n",
      "MAE_48h: 311.9148\n",
      "RMSE_48h: 461.7720\n",
      "MAE_72h: 303.8824\n",
      "RMSE_72h: 448.4539\n",
      "MAE_mean: 377.9276\n",
      "RMSE_mean: 525.2911\n",
      "\n",
      "=== Station S3016061 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1377 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1354, 24, 400) Ytr2: (1354, 4) \n",
      "  Xva3: (197, 24, 400) Yva2: (197, 4) \n",
      "  Xte3: (348, 24, 400) Yte2: (348, 4)\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 3s 60ms/step - loss: 630.5958 - mae: 630.5828 - val_loss: 612.5847 - val_mae: 612.5718 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 625.0015 - mae: 624.9884 - val_loss: 604.3068 - val_mae: 604.2936 - lr: 0.0010\n",
      "Epoch 3/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 13ms/step - loss: 614.5464 - mae: 614.5330 - val_loss: 591.4565 - val_mae: 591.4427 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 600.2491 - mae: 600.2350 - val_loss: 575.1491 - val_mae: 575.1345 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 582.0244 - mae: 582.0092 - val_loss: 554.8878 - val_mae: 554.8719 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 561.1430 - mae: 561.1264 - val_loss: 533.1773 - val_mae: 533.1598 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 539.8303 - mae: 539.8119 - val_loss: 513.0835 - val_mae: 513.0640 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 520.1722 - mae: 520.1518 - val_loss: 494.7542 - val_mae: 494.7326 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 501.7889 - mae: 501.7663 - val_loss: 477.9256 - val_mae: 477.9016 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 483.8440 - mae: 483.8190 - val_loss: 461.5228 - val_mae: 461.4964 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 468.6529 - mae: 468.6255 - val_loss: 446.3010 - val_mae: 446.2721 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 454.3239 - mae: 454.2939 - val_loss: 432.5056 - val_mae: 432.4739 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 440.7906 - mae: 440.7579 - val_loss: 419.9735 - val_mae: 419.9392 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 429.5670 - mae: 429.5316 - val_loss: 409.0396 - val_mae: 409.0026 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 419.1866 - mae: 419.1485 - val_loss: 399.7026 - val_mae: 399.6630 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 411.7878 - mae: 411.7472 - val_loss: 391.9597 - val_mae: 391.9176 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 404.1926 - mae: 404.1495 - val_loss: 384.8976 - val_mae: 384.8532 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 396.5102 - mae: 396.4648 - val_loss: 373.6544 - val_mae: 373.6078 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 381.1446 - mae: 381.0970 - val_loss: 355.4534 - val_mae: 355.4044 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 361.2275 - mae: 361.1772 - val_loss: 332.1123 - val_mae: 332.0603 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 650.0920\n",
      "LV_RMSE_12h: 723.1096\n",
      "LV_MAE_24h: 112.0690\n",
      "LV_RMSE_24h: 171.1248\n",
      "LV_MAE_48h: 156.6810\n",
      "LV_RMSE_48h: 232.1126\n",
      "LV_MAE_72h: 136.3965\n",
      "LV_RMSE_72h: 210.4432\n",
      "LV_MAE_mean: 263.8096\n",
      "LV_RMSE_mean: 334.1975\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 434.0247\n",
      "RMSE_12h: 508.8462\n",
      "MAE_24h: 233.0862\n",
      "RMSE_24h: 314.0267\n",
      "MAE_48h: 224.6692\n",
      "RMSE_48h: 294.9044\n",
      "MAE_72h: 220.5587\n",
      "RMSE_72h: 293.5927\n",
      "MAE_mean: 278.0847\n",
      "RMSE_mean: 352.8425\n",
      "\n",
      "=== Station S3016062 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1376 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1353, 24, 400) Ytr2: (1353, 4) \n",
      "  Xva3: (197, 24, 400) Yva2: (197, 4) \n",
      "  Xte3: (347, 24, 400) Yte2: (347, 4)\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 3s 56ms/step - loss: 81.9316 - mae: 81.9189 - val_loss: 84.5448 - val_mae: 84.5321 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 76.7495 - mae: 76.7367 - val_loss: 78.5029 - val_mae: 78.4900 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 70.9520 - mae: 70.9388 - val_loss: 72.6576 - val_mae: 72.6442 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 65.7264 - mae: 65.7127 - val_loss: 67.5602 - val_mae: 67.5461 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 61.5227 - mae: 61.5082 - val_loss: 63.2934 - val_mae: 63.2784 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 58.2350 - mae: 58.2197 - val_loss: 59.6344 - val_mae: 59.6187 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 54.8924 - mae: 54.8763 - val_loss: 55.6113 - val_mae: 55.5948 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 50.3154 - mae: 50.2986 - val_loss: 50.7210 - val_mae: 50.7037 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 44.8589 - mae: 44.8412 - val_loss: 45.0731 - val_mae: 45.0548 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 39.4702 - mae: 39.4514 - val_loss: 39.8497 - val_mae: 39.8302 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 35.9487 - mae: 35.9286 - val_loss: 37.1950 - val_mae: 37.1743 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 33.8295 - mae: 33.8084 - val_loss: 34.5847 - val_mae: 34.5630 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 31.8918 - mae: 31.8697 - val_loss: 32.8830 - val_mae: 32.8604 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 29.7148 - mae: 29.6918 - val_loss: 30.9042 - val_mae: 30.8807 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 28.2025 - mae: 28.1785 - val_loss: 28.7728 - val_mae: 28.7483 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 26.8319 - mae: 26.8070 - val_loss: 27.8512 - val_mae: 27.8257 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 25.7614 - mae: 25.7355 - val_loss: 25.4451 - val_mae: 25.4186 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 24.4902 - mae: 24.4633 - val_loss: 24.8656 - val_mae: 24.8381 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 23.6052 - mae: 23.5773 - val_loss: 23.3017 - val_mae: 23.2732 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 22.6603 - mae: 22.6315 - val_loss: 22.7324 - val_mae: 22.7032 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 112.3862\n",
      "LV_RMSE_12h: 133.9389\n",
      "LV_MAE_24h: 29.1066\n",
      "LV_RMSE_24h: 43.9420\n",
      "LV_MAE_48h: 35.8530\n",
      "LV_RMSE_48h: 54.7989\n",
      "LV_MAE_72h: 31.1988\n",
      "LV_RMSE_72h: 46.3942\n",
      "LV_MAE_mean: 52.1362\n",
      "LV_RMSE_mean: 69.7685\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 30.0651\n",
      "RMSE_12h: 45.7218\n",
      "MAE_24h: 26.6932\n",
      "RMSE_24h: 40.9470\n",
      "MAE_48h: 24.9955\n",
      "RMSE_48h: 39.0176\n",
      "MAE_72h: 25.3239\n",
      "RMSE_72h: 39.0432\n",
      "MAE_mean: 26.7694\n",
      "RMSE_mean: 41.1824\n",
      "\n",
      "=== Station S3016064 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1376 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1353, 24, 400) Ytr2: (1353, 4) \n",
      "  Xva3: (197, 24, 400) Yva2: (197, 4) \n",
      "  Xte3: (347, 24, 400) Yte2: (347, 4)\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 3s 59ms/step - loss: 337.3439 - mae: 337.3312 - val_loss: 328.6425 - val_mae: 328.6298 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 330.5543 - mae: 330.5415 - val_loss: 319.1947 - val_mae: 319.1818 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 319.4646 - mae: 319.4514 - val_loss: 306.3539 - val_mae: 306.3404 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 305.3073 - mae: 305.2934 - val_loss: 291.3894 - val_mae: 291.3750 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 290.2342 - mae: 290.2193 - val_loss: 276.3738 - val_mae: 276.3582 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 275.9591 - mae: 275.9429 - val_loss: 262.4402 - val_mae: 262.4232 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 263.2012 - mae: 263.1835 - val_loss: 250.5139 - val_mae: 250.4953 - lr: 0.0010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 251.8388 - mae: 251.8194 - val_loss: 239.7743 - val_mae: 239.7539 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 242.9777 - mae: 242.9566 - val_loss: 229.6262 - val_mae: 229.6040 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 232.0205 - mae: 231.9975 - val_loss: 218.2485 - val_mae: 218.2243 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 220.6080 - mae: 220.5830 - val_loss: 206.9558 - val_mae: 206.9297 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 209.2271 - mae: 209.2000 - val_loss: 195.7821 - val_mae: 195.7537 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 198.0546 - mae: 198.0253 - val_loss: 184.5701 - val_mae: 184.5395 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 186.3827 - mae: 186.3511 - val_loss: 173.7893 - val_mae: 173.7564 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 175.5548 - mae: 175.5207 - val_loss: 163.4445 - val_mae: 163.4090 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 164.6310 - mae: 164.5943 - val_loss: 154.1935 - val_mae: 154.1554 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 155.8304 - mae: 155.7911 - val_loss: 147.4898 - val_mae: 147.4490 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 148.0690 - mae: 148.0270 - val_loss: 141.7823 - val_mae: 141.7389 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 140.8060 - mae: 140.7614 - val_loss: 137.3334 - val_mae: 137.2874 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 135.4156 - mae: 135.3687 - val_loss: 132.5824 - val_mae: 132.5343 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 341.0086\n",
      "LV_RMSE_12h: 386.7090\n",
      "LV_MAE_24h: 79.5331\n",
      "LV_RMSE_24h: 114.8853\n",
      "LV_MAE_48h: 102.4380\n",
      "LV_RMSE_48h: 148.0343\n",
      "LV_MAE_72h: 91.3170\n",
      "LV_RMSE_72h: 133.5224\n",
      "LV_MAE_mean: 153.5742\n",
      "LV_RMSE_mean: 195.7878\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 235.0298\n",
      "RMSE_12h: 290.0158\n",
      "MAE_24h: 90.3028\n",
      "RMSE_24h: 128.1889\n",
      "MAE_48h: 86.8580\n",
      "RMSE_48h: 126.1334\n",
      "MAE_72h: 88.0319\n",
      "RMSE_72h: 126.5266\n",
      "MAE_mean: 125.0556\n",
      "RMSE_mean: 167.7162\n",
      "\n",
      "=== Station S3016071 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1377 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1354, 24, 400) Ytr2: (1354, 4) \n",
      "  Xva3: (197, 24, 400) Yva2: (197, 4) \n",
      "  Xte3: (348, 24, 400) Yte2: (348, 4)\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 3s 57ms/step - loss: 984.9382 - mae: 984.9255 - val_loss: 977.4297 - val_mae: 977.4171 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 978.8787 - mae: 978.8660 - val_loss: 969.2616 - val_mae: 969.2486 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 969.2754 - mae: 969.2621 - val_loss: 957.8926 - val_mae: 957.8790 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 956.3128 - mae: 956.2990 - val_loss: 942.8934 - val_mae: 942.8790 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 939.4164 - mae: 939.4016 - val_loss: 923.8853 - val_mae: 923.8697 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 919.0433 - mae: 919.0268 - val_loss: 901.5800 - val_mae: 901.5628 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 896.4598 - mae: 896.4418 - val_loss: 878.6431 - val_mae: 878.6240 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 874.3871 - mae: 874.3671 - val_loss: 858.0131 - val_mae: 857.9919 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 853.6933 - mae: 853.6711 - val_loss: 838.3214 - val_mae: 838.2979 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 833.8745 - mae: 833.8499 - val_loss: 819.6700 - val_mae: 819.6440 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 815.9756 - mae: 815.9485 - val_loss: 801.9041 - val_mae: 801.8754 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 798.7170 - mae: 798.6870 - val_loss: 783.9560 - val_mae: 783.9245 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 780.3060 - mae: 780.2732 - val_loss: 765.9646 - val_mae: 765.9301 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 763.8463 - mae: 763.8105 - val_loss: 749.2765 - val_mae: 749.2389 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 747.9666 - mae: 747.9276 - val_loss: 734.0439 - val_mae: 734.0030 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 733.3957 - mae: 733.3533 - val_loss: 719.0143 - val_mae: 718.9701 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 717.3952 - mae: 717.3494 - val_loss: 704.1030 - val_mae: 704.0552 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 700.7596 - mae: 700.7104 - val_loss: 681.1967 - val_mae: 681.1456 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 677.8864 - mae: 677.8337 - val_loss: 657.3173 - val_mae: 657.2625 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 653.4903 - mae: 653.4337 - val_loss: 632.5764 - val_mae: 632.5175 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 1106.0115\n",
      "LV_RMSE_12h: 1244.7233\n",
      "LV_MAE_24h: 199.0488\n",
      "LV_RMSE_24h: 310.0627\n",
      "LV_MAE_48h: 276.4569\n",
      "LV_RMSE_48h: 417.7765\n",
      "LV_MAE_72h: 234.6810\n",
      "LV_RMSE_72h: 361.1768\n",
      "LV_MAE_mean: 454.0496\n",
      "LV_RMSE_mean: 583.4348\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 665.2523\n",
      "RMSE_12h: 833.2686\n",
      "MAE_24h: 491.3376\n",
      "RMSE_24h: 673.9167\n",
      "MAE_48h: 489.4117\n",
      "RMSE_48h: 668.9350\n",
      "MAE_72h: 484.3310\n",
      "RMSE_72h: 664.2734\n",
      "MAE_mean: 532.5831\n",
      "RMSE_mean: 710.0984\n",
      "\n",
      "=== Station S3016072 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1377 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1354, 24, 400) Ytr2: (1354, 4) \n",
      "  Xva3: (197, 24, 400) Yva2: (197, 4) \n",
      "  Xte3: (348, 24, 400) Yte2: (348, 4)\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 3s 61ms/step - loss: 979.6176 - mae: 979.6047 - val_loss: 973.2881 - val_mae: 973.2751 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 974.0482 - mae: 974.0353 - val_loss: 964.7191 - val_mae: 964.7059 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 963.4066 - mae: 963.3932 - val_loss: 952.0295 - val_mae: 952.0158 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 949.4031 - mae: 949.3889 - val_loss: 936.1097 - val_mae: 936.0953 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 931.6486 - mae: 931.6336 - val_loss: 916.4628 - val_mae: 916.4471 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 910.8426 - mae: 910.8262 - val_loss: 894.4825 - val_mae: 894.4654 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 888.8575 - mae: 888.8395 - val_loss: 872.9688 - val_mae: 872.9496 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 867.4029 - mae: 867.3829 - val_loss: 851.7274 - val_mae: 851.7062 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 846.7657 - mae: 846.7437 - val_loss: 831.3984 - val_mae: 831.3750 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 826.9276 - mae: 826.9031 - val_loss: 811.6896 - val_mae: 811.6637 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 808.3032 - mae: 808.2762 - val_loss: 792.9324 - val_mae: 792.9039 - lr: 0.0010\n",
      "Epoch 12/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 13ms/step - loss: 790.3143 - mae: 790.2847 - val_loss: 774.6078 - val_mae: 774.5765 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 772.0333 - mae: 772.0007 - val_loss: 755.7238 - val_mae: 755.6896 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 754.2242 - mae: 754.1886 - val_loss: 737.0969 - val_mae: 737.0596 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 734.9922 - mae: 734.9535 - val_loss: 717.5966 - val_mae: 717.5560 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 716.4258 - mae: 716.3838 - val_loss: 696.0117 - val_mae: 695.9677 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 691.1878 - mae: 691.1422 - val_loss: 665.9966 - val_mae: 665.9489 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 660.3255 - mae: 660.2761 - val_loss: 636.8445 - val_mae: 636.7926 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 634.2637 - mae: 634.2096 - val_loss: 609.8480 - val_mae: 609.7913 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 608.2321 - mae: 608.1730 - val_loss: 584.1282 - val_mae: 584.0663 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 1060.6293\n",
      "LV_RMSE_12h: 1178.1481\n",
      "LV_MAE_24h: 201.7299\n",
      "LV_RMSE_24h: 315.6037\n",
      "LV_MAE_48h: 283.4885\n",
      "LV_RMSE_48h: 435.3070\n",
      "LV_MAE_72h: 254.0345\n",
      "LV_RMSE_72h: 404.1095\n",
      "LV_MAE_mean: 449.9705\n",
      "LV_RMSE_mean: 583.2921\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 691.2934\n",
      "RMSE_12h: 872.0321\n",
      "MAE_24h: 415.5759\n",
      "RMSE_24h: 616.4833\n",
      "MAE_48h: 399.2570\n",
      "RMSE_48h: 591.1144\n",
      "MAE_72h: 393.0843\n",
      "RMSE_72h: 576.4380\n",
      "MAE_mean: 474.8027\n",
      "RMSE_mean: 664.0170\n",
      "\n",
      "=== Station S3016091 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1377 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1354, 24, 400) Ytr2: (1354, 4) \n",
      "  Xva3: (197, 24, 400) Yva2: (197, 4) \n",
      "  Xte3: (348, 24, 400) Yte2: (348, 4)\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 3s 57ms/step - loss: 1362.0475 - mae: 1362.0347 - val_loss: 1377.9988 - val_mae: 1377.9858 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1355.9061 - mae: 1355.8932 - val_loss: 1369.4629 - val_mae: 1369.4498 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1345.9116 - mae: 1345.8984 - val_loss: 1357.6416 - val_mae: 1357.6282 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1332.7236 - mae: 1332.7096 - val_loss: 1341.9069 - val_mae: 1341.8925 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1314.5631 - mae: 1314.5482 - val_loss: 1321.6787 - val_mae: 1321.6628 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1292.5732 - mae: 1292.5566 - val_loss: 1297.2072 - val_mae: 1297.1896 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1267.2985 - mae: 1267.2799 - val_loss: 1270.6350 - val_mae: 1270.6154 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1241.3165 - mae: 1241.2957 - val_loss: 1244.9457 - val_mae: 1244.9235 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1215.5601 - mae: 1215.5366 - val_loss: 1219.6516 - val_mae: 1219.6267 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1190.7386 - mae: 1190.7124 - val_loss: 1195.2852 - val_mae: 1195.2573 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1167.9528 - mae: 1167.9233 - val_loss: 1171.9418 - val_mae: 1171.9109 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1144.2587 - mae: 1144.2263 - val_loss: 1147.9995 - val_mae: 1147.9652 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1120.7906 - mae: 1120.7548 - val_loss: 1124.7063 - val_mae: 1124.6683 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1099.2195 - mae: 1099.1798 - val_loss: 1104.3665 - val_mae: 1104.3247 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1078.5176 - mae: 1078.4741 - val_loss: 1084.6387 - val_mae: 1084.5931 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1062.1930 - mae: 1062.1459 - val_loss: 1063.4890 - val_mae: 1063.4396 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1038.9688 - mae: 1038.9176 - val_loss: 1039.7170 - val_mae: 1039.6635 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1015.9360 - mae: 1015.8807 - val_loss: 1016.3824 - val_mae: 1016.3246 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 992.3083 - mae: 992.2486 - val_loss: 989.0896 - val_mae: 989.0272 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 965.7040 - mae: 965.6396 - val_loss: 961.5048 - val_mae: 961.4375 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 1625.0834\n",
      "LV_RMSE_12h: 1797.3158\n",
      "LV_MAE_24h: 271.1207\n",
      "LV_RMSE_24h: 430.5354\n",
      "LV_MAE_48h: 364.6782\n",
      "LV_RMSE_48h: 569.2404\n",
      "LV_MAE_72h: 311.5661\n",
      "LV_RMSE_72h: 480.4014\n",
      "LV_MAE_mean: 643.1121\n",
      "LV_RMSE_mean: 819.3733\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 955.4305\n",
      "RMSE_12h: 1209.8921\n",
      "MAE_24h: 809.7752\n",
      "RMSE_24h: 1070.9038\n",
      "MAE_48h: 817.5524\n",
      "RMSE_48h: 1084.0156\n",
      "MAE_72h: 788.0350\n",
      "RMSE_72h: 1040.8425\n",
      "MAE_mean: 842.6982\n",
      "RMSE_mean: 1101.4136\n",
      "\n",
      "=== Station S3016092 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1377 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1354, 24, 400) Ytr2: (1354, 4) \n",
      "  Xva3: (197, 24, 400) Yva2: (197, 4) \n",
      "  Xte3: (348, 24, 400) Yte2: (348, 4)\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 3s 57ms/step - loss: 1361.3900 - mae: 1361.3772 - val_loss: 1376.7546 - val_mae: 1376.7417 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1356.2292 - mae: 1356.2162 - val_loss: 1368.9086 - val_mae: 1368.8956 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1346.4510 - mae: 1346.4379 - val_loss: 1357.0483 - val_mae: 1357.0349 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1333.2415 - mae: 1333.2274 - val_loss: 1341.6577 - val_mae: 1341.6431 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1315.5138 - mae: 1315.4987 - val_loss: 1321.9694 - val_mae: 1321.9535 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1294.4221 - mae: 1294.4058 - val_loss: 1298.6582 - val_mae: 1298.6407 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1270.4949 - mae: 1270.4766 - val_loss: 1274.3118 - val_mae: 1274.2922 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1246.6704 - mae: 1246.6501 - val_loss: 1250.7098 - val_mae: 1250.6881 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1222.8623 - mae: 1222.8394 - val_loss: 1227.8210 - val_mae: 1227.7968 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 1200.4043 - mae: 1200.3789 - val_loss: 1205.2671 - val_mae: 1205.2401 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1179.6024 - mae: 1179.5742 - val_loss: 1183.2761 - val_mae: 1183.2462 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1158.1486 - mae: 1158.1173 - val_loss: 1162.0981 - val_mae: 1162.0651 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 1137.6370 - mae: 1137.6024 - val_loss: 1140.5751 - val_mae: 1140.5387 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1117.3296 - mae: 1117.2915 - val_loss: 1118.7732 - val_mae: 1118.7332 - lr: 0.0010\n",
      "Epoch 15/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 13ms/step - loss: 1096.4922 - mae: 1096.4507 - val_loss: 1097.1638 - val_mae: 1097.1201 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1078.7271 - mae: 1078.6816 - val_loss: 1076.5454 - val_mae: 1076.4978 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1056.6523 - mae: 1056.6029 - val_loss: 1053.2617 - val_mae: 1053.2098 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1031.6653 - mae: 1031.6117 - val_loss: 1028.7390 - val_mae: 1028.6830 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1009.1360 - mae: 1009.0781 - val_loss: 1003.9919 - val_mae: 1003.9314 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 984.0621 - mae: 983.9995 - val_loss: 974.5249 - val_mae: 974.4597 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 1651.4023\n",
      "LV_RMSE_12h: 1847.2966\n",
      "LV_MAE_24h: 263.2730\n",
      "LV_RMSE_24h: 416.2715\n",
      "LV_MAE_48h: 362.9339\n",
      "LV_RMSE_48h: 551.0392\n",
      "LV_MAE_72h: 309.6322\n",
      "LV_RMSE_72h: 462.1545\n",
      "LV_MAE_mean: 646.8103\n",
      "LV_RMSE_mean: 819.1905\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 975.5017\n",
      "RMSE_12h: 1230.7170\n",
      "MAE_24h: 848.2940\n",
      "RMSE_24h: 1135.4540\n",
      "MAE_48h: 821.4048\n",
      "RMSE_48h: 1093.1298\n",
      "MAE_72h: 832.1564\n",
      "RMSE_72h: 1117.2355\n",
      "MAE_mean: 869.3392\n",
      "RMSE_mean: 1144.1340\n",
      "\n",
      "=== Station S3016101 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1377 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1354, 24, 400) Ytr2: (1354, 4) \n",
      "  Xva3: (197, 24, 400) Yva2: (197, 4) \n",
      "  Xte3: (348, 24, 400) Yte2: (348, 4)\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 3s 56ms/step - loss: 862.1088 - mae: 862.0959 - val_loss: 877.9922 - val_mae: 877.9794 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 855.9105 - mae: 855.8978 - val_loss: 869.2159 - val_mae: 869.2029 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 845.0417 - mae: 845.0284 - val_loss: 855.8950 - val_mae: 855.8814 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 830.1447 - mae: 830.1307 - val_loss: 838.7552 - val_mae: 838.7407 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 810.9554 - mae: 810.9402 - val_loss: 817.7215 - val_mae: 817.7057 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 789.6601 - mae: 789.6434 - val_loss: 795.8353 - val_mae: 795.8177 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 768.3248 - mae: 768.3064 - val_loss: 774.9261 - val_mae: 774.9066 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 0s 19ms/step - loss: 747.8398 - mae: 747.8193 - val_loss: 754.9404 - val_mae: 754.9186 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 727.9581 - mae: 727.9354 - val_loss: 735.6511 - val_mae: 735.6269 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 708.5956 - mae: 708.5704 - val_loss: 716.4547 - val_mae: 716.4279 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 691.3361 - mae: 691.3080 - val_loss: 697.9556 - val_mae: 697.9259 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 673.1094 - mae: 673.0784 - val_loss: 680.4296 - val_mae: 680.3969 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 656.1767 - mae: 656.1427 - val_loss: 662.3647 - val_mae: 662.3289 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 638.9454 - mae: 638.9083 - val_loss: 641.2637 - val_mae: 641.2246 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 614.1625 - mae: 614.1219 - val_loss: 612.7857 - val_mae: 612.7429 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 587.0571 - mae: 587.0126 - val_loss: 584.0031 - val_mae: 583.9564 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 560.1127 - mae: 560.0639 - val_loss: 558.6733 - val_mae: 558.6219 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 534.7639 - mae: 534.7103 - val_loss: 535.4996 - val_mae: 535.4433 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 511.1246 - mae: 511.0661 - val_loss: 511.4302 - val_mae: 511.3687 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 489.3484 - mae: 489.2847 - val_loss: 489.3371 - val_mae: 489.2704 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 1003.0029\n",
      "LV_RMSE_12h: 1100.5970\n",
      "LV_MAE_24h: 164.6724\n",
      "LV_RMSE_24h: 257.8375\n",
      "LV_MAE_48h: 219.2874\n",
      "LV_RMSE_48h: 341.4151\n",
      "LV_MAE_72h: 190.3132\n",
      "LV_RMSE_72h: 295.7815\n",
      "LV_MAE_mean: 394.3190\n",
      "LV_RMSE_mean: 498.9078\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 676.1995\n",
      "RMSE_12h: 820.7325\n",
      "MAE_24h: 344.3784\n",
      "RMSE_24h: 490.0547\n",
      "MAE_48h: 342.7368\n",
      "RMSE_48h: 490.0745\n",
      "MAE_72h: 342.9699\n",
      "RMSE_72h: 486.3143\n",
      "MAE_mean: 426.5712\n",
      "RMSE_mean: 571.7940\n",
      "\n",
      "=== Station S3016102 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1377 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1354, 24, 400) Ytr2: (1354, 4) \n",
      "  Xva3: (197, 24, 400) Yva2: (197, 4) \n",
      "  Xte3: (348, 24, 400) Yte2: (348, 4)\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 3s 57ms/step - loss: 866.0027 - mae: 865.9901 - val_loss: 875.3258 - val_mae: 875.3132 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 860.9117 - mae: 860.8991 - val_loss: 867.9124 - val_mae: 867.8996 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 851.8005 - mae: 851.7876 - val_loss: 857.0187 - val_mae: 857.0055 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 839.6750 - mae: 839.6616 - val_loss: 842.7797 - val_mae: 842.7657 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 823.7369 - mae: 823.7224 - val_loss: 825.5726 - val_mae: 825.5575 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 806.1497 - mae: 806.1339 - val_loss: 807.6740 - val_mae: 807.6574 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 787.8190 - mae: 787.8016 - val_loss: 790.2249 - val_mae: 790.2065 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 770.6863 - mae: 770.6671 - val_loss: 773.4568 - val_mae: 773.4365 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 753.8969 - mae: 753.8757 - val_loss: 756.9989 - val_mae: 756.9764 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 736.7679 - mae: 736.7445 - val_loss: 741.0447 - val_mae: 741.0200 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 721.2355 - mae: 721.2095 - val_loss: 724.9673 - val_mae: 724.9401 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 705.0958 - mae: 705.0673 - val_loss: 708.6701 - val_mae: 708.6401 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 689.4118 - mae: 689.3804 - val_loss: 692.9617 - val_mae: 692.9288 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 674.2018 - mae: 674.1675 - val_loss: 677.3324 - val_mae: 677.2964 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 657.9460 - mae: 657.9086 - val_loss: 659.9014 - val_mae: 659.8623 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 638.9578 - mae: 638.9172 - val_loss: 633.6038 - val_mae: 633.5612 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 610.5684 - mae: 610.5242 - val_loss: 601.6338 - val_mae: 601.5873 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 578.4563 - mae: 578.4080 - val_loss: 575.4961 - val_mae: 575.4451 - lr: 0.0010\n",
      "Epoch 19/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 12ms/step - loss: 554.6649 - mae: 554.6118 - val_loss: 548.5377 - val_mae: 548.4817 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 530.7006 - mae: 530.6422 - val_loss: 524.4582 - val_mae: 524.3969 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 1047.6494\n",
      "LV_RMSE_12h: 1182.3766\n",
      "LV_MAE_24h: 154.9799\n",
      "LV_RMSE_24h: 243.6560\n",
      "LV_MAE_48h: 215.8046\n",
      "LV_RMSE_48h: 321.9514\n",
      "LV_MAE_72h: 186.1379\n",
      "LV_RMSE_72h: 275.5120\n",
      "LV_MAE_mean: 401.1429\n",
      "LV_RMSE_mean: 505.8740\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 683.3291\n",
      "RMSE_12h: 860.0189\n",
      "MAE_24h: 409.0030\n",
      "RMSE_24h: 592.8170\n",
      "MAE_48h: 381.4677\n",
      "RMSE_48h: 558.0610\n",
      "MAE_72h: 378.6786\n",
      "RMSE_72h: 556.9482\n",
      "MAE_mean: 463.1196\n",
      "RMSE_mean: 641.9613\n",
      "\n",
      "=== Station S3017021 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1377 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1354, 24, 400) Ytr2: (1354, 4) \n",
      "  Xva3: (197, 24, 400) Yva2: (197, 4) \n",
      "  Xte3: (348, 24, 400) Yte2: (348, 4)\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 3s 57ms/step - loss: 753.3846 - mae: 753.3717 - val_loss: 767.1142 - val_mae: 767.1014 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 746.4744 - mae: 746.4615 - val_loss: 756.9900 - val_mae: 756.9769 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 734.2808 - mae: 734.2675 - val_loss: 742.6284 - val_mae: 742.6145 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 718.5695 - mae: 718.5553 - val_loss: 724.6375 - val_mae: 724.6227 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 699.1664 - mae: 699.1511 - val_loss: 704.9357 - val_mae: 704.9195 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 679.3840 - mae: 679.3671 - val_loss: 685.7095 - val_mae: 685.6915 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 659.7445 - mae: 659.7256 - val_loss: 667.1255 - val_mae: 667.1053 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 641.8956 - mae: 641.8745 - val_loss: 648.8600 - val_mae: 648.8376 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 623.9211 - mae: 623.8976 - val_loss: 631.3475 - val_mae: 631.3226 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 606.8461 - mae: 606.8200 - val_loss: 615.2888 - val_mae: 615.2612 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 591.9877 - mae: 591.9588 - val_loss: 599.6254 - val_mae: 599.5950 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 577.2300 - mae: 577.1984 - val_loss: 583.8348 - val_mae: 583.8015 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 561.3685 - mae: 561.3338 - val_loss: 567.1290 - val_mae: 567.0926 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 544.7548 - mae: 544.7169 - val_loss: 547.0347 - val_mae: 546.9949 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 522.6124 - mae: 522.5711 - val_loss: 523.3719 - val_mae: 523.3286 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 500.8566 - mae: 500.8117 - val_loss: 499.0318 - val_mae: 498.9846 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 476.6847 - mae: 476.6356 - val_loss: 475.0811 - val_mae: 475.0295 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 454.1860 - mae: 454.1324 - val_loss: 453.9702 - val_mae: 453.9141 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 434.0339 - mae: 433.9755 - val_loss: 430.6849 - val_mae: 430.6237 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 412.2603 - mae: 412.1967 - val_loss: 410.6036 - val_mae: 410.5371 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 874.8362\n",
      "LV_RMSE_12h: 961.0538\n",
      "LV_MAE_24h: 154.8276\n",
      "LV_RMSE_24h: 244.3943\n",
      "LV_MAE_48h: 213.8937\n",
      "LV_RMSE_48h: 326.8383\n",
      "LV_MAE_72h: 181.9598\n",
      "LV_RMSE_72h: 283.1031\n",
      "LV_MAE_mean: 356.3793\n",
      "LV_RMSE_mean: 453.8474\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 590.2745\n",
      "RMSE_12h: 719.8505\n",
      "MAE_24h: 264.5208\n",
      "RMSE_24h: 364.6700\n",
      "MAE_48h: 273.9731\n",
      "RMSE_48h: 377.6821\n",
      "MAE_72h: 267.5225\n",
      "RMSE_72h: 364.9464\n",
      "MAE_mean: 349.0727\n",
      "RMSE_mean: 456.7873\n",
      "\n",
      "=== Station S3017022 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1377 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1354, 24, 400) Ytr2: (1354, 4) \n",
      "  Xva3: (197, 24, 400) Yva2: (197, 4) \n",
      "  Xte3: (348, 24, 400) Yte2: (348, 4)\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 3s 57ms/step - loss: 708.6102 - mae: 708.5975 - val_loss: 715.7399 - val_mae: 715.7272 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 703.0497 - mae: 703.0370 - val_loss: 707.7249 - val_mae: 707.7120 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 693.1154 - mae: 693.1023 - val_loss: 695.8074 - val_mae: 695.7941 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 679.9694 - mae: 679.9557 - val_loss: 680.8758 - val_mae: 680.8617 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 663.9647 - mae: 663.9501 - val_loss: 664.0255 - val_mae: 664.0101 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 647.2755 - mae: 647.2596 - val_loss: 647.7361 - val_mae: 647.7193 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 631.1675 - mae: 631.1501 - val_loss: 631.5231 - val_mae: 631.5047 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 614.9904 - mae: 614.9711 - val_loss: 615.6349 - val_mae: 615.6146 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 599.6304 - mae: 599.6091 - val_loss: 600.7087 - val_mae: 600.6862 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 584.1569 - mae: 584.1334 - val_loss: 585.5738 - val_mae: 585.5490 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 569.6678 - mae: 569.6419 - val_loss: 569.8041 - val_mae: 569.7767 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 554.1915 - mae: 554.1630 - val_loss: 554.7033 - val_mae: 554.6733 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 538.5206 - mae: 538.4893 - val_loss: 537.8093 - val_mae: 537.7763 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 520.6258 - mae: 520.5916 - val_loss: 518.9561 - val_mae: 518.9200 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 501.5230 - mae: 501.4857 - val_loss: 498.8755 - val_mae: 498.8362 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 482.4685 - mae: 482.4276 - val_loss: 477.8071 - val_mae: 477.7641 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 462.0891 - mae: 462.0444 - val_loss: 457.8882 - val_mae: 457.8411 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 441.9769 - mae: 441.9281 - val_loss: 436.7722 - val_mae: 436.7210 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 420.6385 - mae: 420.5853 - val_loss: 412.0753 - val_mae: 412.0195 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 396.9840 - mae: 396.9261 - val_loss: 389.7440 - val_mae: 389.6832 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 850.2988\n",
      "LV_RMSE_12h: 962.2015\n",
      "LV_MAE_24h: 128.1494\n",
      "LV_RMSE_24h: 191.7689\n",
      "LV_MAE_48h: 176.9799\n",
      "LV_RMSE_48h: 259.3531\n",
      "LV_MAE_72h: 152.7816\n",
      "LV_RMSE_72h: 224.2802\n",
      "LV_MAE_mean: 327.0524\n",
      "LV_RMSE_mean: 409.4009\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 567.6997\n",
      "RMSE_12h: 698.4521\n",
      "MAE_24h: 269.7071\n",
      "RMSE_24h: 388.2128\n",
      "MAE_48h: 279.2292\n",
      "RMSE_48h: 403.9689\n",
      "MAE_72h: 272.2523\n",
      "RMSE_72h: 395.6215\n",
      "MAE_mean: 347.2220\n",
      "RMSE_mean: 471.5638\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Station S3017031 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1377 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1354, 24, 400) Ytr2: (1354, 4) \n",
      "  Xva3: (197, 24, 400) Yva2: (197, 4) \n",
      "  Xte3: (348, 24, 400) Yte2: (348, 4)\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 3s 58ms/step - loss: 704.8160 - mae: 704.8031 - val_loss: 711.5348 - val_mae: 711.5219 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 699.5858 - mae: 699.5728 - val_loss: 703.8981 - val_mae: 703.8851 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 689.9166 - mae: 689.9032 - val_loss: 691.9340 - val_mae: 691.9203 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 676.5193 - mae: 676.5055 - val_loss: 676.3353 - val_mae: 676.3208 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 659.2797 - mae: 659.2647 - val_loss: 658.5723 - val_mae: 658.5566 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 641.1130 - mae: 641.0966 - val_loss: 640.7164 - val_mae: 640.6991 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 622.6387 - mae: 622.6206 - val_loss: 623.4830 - val_mae: 623.4637 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 604.9018 - mae: 604.8817 - val_loss: 607.1464 - val_mae: 607.1250 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 588.0809 - mae: 588.0585 - val_loss: 591.2949 - val_mae: 591.2712 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 571.8506 - mae: 571.8260 - val_loss: 575.0504 - val_mae: 575.0242 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 556.6842 - mae: 556.6569 - val_loss: 558.4148 - val_mae: 558.3859 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 539.4025 - mae: 539.3724 - val_loss: 542.0417 - val_mae: 542.0099 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 523.5261 - mae: 523.4929 - val_loss: 523.7089 - val_mae: 523.6740 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 504.3014 - mae: 504.2651 - val_loss: 502.7807 - val_mae: 502.7425 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 482.2042 - mae: 482.1645 - val_loss: 480.1068 - val_mae: 480.0651 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 462.6104 - mae: 462.5670 - val_loss: 459.1755 - val_mae: 459.1299 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 441.6273 - mae: 441.5799 - val_loss: 436.8730 - val_mae: 436.8232 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 419.1954 - mae: 419.1437 - val_loss: 415.5180 - val_mae: 415.4638 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 400.0163 - mae: 399.9600 - val_loss: 394.2540 - val_mae: 394.1951 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 378.5105 - mae: 378.4497 - val_loss: 371.9998 - val_mae: 371.9363 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 842.3908\n",
      "LV_RMSE_12h: 953.9279\n",
      "LV_MAE_24h: 129.3075\n",
      "LV_RMSE_24h: 190.8728\n",
      "LV_MAE_48h: 176.5086\n",
      "LV_RMSE_48h: 257.2666\n",
      "LV_MAE_72h: 152.3649\n",
      "LV_RMSE_72h: 223.9727\n",
      "LV_MAE_mean: 325.1430\n",
      "LV_RMSE_mean: 406.5100\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 558.3051\n",
      "RMSE_12h: 686.4268\n",
      "MAE_24h: 261.7323\n",
      "RMSE_24h: 368.2285\n",
      "MAE_48h: 273.7848\n",
      "RMSE_48h: 391.4429\n",
      "MAE_72h: 258.7083\n",
      "RMSE_72h: 364.7376\n",
      "MAE_mean: 338.1326\n",
      "RMSE_mean: 452.7089\n",
      "\n",
      "=== Station S3017032 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1377 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1354, 24, 400) Ytr2: (1354, 4) \n",
      "  Xva3: (197, 24, 400) Yva2: (197, 4) \n",
      "  Xte3: (348, 24, 400) Yte2: (348, 4)\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 3s 57ms/step - loss: 735.9097 - mae: 735.8969 - val_loss: 749.2433 - val_mae: 749.2306 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 729.9950 - mae: 729.9822 - val_loss: 740.6768 - val_mae: 740.6637 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 719.5304 - mae: 719.5172 - val_loss: 728.0228 - val_mae: 728.0092 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 705.4696 - mae: 705.4557 - val_loss: 711.7437 - val_mae: 711.7292 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 688.1008 - mae: 688.0859 - val_loss: 693.6826 - val_mae: 693.6669 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 670.0195 - mae: 670.0031 - val_loss: 675.8114 - val_mae: 675.7942 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 652.8768 - mae: 652.8588 - val_loss: 658.6570 - val_mae: 658.6379 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 635.6154 - mae: 635.5955 - val_loss: 641.5242 - val_mae: 641.5031 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 619.1995 - mae: 619.1774 - val_loss: 624.4153 - val_mae: 624.3920 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 602.4004 - mae: 602.3759 - val_loss: 608.6985 - val_mae: 608.6726 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 588.1509 - mae: 588.1240 - val_loss: 593.6244 - val_mae: 593.5959 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 573.3488 - mae: 573.3193 - val_loss: 577.6909 - val_mae: 577.6597 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 556.6167 - mae: 556.5842 - val_loss: 558.8361 - val_mae: 558.8020 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 537.0015 - mae: 536.9660 - val_loss: 536.8304 - val_mae: 536.7931 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 515.5751 - mae: 515.5361 - val_loss: 512.9808 - val_mae: 512.9399 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 494.1957 - mae: 494.1531 - val_loss: 491.5236 - val_mae: 491.4788 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 472.4931 - mae: 472.4465 - val_loss: 471.0890 - val_mae: 471.0400 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 451.4368 - mae: 451.3860 - val_loss: 451.0952 - val_mae: 451.0420 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 432.9036 - mae: 432.8484 - val_loss: 428.8480 - val_mae: 428.7902 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 412.3048 - mae: 412.2449 - val_loss: 408.3938 - val_mae: 408.3312 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 864.2701\n",
      "LV_RMSE_12h: 949.6544\n",
      "LV_MAE_24h: 152.4052\n",
      "LV_RMSE_24h: 240.3147\n",
      "LV_MAE_48h: 209.4799\n",
      "LV_RMSE_48h: 321.5439\n",
      "LV_MAE_72h: 176.4454\n",
      "LV_RMSE_72h: 273.5047\n",
      "LV_MAE_mean: 350.6501\n",
      "LV_RMSE_mean: 446.2544\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 588.1449\n",
      "RMSE_12h: 717.3671\n",
      "MAE_24h: 258.3966\n",
      "RMSE_24h: 372.3235\n",
      "MAE_48h: 262.6578\n",
      "RMSE_48h: 376.7425\n",
      "MAE_72h: 277.4174\n",
      "RMSE_72h: 395.4738\n",
      "MAE_mean: 346.6542\n",
      "RMSE_mean: 465.4767\n",
      "\n",
      "=== Station S3017051 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1377 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1354, 24, 400) Ytr2: (1354, 4) \n",
      "  Xva3: (197, 24, 400) Yva2: (197, 4) \n",
      "  Xte3: (348, 24, 400) Yte2: (348, 4)\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 3s 57ms/step - loss: 448.7726 - mae: 448.7600 - val_loss: 453.4422 - val_mae: 453.4295 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 443.8805 - mae: 443.8678 - val_loss: 446.3053 - val_mae: 446.2925 - lr: 0.0010\n",
      "Epoch 3/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 13ms/step - loss: 435.1313 - mae: 435.1183 - val_loss: 435.6482 - val_mae: 435.6349 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 422.9683 - mae: 422.9547 - val_loss: 421.3301 - val_mae: 421.3161 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 407.4834 - mae: 407.4689 - val_loss: 405.7488 - val_mae: 405.7336 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 392.6589 - mae: 392.6432 - val_loss: 391.5309 - val_mae: 391.5143 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 378.6275 - mae: 378.6103 - val_loss: 377.9332 - val_mae: 377.9150 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 365.2905 - mae: 365.2716 - val_loss: 364.9939 - val_mae: 364.9739 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 353.0710 - mae: 353.0502 - val_loss: 352.9987 - val_mae: 352.9768 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 341.3994 - mae: 341.3766 - val_loss: 341.7446 - val_mae: 341.7206 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 332.3025 - mae: 332.2776 - val_loss: 330.4000 - val_mae: 330.3739 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 322.0915 - mae: 322.0645 - val_loss: 319.9453 - val_mae: 319.9170 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 312.1575 - mae: 312.1282 - val_loss: 306.9952 - val_mae: 306.9646 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 297.9062 - mae: 297.8745 - val_loss: 288.7414 - val_mae: 288.7083 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 279.9569 - mae: 279.9227 - val_loss: 271.3143 - val_mae: 271.2784 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 262.8752 - mae: 262.8379 - val_loss: 253.7673 - val_mae: 253.7282 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 245.5248 - mae: 245.4843 - val_loss: 237.5309 - val_mae: 237.4883 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 228.9646 - mae: 228.9204 - val_loss: 220.0356 - val_mae: 219.9893 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 214.3609 - mae: 214.3129 - val_loss: 203.8305 - val_mae: 203.7801 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 199.4167 - mae: 199.3645 - val_loss: 193.1278 - val_mae: 193.0733 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 511.9052\n",
      "LV_RMSE_12h: 557.3596\n",
      "LV_MAE_24h: 91.8506\n",
      "LV_RMSE_24h: 136.2034\n",
      "LV_MAE_48h: 121.9914\n",
      "LV_RMSE_48h: 180.9205\n",
      "LV_MAE_72h: 106.3247\n",
      "LV_RMSE_72h: 159.6928\n",
      "LV_MAE_mean: 208.0180\n",
      "LV_RMSE_mean: 258.5441\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 363.3194\n",
      "RMSE_12h: 432.5918\n",
      "MAE_24h: 119.8358\n",
      "RMSE_24h: 161.8019\n",
      "MAE_48h: 122.8696\n",
      "RMSE_48h: 164.5072\n",
      "MAE_72h: 118.6895\n",
      "RMSE_72h: 159.2809\n",
      "MAE_mean: 181.1786\n",
      "RMSE_mean: 229.5454\n",
      "\n",
      "=== Station S3017052 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1377 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1354, 24, 400) Ytr2: (1354, 4) \n",
      "  Xva3: (197, 24, 400) Yva2: (197, 4) \n",
      "  Xte3: (348, 24, 400) Yte2: (348, 4)\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 3s 56ms/step - loss: 441.0046 - mae: 440.9920 - val_loss: 437.4855 - val_mae: 437.4729 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 434.5614 - mae: 434.5486 - val_loss: 428.2851 - val_mae: 428.2721 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 423.7135 - mae: 423.7004 - val_loss: 415.8177 - val_mae: 415.8042 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 410.4965 - mae: 410.4826 - val_loss: 402.3661 - val_mae: 402.3517 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 396.1597 - mae: 396.1448 - val_loss: 388.5925 - val_mae: 388.5769 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 381.3575 - mae: 381.3414 - val_loss: 374.9214 - val_mae: 374.9045 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 367.3485 - mae: 367.3309 - val_loss: 361.7872 - val_mae: 361.7686 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 354.0185 - mae: 353.9992 - val_loss: 349.5735 - val_mae: 349.5531 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 342.0703 - mae: 342.0491 - val_loss: 338.0876 - val_mae: 338.0654 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 330.6051 - mae: 330.5819 - val_loss: 326.9934 - val_mae: 326.9691 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 321.2474 - mae: 321.2222 - val_loss: 316.5233 - val_mae: 316.4969 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 311.3557 - mae: 311.3284 - val_loss: 307.7899 - val_mae: 307.7614 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 303.7981 - mae: 303.7685 - val_loss: 300.4202 - val_mae: 300.3894 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 295.8272 - mae: 295.7955 - val_loss: 292.7572 - val_mae: 292.7242 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 286.7067 - mae: 286.6729 - val_loss: 278.6623 - val_mae: 278.6272 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 270.4717 - mae: 270.4357 - val_loss: 257.6983 - val_mae: 257.6609 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 249.8031 - mae: 249.7644 - val_loss: 239.0058 - val_mae: 238.9654 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 233.2239 - mae: 233.1821 - val_loss: 222.0645 - val_mae: 222.0208 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 217.8699 - mae: 217.8246 - val_loss: 205.8677 - val_mae: 205.8203 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 202.2424 - mae: 202.1934 - val_loss: 192.0340 - val_mae: 191.9828 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 524.4052\n",
      "LV_RMSE_12h: 583.1555\n",
      "LV_MAE_24h: 76.8994\n",
      "LV_RMSE_24h: 108.6501\n",
      "LV_MAE_48h: 103.9971\n",
      "LV_RMSE_48h: 143.7482\n",
      "LV_MAE_72h: 88.2701\n",
      "LV_RMSE_72h: 123.9825\n",
      "LV_MAE_mean: 198.3930\n",
      "LV_RMSE_mean: 239.8841\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 375.9040\n",
      "RMSE_12h: 440.1054\n",
      "MAE_24h: 121.0491\n",
      "RMSE_24h: 170.7763\n",
      "MAE_48h: 131.7634\n",
      "RMSE_48h: 183.8315\n",
      "MAE_72h: 133.7141\n",
      "RMSE_72h: 185.4012\n",
      "MAE_mean: 190.6076\n",
      "RMSE_mean: 245.0286\n",
      "\n",
      "=== Station S3019101 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1377 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1354, 24, 400) Ytr2: (1354, 4) \n",
      "  Xva3: (197, 24, 400) Yva2: (197, 4) \n",
      "  Xte3: (348, 24, 400) Yte2: (348, 4)\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 3s 60ms/step - loss: 1484.7347 - mae: 1484.7219 - val_loss: 1531.5092 - val_mae: 1531.4962 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1477.9805 - mae: 1477.9673 - val_loss: 1522.2208 - val_mae: 1522.2075 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1466.9983 - mae: 1466.9846 - val_loss: 1509.1780 - val_mae: 1509.1641 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1452.2787 - mae: 1452.2642 - val_loss: 1492.1302 - val_mae: 1492.1151 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1433.2361 - mae: 1433.2205 - val_loss: 1470.5637 - val_mae: 1470.5475 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 1409.3590 - mae: 1409.3418 - val_loss: 1444.0588 - val_mae: 1444.0406 - lr: 0.0010\n",
      "Epoch 7/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 15ms/step - loss: 1380.8170 - mae: 1380.7977 - val_loss: 1412.5332 - val_mae: 1412.5127 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1346.7861 - mae: 1346.7644 - val_loss: 1375.7030 - val_mae: 1375.6797 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1307.8722 - mae: 1307.8473 - val_loss: 1333.4969 - val_mae: 1333.4703 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 1263.6820 - mae: 1263.6537 - val_loss: 1286.0753 - val_mae: 1286.0450 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1214.8365 - mae: 1214.8044 - val_loss: 1234.3788 - val_mae: 1234.3441 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1162.1638 - mae: 1162.1272 - val_loss: 1180.3794 - val_mae: 1180.3401 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1110.6559 - mae: 1110.6145 - val_loss: 1126.0195 - val_mae: 1125.9751 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1062.6968 - mae: 1062.6501 - val_loss: 1075.2180 - val_mae: 1075.1686 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1016.6025 - mae: 1016.5508 - val_loss: 1029.2262 - val_mae: 1029.1716 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 977.1942 - mae: 977.1375 - val_loss: 987.4509 - val_mae: 987.3912 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 940.3785 - mae: 940.3165 - val_loss: 949.8673 - val_mae: 949.8024 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 903.8424 - mae: 903.7751 - val_loss: 917.1429 - val_mae: 917.0726 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 874.0748 - mae: 874.0022 - val_loss: 886.9404 - val_mae: 886.8649 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 847.2401 - mae: 847.1623 - val_loss: 858.9290 - val_mae: 858.8482 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 1225.1781\n",
      "LV_RMSE_12h: 1349.2692\n",
      "LV_MAE_24h: 203.7184\n",
      "LV_RMSE_24h: 306.7783\n",
      "LV_MAE_48h: 232.4971\n",
      "LV_RMSE_48h: 350.4200\n",
      "LV_MAE_72h: 192.6379\n",
      "LV_RMSE_72h: 280.8230\n",
      "LV_MAE_mean: 463.5079\n",
      "LV_RMSE_mean: 571.8226\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 777.6692\n",
      "RMSE_12h: 919.1534\n",
      "MAE_24h: 779.2088\n",
      "RMSE_24h: 914.6610\n",
      "MAE_48h: 819.7695\n",
      "RMSE_48h: 975.7831\n",
      "MAE_72h: 826.1403\n",
      "RMSE_72h: 974.2175\n",
      "MAE_mean: 800.6969\n",
      "RMSE_mean: 945.9538\n",
      "\n",
      "=== Station S3019102 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1377 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1354, 24, 400) Ytr2: (1354, 4) \n",
      "  Xva3: (197, 24, 400) Yva2: (197, 4) \n",
      "  Xte3: (348, 24, 400) Yte2: (348, 4)\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 3s 58ms/step - loss: 579.1457 - mae: 579.1329 - val_loss: 556.7230 - val_mae: 556.7103 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 572.6681 - mae: 572.6553 - val_loss: 547.0873 - val_mae: 547.0743 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 560.9786 - mae: 560.9655 - val_loss: 533.2006 - val_mae: 533.1871 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 546.4023 - mae: 546.3885 - val_loss: 517.3677 - val_mae: 517.3533 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 529.4630 - mae: 529.4481 - val_loss: 500.6133 - val_mae: 500.5976 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 512.0198 - mae: 512.0035 - val_loss: 483.3949 - val_mae: 483.3775 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 494.3465 - mae: 494.3283 - val_loss: 464.9501 - val_mae: 464.9308 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 475.0307 - mae: 475.0104 - val_loss: 446.0611 - val_mae: 446.0396 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 455.6734 - mae: 455.6508 - val_loss: 428.2656 - val_mae: 428.2415 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 435.8568 - mae: 435.8315 - val_loss: 410.3113 - val_mae: 410.2844 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 417.7908 - mae: 417.7625 - val_loss: 391.8140 - val_mae: 391.7841 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 398.5858 - mae: 398.5544 - val_loss: 371.1996 - val_mae: 371.1663 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 374.9052 - mae: 374.8704 - val_loss: 344.2750 - val_mae: 344.2381 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 347.4471 - mae: 347.4086 - val_loss: 318.0282 - val_mae: 317.9875 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 321.1008 - mae: 321.0582 - val_loss: 294.9929 - val_mae: 294.9478 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 297.9435 - mae: 297.8965 - val_loss: 272.4539 - val_mae: 272.4045 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 278.4669 - mae: 278.4156 - val_loss: 254.2695 - val_mae: 254.2159 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 261.8361 - mae: 261.7808 - val_loss: 239.9999 - val_mae: 239.9425 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 249.8367 - mae: 249.7777 - val_loss: 227.6689 - val_mae: 227.6079 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 236.9370 - mae: 236.8746 - val_loss: 217.0699 - val_mae: 217.0056 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 640.2328\n",
      "LV_RMSE_12h: 733.1579\n",
      "LV_MAE_24h: 102.5402\n",
      "LV_RMSE_24h: 138.5640\n",
      "LV_MAE_48h: 124.6092\n",
      "LV_RMSE_48h: 161.5128\n",
      "LV_MAE_72h: 116.2155\n",
      "LV_RMSE_72h: 153.6487\n",
      "LV_MAE_mean: 245.8994\n",
      "LV_RMSE_mean: 296.7209\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 466.5383\n",
      "RMSE_12h: 556.6959\n",
      "MAE_24h: 149.9963\n",
      "RMSE_24h: 204.3157\n",
      "MAE_48h: 152.9156\n",
      "RMSE_48h: 210.1022\n",
      "MAE_72h: 161.5586\n",
      "RMSE_72h: 220.5939\n",
      "MAE_mean: 232.7522\n",
      "RMSE_mean: 297.9269\n",
      "\n",
      "=== Station S3019103 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1141 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1118, 24, 400) Ytr2: (1118, 4) \n",
      "  Xva3: (164, 24, 400) Yva2: (164, 4) \n",
      "  Xte3: (280, 24, 400) Yte2: (280, 4)\n",
      "Epoch 1/20\n",
      "9/9 [==============================] - 3s 69ms/step - loss: 89.6983 - mae: 89.6855 - val_loss: 102.4451 - val_mae: 102.4323 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 86.3936 - mae: 86.3807 - val_loss: 97.7694 - val_mae: 97.7565 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 81.1943 - mae: 81.1812 - val_loss: 91.8762 - val_mae: 91.8630 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 75.4846 - mae: 75.4712 - val_loss: 86.1817 - val_mae: 86.1680 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 69.7097 - mae: 69.6958 - val_loss: 81.0223 - val_mae: 81.0080 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 64.4786 - mae: 64.4641 - val_loss: 76.1548 - val_mae: 76.1398 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 59.3957 - mae: 59.3804 - val_loss: 72.0353 - val_mae: 72.0194 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 55.7581 - mae: 55.7419 - val_loss: 68.7745 - val_mae: 68.7578 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 52.6595 - mae: 52.6424 - val_loss: 66.0659 - val_mae: 66.0484 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 50.2766 - mae: 50.2589 - val_loss: 63.0422 - val_mae: 63.0241 - lr: 0.0010\n",
      "Epoch 11/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 14ms/step - loss: 47.5689 - mae: 47.5506 - val_loss: 60.5279 - val_mae: 60.5094 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 44.8480 - mae: 44.8293 - val_loss: 57.5311 - val_mae: 57.5121 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 42.3497 - mae: 42.3305 - val_loss: 54.9820 - val_mae: 54.9625 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 40.4263 - mae: 40.4065 - val_loss: 53.0203 - val_mae: 53.0003 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 38.2863 - mae: 38.2661 - val_loss: 50.6719 - val_mae: 50.6514 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 36.7195 - mae: 36.6988 - val_loss: 48.6109 - val_mae: 48.5899 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "9/9 [==============================] - 0s 21ms/step - loss: 35.0445 - mae: 35.0233 - val_loss: 47.2534 - val_mae: 47.2318 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 33.4389 - mae: 33.4172 - val_loss: 45.7618 - val_mae: 45.7397 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 32.4130 - mae: 32.3906 - val_loss: 44.2385 - val_mae: 44.2158 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 30.9651 - mae: 30.9421 - val_loss: 42.8422 - val_mae: 42.8188 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 95.9679\n",
      "LV_RMSE_12h: 108.5560\n",
      "LV_MAE_24h: 21.8107\n",
      "LV_RMSE_24h: 31.0362\n",
      "LV_MAE_48h: 23.4714\n",
      "LV_RMSE_48h: 34.0899\n",
      "LV_MAE_72h: 23.1571\n",
      "LV_RMSE_72h: 32.5597\n",
      "LV_MAE_mean: 41.1018\n",
      "LV_RMSE_mean: 51.5605\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 45.6053\n",
      "RMSE_12h: 54.5189\n",
      "MAE_24h: 18.1882\n",
      "RMSE_24h: 25.5774\n",
      "MAE_48h: 17.5204\n",
      "RMSE_48h: 25.3112\n",
      "MAE_72h: 17.2285\n",
      "RMSE_72h: 23.7656\n",
      "MAE_mean: 24.6356\n",
      "RMSE_mean: 32.2933\n",
      "\n",
      "=== Station S3019104 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1175 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1152, 24, 400) Ytr2: (1152, 4) \n",
      "  Xva3: (168, 24, 400) Yva2: (168, 4) \n",
      "  Xte3: (290, 24, 400) Yte2: (290, 4)\n",
      "Epoch 1/20\n",
      "9/9 [==============================] - 3s 71ms/step - loss: 685.4675 - mae: 685.4548 - val_loss: 713.9198 - val_mae: 713.9072 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 681.4068 - mae: 681.3941 - val_loss: 708.0992 - val_mae: 708.0865 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 674.3845 - mae: 674.3717 - val_loss: 699.7249 - val_mae: 699.7120 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 665.2482 - mae: 665.2352 - val_loss: 689.3217 - val_mae: 689.3083 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 653.8684 - mae: 653.8548 - val_loss: 676.5554 - val_mae: 676.5413 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 640.5606 - mae: 640.5461 - val_loss: 662.1676 - val_mae: 662.1526 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 625.4587 - mae: 625.4432 - val_loss: 646.7006 - val_mae: 646.6846 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 610.6317 - mae: 610.6151 - val_loss: 631.2130 - val_mae: 631.1956 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 595.3561 - mae: 595.3381 - val_loss: 616.2997 - val_mae: 616.2808 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 580.6276 - mae: 580.6078 - val_loss: 601.7993 - val_mae: 601.7786 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 566.4493 - mae: 566.4279 - val_loss: 587.7477 - val_mae: 587.7253 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 552.1452 - mae: 552.1218 - val_loss: 573.8942 - val_mae: 573.8699 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 538.6416 - mae: 538.6163 - val_loss: 560.8046 - val_mae: 560.7782 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 526.2753 - mae: 526.2479 - val_loss: 548.5800 - val_mae: 548.5514 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 514.3085 - mae: 514.2789 - val_loss: 536.7183 - val_mae: 536.6875 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 503.1284 - mae: 503.0965 - val_loss: 524.7065 - val_mae: 524.6733 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 492.5288 - mae: 492.4946 - val_loss: 513.5275 - val_mae: 513.4921 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 482.2680 - mae: 482.2314 - val_loss: 502.7258 - val_mae: 502.6879 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 470.7318 - mae: 470.6928 - val_loss: 490.0868 - val_mae: 490.0464 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 458.9009 - mae: 458.8595 - val_loss: 475.1033 - val_mae: 475.0605 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 815.8655\n",
      "LV_RMSE_12h: 904.7645\n",
      "LV_MAE_24h: 143.9000\n",
      "LV_RMSE_24h: 225.6544\n",
      "LV_MAE_48h: 168.4586\n",
      "LV_RMSE_48h: 266.5810\n",
      "LV_MAE_72h: 145.9448\n",
      "LV_RMSE_72h: 223.4126\n",
      "LV_MAE_mean: 318.5422\n",
      "LV_RMSE_mean: 405.1031\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 474.5080\n",
      "RMSE_12h: 567.2242\n",
      "MAE_24h: 410.5425\n",
      "RMSE_24h: 498.2743\n",
      "MAE_48h: 401.0512\n",
      "RMSE_48h: 488.0165\n",
      "MAE_72h: 415.7704\n",
      "RMSE_72h: 519.6377\n",
      "MAE_mean: 425.4680\n",
      "RMSE_mean: 518.2882\n",
      "\n",
      "=== Station S3020091 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 219 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (196, 24, 400) Ytr2: (196, 4) \n",
      "  Xva3: (32, 24, 400) Yva2: (32, 4) \n",
      "  Xte3: (16, 24, 400) Yte2: (16, 4)\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 3s 485ms/step - loss: 1350.4635 - mae: 1350.4506 - val_loss: 1272.6898 - val_mae: 1272.6770 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 1349.8094 - mae: 1349.7968 - val_loss: 1271.9607 - val_mae: 1271.9479 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 1349.0447 - mae: 1349.0317 - val_loss: 1271.0380 - val_mae: 1271.0251 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 1348.0714 - mae: 1348.0585 - val_loss: 1269.9608 - val_mae: 1269.9479 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 1347.0115 - mae: 1346.9985 - val_loss: 1268.7476 - val_mae: 1268.7346 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 1345.7692 - mae: 1345.7562 - val_loss: 1267.3752 - val_mae: 1267.3623 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 1344.2908 - mae: 1344.2780 - val_loss: 1265.8436 - val_mae: 1265.8306 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 1342.7692 - mae: 1342.7561 - val_loss: 1264.1740 - val_mae: 1264.1609 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 1340.9601 - mae: 1340.9470 - val_loss: 1262.3840 - val_mae: 1262.3710 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 1339.1410 - mae: 1339.1279 - val_loss: 1260.4496 - val_mae: 1260.4364 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 1337.2073 - mae: 1337.1941 - val_loss: 1258.3854 - val_mae: 1258.3721 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 1335.0658 - mae: 1335.0525 - val_loss: 1256.2225 - val_mae: 1256.2092 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 1332.8895 - mae: 1332.8761 - val_loss: 1253.9573 - val_mae: 1253.9438 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 1330.6088 - mae: 1330.5953 - val_loss: 1251.5712 - val_mae: 1251.5576 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 1328.1545 - mae: 1328.1410 - val_loss: 1249.0789 - val_mae: 1249.0652 - lr: 0.0010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 1325.6912 - mae: 1325.6775 - val_loss: 1246.4645 - val_mae: 1246.4507 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 1323.2505 - mae: 1323.2367 - val_loss: 1243.7235 - val_mae: 1243.7096 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 1320.3253 - mae: 1320.3114 - val_loss: 1240.8711 - val_mae: 1240.8571 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 1317.4636 - mae: 1317.4496 - val_loss: 1237.9005 - val_mae: 1237.8862 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 1314.7006 - mae: 1314.6863 - val_loss: 1234.8066 - val_mae: 1234.7922 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 1142.2500\n",
      "LV_RMSE_12h: 1235.8604\n",
      "LV_MAE_24h: 109.1250\n",
      "LV_RMSE_24h: 148.9635\n",
      "LV_MAE_48h: 99.8125\n",
      "LV_RMSE_48h: 153.2484\n",
      "LV_MAE_72h: 119.8125\n",
      "LV_RMSE_72h: 181.6568\n",
      "LV_MAE_mean: 367.7500\n",
      "LV_RMSE_mean: 429.9323\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 1147.3562\n",
      "RMSE_12h: 1375.5039\n",
      "MAE_24h: 1466.1195\n",
      "RMSE_24h: 1574.8412\n",
      "MAE_48h: 1488.8137\n",
      "RMSE_48h: 1590.6566\n",
      "MAE_72h: 1506.9769\n",
      "RMSE_72h: 1626.3308\n",
      "MAE_mean: 1402.3165\n",
      "RMSE_mean: 1541.8333\n",
      "\n",
      "=== Station S3021011 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1266 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1243, 24, 400) Ytr2: (1243, 4) \n",
      "  Xva3: (181, 24, 400) Yva2: (181, 4) \n",
      "  Xte3: (316, 24, 400) Yte2: (316, 4)\n",
      "Epoch 1/20\n",
      "10/10 [==============================] - 3s 64ms/step - loss: 63.7288 - mae: 63.7161 - val_loss: 63.7241 - val_mae: 63.7113 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 59.0806 - mae: 59.0677 - val_loss: 57.8005 - val_mae: 57.7875 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 53.7315 - mae: 53.7184 - val_loss: 52.5819 - val_mae: 52.5686 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 49.9695 - mae: 49.9560 - val_loss: 49.5089 - val_mae: 49.4951 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 48.1736 - mae: 48.1596 - val_loss: 47.8282 - val_mae: 47.8140 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 47.0216 - mae: 47.0073 - val_loss: 46.8226 - val_mae: 46.8082 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 46.2523 - mae: 46.2379 - val_loss: 45.3794 - val_mae: 45.3650 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 44.7607 - mae: 44.7462 - val_loss: 43.1785 - val_mae: 43.1639 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 42.9064 - mae: 42.8917 - val_loss: 40.6618 - val_mae: 40.6470 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 40.9587 - mae: 40.9437 - val_loss: 38.6456 - val_mae: 38.6304 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 39.4095 - mae: 39.3940 - val_loss: 37.1087 - val_mae: 37.0929 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 37.9252 - mae: 37.9092 - val_loss: 35.6952 - val_mae: 35.6789 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 36.8238 - mae: 36.8073 - val_loss: 34.8395 - val_mae: 34.8227 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 35.6140 - mae: 35.5969 - val_loss: 33.7958 - val_mae: 33.7784 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 34.4656 - mae: 34.4480 - val_loss: 32.5314 - val_mae: 32.5134 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 33.6330 - mae: 33.6147 - val_loss: 31.6974 - val_mae: 31.6787 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 32.4560 - mae: 32.4370 - val_loss: 30.5422 - val_mae: 30.5228 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 31.6606 - mae: 31.6409 - val_loss: 30.0540 - val_mae: 30.0339 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 31.1146 - mae: 31.0943 - val_loss: 29.3806 - val_mae: 29.3600 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 30.6223 - mae: 30.6014 - val_loss: 29.0947 - val_mae: 29.0735 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 69.1709\n",
      "LV_RMSE_12h: 89.9539\n",
      "LV_MAE_24h: 24.0158\n",
      "LV_RMSE_24h: 44.5742\n",
      "LV_MAE_48h: 30.4177\n",
      "LV_RMSE_48h: 51.8611\n",
      "LV_MAE_72h: 25.6108\n",
      "LV_RMSE_72h: 50.2876\n",
      "LV_MAE_mean: 37.3038\n",
      "LV_RMSE_mean: 59.1692\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 21.9158\n",
      "RMSE_12h: 43.5822\n",
      "MAE_24h: 25.0781\n",
      "RMSE_24h: 44.7780\n",
      "MAE_48h: 21.3026\n",
      "RMSE_48h: 36.5895\n",
      "MAE_72h: 20.2626\n",
      "RMSE_72h: 35.4902\n",
      "MAE_mean: 22.1398\n",
      "RMSE_mean: 40.1099\n",
      "\n",
      "=== Station S3021081 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1266 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1243, 24, 400) Ytr2: (1243, 4) \n",
      "  Xva3: (181, 24, 400) Yva2: (181, 4) \n",
      "  Xte3: (316, 24, 400) Yte2: (316, 4)\n",
      "Epoch 1/20\n",
      "10/10 [==============================] - 3s 62ms/step - loss: 33.6197 - mae: 33.6068 - val_loss: 31.0811 - val_mae: 31.0682 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 30.6244 - mae: 30.6114 - val_loss: 27.5179 - val_mae: 27.5049 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 27.1986 - mae: 27.1854 - val_loss: 24.1354 - val_mae: 24.1220 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 24.3307 - mae: 24.3171 - val_loss: 21.3826 - val_mae: 21.3688 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 21.9093 - mae: 21.8952 - val_loss: 18.7129 - val_mae: 18.6985 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 19.5891 - mae: 19.5745 - val_loss: 16.2671 - val_mae: 16.2522 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 17.7254 - mae: 17.7103 - val_loss: 14.2163 - val_mae: 14.2009 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 16.2756 - mae: 16.2600 - val_loss: 12.7935 - val_mae: 12.7776 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 15.3814 - mae: 15.3654 - val_loss: 12.0739 - val_mae: 12.0575 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 15.1345 - mae: 15.1180 - val_loss: 11.9109 - val_mae: 11.8943 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 14.9124 - mae: 14.8958 - val_loss: 11.6583 - val_mae: 11.6417 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 14.7301 - mae: 14.7135 - val_loss: 11.5421 - val_mae: 11.5255 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 14.6360 - mae: 14.6194 - val_loss: 11.5236 - val_mae: 11.5070 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 14.5862 - mae: 14.5696 - val_loss: 11.5665 - val_mae: 11.5499 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 14.4886 - mae: 14.4720 - val_loss: 11.3812 - val_mae: 11.3647 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 14.4905 - mae: 14.4740 - val_loss: 11.4065 - val_mae: 11.3900 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 14.2928 - mae: 14.2764 - val_loss: 11.4240 - val_mae: 11.4076 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 14.3342 - mae: 14.3178 - val_loss: 11.3902 - val_mae: 11.3738 - lr: 5.0000e-04\n",
      "Epoch 19/20\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 14.3686 - mae: 14.3522 - val_loss: 11.2343 - val_mae: 11.2179 - lr: 5.0000e-04\n",
      "Epoch 20/20\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 14.2473 - mae: 14.2309 - val_loss: 11.2595 - val_mae: 11.2432 - lr: 5.0000e-04\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 49.1519\n",
      "LV_RMSE_12h: 56.9635\n",
      "LV_MAE_24h: 12.8165\n",
      "LV_RMSE_24h: 19.1967\n",
      "LV_MAE_48h: 14.4810\n",
      "LV_RMSE_48h: 22.5533\n",
      "LV_MAE_72h: 12.7310\n",
      "LV_RMSE_72h: 19.9608\n",
      "LV_MAE_mean: 22.2951\n",
      "LV_RMSE_mean: 29.6686\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 12.8333\n",
      "RMSE_12h: 18.5279\n",
      "MAE_24h: 12.2006\n",
      "RMSE_24h: 17.8911\n",
      "MAE_48h: 11.8129\n",
      "RMSE_48h: 17.4216\n",
      "MAE_72h: 11.6205\n",
      "RMSE_72h: 17.1492\n",
      "MAE_mean: 12.1168\n",
      "RMSE_mean: 17.7475\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Station S3021111 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1266 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1243, 24, 400) Ytr2: (1243, 4) \n",
      "  Xva3: (181, 24, 400) Yva2: (181, 4) \n",
      "  Xte3: (316, 24, 400) Yte2: (316, 4)\n",
      "Epoch 1/20\n",
      "10/10 [==============================] - 3s 63ms/step - loss: 294.2736 - mae: 294.2608 - val_loss: 272.3165 - val_mae: 272.3036 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 289.8536 - mae: 289.8406 - val_loss: 266.3649 - val_mae: 266.3519 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 282.3070 - mae: 282.2939 - val_loss: 257.6752 - val_mae: 257.6618 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 271.8841 - mae: 271.8705 - val_loss: 246.5631 - val_mae: 246.5491 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 259.0559 - mae: 259.0416 - val_loss: 233.2523 - val_mae: 233.2374 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 244.5923 - mae: 244.5769 - val_loss: 219.2399 - val_mae: 219.2238 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 229.1599 - mae: 229.1433 - val_loss: 205.1901 - val_mae: 205.1727 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 213.6890 - mae: 213.6709 - val_loss: 191.6288 - val_mae: 191.6098 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 199.6521 - mae: 199.6323 - val_loss: 179.2829 - val_mae: 179.2621 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 186.4236 - mae: 186.4020 - val_loss: 169.3496 - val_mae: 169.3270 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 176.1550 - mae: 176.1316 - val_loss: 161.0346 - val_mae: 161.0102 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 166.7546 - mae: 166.7294 - val_loss: 153.7522 - val_mae: 153.7260 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 159.7078 - mae: 159.6808 - val_loss: 147.8509 - val_mae: 147.8229 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 154.3449 - mae: 154.3162 - val_loss: 143.9465 - val_mae: 143.9170 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 151.4398 - mae: 151.4096 - val_loss: 141.2293 - val_mae: 141.1984 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 149.4980 - mae: 149.4666 - val_loss: 139.4283 - val_mae: 139.3963 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 146.8289 - mae: 146.7965 - val_loss: 138.4473 - val_mae: 138.4145 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 146.5874 - mae: 146.5543 - val_loss: 136.5335 - val_mae: 136.5001 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 144.6630 - mae: 144.6295 - val_loss: 134.5215 - val_mae: 134.4877 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 142.3617 - mae: 142.3277 - val_loss: 129.5368 - val_mae: 129.5027 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 252.7025\n",
      "LV_RMSE_12h: 281.7358\n",
      "LV_MAE_24h: 56.4272\n",
      "LV_RMSE_24h: 81.7567\n",
      "LV_MAE_48h: 73.3354\n",
      "LV_RMSE_48h: 102.9953\n",
      "LV_MAE_72h: 60.8671\n",
      "LV_RMSE_72h: 84.6691\n",
      "LV_MAE_mean: 110.8331\n",
      "LV_RMSE_mean: 137.7892\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 149.8440\n",
      "RMSE_12h: 172.4765\n",
      "MAE_24h: 120.2722\n",
      "RMSE_24h: 141.4297\n",
      "MAE_48h: 116.4777\n",
      "RMSE_48h: 136.6995\n",
      "MAE_72h: 111.4357\n",
      "RMSE_72h: 130.1039\n",
      "MAE_mean: 124.5074\n",
      "RMSE_mean: 145.1774\n",
      "\n",
      "=== Station S3021121 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1377 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1354, 24, 400) Ytr2: (1354, 4) \n",
      "  Xva3: (197, 24, 400) Yva2: (197, 4) \n",
      "  Xte3: (348, 24, 400) Yte2: (348, 4)\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 3s 59ms/step - loss: 398.9117 - mae: 398.8989 - val_loss: 426.6784 - val_mae: 426.6654 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 393.1880 - mae: 393.1750 - val_loss: 418.1217 - val_mae: 418.1086 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 382.5449 - mae: 382.5316 - val_loss: 405.4940 - val_mae: 405.4803 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 368.7147 - mae: 368.7006 - val_loss: 389.3618 - val_mae: 389.3471 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 350.4178 - mae: 350.4027 - val_loss: 369.3058 - val_mae: 369.2899 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 328.7593 - mae: 328.7427 - val_loss: 345.1032 - val_mae: 345.0857 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 304.3894 - mae: 304.3710 - val_loss: 318.8125 - val_mae: 318.7930 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 280.6887 - mae: 280.6682 - val_loss: 294.1689 - val_mae: 294.1472 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 259.0189 - mae: 258.9962 - val_loss: 271.2828 - val_mae: 271.2587 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 239.2431 - mae: 239.2179 - val_loss: 250.1033 - val_mae: 250.0768 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 223.2525 - mae: 223.2249 - val_loss: 230.1742 - val_mae: 230.1453 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 209.1188 - mae: 209.0887 - val_loss: 212.5011 - val_mae: 212.4696 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 197.3260 - mae: 197.2936 - val_loss: 197.8499 - val_mae: 197.8161 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 188.5710 - mae: 188.5363 - val_loss: 185.7414 - val_mae: 185.7054 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 183.2930 - mae: 183.2562 - val_loss: 176.7201 - val_mae: 176.6822 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 177.8981 - mae: 177.8595 - val_loss: 168.8238 - val_mae: 168.7842 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 161.3126 - mae: 161.2723 - val_loss: 160.0257 - val_mae: 159.9843 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 143.9781 - mae: 143.9357 - val_loss: 147.8246 - val_mae: 147.7809 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 133.3143 - mae: 133.2695 - val_loss: 140.7503 - val_mae: 140.7043 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 126.8532 - mae: 126.8063 - val_loss: 134.5672 - val_mae: 134.5193 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 323.6322\n",
      "LV_RMSE_12h: 359.7210\n",
      "LV_MAE_24h: 71.1236\n",
      "LV_RMSE_24h: 111.5575\n",
      "LV_MAE_48h: 94.2040\n",
      "LV_RMSE_48h: 139.6539\n",
      "LV_MAE_72h: 76.8046\n",
      "LV_RMSE_72h: 111.0969\n",
      "LV_MAE_mean: 141.4411\n",
      "LV_RMSE_mean: 180.5073\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 258.0240\n",
      "RMSE_12h: 294.3445\n",
      "MAE_24h: 76.9821\n",
      "RMSE_24h: 110.4745\n",
      "MAE_48h: 72.6836\n",
      "RMSE_48h: 108.2822\n",
      "MAE_72h: 69.6957\n",
      "RMSE_72h: 103.1798\n",
      "MAE_mean: 119.3464\n",
      "RMSE_mean: 154.0702\n",
      "\n",
      "=== Station S3021122 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1377 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1354, 24, 400) Ytr2: (1354, 4) \n",
      "  Xva3: (197, 24, 400) Yva2: (197, 4) \n",
      "  Xte3: (348, 24, 400) Yte2: (348, 4)\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 3s 56ms/step - loss: 1914.7494 - mae: 1914.7367 - val_loss: 1894.5005 - val_mae: 1894.4878 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1909.5667 - mae: 1909.5537 - val_loss: 1887.0160 - val_mae: 1887.0032 - lr: 0.0010\n",
      "Epoch 3/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 13ms/step - loss: 1900.1233 - mae: 1900.1102 - val_loss: 1875.8645 - val_mae: 1875.8512 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1887.0748 - mae: 1887.0612 - val_loss: 1861.3395 - val_mae: 1861.3252 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1870.2356 - mae: 1870.2212 - val_loss: 1843.1792 - val_mae: 1843.1641 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1849.4647 - mae: 1849.4489 - val_loss: 1820.8081 - val_mae: 1820.7913 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1824.4219 - mae: 1824.4042 - val_loss: 1794.5327 - val_mae: 1794.5139 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1793.7961 - mae: 1793.7762 - val_loss: 1764.2041 - val_mae: 1764.1829 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1759.8881 - mae: 1759.8654 - val_loss: 1729.7805 - val_mae: 1729.7563 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1719.8960 - mae: 1719.8706 - val_loss: 1691.4945 - val_mae: 1691.4670 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1678.9967 - mae: 1678.9680 - val_loss: 1650.7512 - val_mae: 1650.7203 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1636.6127 - mae: 1636.5801 - val_loss: 1609.8049 - val_mae: 1609.7700 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1594.2832 - mae: 1594.2463 - val_loss: 1570.2468 - val_mae: 1570.2078 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1553.5897 - mae: 1553.5486 - val_loss: 1531.5367 - val_mae: 1531.4932 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1511.2112 - mae: 1511.1656 - val_loss: 1492.0679 - val_mae: 1492.0197 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1471.5112 - mae: 1471.4608 - val_loss: 1452.5203 - val_mae: 1452.4673 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1431.1791 - mae: 1431.1234 - val_loss: 1415.0305 - val_mae: 1414.9720 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1391.1697 - mae: 1391.1093 - val_loss: 1379.4921 - val_mae: 1379.4286 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1356.9261 - mae: 1356.8604 - val_loss: 1344.3627 - val_mae: 1344.2938 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1321.9714 - mae: 1321.9001 - val_loss: 1309.6837 - val_mae: 1309.6095 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 1781.3103\n",
      "LV_RMSE_12h: 1972.0862\n",
      "LV_MAE_24h: 327.3592\n",
      "LV_RMSE_24h: 512.8431\n",
      "LV_MAE_48h: 417.4310\n",
      "LV_RMSE_48h: 645.4822\n",
      "LV_MAE_72h: 362.4598\n",
      "LV_RMSE_72h: 557.7274\n",
      "LV_MAE_mean: 722.1401\n",
      "LV_RMSE_mean: 922.0347\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 1222.5216\n",
      "RMSE_12h: 1483.0212\n",
      "MAE_24h: 1313.5453\n",
      "RMSE_24h: 1596.8198\n",
      "MAE_48h: 1281.5968\n",
      "RMSE_48h: 1560.5094\n",
      "MAE_72h: 1251.1550\n",
      "RMSE_72h: 1521.0398\n",
      "MAE_mean: 1267.2046\n",
      "RMSE_mean: 1540.3477\n",
      "\n",
      "=== Station S3021123 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1266 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1243, 24, 400) Ytr2: (1243, 4) \n",
      "  Xva3: (181, 24, 400) Yva2: (181, 4) \n",
      "  Xte3: (316, 24, 400) Yte2: (316, 4)\n",
      "Epoch 1/20\n",
      "10/10 [==============================] - 3s 64ms/step - loss: 192.1040 - mae: 192.0913 - val_loss: 196.1114 - val_mae: 196.0986 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 186.1292 - mae: 186.1163 - val_loss: 187.3255 - val_mae: 187.3125 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 175.7168 - mae: 175.7036 - val_loss: 174.9881 - val_mae: 174.9746 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 162.3542 - mae: 162.3404 - val_loss: 160.7359 - val_mae: 160.7216 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 147.9686 - mae: 147.9539 - val_loss: 146.7216 - val_mae: 146.7063 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 134.9196 - mae: 134.9038 - val_loss: 133.6270 - val_mae: 133.6104 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 123.1240 - mae: 123.1068 - val_loss: 122.3814 - val_mae: 122.3633 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 112.4625 - mae: 112.4438 - val_loss: 112.1955 - val_mae: 112.1760 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 103.6169 - mae: 103.5967 - val_loss: 103.8358 - val_mae: 103.8147 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 96.6678 - mae: 96.6460 - val_loss: 98.1752 - val_mae: 98.1526 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 93.1582 - mae: 93.1350 - val_loss: 94.3747 - val_mae: 94.3509 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 91.4539 - mae: 91.4297 - val_loss: 92.4395 - val_mae: 92.4148 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 90.6229 - mae: 90.5980 - val_loss: 91.1755 - val_mae: 91.1504 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 89.8478 - mae: 89.8226 - val_loss: 88.4501 - val_mae: 88.4248 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 85.3201 - mae: 85.2947 - val_loss: 82.0705 - val_mae: 82.0449 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 80.3217 - mae: 80.2958 - val_loss: 77.3648 - val_mae: 77.3385 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 76.2738 - mae: 76.2471 - val_loss: 72.3552 - val_mae: 72.3281 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 74.0514 - mae: 74.0240 - val_loss: 68.5788 - val_mae: 68.5510 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 71.8117 - mae: 71.7838 - val_loss: 65.7037 - val_mae: 65.6755 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 69.3066 - mae: 69.2782 - val_loss: 63.9632 - val_mae: 63.9346 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 154.7468\n",
      "LV_RMSE_12h: 177.8553\n",
      "LV_MAE_24h: 42.7184\n",
      "LV_RMSE_24h: 61.0811\n",
      "LV_MAE_48h: 55.8576\n",
      "LV_RMSE_48h: 75.5767\n",
      "LV_MAE_72h: 45.6266\n",
      "LV_RMSE_72h: 64.8583\n",
      "LV_MAE_mean: 74.7373\n",
      "LV_RMSE_mean: 94.8428\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 122.8169\n",
      "RMSE_12h: 143.2186\n",
      "MAE_24h: 45.4021\n",
      "RMSE_24h: 65.4505\n",
      "MAE_48h: 43.7106\n",
      "RMSE_48h: 62.6193\n",
      "MAE_72h: 41.4251\n",
      "RMSE_72h: 60.4956\n",
      "MAE_mean: 63.3387\n",
      "RMSE_mean: 82.9460\n",
      "\n",
      "=== Station S3022011 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1377 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1354, 24, 400) Ytr2: (1354, 4) \n",
      "  Xva3: (197, 24, 400) Yva2: (197, 4) \n",
      "  Xte3: (348, 24, 400) Yte2: (348, 4)\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 3s 59ms/step - loss: 177.0201 - mae: 177.0073 - val_loss: 171.1428 - val_mae: 171.1300 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 171.3737 - mae: 171.3609 - val_loss: 163.2385 - val_mae: 163.2255 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 162.3222 - mae: 162.3089 - val_loss: 153.6202 - val_mae: 153.6066 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 152.8783 - mae: 152.8643 - val_loss: 143.7596 - val_mae: 143.7451 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 142.9351 - mae: 142.9202 - val_loss: 133.5489 - val_mae: 133.5333 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 132.4762 - mae: 132.4600 - val_loss: 122.4778 - val_mae: 122.4608 - lr: 0.0010\n",
      "Epoch 7/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 15ms/step - loss: 122.1013 - mae: 122.0836 - val_loss: 111.8643 - val_mae: 111.8456 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 111.6925 - mae: 111.6730 - val_loss: 101.6536 - val_mae: 101.6331 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 100.5762 - mae: 100.5550 - val_loss: 90.0564 - val_mae: 90.0340 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 87.3298 - mae: 87.3065 - val_loss: 78.4020 - val_mae: 78.3775 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 76.7816 - mae: 76.7561 - val_loss: 70.1050 - val_mae: 70.0783 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 69.3338 - mae: 69.3062 - val_loss: 65.2554 - val_mae: 65.2267 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 66.5359 - mae: 66.5066 - val_loss: 63.7689 - val_mae: 63.7390 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 64.7169 - mae: 64.6868 - val_loss: 62.8523 - val_mae: 62.8220 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 64.3255 - mae: 64.2951 - val_loss: 61.5602 - val_mae: 61.5298 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 62.7444 - mae: 62.7140 - val_loss: 60.3899 - val_mae: 60.3594 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 61.8960 - mae: 61.8654 - val_loss: 58.5800 - val_mae: 58.5491 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 60.6737 - mae: 60.6426 - val_loss: 56.8912 - val_mae: 56.8597 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 58.4814 - mae: 58.4496 - val_loss: 54.3436 - val_mae: 54.3112 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 57.2210 - mae: 57.1882 - val_loss: 52.7296 - val_mae: 52.6962 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 178.5374\n",
      "LV_RMSE_12h: 200.2917\n",
      "LV_MAE_24h: 36.8017\n",
      "LV_RMSE_24h: 54.7118\n",
      "LV_MAE_48h: 47.0891\n",
      "LV_RMSE_48h: 69.9151\n",
      "LV_MAE_72h: 39.3218\n",
      "LV_RMSE_72h: 61.0729\n",
      "LV_MAE_mean: 75.4375\n",
      "LV_RMSE_mean: 96.4979\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 107.2471\n",
      "RMSE_12h: 129.0647\n",
      "MAE_24h: 38.6946\n",
      "RMSE_24h: 57.8836\n",
      "MAE_48h: 36.8567\n",
      "RMSE_48h: 55.9965\n",
      "MAE_72h: 37.0483\n",
      "RMSE_72h: 54.6249\n",
      "MAE_mean: 54.9617\n",
      "RMSE_mean: 74.3924\n",
      "\n",
      "=== Station S3022012 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1377 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1354, 24, 400) Ytr2: (1354, 4) \n",
      "  Xva3: (197, 24, 400) Yva2: (197, 4) \n",
      "  Xte3: (348, 24, 400) Yte2: (348, 4)\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 3s 58ms/step - loss: 214.3641 - mae: 214.3513 - val_loss: 172.6084 - val_mae: 172.5956 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 208.2715 - mae: 208.2585 - val_loss: 163.1982 - val_mae: 163.1851 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 197.4871 - mae: 197.4737 - val_loss: 151.4700 - val_mae: 151.4563 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 186.3839 - mae: 186.3698 - val_loss: 141.0409 - val_mae: 141.0262 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 176.5433 - mae: 176.5282 - val_loss: 132.8925 - val_mae: 132.8767 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 168.3754 - mae: 168.3590 - val_loss: 126.1074 - val_mae: 126.0902 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 161.9565 - mae: 161.9387 - val_loss: 121.1059 - val_mae: 121.0873 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 157.1775 - mae: 157.1583 - val_loss: 117.2647 - val_mae: 117.2448 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 152.9893 - mae: 152.9689 - val_loss: 113.4937 - val_mae: 113.4726 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 147.5550 - mae: 147.5334 - val_loss: 105.5924 - val_mae: 105.5702 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 138.5382 - mae: 138.5153 - val_loss: 95.6199 - val_mae: 95.5961 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 0s 17ms/step - loss: 129.2314 - mae: 129.2068 - val_loss: 85.6805 - val_mae: 85.6548 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 118.8361 - mae: 118.8094 - val_loss: 74.9418 - val_mae: 74.9138 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 110.8409 - mae: 110.8120 - val_loss: 68.5952 - val_mae: 68.5651 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 0s 18ms/step - loss: 105.4558 - mae: 105.4250 - val_loss: 64.9642 - val_mae: 64.9325 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 102.4263 - mae: 102.3940 - val_loss: 62.0242 - val_mae: 61.9911 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 100.2481 - mae: 100.2145 - val_loss: 60.2814 - val_mae: 60.2471 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 98.0587 - mae: 98.0240 - val_loss: 57.7321 - val_mae: 57.6968 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 95.8214 - mae: 95.7857 - val_loss: 56.1946 - val_mae: 56.1583 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 94.1882 - mae: 94.1513 - val_loss: 55.5896 - val_mae: 55.5521 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 223.4167\n",
      "LV_RMSE_12h: 250.2100\n",
      "LV_MAE_24h: 39.9195\n",
      "LV_RMSE_24h: 59.3248\n",
      "LV_MAE_48h: 50.5115\n",
      "LV_RMSE_48h: 78.4547\n",
      "LV_MAE_72h: 43.9425\n",
      "LV_RMSE_72h: 68.9668\n",
      "LV_MAE_mean: 89.4476\n",
      "LV_RMSE_mean: 114.2391\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 120.1753\n",
      "RMSE_12h: 158.8658\n",
      "MAE_24h: 36.4588\n",
      "RMSE_24h: 55.4041\n",
      "MAE_48h: 36.5786\n",
      "RMSE_48h: 55.7865\n",
      "MAE_72h: 35.6000\n",
      "RMSE_72h: 54.1613\n",
      "MAE_mean: 57.2031\n",
      "RMSE_mean: 81.0544\n",
      "\n",
      "=== Station S3022021 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1377 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1354, 24, 400) Ytr2: (1354, 4) \n",
      "  Xva3: (197, 24, 400) Yva2: (197, 4) \n",
      "  Xte3: (348, 24, 400) Yte2: (348, 4)\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 3s 58ms/step - loss: 225.8948 - mae: 225.8820 - val_loss: 217.2303 - val_mae: 217.2175 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 219.5511 - mae: 219.5381 - val_loss: 208.3039 - val_mae: 208.2908 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 209.7069 - mae: 209.6936 - val_loss: 197.8670 - val_mae: 197.8533 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 199.5914 - mae: 199.5774 - val_loss: 187.1673 - val_mae: 187.1528 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 188.6847 - mae: 188.6697 - val_loss: 176.4644 - val_mae: 176.4486 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 177.8773 - mae: 177.8609 - val_loss: 166.1942 - val_mae: 166.1769 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 167.9371 - mae: 167.9190 - val_loss: 156.4904 - val_mae: 156.4715 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 158.7115 - mae: 158.6917 - val_loss: 148.1550 - val_mae: 148.1342 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 150.7244 - mae: 150.7028 - val_loss: 139.5454 - val_mae: 139.5227 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 141.2266 - mae: 141.2031 - val_loss: 129.7197 - val_mae: 129.6952 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 130.6647 - mae: 130.6393 - val_loss: 119.7594 - val_mae: 119.7329 - lr: 0.0010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 119.6906 - mae: 119.6632 - val_loss: 109.2300 - val_mae: 109.2012 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 108.9485 - mae: 108.9188 - val_loss: 99.5183 - val_mae: 99.4873 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 98.9491 - mae: 98.9171 - val_loss: 90.0893 - val_mae: 90.0561 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 90.4491 - mae: 90.4150 - val_loss: 84.4697 - val_mae: 84.4347 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 85.4476 - mae: 85.4119 - val_loss: 81.9577 - val_mae: 81.9213 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 82.7963 - mae: 82.7593 - val_loss: 78.7979 - val_mae: 78.7603 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 80.6725 - mae: 80.6345 - val_loss: 76.7225 - val_mae: 76.6841 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 78.6163 - mae: 78.5774 - val_loss: 74.6596 - val_mae: 74.6203 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 76.6096 - mae: 76.5699 - val_loss: 72.9200 - val_mae: 72.8798 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 245.0488\n",
      "LV_RMSE_12h: 271.0818\n",
      "LV_MAE_24h: 44.0632\n",
      "LV_RMSE_24h: 64.8818\n",
      "LV_MAE_48h: 56.6810\n",
      "LV_RMSE_48h: 83.6129\n",
      "LV_MAE_72h: 45.7356\n",
      "LV_RMSE_72h: 68.0276\n",
      "LV_MAE_mean: 97.8822\n",
      "LV_RMSE_mean: 121.9010\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 158.9938\n",
      "RMSE_12h: 194.5275\n",
      "MAE_24h: 46.8848\n",
      "RMSE_24h: 70.5154\n",
      "MAE_48h: 45.4132\n",
      "RMSE_48h: 71.2642\n",
      "MAE_72h: 43.9323\n",
      "RMSE_72h: 67.5558\n",
      "MAE_mean: 73.8060\n",
      "RMSE_mean: 100.9657\n",
      "\n",
      "=== Station S3022022 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1377 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1354, 24, 400) Ytr2: (1354, 4) \n",
      "  Xva3: (197, 24, 400) Yva2: (197, 4) \n",
      "  Xte3: (348, 24, 400) Yte2: (348, 4)\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 3s 59ms/step - loss: 218.6978 - mae: 218.6850 - val_loss: 202.8855 - val_mae: 202.8727 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 215.8362 - mae: 215.8233 - val_loss: 199.1487 - val_mae: 199.1355 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 211.3878 - mae: 211.3744 - val_loss: 194.0777 - val_mae: 194.0639 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 205.8026 - mae: 205.7885 - val_loss: 187.9364 - val_mae: 187.9216 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 198.8230 - mae: 198.8077 - val_loss: 180.5898 - val_mae: 180.5738 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 190.5016 - mae: 190.4848 - val_loss: 171.5914 - val_mae: 171.5735 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 180.5490 - mae: 180.5302 - val_loss: 161.6818 - val_mae: 161.6616 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 168.9415 - mae: 168.9202 - val_loss: 149.9874 - val_mae: 149.9645 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 156.1782 - mae: 156.1540 - val_loss: 137.2036 - val_mae: 137.1775 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 142.5594 - mae: 142.5318 - val_loss: 123.7785 - val_mae: 123.7488 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 127.5463 - mae: 127.5149 - val_loss: 110.2415 - val_mae: 110.2077 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 112.9589 - mae: 112.9232 - val_loss: 96.9399 - val_mae: 96.9018 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 99.1312 - mae: 99.0911 - val_loss: 86.1751 - val_mae: 86.1324 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 87.9642 - mae: 87.9196 - val_loss: 77.0556 - val_mae: 77.0087 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 80.1070 - mae: 80.0583 - val_loss: 71.7114 - val_mae: 71.6609 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 76.2755 - mae: 76.2236 - val_loss: 68.3157 - val_mae: 68.2621 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 71.6130 - mae: 71.5583 - val_loss: 67.3268 - val_mae: 67.2705 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 69.4474 - mae: 69.3899 - val_loss: 62.7925 - val_mae: 62.7336 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 66.3163 - mae: 66.2563 - val_loss: 60.4138 - val_mae: 60.3525 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 63.2663 - mae: 63.2041 - val_loss: 58.7765 - val_mae: 58.7129 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 358.9195\n",
      "LV_RMSE_12h: 399.0178\n",
      "LV_MAE_24h: 80.2672\n",
      "LV_RMSE_24h: 141.6179\n",
      "LV_MAE_48h: 177.5575\n",
      "LV_RMSE_48h: 393.7580\n",
      "LV_MAE_72h: 147.9626\n",
      "LV_RMSE_72h: 363.9647\n",
      "LV_MAE_mean: 191.1767\n",
      "LV_RMSE_mean: 324.5896\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 82.4832\n",
      "RMSE_12h: 126.9360\n",
      "MAE_24h: 70.8313\n",
      "RMSE_24h: 114.3553\n",
      "MAE_48h: 144.1955\n",
      "RMSE_48h: 350.5978\n",
      "MAE_72h: 142.8307\n",
      "RMSE_72h: 349.7020\n",
      "MAE_mean: 110.0852\n",
      "RMSE_mean: 235.3978\n",
      "\n",
      "=== Station S3022031 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1377 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1354, 24, 400) Ytr2: (1354, 4) \n",
      "  Xva3: (197, 24, 400) Yva2: (197, 4) \n",
      "  Xte3: (348, 24, 400) Yte2: (348, 4)\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 3s 59ms/step - loss: 1844.3737 - mae: 1844.3610 - val_loss: 1851.2415 - val_mae: 1851.2288 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 1838.5665 - mae: 1838.5540 - val_loss: 1842.7263 - val_mae: 1842.7134 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1828.0305 - mae: 1828.0172 - val_loss: 1829.9996 - val_mae: 1829.9858 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1813.8569 - mae: 1813.8425 - val_loss: 1813.1790 - val_mae: 1813.1641 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1794.5229 - mae: 1794.5074 - val_loss: 1791.5574 - val_mae: 1791.5411 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1770.7363 - mae: 1770.7194 - val_loss: 1764.8756 - val_mae: 1764.8574 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1741.7452 - mae: 1741.7260 - val_loss: 1732.8622 - val_mae: 1732.8416 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 1707.3209 - mae: 1707.2991 - val_loss: 1695.3367 - val_mae: 1695.3130 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1667.9784 - mae: 1667.9532 - val_loss: 1652.2357 - val_mae: 1652.2087 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1622.0846 - mae: 1622.0559 - val_loss: 1603.4689 - val_mae: 1603.4380 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 1570.2391 - mae: 1570.2061 - val_loss: 1548.8833 - val_mae: 1548.8477 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1513.8051 - mae: 1513.7673 - val_loss: 1488.4705 - val_mae: 1488.4301 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1451.0573 - mae: 1451.0143 - val_loss: 1422.2551 - val_mae: 1422.2091 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1382.7097 - mae: 1382.6608 - val_loss: 1350.2427 - val_mae: 1350.1903 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1306.7531 - mae: 1306.6976 - val_loss: 1272.4922 - val_mae: 1272.4331 - lr: 0.0010\n",
      "Epoch 16/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 12ms/step - loss: 1230.2635 - mae: 1230.2014 - val_loss: 1195.5493 - val_mae: 1195.4832 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1161.8785 - mae: 1161.8093 - val_loss: 1134.3958 - val_mae: 1134.3226 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1103.2775 - mae: 1103.2015 - val_loss: 1083.4895 - val_mae: 1083.4098 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1059.2909 - mae: 1059.2085 - val_loss: 1041.2739 - val_mae: 1041.1879 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1021.0389 - mae: 1020.9501 - val_loss: 1005.2568 - val_mae: 1005.1647 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 1344.1466\n",
      "LV_RMSE_12h: 1489.4103\n",
      "LV_MAE_24h: 267.0603\n",
      "LV_RMSE_24h: 422.9833\n",
      "LV_MAE_48h: 354.0747\n",
      "LV_RMSE_48h: 533.7098\n",
      "LV_MAE_72h: 290.3477\n",
      "LV_RMSE_72h: 468.8281\n",
      "LV_MAE_mean: 563.9073\n",
      "LV_RMSE_mean: 728.7328\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 924.4932\n",
      "RMSE_12h: 1151.7791\n",
      "MAE_24h: 909.0364\n",
      "RMSE_24h: 1121.2061\n",
      "MAE_48h: 939.2616\n",
      "RMSE_48h: 1164.3398\n",
      "MAE_72h: 930.6559\n",
      "RMSE_72h: 1151.3093\n",
      "MAE_mean: 925.8617\n",
      "RMSE_mean: 1147.1586\n",
      "\n",
      "=== Station S3022032 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1377 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1354, 24, 400) Ytr2: (1354, 4) \n",
      "  Xva3: (197, 24, 400) Yva2: (197, 4) \n",
      "  Xte3: (348, 24, 400) Yte2: (348, 4)\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 3s 60ms/step - loss: 1352.4257 - mae: 1352.4132 - val_loss: 1357.3607 - val_mae: 1357.3481 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 1346.2682 - mae: 1346.2556 - val_loss: 1348.4058 - val_mae: 1348.3931 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1335.3390 - mae: 1335.3259 - val_loss: 1335.4222 - val_mae: 1335.4089 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 1320.9846 - mae: 1320.9707 - val_loss: 1318.9792 - val_mae: 1318.9650 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1302.5188 - mae: 1302.5040 - val_loss: 1298.0261 - val_mae: 1298.0105 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 1278.9193 - mae: 1278.9031 - val_loss: 1271.9073 - val_mae: 1271.8899 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1250.7782 - mae: 1250.7599 - val_loss: 1240.8534 - val_mae: 1240.8336 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 1217.7166 - mae: 1217.6956 - val_loss: 1204.5985 - val_mae: 1204.5759 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1179.7561 - mae: 1179.7321 - val_loss: 1163.8815 - val_mae: 1163.8556 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 1138.4702 - mae: 1138.4427 - val_loss: 1121.9929 - val_mae: 1121.9634 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 1098.0637 - mae: 1098.0325 - val_loss: 1083.1377 - val_mae: 1083.1044 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1061.0276 - mae: 1060.9924 - val_loss: 1046.4567 - val_mae: 1046.4193 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1025.2230 - mae: 1025.1838 - val_loss: 1011.1880 - val_mae: 1011.1462 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 991.5796 - mae: 991.5360 - val_loss: 976.9413 - val_mae: 976.8951 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 956.2725 - mae: 956.2242 - val_loss: 943.3200 - val_mae: 943.2693 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 927.2259 - mae: 927.1730 - val_loss: 912.2125 - val_mae: 912.1570 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 896.7081 - mae: 896.6503 - val_loss: 883.1645 - val_mae: 883.1041 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 865.5234 - mae: 865.4609 - val_loss: 853.4587 - val_mae: 853.3932 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 837.7649 - mae: 837.6972 - val_loss: 820.5217 - val_mae: 820.4510 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 804.8392 - mae: 804.7661 - val_loss: 781.1700 - val_mae: 781.0938 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 1197.9971\n",
      "LV_RMSE_12h: 1301.6154\n",
      "LV_MAE_24h: 114.4713\n",
      "LV_RMSE_24h: 241.7896\n",
      "LV_MAE_48h: 181.9195\n",
      "LV_RMSE_48h: 341.6777\n",
      "LV_MAE_72h: 194.8649\n",
      "LV_RMSE_72h: 353.2448\n",
      "LV_MAE_mean: 422.3132\n",
      "LV_RMSE_mean: 559.5819\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 792.9221\n",
      "RMSE_12h: 895.9011\n",
      "MAE_24h: 767.3242\n",
      "RMSE_24h: 889.6768\n",
      "MAE_48h: 779.0117\n",
      "RMSE_48h: 906.1502\n",
      "MAE_72h: 774.4775\n",
      "RMSE_72h: 899.5831\n",
      "MAE_mean: 778.4339\n",
      "RMSE_mean: 897.8278\n",
      "\n",
      "=== Station S3022053 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 604 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (581, 24, 400) Ytr2: (581, 4) \n",
      "  Xva3: (87, 24, 400) Yva2: (87, 4) \n",
      "  Xte3: (127, 24, 400) Yte2: (127, 4)\n",
      "Epoch 1/20\n",
      "5/5 [==============================] - 3s 133ms/step - loss: 17.8817 - mae: 17.8689 - val_loss: 16.0280 - val_mae: 16.0152 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 16.9902 - mae: 16.9775 - val_loss: 14.9967 - val_mae: 14.9839 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 15.8820 - mae: 15.8692 - val_loss: 13.6866 - val_mae: 13.6738 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 14.5356 - mae: 14.5228 - val_loss: 12.2157 - val_mae: 12.2028 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 13.2230 - mae: 13.2101 - val_loss: 10.9839 - val_mae: 10.9708 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 12.0477 - mae: 12.0346 - val_loss: 9.8212 - val_mae: 9.8078 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 11.0187 - mae: 11.0053 - val_loss: 9.0632 - val_mae: 9.0496 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 10.2617 - mae: 10.2480 - val_loss: 8.4735 - val_mae: 8.4597 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 9.9036 - mae: 9.8897 - val_loss: 8.5576 - val_mae: 8.5436 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 9.8558 - mae: 9.8417 - val_loss: 8.3859 - val_mae: 8.3717 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 9.6731 - mae: 9.6589 - val_loss: 8.2026 - val_mae: 8.1884 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 9.4243 - mae: 9.4102 - val_loss: 7.8306 - val_mae: 7.8164 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 9.3298 - mae: 9.3157 - val_loss: 8.1163 - val_mae: 8.1021 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 9.2614 - mae: 9.2472 - val_loss: 7.7691 - val_mae: 7.7549 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 9.2288 - mae: 9.2146 - val_loss: 7.8990 - val_mae: 7.8847 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 9.1000 - mae: 9.0858 - val_loss: 7.9378 - val_mae: 7.9236 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 9.0191 - mae: 9.0048 - val_loss: 7.6664 - val_mae: 7.6521 - lr: 5.0000e-04\n",
      "Epoch 18/20\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 8.9470 - mae: 8.9327 - val_loss: 7.6252 - val_mae: 7.6109 - lr: 5.0000e-04\n",
      "Epoch 19/20\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 8.8298 - mae: 8.8155 - val_loss: 7.6753 - val_mae: 7.6610 - lr: 5.0000e-04\n",
      "Epoch 20/20\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 8.8335 - mae: 8.8192 - val_loss: 7.7197 - val_mae: 7.7053 - lr: 5.0000e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 21.8661\n",
      "LV_RMSE_12h: 26.4734\n",
      "LV_MAE_24h: 9.4646\n",
      "LV_RMSE_24h: 14.2343\n",
      "LV_MAE_48h: 8.6850\n",
      "LV_RMSE_48h: 12.8838\n",
      "LV_MAE_72h: 8.9843\n",
      "LV_RMSE_72h: 13.6315\n",
      "LV_MAE_mean: 12.2500\n",
      "LV_RMSE_mean: 16.8058\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 6.9695\n",
      "RMSE_12h: 10.4358\n",
      "MAE_24h: 7.7714\n",
      "RMSE_24h: 11.9179\n",
      "MAE_48h: 6.7574\n",
      "RMSE_48h: 10.4275\n",
      "MAE_72h: 6.5216\n",
      "RMSE_72h: 10.3028\n",
      "MAE_mean: 7.0050\n",
      "RMSE_mean: 10.7710\n",
      "\n",
      "=== Station S3022061 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1374 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1351, 24, 400) Ytr2: (1351, 4) \n",
      "  Xva3: (197, 24, 400) Yva2: (197, 4) \n",
      "  Xte3: (347, 24, 400) Yte2: (347, 4)\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 3s 61ms/step - loss: 838.1576 - mae: 838.1449 - val_loss: 858.9510 - val_mae: 858.9383 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 832.4725 - mae: 832.4596 - val_loss: 850.5972 - val_mae: 850.5842 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 822.0101 - mae: 821.9968 - val_loss: 837.7802 - val_mae: 837.7664 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 807.5690 - mae: 807.5549 - val_loss: 821.5175 - val_mae: 821.5027 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 789.8887 - mae: 789.8734 - val_loss: 801.2480 - val_mae: 801.2319 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 768.6989 - mae: 768.6820 - val_loss: 778.8358 - val_mae: 778.8178 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 746.3441 - mae: 746.3253 - val_loss: 756.8123 - val_mae: 756.7923 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 725.3243 - mae: 725.3033 - val_loss: 734.1187 - val_mae: 734.0961 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 703.1729 - mae: 703.1493 - val_loss: 712.2240 - val_mae: 712.1989 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 681.4623 - mae: 681.4359 - val_loss: 690.7386 - val_mae: 690.7106 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 662.0377 - mae: 662.0085 - val_loss: 669.6965 - val_mae: 669.6655 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 641.3191 - mae: 641.2866 - val_loss: 648.8848 - val_mae: 648.8504 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 620.5969 - mae: 620.5611 - val_loss: 628.0131 - val_mae: 627.9752 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 601.1414 - mae: 601.1018 - val_loss: 607.9931 - val_mae: 607.9514 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 581.9333 - mae: 581.8900 - val_loss: 589.3027 - val_mae: 589.2571 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 564.5234 - mae: 564.4761 - val_loss: 571.8012 - val_mae: 571.7516 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 547.7704 - mae: 547.7190 - val_loss: 553.8541 - val_mae: 553.8005 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 526.3463 - mae: 526.2909 - val_loss: 525.4897 - val_mae: 525.4322 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 495.3979 - mae: 495.3384 - val_loss: 495.6267 - val_mae: 495.5649 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 467.6593 - mae: 467.5953 - val_loss: 467.6871 - val_mae: 467.6204 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 892.8444\n",
      "LV_RMSE_12h: 989.2360\n",
      "LV_MAE_24h: 194.8415\n",
      "LV_RMSE_24h: 293.4566\n",
      "LV_MAE_48h: 233.1931\n",
      "LV_RMSE_48h: 342.4928\n",
      "LV_MAE_72h: 221.8905\n",
      "LV_RMSE_72h: 325.4803\n",
      "LV_MAE_mean: 385.6924\n",
      "LV_RMSE_mean: 487.6664\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 580.1123\n",
      "RMSE_12h: 687.1237\n",
      "MAE_24h: 340.7434\n",
      "RMSE_24h: 437.4003\n",
      "MAE_48h: 354.2178\n",
      "RMSE_48h: 460.2816\n",
      "MAE_72h: 364.6447\n",
      "RMSE_72h: 475.9165\n",
      "MAE_mean: 409.9295\n",
      "RMSE_mean: 515.1805\n",
      "\n",
      "=== Station S3022062 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1374 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1351, 24, 400) Ytr2: (1351, 4) \n",
      "  Xva3: (197, 24, 400) Yva2: (197, 4) \n",
      "  Xte3: (347, 24, 400) Yte2: (347, 4)\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 3s 59ms/step - loss: 30.4754 - mae: 30.4627 - val_loss: 35.8769 - val_mae: 35.8642 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 28.5985 - mae: 28.5858 - val_loss: 34.7601 - val_mae: 34.7473 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 27.7412 - mae: 27.7284 - val_loss: 34.3599 - val_mae: 34.3471 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 27.4623 - mae: 27.4494 - val_loss: 34.0552 - val_mae: 34.0424 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 27.1913 - mae: 27.1785 - val_loss: 33.7422 - val_mae: 33.7293 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 26.9874 - mae: 26.9745 - val_loss: 33.4646 - val_mae: 33.4516 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 26.6922 - mae: 26.6791 - val_loss: 33.1543 - val_mae: 33.1411 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 26.4872 - mae: 26.4739 - val_loss: 32.8143 - val_mae: 32.8009 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 26.2633 - mae: 26.2498 - val_loss: 32.4199 - val_mae: 32.4062 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 25.9651 - mae: 25.9513 - val_loss: 32.1945 - val_mae: 32.1805 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 25.7328 - mae: 25.7187 - val_loss: 31.9102 - val_mae: 31.8958 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 25.4151 - mae: 25.4006 - val_loss: 31.3710 - val_mae: 31.3562 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 25.0774 - mae: 25.0624 - val_loss: 30.9922 - val_mae: 30.9770 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 24.8368 - mae: 24.8214 - val_loss: 30.6898 - val_mae: 30.6741 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 24.5805 - mae: 24.5646 - val_loss: 30.9236 - val_mae: 30.9073 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 24.3002 - mae: 24.2837 - val_loss: 29.9211 - val_mae: 29.9043 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 23.7923 - mae: 23.7752 - val_loss: 29.6303 - val_mae: 29.6128 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 23.4100 - mae: 23.3922 - val_loss: 29.2078 - val_mae: 29.1896 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 22.9375 - mae: 22.9189 - val_loss: 28.4072 - val_mae: 28.3881 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 22.5389 - mae: 22.5194 - val_loss: 27.6782 - val_mae: 27.6581 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 46.7723\n",
      "LV_RMSE_12h: 105.2315\n",
      "LV_MAE_24h: 19.9914\n",
      "LV_RMSE_24h: 52.9890\n",
      "LV_MAE_48h: 23.5130\n",
      "LV_RMSE_48h: 66.7349\n",
      "LV_MAE_72h: 24.7839\n",
      "LV_RMSE_72h: 67.3125\n",
      "LV_MAE_mean: 28.7651\n",
      "LV_RMSE_mean: 73.0669\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 20.6930\n",
      "RMSE_12h: 57.3356\n",
      "MAE_24h: 22.8657\n",
      "RMSE_24h: 59.9603\n",
      "MAE_48h: 22.7087\n",
      "RMSE_48h: 57.2650\n",
      "MAE_72h: 21.6434\n",
      "RMSE_72h: 54.8731\n",
      "MAE_mean: 21.9777\n",
      "RMSE_mean: 57.3585\n",
      "\n",
      "=== Station S3022073 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1360 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1337, 24, 400) Ytr2: (1337, 4) \n",
      "  Xva3: (195, 24, 400) Yva2: (195, 4) \n",
      "  Xte3: (342, 24, 400) Yte2: (342, 4)\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 3s 59ms/step - loss: 18.1347 - mae: 18.1219 - val_loss: 16.3432 - val_mae: 16.3305 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 15.0878 - mae: 15.0750 - val_loss: 13.1076 - val_mae: 13.0946 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 12.1316 - mae: 12.1186 - val_loss: 10.3927 - val_mae: 10.3794 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 9.8753 - mae: 9.8619 - val_loss: 8.7468 - val_mae: 8.7331 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 8.5610 - mae: 8.5472 - val_loss: 7.7988 - val_mae: 7.7848 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 7.9053 - mae: 7.8911 - val_loss: 7.2982 - val_mae: 7.2840 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 7.5515 - mae: 7.5372 - val_loss: 7.1356 - val_mae: 7.1212 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 7.4801 - mae: 7.4657 - val_loss: 7.2601 - val_mae: 7.2457 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 7.2891 - mae: 7.2747 - val_loss: 7.3861 - val_mae: 7.3717 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 7.1441 - mae: 7.1298 - val_loss: 7.2516 - val_mae: 7.2372 - lr: 5.0000e-04\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 7.0734 - mae: 7.0590 - val_loss: 7.3562 - val_mae: 7.3418 - lr: 5.0000e-04\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 7.0304 - mae: 7.0161 - val_loss: 7.5700 - val_mae: 7.5557 - lr: 2.5000e-04\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 23.6637\n",
      "LV_RMSE_12h: 28.2487\n",
      "LV_MAE_24h: 7.5643\n",
      "LV_RMSE_24h: 12.0069\n",
      "LV_MAE_48h: 9.1228\n",
      "LV_RMSE_48h: 14.1525\n",
      "LV_MAE_72h: 8.2339\n",
      "LV_RMSE_72h: 12.4461\n",
      "LV_MAE_mean: 12.1462\n",
      "LV_RMSE_mean: 16.7136\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 9.2013\n",
      "RMSE_12h: 11.8400\n",
      "MAE_24h: 9.2592\n",
      "RMSE_24h: 12.0239\n",
      "MAE_48h: 8.7810\n",
      "RMSE_48h: 11.6167\n",
      "MAE_72h: 8.6865\n",
      "RMSE_72h: 11.4315\n",
      "MAE_mean: 8.9820\n",
      "RMSE_mean: 11.7280\n",
      "\n",
      "=== Station S3022081 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1377 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1354, 24, 400) Ytr2: (1354, 4) \n",
      "  Xva3: (197, 24, 400) Yva2: (197, 4) \n",
      "  Xte3: (348, 24, 400) Yte2: (348, 4)\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 3s 61ms/step - loss: 431.4536 - mae: 431.4407 - val_loss: 437.7936 - val_mae: 437.7807 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 426.0759 - mae: 426.0628 - val_loss: 429.9484 - val_mae: 429.9351 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 417.2887 - mae: 417.2752 - val_loss: 419.8190 - val_mae: 419.8051 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 407.1242 - mae: 407.1100 - val_loss: 408.5467 - val_mae: 408.5319 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 395.8903 - mae: 395.8750 - val_loss: 396.3622 - val_mae: 396.3462 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 384.2952 - mae: 384.2786 - val_loss: 382.8875 - val_mae: 382.8699 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 371.7010 - mae: 371.6826 - val_loss: 368.1575 - val_mae: 368.1380 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 358.6250 - mae: 358.6046 - val_loss: 353.8059 - val_mae: 353.7842 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 346.8403 - mae: 346.8176 - val_loss: 340.4186 - val_mae: 340.3946 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 335.7213 - mae: 335.6961 - val_loss: 328.3340 - val_mae: 328.3075 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 325.3072 - mae: 325.2796 - val_loss: 316.3094 - val_mae: 316.2803 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 314.5372 - mae: 314.5069 - val_loss: 302.1614 - val_mae: 302.1296 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 299.4336 - mae: 299.4006 - val_loss: 283.2017 - val_mae: 283.1670 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 280.8127 - mae: 280.7766 - val_loss: 261.8730 - val_mae: 261.8352 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 262.5645 - mae: 262.5251 - val_loss: 243.1488 - val_mae: 243.1073 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 246.8940 - mae: 246.8507 - val_loss: 225.5389 - val_mae: 225.4934 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 230.6525 - mae: 230.6053 - val_loss: 211.0824 - val_mae: 211.0329 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 216.5443 - mae: 216.4931 - val_loss: 196.5826 - val_mae: 196.5293 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 205.2439 - mae: 205.1887 - val_loss: 184.8526 - val_mae: 184.7953 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 196.2532 - mae: 196.1946 - val_loss: 176.6042 - val_mae: 176.5439 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 566.1552\n",
      "LV_RMSE_12h: 626.1406\n",
      "LV_MAE_24h: 95.1667\n",
      "LV_RMSE_24h: 143.1380\n",
      "LV_MAE_48h: 119.2270\n",
      "LV_RMSE_48h: 169.8132\n",
      "LV_MAE_72h: 115.6121\n",
      "LV_RMSE_72h: 171.1412\n",
      "LV_MAE_mean: 224.0402\n",
      "LV_RMSE_mean: 277.5582\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 394.2231\n",
      "RMSE_12h: 468.0635\n",
      "MAE_24h: 138.4819\n",
      "RMSE_24h: 188.6320\n",
      "MAE_48h: 135.8511\n",
      "RMSE_48h: 185.5732\n",
      "MAE_72h: 133.2699\n",
      "RMSE_72h: 183.3858\n",
      "MAE_mean: 200.4565\n",
      "RMSE_mean: 256.4136\n",
      "\n",
      "=== Station S3022082 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1377 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1354, 24, 400) Ytr2: (1354, 4) \n",
      "  Xva3: (197, 24, 400) Yva2: (197, 4) \n",
      "  Xte3: (348, 24, 400) Yte2: (348, 4)\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 3s 59ms/step - loss: 1632.1168 - mae: 1632.1041 - val_loss: 1675.5332 - val_mae: 1675.5205 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 1625.5464 - mae: 1625.5336 - val_loss: 1666.0282 - val_mae: 1666.0153 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 1614.7712 - mae: 1614.7582 - val_loss: 1653.0880 - val_mae: 1653.0746 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1601.1926 - mae: 1601.1790 - val_loss: 1636.7904 - val_mae: 1636.7761 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 1583.6686 - mae: 1583.6538 - val_loss: 1616.3730 - val_mae: 1616.3575 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 1562.1453 - mae: 1562.1289 - val_loss: 1591.4830 - val_mae: 1591.4659 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1536.5381 - mae: 1536.5199 - val_loss: 1561.8760 - val_mae: 1561.8566 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1506.5812 - mae: 1506.5608 - val_loss: 1528.2666 - val_mae: 1528.2448 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1473.4270 - mae: 1473.4039 - val_loss: 1493.5712 - val_mae: 1493.5463 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1440.4617 - mae: 1440.4355 - val_loss: 1458.1466 - val_mae: 1458.1187 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1408.7484 - mae: 1408.7190 - val_loss: 1423.9681 - val_mae: 1423.9369 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 1377.4501 - mae: 1377.4171 - val_loss: 1391.7087 - val_mae: 1391.6738 - lr: 0.0010\n",
      "Epoch 13/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 15ms/step - loss: 1347.0568 - mae: 1347.0203 - val_loss: 1359.4313 - val_mae: 1359.3925 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1317.9469 - mae: 1317.9064 - val_loss: 1327.2782 - val_mae: 1327.2356 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 1287.8392 - mae: 1287.7944 - val_loss: 1295.2030 - val_mae: 1295.1559 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 1260.8992 - mae: 1260.8501 - val_loss: 1263.8762 - val_mae: 1263.8247 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1231.3677 - mae: 1231.3142 - val_loss: 1232.2191 - val_mae: 1232.1630 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1202.6615 - mae: 1202.6034 - val_loss: 1200.9652 - val_mae: 1200.9043 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1178.1624 - mae: 1178.0991 - val_loss: 1171.8861 - val_mae: 1171.8201 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1156.2029 - mae: 1156.1346 - val_loss: 1145.3743 - val_mae: 1145.3033 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 1607.0000\n",
      "LV_RMSE_12h: 1759.0286\n",
      "LV_MAE_24h: 285.8621\n",
      "LV_RMSE_24h: 491.9953\n",
      "LV_MAE_48h: 408.0000\n",
      "LV_RMSE_48h: 661.6151\n",
      "LV_MAE_72h: 336.3678\n",
      "LV_RMSE_72h: 587.3712\n",
      "LV_MAE_mean: 659.3075\n",
      "LV_RMSE_mean: 875.0026\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 1014.7064\n",
      "RMSE_12h: 1247.2987\n",
      "MAE_24h: 1027.9421\n",
      "RMSE_24h: 1258.7173\n",
      "MAE_48h: 1014.1371\n",
      "RMSE_48h: 1237.0315\n",
      "MAE_72h: 1006.9123\n",
      "RMSE_72h: 1223.5382\n",
      "MAE_mean: 1015.9245\n",
      "RMSE_mean: 1241.6465\n",
      "\n",
      "=== Station S3022083 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1376 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1353, 24, 400) Ytr2: (1353, 4) \n",
      "  Xva3: (197, 24, 400) Yva2: (197, 4) \n",
      "  Xte3: (348, 24, 400) Yte2: (348, 4)\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 3s 60ms/step - loss: 323.4172 - mae: 323.4043 - val_loss: 303.1198 - val_mae: 303.1069 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 318.1000 - mae: 318.0871 - val_loss: 296.2409 - val_mae: 296.2278 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 310.7828 - mae: 310.7696 - val_loss: 288.4779 - val_mae: 288.4644 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 303.2614 - mae: 303.2477 - val_loss: 280.3144 - val_mae: 280.3002 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 296.3528 - mae: 296.3382 - val_loss: 272.1892 - val_mae: 272.1741 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 290.1845 - mae: 290.1689 - val_loss: 264.5999 - val_mae: 264.5837 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 285.3958 - mae: 285.3792 - val_loss: 258.6878 - val_mae: 258.6705 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 281.8564 - mae: 281.8386 - val_loss: 254.6679 - val_mae: 254.6496 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 279.3147 - mae: 279.2960 - val_loss: 250.8033 - val_mae: 250.7841 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 273.0893 - mae: 273.0697 - val_loss: 243.3270 - val_mae: 243.3069 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 265.3346 - mae: 265.3139 - val_loss: 235.2950 - val_mae: 235.2734 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 254.7048 - mae: 254.6823 - val_loss: 224.0573 - val_mae: 224.0336 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 241.1059 - mae: 241.0810 - val_loss: 209.8799 - val_mae: 209.8533 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 224.9255 - mae: 224.8973 - val_loss: 195.1957 - val_mae: 195.1654 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 208.3286 - mae: 208.2964 - val_loss: 176.4019 - val_mae: 176.3673 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 190.0661 - mae: 190.0294 - val_loss: 164.1451 - val_mae: 164.1057 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 176.3269 - mae: 176.2856 - val_loss: 154.1096 - val_mae: 154.0658 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 167.4392 - mae: 167.3936 - val_loss: 151.2572 - val_mae: 151.2093 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 161.6131 - mae: 161.5636 - val_loss: 145.1858 - val_mae: 145.1343 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 155.6431 - mae: 155.5901 - val_loss: 138.6265 - val_mae: 138.5715 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 500.8477\n",
      "LV_RMSE_12h: 562.5680\n",
      "LV_MAE_24h: 102.5747\n",
      "LV_RMSE_24h: 171.8326\n",
      "LV_MAE_48h: 113.0086\n",
      "LV_RMSE_48h: 189.2325\n",
      "LV_MAE_72h: 102.5431\n",
      "LV_RMSE_72h: 173.2915\n",
      "LV_MAE_mean: 204.7435\n",
      "LV_RMSE_mean: 274.2311\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 262.2350\n",
      "RMSE_12h: 386.5785\n",
      "MAE_24h: 103.3837\n",
      "RMSE_24h: 155.9328\n",
      "MAE_48h: 99.1960\n",
      "RMSE_48h: 149.1400\n",
      "MAE_72h: 96.3318\n",
      "RMSE_72h: 148.1815\n",
      "MAE_mean: 140.2866\n",
      "RMSE_mean: 209.9582\n",
      "\n",
      "=== Station S3023021 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1377 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1354, 24, 400) Ytr2: (1354, 4) \n",
      "  Xva3: (197, 24, 400) Yva2: (197, 4) \n",
      "  Xte3: (348, 24, 400) Yte2: (348, 4)\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 3s 59ms/step - loss: 2086.9001 - mae: 2086.8877 - val_loss: 2116.9939 - val_mae: 2116.9817 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 2082.1670 - mae: 2082.1545 - val_loss: 2110.2202 - val_mae: 2110.2075 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 2073.8892 - mae: 2073.8765 - val_loss: 2100.1687 - val_mae: 2100.1558 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 2062.4397 - mae: 2062.4263 - val_loss: 2086.5986 - val_mae: 2086.5850 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 2046.8691 - mae: 2046.8547 - val_loss: 2068.9927 - val_mae: 2068.9780 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 2027.3729 - mae: 2027.3577 - val_loss: 2047.0023 - val_mae: 2046.9861 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 2003.6588 - mae: 2003.6418 - val_loss: 2020.6570 - val_mae: 2020.6388 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1975.2441 - mae: 1975.2249 - val_loss: 1989.7601 - val_mae: 1989.7397 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1942.1692 - mae: 1942.1473 - val_loss: 1954.2034 - val_mae: 1954.1802 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1904.1549 - mae: 1904.1304 - val_loss: 1913.8745 - val_mae: 1913.8480 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1862.7690 - mae: 1862.7410 - val_loss: 1868.8105 - val_mae: 1868.7805 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1816.4520 - mae: 1816.4200 - val_loss: 1819.0944 - val_mae: 1819.0602 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1763.2415 - mae: 1763.2051 - val_loss: 1764.8679 - val_mae: 1764.8290 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1710.1827 - mae: 1710.1416 - val_loss: 1707.2727 - val_mae: 1707.2289 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1653.5793 - mae: 1653.5334 - val_loss: 1648.2592 - val_mae: 1648.2103 - lr: 0.0010\n",
      "Epoch 16/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 13ms/step - loss: 1601.6797 - mae: 1601.6283 - val_loss: 1589.9783 - val_mae: 1589.9238 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1550.0497 - mae: 1549.9930 - val_loss: 1534.5446 - val_mae: 1534.4846 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1497.9828 - mae: 1497.9207 - val_loss: 1482.4519 - val_mae: 1482.3861 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1450.9454 - mae: 1450.8771 - val_loss: 1432.4512 - val_mae: 1432.3794 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1402.9819 - mae: 1402.9073 - val_loss: 1384.7075 - val_mae: 1384.6296 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 1640.2356\n",
      "LV_RMSE_12h: 1805.1984\n",
      "LV_MAE_24h: 391.0833\n",
      "LV_RMSE_24h: 575.3884\n",
      "LV_MAE_48h: 488.3994\n",
      "LV_RMSE_48h: 719.7023\n",
      "LV_MAE_72h: 407.4052\n",
      "LV_RMSE_72h: 605.2468\n",
      "LV_MAE_mean: 731.7809\n",
      "LV_RMSE_mean: 926.3840\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 1267.4822\n",
      "RMSE_12h: 1552.2755\n",
      "MAE_24h: 1257.1331\n",
      "RMSE_24h: 1523.0153\n",
      "MAE_48h: 1306.8887\n",
      "RMSE_48h: 1592.7914\n",
      "MAE_72h: 1280.1528\n",
      "RMSE_72h: 1556.0703\n",
      "MAE_mean: 1277.9142\n",
      "RMSE_mean: 1556.0381\n",
      "\n",
      "=== Station S3023022 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1377 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1354, 24, 400) Ytr2: (1354, 4) \n",
      "  Xva3: (197, 24, 400) Yva2: (197, 4) \n",
      "  Xte3: (348, 24, 400) Yte2: (348, 4)\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 3s 59ms/step - loss: 690.5918 - mae: 690.5790 - val_loss: 493.2532 - val_mae: 493.2402 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 682.5350 - mae: 682.5220 - val_loss: 481.9396 - val_mae: 481.9263 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 669.1295 - mae: 669.1158 - val_loss: 467.0250 - val_mae: 467.0110 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 653.2537 - mae: 653.2393 - val_loss: 450.8528 - val_mae: 450.8378 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 634.8630 - mae: 634.8474 - val_loss: 433.3219 - val_mae: 433.3055 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 614.9553 - mae: 614.9382 - val_loss: 414.3123 - val_mae: 414.2941 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 593.5481 - mae: 593.5290 - val_loss: 394.7493 - val_mae: 394.7290 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 570.7815 - mae: 570.7601 - val_loss: 374.6113 - val_mae: 374.5885 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 548.6674 - mae: 548.6433 - val_loss: 355.4033 - val_mae: 355.3777 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 525.9650 - mae: 525.9382 - val_loss: 337.4710 - val_mae: 337.4426 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 507.7560 - mae: 507.7262 - val_loss: 323.6412 - val_mae: 323.6098 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 492.1925 - mae: 492.1598 - val_loss: 313.4011 - val_mae: 313.3667 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 480.4094 - mae: 480.3738 - val_loss: 306.0881 - val_mae: 306.0510 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 470.7740 - mae: 470.7357 - val_loss: 301.4008 - val_mae: 301.3610 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 462.9885 - mae: 462.9476 - val_loss: 298.9392 - val_mae: 298.8970 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 455.7556 - mae: 455.7122 - val_loss: 293.9872 - val_mae: 293.9426 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 445.7086 - mae: 445.6629 - val_loss: 276.0775 - val_mae: 276.0305 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 427.5669 - mae: 427.5187 - val_loss: 258.7364 - val_mae: 258.6866 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 412.3682 - mae: 412.3170 - val_loss: 244.9208 - val_mae: 244.8677 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 398.3459 - mae: 398.2911 - val_loss: 233.9699 - val_mae: 233.9130 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 728.6667\n",
      "LV_RMSE_12h: 848.7643\n",
      "LV_MAE_24h: 249.2241\n",
      "LV_RMSE_24h: 430.6228\n",
      "LV_MAE_48h: 379.5431\n",
      "LV_RMSE_48h: 573.7703\n",
      "LV_MAE_72h: 399.4023\n",
      "LV_RMSE_72h: 593.4470\n",
      "LV_MAE_mean: 439.2090\n",
      "LV_RMSE_mean: 611.6511\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 539.4035\n",
      "RMSE_12h: 683.8217\n",
      "MAE_24h: 323.3366\n",
      "RMSE_24h: 489.8763\n",
      "MAE_48h: 322.7573\n",
      "RMSE_48h: 494.4108\n",
      "MAE_72h: 328.4527\n",
      "RMSE_72h: 502.9767\n",
      "MAE_mean: 378.4875\n",
      "RMSE_mean: 542.7714\n",
      "\n",
      "=== Station S3023111 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1377 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1354, 24, 400) Ytr2: (1354, 4) \n",
      "  Xva3: (197, 24, 400) Yva2: (197, 4) \n",
      "  Xte3: (348, 24, 400) Yte2: (348, 4)\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 3s 58ms/step - loss: 437.5297 - mae: 437.5171 - val_loss: 389.8584 - val_mae: 389.8457 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 430.2932 - mae: 430.2804 - val_loss: 379.3142 - val_mae: 379.3011 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 417.6414 - mae: 417.6281 - val_loss: 364.4630 - val_mae: 364.4492 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 401.5463 - mae: 401.5321 - val_loss: 345.8554 - val_mae: 345.8405 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 381.9936 - mae: 381.9781 - val_loss: 325.6582 - val_mae: 325.6418 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 362.0889 - mae: 362.0717 - val_loss: 305.6054 - val_mae: 305.5872 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 343.3291 - mae: 343.3099 - val_loss: 287.1421 - val_mae: 287.1217 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 326.9186 - mae: 326.8973 - val_loss: 270.2196 - val_mae: 270.1970 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 313.4413 - mae: 313.4177 - val_loss: 257.0154 - val_mae: 256.9905 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 301.1620 - mae: 301.1361 - val_loss: 246.0052 - val_mae: 245.9780 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 291.1430 - mae: 291.1149 - val_loss: 236.0330 - val_mae: 236.0036 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 281.6577 - mae: 281.6273 - val_loss: 227.4576 - val_mae: 227.4259 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 269.5715 - mae: 269.5389 - val_loss: 219.7853 - val_mae: 219.7514 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 256.6670 - mae: 256.6320 - val_loss: 213.5412 - val_mae: 213.5049 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 245.3333 - mae: 245.2960 - val_loss: 208.1339 - val_mae: 208.0951 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 233.5442 - mae: 233.5042 - val_loss: 203.2631 - val_mae: 203.2216 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 222.4751 - mae: 222.4323 - val_loss: 198.3292 - val_mae: 198.2848 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 213.4683 - mae: 213.4227 - val_loss: 193.4554 - val_mae: 193.4082 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 205.0121 - mae: 204.9635 - val_loss: 189.1270 - val_mae: 189.0768 - lr: 0.0010\n",
      "Epoch 20/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 13ms/step - loss: 197.6856 - mae: 197.6342 - val_loss: 187.7227 - val_mae: 187.6696 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 572.3448\n",
      "LV_RMSE_12h: 692.2870\n",
      "LV_MAE_24h: 184.0546\n",
      "LV_RMSE_24h: 281.0953\n",
      "LV_MAE_48h: 184.7471\n",
      "LV_RMSE_48h: 281.5919\n",
      "LV_MAE_72h: 192.3592\n",
      "LV_RMSE_72h: 279.2825\n",
      "LV_MAE_mean: 283.3764\n",
      "LV_RMSE_mean: 383.5641\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 408.4767\n",
      "RMSE_12h: 540.1691\n",
      "MAE_24h: 183.9332\n",
      "RMSE_24h: 283.0472\n",
      "MAE_48h: 184.2206\n",
      "RMSE_48h: 284.6797\n",
      "MAE_72h: 194.4431\n",
      "RMSE_72h: 295.9830\n",
      "MAE_mean: 242.7684\n",
      "RMSE_mean: 350.9698\n",
      "\n",
      "=== Station S3023112 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1377 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1354, 24, 400) Ytr2: (1354, 4) \n",
      "  Xva3: (197, 24, 400) Yva2: (197, 4) \n",
      "  Xte3: (348, 24, 400) Yte2: (348, 4)\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 3s 61ms/step - loss: 302.4103 - mae: 302.3975 - val_loss: 329.2632 - val_mae: 329.2504 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 297.5831 - mae: 297.5703 - val_loss: 322.8787 - val_mae: 322.8658 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 290.6339 - mae: 290.6208 - val_loss: 314.9502 - val_mae: 314.9370 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 283.2617 - mae: 283.2481 - val_loss: 306.2581 - val_mae: 306.2441 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 275.1344 - mae: 275.1201 - val_loss: 296.8805 - val_mae: 296.8657 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 266.9875 - mae: 266.9722 - val_loss: 286.6160 - val_mae: 286.6001 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 257.9436 - mae: 257.9271 - val_loss: 275.6554 - val_mae: 275.6381 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 248.7848 - mae: 248.7668 - val_loss: 264.7983 - val_mae: 264.7794 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 239.8424 - mae: 239.8227 - val_loss: 253.9070 - val_mae: 253.8863 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 230.1546 - mae: 230.1332 - val_loss: 242.7262 - val_mae: 242.7037 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 218.9896 - mae: 218.9662 - val_loss: 231.7438 - val_mae: 231.7192 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 208.4378 - mae: 208.4123 - val_loss: 218.8420 - val_mae: 218.8152 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 195.3487 - mae: 195.3208 - val_loss: 204.8732 - val_mae: 204.8439 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 181.3137 - mae: 181.2830 - val_loss: 189.7354 - val_mae: 189.7031 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 165.5923 - mae: 165.5586 - val_loss: 173.2705 - val_mae: 173.2348 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 149.5250 - mae: 149.4877 - val_loss: 157.7714 - val_mae: 157.7319 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 134.8101 - mae: 134.7688 - val_loss: 141.7476 - val_mae: 141.7040 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 122.4308 - mae: 122.3855 - val_loss: 129.2961 - val_mae: 129.2487 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 115.5208 - mae: 115.4719 - val_loss: 122.5670 - val_mae: 122.5165 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 111.0717 - mae: 111.0202 - val_loss: 122.2427 - val_mae: 122.1901 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 569.4167\n",
      "LV_RMSE_12h: 613.8020\n",
      "LV_MAE_24h: 91.4052\n",
      "LV_RMSE_24h: 133.5373\n",
      "LV_MAE_48h: 116.4856\n",
      "LV_RMSE_48h: 167.9605\n",
      "LV_MAE_72h: 106.7414\n",
      "LV_RMSE_72h: 157.5231\n",
      "LV_MAE_mean: 221.0122\n",
      "LV_RMSE_mean: 268.2057\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 355.5623\n",
      "RMSE_12h: 468.5776\n",
      "MAE_24h: 132.2764\n",
      "RMSE_24h: 192.1522\n",
      "MAE_48h: 139.7307\n",
      "RMSE_48h: 198.4002\n",
      "MAE_72h: 145.6636\n",
      "RMSE_72h: 202.7933\n",
      "MAE_mean: 193.3083\n",
      "RMSE_mean: 265.4808\n",
      "\n",
      "=== Station S3023113 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1132 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1109, 24, 400) Ytr2: (1109, 4) \n",
      "  Xva3: (162, 24, 400) Yva2: (162, 4) \n",
      "  Xte3: (278, 24, 400) Yte2: (278, 4)\n",
      "Epoch 1/20\n",
      "9/9 [==============================] - 3s 71ms/step - loss: 83.7227 - mae: 83.7099 - val_loss: 121.3905 - val_mae: 121.3778 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 80.0088 - mae: 79.9960 - val_loss: 116.6214 - val_mae: 116.6085 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 75.1965 - mae: 75.1835 - val_loss: 110.2032 - val_mae: 110.1900 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 70.1048 - mae: 70.0914 - val_loss: 103.4591 - val_mae: 103.4454 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 65.5494 - mae: 65.5354 - val_loss: 97.0992 - val_mae: 97.0848 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 61.0889 - mae: 61.0742 - val_loss: 91.4883 - val_mae: 91.4731 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 57.6769 - mae: 57.6615 - val_loss: 86.7208 - val_mae: 86.7049 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 54.8561 - mae: 54.8399 - val_loss: 83.0612 - val_mae: 83.0445 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 52.2854 - mae: 52.2684 - val_loss: 80.0095 - val_mae: 79.9922 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 49.0998 - mae: 49.0822 - val_loss: 77.5937 - val_mae: 77.5758 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 45.6424 - mae: 45.6243 - val_loss: 74.9342 - val_mae: 74.9157 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 42.3903 - mae: 42.3716 - val_loss: 73.2515 - val_mae: 73.2325 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 39.5437 - mae: 39.5244 - val_loss: 71.1091 - val_mae: 71.0895 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 37.8766 - mae: 37.8569 - val_loss: 70.4451 - val_mae: 70.4252 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 36.4566 - mae: 36.4365 - val_loss: 69.3903 - val_mae: 69.3699 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 35.1045 - mae: 35.0840 - val_loss: 69.2972 - val_mae: 69.2766 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 34.3821 - mae: 34.3613 - val_loss: 68.4412 - val_mae: 68.4201 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 33.0659 - mae: 33.0446 - val_loss: 66.2148 - val_mae: 66.1931 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 32.0967 - mae: 32.0748 - val_loss: 66.4455 - val_mae: 66.4233 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 30.6171 - mae: 30.5946 - val_loss: 63.4801 - val_mae: 63.4572 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 199.3201\n",
      "LV_RMSE_12h: 227.0019\n",
      "LV_MAE_24h: 46.9964\n",
      "LV_RMSE_24h: 70.8173\n",
      "LV_MAE_48h: 54.5216\n",
      "LV_RMSE_48h: 78.4442\n",
      "LV_MAE_72h: 57.1367\n",
      "LV_RMSE_72h: 83.0570\n",
      "LV_MAE_mean: 89.4937\n",
      "LV_RMSE_mean: 114.8301\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 111.2918\n",
      "RMSE_12h: 151.7180\n",
      "MAE_24h: 72.7738\n",
      "RMSE_24h: 103.7397\n",
      "MAE_48h: 79.6701\n",
      "RMSE_48h: 111.6321\n",
      "MAE_72h: 83.3277\n",
      "RMSE_72h: 116.6790\n",
      "MAE_mean: 86.7659\n",
      "RMSE_mean: 120.9422\n",
      "\n",
      "=== Station S3023114 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1377 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1354, 24, 400) Ytr2: (1354, 4) \n",
      "  Xva3: (197, 24, 400) Yva2: (197, 4) \n",
      "  Xte3: (348, 24, 400) Yte2: (348, 4)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "11/11 [==============================] - 3s 57ms/step - loss: 328.8889 - mae: 328.8762 - val_loss: 330.3521 - val_mae: 330.3394 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 323.5279 - mae: 323.5151 - val_loss: 323.4788 - val_mae: 323.4659 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 315.9028 - mae: 315.8897 - val_loss: 316.0247 - val_mae: 316.0114 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 308.1255 - mae: 308.1119 - val_loss: 308.6529 - val_mae: 308.6389 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 300.0972 - mae: 300.0828 - val_loss: 301.1249 - val_mae: 301.1100 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 292.2724 - mae: 292.2570 - val_loss: 293.6940 - val_mae: 293.6780 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 284.2317 - mae: 284.2151 - val_loss: 286.4494 - val_mae: 286.4321 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 276.2712 - mae: 276.2532 - val_loss: 279.4846 - val_mae: 279.4658 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 268.7249 - mae: 268.7054 - val_loss: 272.4863 - val_mae: 272.4659 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 260.5262 - mae: 260.5050 - val_loss: 263.9811 - val_mae: 263.9590 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 251.7045 - mae: 251.6816 - val_loss: 254.0253 - val_mae: 254.0013 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 242.0889 - mae: 242.0641 - val_loss: 245.4434 - val_mae: 245.4175 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 233.9684 - mae: 233.9416 - val_loss: 237.2879 - val_mae: 237.2599 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 225.5778 - mae: 225.5489 - val_loss: 228.2450 - val_mae: 228.2149 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 216.0247 - mae: 215.9935 - val_loss: 218.2097 - val_mae: 218.1771 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 206.1669 - mae: 206.1331 - val_loss: 206.7354 - val_mae: 206.7002 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 195.8378 - mae: 195.8013 - val_loss: 197.1820 - val_mae: 197.1439 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 186.0013 - mae: 185.9620 - val_loss: 186.3766 - val_mae: 186.3357 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 175.4684 - mae: 175.4261 - val_loss: 175.0769 - val_mae: 175.0328 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 162.9784 - mae: 162.9330 - val_loss: 164.0548 - val_mae: 164.0076 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 564.3965\n",
      "LV_RMSE_12h: 640.4940\n",
      "LV_MAE_24h: 93.2011\n",
      "LV_RMSE_24h: 148.0102\n",
      "LV_MAE_48h: 105.1724\n",
      "LV_RMSE_48h: 159.5214\n",
      "LV_MAE_72h: 116.0489\n",
      "LV_RMSE_72h: 171.0010\n",
      "LV_MAE_mean: 219.7047\n",
      "LV_RMSE_mean: 279.7567\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 352.5849\n",
      "RMSE_12h: 460.2498\n",
      "MAE_24h: 150.8023\n",
      "RMSE_24h: 215.5723\n",
      "MAE_48h: 164.9661\n",
      "RMSE_48h: 240.5602\n",
      "MAE_72h: 185.3518\n",
      "RMSE_72h: 260.1599\n",
      "MAE_mean: 213.4263\n",
      "RMSE_mean: 294.1356\n",
      "\n",
      "=== Station S3023115 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1376 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1353, 24, 400) Ytr2: (1353, 4) \n",
      "  Xva3: (197, 24, 400) Yva2: (197, 4) \n",
      "  Xte3: (348, 24, 400) Yte2: (348, 4)\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 3s 60ms/step - loss: 221.5838 - mae: 221.5710 - val_loss: 215.9523 - val_mae: 215.9394 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 216.7273 - mae: 216.7144 - val_loss: 209.4901 - val_mae: 209.4770 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 210.3547 - mae: 210.3414 - val_loss: 202.5128 - val_mae: 202.4993 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 203.8920 - mae: 203.8781 - val_loss: 195.5452 - val_mae: 195.5309 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 197.5784 - mae: 197.5636 - val_loss: 188.8636 - val_mae: 188.8483 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 191.0935 - mae: 191.0777 - val_loss: 182.0665 - val_mae: 182.0500 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 184.7763 - mae: 184.7593 - val_loss: 175.2301 - val_mae: 175.2122 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 178.1601 - mae: 178.1417 - val_loss: 168.8961 - val_mae: 168.8769 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 172.3927 - mae: 172.3728 - val_loss: 162.7495 - val_mae: 162.7288 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 166.5623 - mae: 166.5409 - val_loss: 156.6685 - val_mae: 156.6463 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 159.0679 - mae: 159.0450 - val_loss: 148.5591 - val_mae: 148.5354 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 149.5594 - mae: 149.5350 - val_loss: 140.4241 - val_mae: 140.3986 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 139.8707 - mae: 139.8443 - val_loss: 132.1228 - val_mae: 132.0951 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 129.5484 - mae: 129.5196 - val_loss: 124.2952 - val_mae: 124.2650 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 120.4991 - mae: 120.4678 - val_loss: 116.7129 - val_mae: 116.6802 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 111.3792 - mae: 111.3455 - val_loss: 110.9025 - val_mae: 110.8675 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 104.9988 - mae: 104.9628 - val_loss: 104.9326 - val_mae: 104.8952 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 99.0296 - mae: 98.9912 - val_loss: 99.8061 - val_mae: 99.7664 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 94.6979 - mae: 94.6573 - val_loss: 96.2180 - val_mae: 96.1761 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 91.7145 - mae: 91.6717 - val_loss: 92.4205 - val_mae: 92.3765 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 356.3822\n",
      "LV_RMSE_12h: 422.6471\n",
      "LV_MAE_24h: 66.9080\n",
      "LV_RMSE_24h: 108.0815\n",
      "LV_MAE_48h: 86.6322\n",
      "LV_RMSE_48h: 140.2760\n",
      "LV_MAE_72h: 79.2069\n",
      "LV_RMSE_72h: 130.8790\n",
      "LV_MAE_mean: 147.2823\n",
      "LV_RMSE_mean: 200.4709\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 196.3007\n",
      "RMSE_12h: 291.5859\n",
      "MAE_24h: 66.4301\n",
      "RMSE_24h: 113.0817\n",
      "MAE_48h: 70.8790\n",
      "RMSE_48h: 121.9689\n",
      "MAE_72h: 74.2392\n",
      "RMSE_72h: 125.9869\n",
      "MAE_mean: 101.9623\n",
      "RMSE_mean: 163.1559\n",
      "\n",
      "=== Station S3023116 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1376 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1353, 24, 400) Ytr2: (1353, 4) \n",
      "  Xva3: (197, 24, 400) Yva2: (197, 4) \n",
      "  Xte3: (348, 24, 400) Yte2: (348, 4)\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 3s 57ms/step - loss: 119.0881 - mae: 119.0753 - val_loss: 137.7243 - val_mae: 137.7114 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 113.9268 - mae: 113.9138 - val_loss: 130.1805 - val_mae: 130.1673 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 107.6018 - mae: 107.5884 - val_loss: 121.8677 - val_mae: 121.8540 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 101.5938 - mae: 101.5798 - val_loss: 113.1941 - val_mae: 113.1796 - lr: 0.0010\n",
      "Epoch 5/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 16ms/step - loss: 96.0349 - mae: 96.0200 - val_loss: 104.8609 - val_mae: 104.8454 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 89.4316 - mae: 89.4156 - val_loss: 97.5263 - val_mae: 97.5095 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 0s 18ms/step - loss: 84.2669 - mae: 84.2496 - val_loss: 90.9802 - val_mae: 90.9621 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 78.6114 - mae: 78.5927 - val_loss: 83.9115 - val_mae: 83.8921 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 72.0849 - mae: 72.0648 - val_loss: 75.8360 - val_mae: 75.8150 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 64.8953 - mae: 64.8736 - val_loss: 67.3461 - val_mae: 67.3233 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 57.5329 - mae: 57.5093 - val_loss: 59.5477 - val_mae: 59.5230 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 52.6203 - mae: 52.5950 - val_loss: 54.2118 - val_mae: 54.1859 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 50.1265 - mae: 50.1003 - val_loss: 52.7081 - val_mae: 52.6816 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 48.6177 - mae: 48.5909 - val_loss: 52.1206 - val_mae: 52.0937 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 47.5042 - mae: 47.4771 - val_loss: 51.9960 - val_mae: 51.9688 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 46.4509 - mae: 46.4234 - val_loss: 50.2152 - val_mae: 50.1873 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 45.1700 - mae: 45.1416 - val_loss: 48.5855 - val_mae: 48.5566 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 43.5411 - mae: 43.5116 - val_loss: 46.6620 - val_mae: 46.6320 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 41.6962 - mae: 41.6657 - val_loss: 44.8486 - val_mae: 44.8174 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 39.8560 - mae: 39.8243 - val_loss: 42.9828 - val_mae: 42.9502 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 158.5919\n",
      "LV_RMSE_12h: 169.4280\n",
      "LV_MAE_24h: 33.2960\n",
      "LV_RMSE_24h: 50.9834\n",
      "LV_MAE_48h: 40.2126\n",
      "LV_RMSE_48h: 59.1020\n",
      "LV_MAE_72h: 37.6983\n",
      "LV_RMSE_72h: 54.7190\n",
      "LV_MAE_mean: 67.4497\n",
      "LV_RMSE_mean: 83.5581\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 67.2735\n",
      "RMSE_12h: 88.2639\n",
      "MAE_24h: 30.5511\n",
      "RMSE_24h: 45.1192\n",
      "MAE_48h: 30.7977\n",
      "RMSE_48h: 44.7494\n",
      "MAE_72h: 31.5777\n",
      "RMSE_72h: 45.2158\n",
      "MAE_mean: 40.0500\n",
      "RMSE_mean: 55.8371\n",
      "\n",
      "=== Station S3023121 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1377 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1354, 24, 400) Ytr2: (1354, 4) \n",
      "  Xva3: (197, 24, 400) Yva2: (197, 4) \n",
      "  Xte3: (348, 24, 400) Yte2: (348, 4)\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 3s 59ms/step - loss: 664.5237 - mae: 664.5111 - val_loss: 619.3732 - val_mae: 619.3607 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 660.1722 - mae: 660.1595 - val_loss: 613.5191 - val_mae: 613.5065 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 653.3361 - mae: 653.3233 - val_loss: 605.5252 - val_mae: 605.5123 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 644.6837 - mae: 644.6705 - val_loss: 596.0014 - val_mae: 595.9879 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 634.3810 - mae: 634.3672 - val_loss: 585.2048 - val_mae: 585.1904 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 623.3058 - mae: 623.2910 - val_loss: 572.9756 - val_mae: 572.9601 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 611.3391 - mae: 611.3232 - val_loss: 559.9264 - val_mae: 559.9095 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 599.0265 - mae: 599.0089 - val_loss: 546.3133 - val_mae: 546.2948 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 586.4089 - mae: 586.3896 - val_loss: 532.6846 - val_mae: 532.6644 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 573.3249 - mae: 573.3037 - val_loss: 519.5997 - val_mae: 519.5774 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 561.7258 - mae: 561.7026 - val_loss: 507.0578 - val_mae: 507.0334 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 549.3884 - mae: 549.3629 - val_loss: 494.0800 - val_mae: 494.0532 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 534.8873 - mae: 534.8594 - val_loss: 480.0063 - val_mae: 479.9770 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 518.6365 - mae: 518.6060 - val_loss: 464.7696 - val_mae: 464.7373 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 500.1359 - mae: 500.1023 - val_loss: 448.7797 - val_mae: 448.7442 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 481.9292 - mae: 481.8923 - val_loss: 433.9605 - val_mae: 433.9216 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 466.5314 - mae: 466.4908 - val_loss: 420.4307 - val_mae: 420.3879 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 447.5460 - mae: 447.5014 - val_loss: 406.2096 - val_mae: 406.1628 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 431.9876 - mae: 431.9390 - val_loss: 390.9071 - val_mae: 390.8560 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 414.0216 - mae: 413.9686 - val_loss: 375.3560 - val_mae: 375.3004 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 931.0115\n",
      "LV_RMSE_12h: 1064.2841\n",
      "LV_MAE_24h: 272.8908\n",
      "LV_RMSE_24h: 408.7133\n",
      "LV_MAE_48h: 238.0201\n",
      "LV_RMSE_48h: 345.7780\n",
      "LV_MAE_72h: 246.0431\n",
      "LV_RMSE_72h: 334.3072\n",
      "LV_MAE_mean: 421.9914\n",
      "LV_RMSE_mean: 538.2706\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 620.1481\n",
      "RMSE_12h: 798.6967\n",
      "MAE_24h: 362.0859\n",
      "RMSE_24h: 513.1022\n",
      "MAE_48h: 351.8379\n",
      "RMSE_48h: 508.3031\n",
      "MAE_72h: 372.8454\n",
      "RMSE_72h: 540.5377\n",
      "MAE_mean: 426.7293\n",
      "RMSE_mean: 590.1599\n",
      "\n",
      "=== Station S3023122 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1377 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1354, 24, 400) Ytr2: (1354, 4) \n",
      "  Xva3: (197, 24, 400) Yva2: (197, 4) \n",
      "  Xte3: (348, 24, 400) Yte2: (348, 4)\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 3s 57ms/step - loss: 359.5122 - mae: 359.4995 - val_loss: 382.8412 - val_mae: 382.8284 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 355.9118 - mae: 355.8991 - val_loss: 377.9104 - val_mae: 377.8975 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 350.5997 - mae: 350.5866 - val_loss: 371.6559 - val_mae: 371.6425 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 344.5768 - mae: 344.5632 - val_loss: 364.3036 - val_mae: 364.2895 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 336.9178 - mae: 336.9033 - val_loss: 355.6454 - val_mae: 355.6302 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 328.1877 - mae: 328.1718 - val_loss: 345.5800 - val_mae: 345.5632 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 318.3203 - mae: 318.3027 - val_loss: 333.9159 - val_mae: 333.8971 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 306.7121 - mae: 306.6924 - val_loss: 320.7313 - val_mae: 320.7102 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 294.3871 - mae: 294.3648 - val_loss: 306.5556 - val_mae: 306.5317 - lr: 0.0010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 279.9551 - mae: 279.9299 - val_loss: 290.7158 - val_mae: 290.6887 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 265.4526 - mae: 265.4240 - val_loss: 275.0950 - val_mae: 275.0642 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 250.3122 - mae: 250.2796 - val_loss: 256.9490 - val_mae: 256.9141 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 234.2472 - mae: 234.2105 - val_loss: 239.2657 - val_mae: 239.2265 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 217.8296 - mae: 217.7883 - val_loss: 221.6936 - val_mae: 221.6496 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 201.1312 - mae: 201.0850 - val_loss: 203.8364 - val_mae: 203.7873 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 186.0550 - mae: 186.0036 - val_loss: 187.5987 - val_mae: 187.5445 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 173.6269 - mae: 173.5704 - val_loss: 173.5229 - val_mae: 173.4637 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 164.9603 - mae: 164.8992 - val_loss: 164.1088 - val_mae: 164.0454 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 156.0612 - mae: 155.9961 - val_loss: 157.5815 - val_mae: 157.5143 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 152.7521 - mae: 152.6834 - val_loss: 151.7787 - val_mae: 151.7084 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 615.4396\n",
      "LV_RMSE_12h: 672.2596\n",
      "LV_MAE_24h: 184.1810\n",
      "LV_RMSE_24h: 246.4086\n",
      "LV_MAE_48h: 258.2672\n",
      "LV_RMSE_48h: 318.2182\n",
      "LV_MAE_72h: 264.3937\n",
      "LV_RMSE_72h: 317.2940\n",
      "LV_MAE_mean: 330.5704\n",
      "LV_RMSE_mean: 388.5451\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 370.0564\n",
      "RMSE_12h: 469.3361\n",
      "MAE_24h: 231.6088\n",
      "RMSE_24h: 285.7323\n",
      "MAE_48h: 255.9521\n",
      "RMSE_48h: 308.7779\n",
      "MAE_72h: 260.9373\n",
      "RMSE_72h: 310.7017\n",
      "MAE_mean: 279.6386\n",
      "RMSE_mean: 343.6370\n",
      "\n",
      "=== Station S3023123 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1377 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1354, 24, 400) Ytr2: (1354, 4) \n",
      "  Xva3: (197, 24, 400) Yva2: (197, 4) \n",
      "  Xte3: (348, 24, 400) Yte2: (348, 4)\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 3s 56ms/step - loss: 253.3562 - mae: 253.3435 - val_loss: 192.9362 - val_mae: 192.9235 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 249.9075 - mae: 249.8947 - val_loss: 188.8242 - val_mae: 188.8112 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 245.0944 - mae: 245.0812 - val_loss: 183.8132 - val_mae: 183.7996 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 239.7048 - mae: 239.6908 - val_loss: 177.9503 - val_mae: 177.9358 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 233.0631 - mae: 233.0481 - val_loss: 171.1452 - val_mae: 171.1295 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 225.5093 - mae: 225.4928 - val_loss: 162.6111 - val_mae: 162.5937 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 216.4934 - mae: 216.4751 - val_loss: 153.2316 - val_mae: 153.2121 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 206.4462 - mae: 206.4257 - val_loss: 142.8938 - val_mae: 142.8718 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 195.7277 - mae: 195.7044 - val_loss: 130.5169 - val_mae: 130.4919 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 183.3683 - mae: 183.3419 - val_loss: 117.5148 - val_mae: 117.4865 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 170.7323 - mae: 170.7023 - val_loss: 104.5103 - val_mae: 104.4782 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 158.2269 - mae: 158.1931 - val_loss: 93.0142 - val_mae: 92.9780 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 146.9374 - mae: 146.8994 - val_loss: 82.5745 - val_mae: 82.5341 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 137.5450 - mae: 137.5027 - val_loss: 74.4169 - val_mae: 74.3724 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 130.6676 - mae: 130.6215 - val_loss: 69.9689 - val_mae: 69.9210 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 127.1566 - mae: 127.1074 - val_loss: 64.8857 - val_mae: 64.8350 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 123.5713 - mae: 123.5196 - val_loss: 62.6710 - val_mae: 62.6180 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 121.3005 - mae: 121.2466 - val_loss: 60.1814 - val_mae: 60.1265 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 119.1227 - mae: 119.0670 - val_loss: 58.2165 - val_mae: 58.1599 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 116.4006 - mae: 116.3432 - val_loss: 56.6583 - val_mae: 56.5997 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 410.0891\n",
      "LV_RMSE_12h: 449.2890\n",
      "LV_MAE_24h: 89.6494\n",
      "LV_RMSE_24h: 146.3759\n",
      "LV_MAE_48h: 120.0575\n",
      "LV_RMSE_48h: 175.9005\n",
      "LV_MAE_72h: 111.1063\n",
      "LV_RMSE_72h: 166.4399\n",
      "LV_MAE_mean: 182.7256\n",
      "LV_RMSE_mean: 234.5013\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 124.0657\n",
      "RMSE_12h: 179.3864\n",
      "MAE_24h: 80.6503\n",
      "RMSE_24h: 133.0688\n",
      "MAE_48h: 98.5115\n",
      "RMSE_48h: 164.7770\n",
      "MAE_72h: 101.4040\n",
      "RMSE_72h: 166.2883\n",
      "MAE_mean: 101.1579\n",
      "RMSE_mean: 160.8801\n",
      "\n",
      "=== Station S3023124 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1376 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1353, 24, 400) Ytr2: (1353, 4) \n",
      "  Xva3: (197, 24, 400) Yva2: (197, 4) \n",
      "  Xte3: (348, 24, 400) Yte2: (348, 4)\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 3s 56ms/step - loss: 216.8580 - mae: 216.8452 - val_loss: 179.7307 - val_mae: 179.7179 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 213.1872 - mae: 213.1743 - val_loss: 175.6103 - val_mae: 175.5972 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 207.6713 - mae: 207.6579 - val_loss: 170.5527 - val_mae: 170.5390 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 200.7378 - mae: 200.7238 - val_loss: 164.8538 - val_mae: 164.8392 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 191.9742 - mae: 191.9590 - val_loss: 158.7538 - val_mae: 158.7379 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 181.2305 - mae: 181.2138 - val_loss: 153.1447 - val_mae: 153.1270 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 169.5953 - mae: 169.5768 - val_loss: 148.7271 - val_mae: 148.7073 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 156.8184 - mae: 156.7975 - val_loss: 147.1298 - val_mae: 147.1074 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 146.4476 - mae: 146.4241 - val_loss: 148.5330 - val_mae: 148.5080 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 140.8656 - mae: 140.8397 - val_loss: 151.6006 - val_mae: 151.5737 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 137.8583 - mae: 137.8310 - val_loss: 149.3274 - val_mae: 149.2998 - lr: 5.0000e-04\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 135.7392 - mae: 135.7112 - val_loss: 149.4518 - val_mae: 149.4235 - lr: 5.0000e-04\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 134.2426 - mae: 134.2141 - val_loss: 148.0887 - val_mae: 148.0600 - lr: 2.5000e-04\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 235.7902\n",
      "LV_RMSE_12h: 282.3072\n",
      "LV_MAE_24h: 140.6236\n",
      "LV_RMSE_24h: 214.0080\n",
      "LV_MAE_48h: 130.9856\n",
      "LV_RMSE_48h: 189.5245\n",
      "LV_MAE_72h: 138.9195\n",
      "LV_RMSE_72h: 196.6229\n",
      "LV_MAE_mean: 161.5797\n",
      "LV_RMSE_mean: 220.6156\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 147.6457\n",
      "RMSE_12h: 189.1036\n",
      "MAE_24h: 148.6433\n",
      "RMSE_24h: 185.2964\n",
      "MAE_48h: 144.6456\n",
      "RMSE_48h: 180.7616\n",
      "MAE_72h: 141.2254\n",
      "RMSE_72h: 174.6971\n",
      "MAE_mean: 145.5400\n",
      "RMSE_mean: 182.4647\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Station S3024031 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1372 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1349, 24, 400) Ytr2: (1349, 4) \n",
      "  Xva3: (197, 24, 400) Yva2: (197, 4) \n",
      "  Xte3: (345, 24, 400) Yte2: (345, 4)\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 3s 57ms/step - loss: 3.9080 - mae: 3.8953 - val_loss: 4.8380 - val_mae: 4.8254 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 3.6085 - mae: 3.5960 - val_loss: 4.6754 - val_mae: 4.6629 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 3.5003 - mae: 3.4878 - val_loss: 4.5961 - val_mae: 4.5836 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 3.3912 - mae: 3.3787 - val_loss: 4.5153 - val_mae: 4.5028 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 3.2951 - mae: 3.2826 - val_loss: 4.3775 - val_mae: 4.3649 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 3.2217 - mae: 3.2091 - val_loss: 4.3125 - val_mae: 4.2999 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 3.1201 - mae: 3.1075 - val_loss: 4.2077 - val_mae: 4.1950 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 3.0626 - mae: 3.0499 - val_loss: 4.1346 - val_mae: 4.1217 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 2.9828 - mae: 2.9699 - val_loss: 4.1477 - val_mae: 4.1347 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 2.8934 - mae: 2.8803 - val_loss: 3.9656 - val_mae: 3.9524 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 0s 20ms/step - loss: 2.8264 - mae: 2.8131 - val_loss: 4.1051 - val_mae: 4.0918 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 2.7519 - mae: 2.7386 - val_loss: 3.8873 - val_mae: 3.8738 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 2.7185 - mae: 2.7050 - val_loss: 3.8149 - val_mae: 3.8013 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 2.6701 - mae: 2.6564 - val_loss: 3.7556 - val_mae: 3.7419 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 2.6386 - mae: 2.6249 - val_loss: 3.8503 - val_mae: 3.8365 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 2.6186 - mae: 2.6048 - val_loss: 3.7688 - val_mae: 3.7549 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 2.5482 - mae: 2.5343 - val_loss: 3.5749 - val_mae: 3.5610 - lr: 5.0000e-04\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 2.4943 - mae: 2.4804 - val_loss: 3.5828 - val_mae: 3.5689 - lr: 5.0000e-04\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 2.4529 - mae: 2.4390 - val_loss: 3.5052 - val_mae: 3.4912 - lr: 5.0000e-04\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 2.4161 - mae: 2.4021 - val_loss: 3.6888 - val_mae: 3.6748 - lr: 5.0000e-04\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 6.2290\n",
      "LV_RMSE_12h: 12.4485\n",
      "LV_MAE_24h: 2.9884\n",
      "LV_RMSE_24h: 5.6648\n",
      "LV_MAE_48h: 3.8754\n",
      "LV_RMSE_48h: 8.3077\n",
      "LV_MAE_72h: 4.3188\n",
      "LV_RMSE_72h: 9.8204\n",
      "LV_MAE_mean: 4.3529\n",
      "LV_RMSE_mean: 9.0603\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 2.6362\n",
      "RMSE_12h: 5.6218\n",
      "MAE_24h: 3.0048\n",
      "RMSE_24h: 6.4599\n",
      "MAE_48h: 2.9313\n",
      "RMSE_48h: 5.8413\n",
      "MAE_72h: 2.9456\n",
      "RMSE_72h: 6.0680\n",
      "MAE_mean: 2.8795\n",
      "RMSE_mean: 5.9978\n",
      "\n",
      "=== Station S3024033 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1376 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1353, 24, 400) Ytr2: (1353, 4) \n",
      "  Xva3: (197, 24, 400) Yva2: (197, 4) \n",
      "  Xte3: (348, 24, 400) Yte2: (348, 4)\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 3s 59ms/step - loss: 562.6722 - mae: 562.6594 - val_loss: 568.1937 - val_mae: 568.1808 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 556.2888 - mae: 556.2758 - val_loss: 558.8918 - val_mae: 558.8786 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 545.2145 - mae: 545.2011 - val_loss: 545.9691 - val_mae: 545.9553 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 530.8059 - mae: 530.7917 - val_loss: 529.5970 - val_mae: 529.5823 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 512.8737 - mae: 512.8585 - val_loss: 509.4680 - val_mae: 509.4520 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 491.6293 - mae: 491.6128 - val_loss: 487.8140 - val_mae: 487.7963 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 469.6488 - mae: 469.6303 - val_loss: 466.3165 - val_mae: 466.2969 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 448.4542 - mae: 448.4337 - val_loss: 445.3607 - val_mae: 445.3389 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 427.9383 - mae: 427.9154 - val_loss: 425.7548 - val_mae: 425.7305 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 408.1339 - mae: 408.1086 - val_loss: 408.0905 - val_mae: 408.0637 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 390.3622 - mae: 390.3342 - val_loss: 391.2036 - val_mae: 391.1740 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 373.8089 - mae: 373.7781 - val_loss: 374.9768 - val_mae: 374.9444 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 357.8063 - mae: 357.7726 - val_loss: 359.2676 - val_mae: 359.2322 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 342.7505 - mae: 342.7138 - val_loss: 342.0211 - val_mae: 341.9827 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 324.8472 - mae: 324.8074 - val_loss: 321.1866 - val_mae: 321.1449 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 302.3563 - mae: 302.3132 - val_loss: 296.7679 - val_mae: 296.7227 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 282.0419 - mae: 281.9952 - val_loss: 275.3705 - val_mae: 275.3217 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 264.3098 - mae: 264.2594 - val_loss: 257.9185 - val_mae: 257.8660 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 248.1934 - mae: 248.1394 - val_loss: 243.1253 - val_mae: 243.0693 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 234.8379 - mae: 234.7804 - val_loss: 228.2290 - val_mae: 228.1697 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 515.3965\n",
      "LV_RMSE_12h: 578.6367\n",
      "LV_MAE_24h: 128.4713\n",
      "LV_RMSE_24h: 199.6207\n",
      "LV_MAE_48h: 170.1667\n",
      "LV_RMSE_48h: 253.4019\n",
      "LV_MAE_72h: 140.2155\n",
      "LV_RMSE_72h: 214.6521\n",
      "LV_MAE_mean: 238.5625\n",
      "LV_RMSE_mean: 311.5779\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 382.6264\n",
      "RMSE_12h: 443.5865\n",
      "MAE_24h: 153.3109\n",
      "RMSE_24h: 209.0340\n",
      "MAE_48h: 153.1792\n",
      "RMSE_48h: 210.2757\n",
      "MAE_72h: 147.5293\n",
      "RMSE_72h: 206.3075\n",
      "MAE_mean: 209.1615\n",
      "RMSE_mean: 267.3009\n",
      "\n",
      "=== Station S3024041 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1377 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1354, 24, 400) Ytr2: (1354, 4) \n",
      "  Xva3: (197, 24, 400) Yva2: (197, 4) \n",
      "  Xte3: (348, 24, 400) Yte2: (348, 4)\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 3s 58ms/step - loss: 1448.5194 - mae: 1448.5066 - val_loss: 1449.1802 - val_mae: 1449.1674 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1443.0684 - mae: 1443.0555 - val_loss: 1441.4641 - val_mae: 1441.4512 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 1433.7025 - mae: 1433.6892 - val_loss: 1430.3396 - val_mae: 1430.3262 - lr: 0.0010\n",
      "Epoch 4/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 13ms/step - loss: 1421.2159 - mae: 1421.2021 - val_loss: 1415.7316 - val_mae: 1415.7173 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1404.7902 - mae: 1404.7754 - val_loss: 1397.0812 - val_mae: 1397.0657 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1383.9747 - mae: 1383.9586 - val_loss: 1373.8899 - val_mae: 1373.8728 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 1358.7452 - mae: 1358.7274 - val_loss: 1346.1378 - val_mae: 1346.1188 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 1329.0182 - mae: 1328.9979 - val_loss: 1313.6150 - val_mae: 1313.5935 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1294.6987 - mae: 1294.6760 - val_loss: 1276.2755 - val_mae: 1276.2511 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 1255.1707 - mae: 1255.1448 - val_loss: 1234.0477 - val_mae: 1234.0199 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1210.4333 - mae: 1210.4039 - val_loss: 1186.7975 - val_mae: 1186.7659 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1161.4614 - mae: 1161.4279 - val_loss: 1134.5641 - val_mae: 1134.5281 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 1107.3815 - mae: 1107.3436 - val_loss: 1077.3108 - val_mae: 1077.2700 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1048.8220 - mae: 1048.7791 - val_loss: 1015.5860 - val_mae: 1015.5400 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 985.5497 - mae: 985.5013 - val_loss: 954.0985 - val_mae: 954.0471 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 930.8529 - mae: 930.7990 - val_loss: 900.3716 - val_mae: 900.3146 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 882.2934 - mae: 882.2339 - val_loss: 855.6711 - val_mae: 855.6086 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 840.4575 - mae: 840.3926 - val_loss: 818.0133 - val_mae: 817.9456 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 807.9305 - mae: 807.8606 - val_loss: 784.9305 - val_mae: 784.8576 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 777.2841 - mae: 777.2090 - val_loss: 755.3553 - val_mae: 755.2776 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 1036.3966\n",
      "LV_RMSE_12h: 1147.3167\n",
      "LV_MAE_24h: 161.4339\n",
      "LV_RMSE_24h: 237.9329\n",
      "LV_MAE_48h: 210.3305\n",
      "LV_RMSE_48h: 304.7672\n",
      "LV_MAE_72h: 172.2213\n",
      "LV_RMSE_72h: 265.0184\n",
      "LV_MAE_mean: 395.0956\n",
      "LV_RMSE_mean: 488.7588\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 734.6990\n",
      "RMSE_12h: 885.7261\n",
      "MAE_24h: 718.4445\n",
      "RMSE_24h: 854.1587\n",
      "MAE_48h: 704.1425\n",
      "RMSE_48h: 834.3058\n",
      "MAE_72h: 679.2025\n",
      "RMSE_72h: 800.4932\n",
      "MAE_mean: 709.1222\n",
      "RMSE_mean: 843.6710\n",
      "\n",
      "=== Station S3024042 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1280 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1257, 24, 400) Ytr2: (1257, 4) \n",
      "  Xva3: (183, 24, 400) Yva2: (183, 4) \n",
      "  Xte3: (320, 24, 400) Yte2: (320, 4)\n",
      "Epoch 1/20\n",
      "10/10 [==============================] - 3s 67ms/step - loss: 313.4429 - mae: 313.4301 - val_loss: 328.0246 - val_mae: 328.0117 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 308.3186 - mae: 308.3057 - val_loss: 320.8613 - val_mae: 320.8483 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 300.4789 - mae: 300.4657 - val_loss: 312.5608 - val_mae: 312.5473 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 292.3524 - mae: 292.3387 - val_loss: 304.3364 - val_mae: 304.3223 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 283.9113 - mae: 283.8970 - val_loss: 295.8352 - val_mae: 295.8204 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 275.4789 - mae: 275.4636 - val_loss: 287.0911 - val_mae: 287.0752 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 267.3325 - mae: 267.3161 - val_loss: 278.6829 - val_mae: 278.6658 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 259.0154 - mae: 258.9977 - val_loss: 270.1288 - val_mae: 270.1104 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 250.6557 - mae: 250.6366 - val_loss: 261.3682 - val_mae: 261.3483 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 242.4316 - mae: 242.4109 - val_loss: 252.8859 - val_mae: 252.8643 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 233.9238 - mae: 233.9015 - val_loss: 243.8009 - val_mae: 243.7777 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 225.2802 - mae: 225.2561 - val_loss: 232.7202 - val_mae: 232.6952 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 214.4950 - mae: 214.4691 - val_loss: 220.8483 - val_mae: 220.8213 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 204.5481 - mae: 204.5201 - val_loss: 208.8937 - val_mae: 208.8645 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 194.6407 - mae: 194.6105 - val_loss: 197.9214 - val_mae: 197.8900 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 186.0359 - mae: 186.0036 - val_loss: 187.6275 - val_mae: 187.5940 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 177.2753 - mae: 177.2409 - val_loss: 178.8401 - val_mae: 178.8045 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 168.4576 - mae: 168.4211 - val_loss: 168.1084 - val_mae: 168.0705 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 158.4552 - mae: 158.4163 - val_loss: 157.2281 - val_mae: 157.1878 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 148.5748 - mae: 148.5332 - val_loss: 146.7728 - val_mae: 146.7296 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 451.7000\n",
      "LV_RMSE_12h: 512.2230\n",
      "LV_MAE_24h: 80.0312\n",
      "LV_RMSE_24h: 143.7201\n",
      "LV_MAE_48h: 94.5500\n",
      "LV_RMSE_48h: 163.9825\n",
      "LV_MAE_72h: 91.2906\n",
      "LV_RMSE_72h: 153.1940\n",
      "LV_MAE_mean: 179.3930\n",
      "LV_RMSE_mean: 243.2799\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 301.7967\n",
      "RMSE_12h: 374.3495\n",
      "MAE_24h: 109.3706\n",
      "RMSE_24h: 148.4230\n",
      "MAE_48h: 113.9308\n",
      "RMSE_48h: 153.2465\n",
      "MAE_72h: 116.0949\n",
      "RMSE_72h: 157.0223\n",
      "MAE_mean: 160.2982\n",
      "RMSE_mean: 208.2603\n",
      "\n",
      "=== Station S3024088 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 872 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (849, 24, 400) Ytr2: (849, 4) \n",
      "  Xva3: (125, 24, 400) Yva2: (125, 4) \n",
      "  Xte3: (204, 24, 400) Yte2: (204, 4)\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 3s 93ms/step - loss: 7.2425 - mae: 7.2298 - val_loss: 9.8497 - val_mae: 9.8370 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 6.0750 - mae: 6.0623 - val_loss: 9.0255 - val_mae: 9.0128 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 5.2963 - mae: 5.2836 - val_loss: 8.8930 - val_mae: 8.8803 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 4.8303 - mae: 4.8176 - val_loss: 9.0592 - val_mae: 9.0464 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 4.7141 - mae: 4.7013 - val_loss: 9.1181 - val_mae: 9.1054 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 4.6662 - mae: 4.6534 - val_loss: 8.9923 - val_mae: 8.9796 - lr: 5.0000e-04\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 4.5972 - mae: 4.5845 - val_loss: 8.8241 - val_mae: 8.8115 - lr: 5.0000e-04\n",
      "Epoch 8/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 18ms/step - loss: 4.5541 - mae: 4.5414 - val_loss: 8.8189 - val_mae: 8.8062 - lr: 5.0000e-04\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 4.4823 - mae: 4.4697 - val_loss: 8.8531 - val_mae: 8.8404 - lr: 5.0000e-04\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 4.5223 - mae: 4.5097 - val_loss: 8.8059 - val_mae: 8.7933 - lr: 5.0000e-04\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 4.4611 - mae: 4.4486 - val_loss: 8.8303 - val_mae: 8.8178 - lr: 5.0000e-04\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 4.4660 - mae: 4.4535 - val_loss: 8.7930 - val_mae: 8.7805 - lr: 5.0000e-04\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 4.4877 - mae: 4.4752 - val_loss: 8.7414 - val_mae: 8.7289 - lr: 5.0000e-04\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 4.4038 - mae: 4.3912 - val_loss: 8.7021 - val_mae: 8.6896 - lr: 5.0000e-04\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 4.3691 - mae: 4.3566 - val_loss: 8.7090 - val_mae: 8.6965 - lr: 5.0000e-04\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 4.3490 - mae: 4.3365 - val_loss: 8.6829 - val_mae: 8.6704 - lr: 5.0000e-04\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 4.3150 - mae: 4.3025 - val_loss: 8.6581 - val_mae: 8.6457 - lr: 5.0000e-04\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 4.3142 - mae: 4.3018 - val_loss: 8.6373 - val_mae: 8.6248 - lr: 5.0000e-04\n",
      "Epoch 19/20\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 4.2294 - mae: 4.2169 - val_loss: 8.6876 - val_mae: 8.6751 - lr: 5.0000e-04\n",
      "Epoch 20/20\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 4.2391 - mae: 4.2266 - val_loss: 8.6086 - val_mae: 8.5961 - lr: 5.0000e-04\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 9.8382\n",
      "LV_RMSE_12h: 15.2230\n",
      "LV_MAE_24h: 6.6078\n",
      "LV_RMSE_24h: 13.1253\n",
      "LV_MAE_48h: 7.0490\n",
      "LV_RMSE_48h: 13.8384\n",
      "LV_MAE_72h: 7.0637\n",
      "LV_RMSE_72h: 13.8930\n",
      "LV_MAE_mean: 7.6397\n",
      "LV_RMSE_mean: 14.0199\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 4.6225\n",
      "RMSE_12h: 8.5974\n",
      "MAE_24h: 4.9908\n",
      "RMSE_24h: 9.8066\n",
      "MAE_48h: 5.0394\n",
      "RMSE_48h: 9.8235\n",
      "MAE_72h: 4.4178\n",
      "RMSE_72h: 9.0816\n",
      "MAE_mean: 4.7676\n",
      "RMSE_mean: 9.3273\n",
      "\n",
      "=== Station S3024101 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1377 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1354, 24, 400) Ytr2: (1354, 4) \n",
      "  Xva3: (197, 24, 400) Yva2: (197, 4) \n",
      "  Xte3: (348, 24, 400) Yte2: (348, 4)\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 3s 59ms/step - loss: 485.3482 - mae: 485.3356 - val_loss: 450.2289 - val_mae: 450.2162 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 479.1577 - mae: 479.1448 - val_loss: 441.4706 - val_mae: 441.4576 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 468.5553 - mae: 468.5421 - val_loss: 428.9554 - val_mae: 428.9418 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 454.8975 - mae: 454.8835 - val_loss: 413.4527 - val_mae: 413.4383 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 437.5616 - mae: 437.5465 - val_loss: 395.9874 - val_mae: 395.9716 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 419.7405 - mae: 419.7241 - val_loss: 378.4174 - val_mae: 378.4001 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 401.6018 - mae: 401.5836 - val_loss: 361.0690 - val_mae: 361.0498 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 383.2344 - mae: 383.2144 - val_loss: 343.6815 - val_mae: 343.6602 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 366.5473 - mae: 366.5249 - val_loss: 327.1654 - val_mae: 327.1418 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 349.0315 - mae: 349.0068 - val_loss: 311.2324 - val_mae: 311.2063 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 332.4901 - mae: 332.4628 - val_loss: 295.5076 - val_mae: 295.4788 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 316.1752 - mae: 316.1451 - val_loss: 279.6665 - val_mae: 279.6348 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 299.9170 - mae: 299.8839 - val_loss: 264.6647 - val_mae: 264.6299 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 282.6058 - mae: 282.5696 - val_loss: 245.6206 - val_mae: 245.5826 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 261.3430 - mae: 261.3036 - val_loss: 224.1405 - val_mae: 224.0992 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 241.0023 - mae: 240.9594 - val_loss: 203.2385 - val_mae: 203.1936 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 220.5123 - mae: 220.4656 - val_loss: 187.1115 - val_mae: 187.0626 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 201.2642 - mae: 201.2135 - val_loss: 172.8099 - val_mae: 172.7569 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 186.8780 - mae: 186.8233 - val_loss: 160.6655 - val_mae: 160.6086 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 177.1523 - mae: 177.0940 - val_loss: 154.8176 - val_mae: 154.7576 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 443.3506\n",
      "LV_RMSE_12h: 493.0087\n",
      "LV_MAE_24h: 81.2787\n",
      "LV_RMSE_24h: 121.4983\n",
      "LV_MAE_48h: 101.5460\n",
      "LV_RMSE_48h: 152.8169\n",
      "LV_MAE_72h: 89.2069\n",
      "LV_RMSE_72h: 134.4383\n",
      "LV_MAE_mean: 178.8456\n",
      "LV_RMSE_mean: 225.4405\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 353.6599\n",
      "RMSE_12h: 404.7224\n",
      "MAE_24h: 91.9471\n",
      "RMSE_24h: 134.6974\n",
      "MAE_48h: 90.9838\n",
      "RMSE_48h: 132.0289\n",
      "MAE_72h: 92.5357\n",
      "RMSE_72h: 133.9061\n",
      "MAE_mean: 157.2816\n",
      "RMSE_mean: 201.3387\n",
      "\n",
      "=== Station S3024102 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1360 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1337, 24, 400) Ytr2: (1337, 4) \n",
      "  Xva3: (195, 24, 400) Yva2: (195, 4) \n",
      "  Xte3: (342, 24, 400) Yte2: (342, 4)\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 3s 59ms/step - loss: 84.6788 - mae: 84.6662 - val_loss: 78.7668 - val_mae: 78.7542 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 79.7749 - mae: 79.7622 - val_loss: 72.2307 - val_mae: 72.2178 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 72.9097 - mae: 72.8967 - val_loss: 65.7417 - val_mae: 65.7285 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 66.6263 - mae: 66.6129 - val_loss: 59.9267 - val_mae: 59.9130 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 61.2155 - mae: 61.2014 - val_loss: 55.4102 - val_mae: 55.3957 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 56.9418 - mae: 56.9270 - val_loss: 52.2450 - val_mae: 52.2297 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 54.1888 - mae: 54.1732 - val_loss: 50.6899 - val_mae: 50.6740 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 52.1242 - mae: 52.1080 - val_loss: 49.1032 - val_mae: 49.0868 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 49.7605 - mae: 49.7440 - val_loss: 45.4659 - val_mae: 45.4491 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 45.3205 - mae: 45.3036 - val_loss: 41.0937 - val_mae: 41.0765 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 41.8706 - mae: 41.8531 - val_loss: 38.2375 - val_mae: 38.2197 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 39.1974 - mae: 39.1793 - val_loss: 36.6244 - val_mae: 36.6060 - lr: 0.0010\n",
      "Epoch 13/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 13ms/step - loss: 37.1052 - mae: 37.0866 - val_loss: 34.8132 - val_mae: 34.7943 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 35.7744 - mae: 35.7552 - val_loss: 33.0236 - val_mae: 33.0039 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 33.7425 - mae: 33.7225 - val_loss: 30.9058 - val_mae: 30.8853 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 31.8955 - mae: 31.8746 - val_loss: 28.3818 - val_mae: 28.3602 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 29.2039 - mae: 29.1816 - val_loss: 25.8584 - val_mae: 25.8353 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 27.4555 - mae: 27.4317 - val_loss: 24.8534 - val_mae: 24.8288 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 26.2699 - mae: 26.2448 - val_loss: 23.6035 - val_mae: 23.5777 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 25.2594 - mae: 25.2332 - val_loss: 23.4411 - val_mae: 23.4144 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 78.5877\n",
      "LV_RMSE_12h: 88.5516\n",
      "LV_MAE_24h: 21.9532\n",
      "LV_RMSE_24h: 35.9885\n",
      "LV_MAE_48h: 28.3304\n",
      "LV_RMSE_48h: 45.1010\n",
      "LV_MAE_72h: 23.3772\n",
      "LV_RMSE_72h: 38.9281\n",
      "LV_MAE_mean: 38.0621\n",
      "LV_RMSE_mean: 52.1423\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 24.0186\n",
      "RMSE_12h: 34.9124\n",
      "MAE_24h: 21.1770\n",
      "RMSE_24h: 32.8816\n",
      "MAE_48h: 20.2679\n",
      "RMSE_48h: 31.2609\n",
      "MAE_72h: 20.6176\n",
      "RMSE_72h: 29.8671\n",
      "MAE_mean: 21.5203\n",
      "RMSE_mean: 32.2305\n",
      "\n",
      "=== Station S3024103 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1360 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1337, 24, 400) Ytr2: (1337, 4) \n",
      "  Xva3: (195, 24, 400) Yva2: (195, 4) \n",
      "  Xte3: (342, 24, 400) Yte2: (342, 4)\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 3s 58ms/step - loss: 82.0993 - mae: 82.0864 - val_loss: 78.7276 - val_mae: 78.7147 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 76.1534 - mae: 76.1404 - val_loss: 70.8090 - val_mae: 70.7958 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 68.0887 - mae: 68.0752 - val_loss: 62.7493 - val_mae: 62.7355 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 60.5814 - mae: 60.5673 - val_loss: 55.5461 - val_mae: 55.5315 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 53.5820 - mae: 53.5670 - val_loss: 49.2475 - val_mae: 49.2319 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 47.7480 - mae: 47.7319 - val_loss: 43.3263 - val_mae: 43.3097 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 42.8513 - mae: 42.8343 - val_loss: 37.8605 - val_mae: 37.8429 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 38.6743 - mae: 38.6565 - val_loss: 34.0063 - val_mae: 33.9881 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 35.3744 - mae: 35.3560 - val_loss: 31.2484 - val_mae: 31.2297 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 32.2873 - mae: 32.2682 - val_loss: 28.8379 - val_mae: 28.8185 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 30.5277 - mae: 30.5081 - val_loss: 27.9285 - val_mae: 27.9085 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 29.2271 - mae: 29.2070 - val_loss: 26.6973 - val_mae: 26.6769 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 28.5453 - mae: 28.5248 - val_loss: 25.7042 - val_mae: 25.6834 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 27.4809 - mae: 27.4599 - val_loss: 24.8767 - val_mae: 24.8555 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 26.5387 - mae: 26.5173 - val_loss: 23.6479 - val_mae: 23.6262 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 25.4253 - mae: 25.4034 - val_loss: 22.4992 - val_mae: 22.4769 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 24.0226 - mae: 24.0000 - val_loss: 20.9588 - val_mae: 20.9358 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 22.4502 - mae: 22.4268 - val_loss: 18.9869 - val_mae: 18.9629 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 21.0045 - mae: 20.9801 - val_loss: 17.4995 - val_mae: 17.4746 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 19.9214 - mae: 19.8961 - val_loss: 15.7828 - val_mae: 15.7570 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 95.8977\n",
      "LV_RMSE_12h: 109.1642\n",
      "LV_MAE_24h: 17.3041\n",
      "LV_RMSE_24h: 25.4929\n",
      "LV_MAE_48h: 18.1257\n",
      "LV_RMSE_48h: 26.4004\n",
      "LV_MAE_72h: 17.1491\n",
      "LV_RMSE_72h: 24.5164\n",
      "LV_MAE_mean: 37.1192\n",
      "LV_RMSE_mean: 46.3935\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 25.2001\n",
      "RMSE_12h: 34.5251\n",
      "MAE_24h: 14.8925\n",
      "RMSE_24h: 20.9661\n",
      "MAE_48h: 14.4527\n",
      "RMSE_48h: 20.6361\n",
      "MAE_72h: 14.5963\n",
      "RMSE_72h: 20.9782\n",
      "MAE_mean: 17.2854\n",
      "RMSE_mean: 24.2764\n",
      "\n",
      "=== Station S3024104 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1132 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1109, 24, 400) Ytr2: (1109, 4) \n",
      "  Xva3: (162, 24, 400) Yva2: (162, 4) \n",
      "  Xte3: (278, 24, 400) Yte2: (278, 4)\n",
      "Epoch 1/20\n",
      "9/9 [==============================] - 3s 70ms/step - loss: 76.7815 - mae: 76.7686 - val_loss: 69.8212 - val_mae: 69.8083 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 72.6799 - mae: 72.6671 - val_loss: 64.4859 - val_mae: 64.4729 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 66.8025 - mae: 66.7894 - val_loss: 58.5807 - val_mae: 58.5675 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 61.0088 - mae: 60.9954 - val_loss: 53.2143 - val_mae: 53.2006 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 55.4105 - mae: 55.3965 - val_loss: 48.4354 - val_mae: 48.4210 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 50.7195 - mae: 50.7048 - val_loss: 44.6118 - val_mae: 44.5966 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 47.3030 - mae: 47.2875 - val_loss: 42.0764 - val_mae: 42.0604 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 44.8348 - mae: 44.8186 - val_loss: 39.9702 - val_mae: 39.9537 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 42.2622 - mae: 42.2455 - val_loss: 36.5429 - val_mae: 36.5260 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 39.2054 - mae: 39.1883 - val_loss: 33.4771 - val_mae: 33.4598 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 36.8783 - mae: 36.8608 - val_loss: 31.5628 - val_mae: 31.5451 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 34.8099 - mae: 34.7920 - val_loss: 30.0189 - val_mae: 30.0007 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 33.1871 - mae: 33.1688 - val_loss: 28.7917 - val_mae: 28.7731 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "9/9 [==============================] - 0s 17ms/step - loss: 31.9422 - mae: 31.9234 - val_loss: 28.5318 - val_mae: 28.5128 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 31.1095 - mae: 31.0904 - val_loss: 27.4154 - val_mae: 27.3960 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 30.2328 - mae: 30.2132 - val_loss: 26.5820 - val_mae: 26.5621 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 29.2469 - mae: 29.2268 - val_loss: 25.6697 - val_mae: 25.6494 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 28.3237 - mae: 28.3030 - val_loss: 24.4538 - val_mae: 24.4328 - lr: 0.0010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/20\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 27.0197 - mae: 26.9984 - val_loss: 23.3422 - val_mae: 23.3204 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 25.7173 - mae: 25.6951 - val_loss: 22.2972 - val_mae: 22.2745 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 71.0863\n",
      "LV_RMSE_12h: 84.5891\n",
      "LV_MAE_24h: 19.4856\n",
      "LV_RMSE_24h: 27.5145\n",
      "LV_MAE_48h: 25.5000\n",
      "LV_RMSE_48h: 34.9538\n",
      "LV_MAE_72h: 20.7122\n",
      "LV_RMSE_72h: 29.6223\n",
      "LV_MAE_mean: 34.1960\n",
      "LV_RMSE_mean: 44.1699\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 33.3314\n",
      "RMSE_12h: 42.5199\n",
      "MAE_24h: 20.0544\n",
      "RMSE_24h: 28.1248\n",
      "MAE_48h: 19.6792\n",
      "RMSE_48h: 27.7747\n",
      "MAE_72h: 18.6760\n",
      "RMSE_72h: 25.6157\n",
      "MAE_mean: 22.9352\n",
      "RMSE_mean: 31.0088\n",
      "\n",
      "=== Station S3024105 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1360 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1337, 24, 400) Ytr2: (1337, 4) \n",
      "  Xva3: (195, 24, 400) Yva2: (195, 4) \n",
      "  Xte3: (342, 24, 400) Yte2: (342, 4)\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 3s 58ms/step - loss: 114.5493 - mae: 114.5365 - val_loss: 112.1168 - val_mae: 112.1040 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 109.2713 - mae: 109.2585 - val_loss: 105.0597 - val_mae: 105.0467 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 101.5474 - mae: 101.5343 - val_loss: 97.0652 - val_mae: 97.0517 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 93.6847 - mae: 93.6709 - val_loss: 88.8570 - val_mae: 88.8428 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 85.9289 - mae: 85.9143 - val_loss: 81.3844 - val_mae: 81.3692 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 78.2134 - mae: 78.1977 - val_loss: 74.1339 - val_mae: 74.1174 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 71.1239 - mae: 71.1068 - val_loss: 67.0655 - val_mae: 67.0477 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 62.8589 - mae: 62.8405 - val_loss: 58.9494 - val_mae: 58.9301 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 54.6152 - mae: 54.5953 - val_loss: 52.0107 - val_mae: 51.9900 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 48.1320 - mae: 48.1108 - val_loss: 46.5333 - val_mae: 46.5115 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 44.4518 - mae: 44.4297 - val_loss: 43.7803 - val_mae: 43.7579 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 42.7272 - mae: 42.7047 - val_loss: 42.7597 - val_mae: 42.7371 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 41.4147 - mae: 41.3920 - val_loss: 41.6892 - val_mae: 41.6665 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 40.6494 - mae: 40.6266 - val_loss: 40.7994 - val_mae: 40.7764 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 39.8763 - mae: 39.8533 - val_loss: 39.8634 - val_mae: 39.8402 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 39.0557 - mae: 39.0324 - val_loss: 38.8206 - val_mae: 38.7971 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 38.0057 - mae: 37.9820 - val_loss: 38.0578 - val_mae: 38.0336 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 37.1498 - mae: 37.1254 - val_loss: 36.6286 - val_mae: 36.6038 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 35.5764 - mae: 35.5514 - val_loss: 35.2300 - val_mae: 35.2046 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 34.3629 - mae: 34.3371 - val_loss: 33.2721 - val_mae: 33.2459 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 124.4971\n",
      "LV_RMSE_12h: 136.0468\n",
      "LV_MAE_24h: 24.1199\n",
      "LV_RMSE_24h: 37.3042\n",
      "LV_MAE_48h: 27.2573\n",
      "LV_RMSE_48h: 41.3372\n",
      "LV_MAE_72h: 25.3713\n",
      "LV_RMSE_72h: 38.9121\n",
      "LV_MAE_mean: 50.3114\n",
      "LV_RMSE_mean: 63.4001\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 58.4052\n",
      "RMSE_12h: 68.4218\n",
      "MAE_24h: 23.4211\n",
      "RMSE_24h: 35.9631\n",
      "MAE_48h: 22.1579\n",
      "RMSE_48h: 34.3695\n",
      "MAE_72h: 21.9886\n",
      "RMSE_72h: 33.5022\n",
      "MAE_mean: 31.4932\n",
      "RMSE_mean: 43.0642\n",
      "\n",
      "=== Station S3024111 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1377 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1354, 24, 400) Ytr2: (1354, 4) \n",
      "  Xva3: (197, 24, 400) Yva2: (197, 4) \n",
      "  Xte3: (348, 24, 400) Yte2: (348, 4)\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 3s 58ms/step - loss: 345.0269 - mae: 345.0141 - val_loss: 319.8342 - val_mae: 319.8214 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 339.8681 - mae: 339.8552 - val_loss: 312.1542 - val_mae: 312.1411 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 330.4537 - mae: 330.4404 - val_loss: 300.7245 - val_mae: 300.7109 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 317.7826 - mae: 317.7687 - val_loss: 285.9933 - val_mae: 285.9789 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 301.8569 - mae: 301.8419 - val_loss: 270.1192 - val_mae: 270.1035 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 285.3945 - mae: 285.3781 - val_loss: 254.3815 - val_mae: 254.3643 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 268.6048 - mae: 268.5869 - val_loss: 239.1975 - val_mae: 239.1786 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 252.6443 - mae: 252.6245 - val_loss: 225.0606 - val_mae: 225.0397 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 238.1111 - mae: 238.0893 - val_loss: 211.8823 - val_mae: 211.8592 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 224.7708 - mae: 224.7468 - val_loss: 200.3871 - val_mae: 200.3618 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 0s 18ms/step - loss: 213.6997 - mae: 213.6734 - val_loss: 189.7718 - val_mae: 189.7442 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 202.5401 - mae: 202.5115 - val_loss: 178.8746 - val_mae: 178.8447 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 192.5065 - mae: 192.4756 - val_loss: 167.8915 - val_mae: 167.8593 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 180.6156 - mae: 180.5824 - val_loss: 154.7486 - val_mae: 154.7141 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 165.4873 - mae: 165.4517 - val_loss: 141.1885 - val_mae: 141.1515 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 152.3343 - mae: 152.2961 - val_loss: 128.4602 - val_mae: 128.4206 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 138.8333 - mae: 138.7925 - val_loss: 117.8034 - val_mae: 117.7611 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 129.8380 - mae: 129.7947 - val_loss: 112.9642 - val_mae: 112.9196 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 125.2080 - mae: 125.1626 - val_loss: 111.4894 - val_mae: 111.4430 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 121.2263 - mae: 121.1794 - val_loss: 106.8533 - val_mae: 106.8058 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 318.1983\n",
      "LV_RMSE_12h: 354.4527\n",
      "LV_MAE_24h: 56.9943\n",
      "LV_RMSE_24h: 80.5210\n",
      "LV_MAE_48h: 72.9310\n",
      "LV_RMSE_48h: 103.8562\n",
      "LV_MAE_72h: 63.4167\n",
      "LV_RMSE_72h: 96.0466\n",
      "LV_MAE_mean: 127.8851\n",
      "LV_RMSE_mean: 158.7191\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 252.8712\n",
      "RMSE_12h: 290.3445\n",
      "MAE_24h: 63.1344\n",
      "RMSE_24h: 93.8194\n",
      "MAE_48h: 61.8237\n",
      "RMSE_48h: 92.7363\n",
      "MAE_72h: 62.7969\n",
      "RMSE_72h: 92.6932\n",
      "MAE_mean: 110.1566\n",
      "RMSE_mean: 142.3983\n",
      "\n",
      "=== Station S3024112 ===\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1377 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1354, 24, 400) Ytr2: (1354, 4) \n",
      "  Xva3: (197, 24, 400) Yva2: (197, 4) \n",
      "  Xte3: (348, 24, 400) Yte2: (348, 4)\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 3s 57ms/step - loss: 382.3166 - mae: 382.3037 - val_loss: 357.4895 - val_mae: 357.4767 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 375.8060 - mae: 375.7930 - val_loss: 348.2815 - val_mae: 348.2684 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 364.5448 - mae: 364.5315 - val_loss: 334.7495 - val_mae: 334.7357 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 349.8023 - mae: 349.7881 - val_loss: 318.5423 - val_mae: 318.5276 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 332.6985 - mae: 332.6832 - val_loss: 302.4108 - val_mae: 302.3947 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 315.7031 - mae: 315.6863 - val_loss: 285.9413 - val_mae: 285.9235 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 299.2713 - mae: 299.2527 - val_loss: 270.5998 - val_mae: 270.5801 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 284.6489 - mae: 284.6284 - val_loss: 256.4879 - val_mae: 256.4662 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 270.8460 - mae: 270.8233 - val_loss: 243.4709 - val_mae: 243.4470 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 0s 21ms/step - loss: 258.2432 - mae: 258.2183 - val_loss: 231.5651 - val_mae: 231.5388 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 0s 17ms/step - loss: 247.5635 - mae: 247.5363 - val_loss: 220.7715 - val_mae: 220.7428 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 236.3355 - mae: 236.3059 - val_loss: 209.5455 - val_mae: 209.5146 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 224.2128 - mae: 224.1808 - val_loss: 197.9958 - val_mae: 197.9624 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 211.0714 - mae: 211.0370 - val_loss: 184.5898 - val_mae: 184.5538 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 194.3800 - mae: 194.3428 - val_loss: 167.8745 - val_mae: 167.8356 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 176.9744 - mae: 176.9341 - val_loss: 153.0013 - val_mae: 152.9590 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 160.3964 - mae: 160.3525 - val_loss: 140.4474 - val_mae: 140.4014 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 147.2812 - mae: 147.2336 - val_loss: 132.9199 - val_mae: 132.8705 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 139.1466 - mae: 139.0960 - val_loss: 128.0253 - val_mae: 127.9733 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 134.4528 - mae: 134.3999 - val_loss: 125.4990 - val_mae: 125.4451 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 405.4828\n",
      "LV_RMSE_12h: 440.7241\n",
      "LV_MAE_24h: 66.9799\n",
      "LV_RMSE_24h: 94.3151\n",
      "LV_MAE_48h: 87.2615\n",
      "LV_RMSE_48h: 121.8687\n",
      "LV_MAE_72h: 76.9167\n",
      "LV_RMSE_72h: 113.1124\n",
      "LV_MAE_mean: 159.1602\n",
      "LV_RMSE_mean: 192.5051\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 301.4349\n",
      "RMSE_12h: 347.3539\n",
      "MAE_24h: 75.3511\n",
      "RMSE_24h: 108.6703\n",
      "MAE_48h: 74.1636\n",
      "RMSE_48h: 106.9494\n",
      "MAE_72h: 75.0822\n",
      "RMSE_72h: 109.4856\n",
      "MAE_mean: 131.5080\n",
      "RMSE_mean: 168.1148\n",
      "\n",
      "=== Station S3024151 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1377 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1354, 24, 400) Ytr2: (1354, 4) \n",
      "  Xva3: (197, 24, 400) Yva2: (197, 4) \n",
      "  Xte3: (348, 24, 400) Yte2: (348, 4)\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 3s 57ms/step - loss: 441.3526 - mae: 441.3396 - val_loss: 526.4230 - val_mae: 526.4100 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 437.8076 - mae: 437.7946 - val_loss: 521.0604 - val_mae: 521.0472 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 431.9995 - mae: 431.9861 - val_loss: 513.5128 - val_mae: 513.4991 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 424.7895 - mae: 424.7756 - val_loss: 504.2177 - val_mae: 504.2032 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 415.6609 - mae: 415.6461 - val_loss: 493.0402 - val_mae: 493.0247 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 405.5614 - mae: 405.5453 - val_loss: 480.1642 - val_mae: 480.1473 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 393.8447 - mae: 393.8269 - val_loss: 465.8786 - val_mae: 465.8597 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 380.4970 - mae: 380.4772 - val_loss: 450.4004 - val_mae: 450.3793 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 366.5193 - mae: 366.4971 - val_loss: 433.7816 - val_mae: 433.7578 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 351.4858 - mae: 351.4608 - val_loss: 416.0753 - val_mae: 416.0487 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 336.0493 - mae: 336.0212 - val_loss: 397.9146 - val_mae: 397.8846 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 318.6860 - mae: 318.6546 - val_loss: 380.0690 - val_mae: 380.0353 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 301.2852 - mae: 301.2498 - val_loss: 361.6243 - val_mae: 361.5867 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 283.6265 - mae: 283.5871 - val_loss: 344.1815 - val_mae: 344.1397 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 0s 17ms/step - loss: 267.1060 - mae: 267.0623 - val_loss: 328.4876 - val_mae: 328.4415 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 253.9156 - mae: 253.8677 - val_loss: 313.6315 - val_mae: 313.5813 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 242.9987 - mae: 242.9469 - val_loss: 306.0858 - val_mae: 306.0320 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 234.7328 - mae: 234.6774 - val_loss: 299.6224 - val_mae: 299.5653 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 230.5976 - mae: 230.5394 - val_loss: 295.3939 - val_mae: 295.3343 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 226.7012 - mae: 226.6408 - val_loss: 292.9490 - val_mae: 292.8875 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 489.0144\n",
      "LV_RMSE_12h: 563.2806\n",
      "LV_MAE_24h: 270.1581\n",
      "LV_RMSE_24h: 351.4415\n",
      "LV_MAE_48h: 399.8305\n",
      "LV_RMSE_48h: 457.9757\n",
      "LV_MAE_72h: 277.7443\n",
      "LV_RMSE_72h: 355.4854\n",
      "LV_MAE_mean: 359.1868\n",
      "LV_RMSE_mean: 432.0458\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 438.4889\n",
      "RMSE_12h: 528.4330\n",
      "MAE_24h: 247.7582\n",
      "RMSE_24h: 311.5237\n",
      "MAE_48h: 253.6830\n",
      "RMSE_48h: 319.7820\n",
      "MAE_72h: 249.3154\n",
      "RMSE_72h: 318.1283\n",
      "MAE_mean: 297.3113\n",
      "RMSE_mean: 369.4668\n",
      "\n",
      "=== Station S3025031 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1377 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1354, 24, 400) Ytr2: (1354, 4) \n",
      "  Xva3: (197, 24, 400) Yva2: (197, 4) \n",
      "  Xte3: (348, 24, 400) Yte2: (348, 4)\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 3s 60ms/step - loss: 465.6821 - mae: 465.6694 - val_loss: 439.7058 - val_mae: 439.6931 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 460.5392 - mae: 460.5263 - val_loss: 432.3693 - val_mae: 432.3564 - lr: 0.0010\n",
      "Epoch 3/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 13ms/step - loss: 451.4668 - mae: 451.4538 - val_loss: 421.7488 - val_mae: 421.7355 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 439.7190 - mae: 439.7054 - val_loss: 407.9615 - val_mae: 407.9476 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 424.0343 - mae: 424.0199 - val_loss: 390.2932 - val_mae: 390.2781 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 404.7954 - mae: 404.7797 - val_loss: 369.2218 - val_mae: 369.2053 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 382.8583 - mae: 382.8411 - val_loss: 346.3272 - val_mae: 346.3090 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 360.6524 - mae: 360.6333 - val_loss: 327.1104 - val_mae: 327.0902 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 343.7936 - mae: 343.7725 - val_loss: 313.4128 - val_mae: 313.3905 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 329.7306 - mae: 329.7075 - val_loss: 302.1242 - val_mae: 302.0999 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 318.7687 - mae: 318.7436 - val_loss: 292.1249 - val_mae: 292.0987 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 308.7036 - mae: 308.6764 - val_loss: 283.3939 - val_mae: 283.3657 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 299.2835 - mae: 299.2543 - val_loss: 276.0380 - val_mae: 276.0077 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 291.7024 - mae: 291.6713 - val_loss: 269.9668 - val_mae: 269.9346 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 285.6837 - mae: 285.6505 - val_loss: 264.9692 - val_mae: 264.9350 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 280.9457 - mae: 280.9107 - val_loss: 259.1395 - val_mae: 259.1034 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 271.9888 - mae: 271.9519 - val_loss: 248.0323 - val_mae: 247.9943 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 256.0023 - mae: 255.9634 - val_loss: 225.4080 - val_mae: 225.3679 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 234.3453 - mae: 234.3040 - val_loss: 208.4621 - val_mae: 208.4191 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 219.6396 - mae: 219.5952 - val_loss: 193.9464 - val_mae: 193.9000 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 498.0632\n",
      "LV_RMSE_12h: 562.1960\n",
      "LV_MAE_24h: 107.4741\n",
      "LV_RMSE_24h: 164.1253\n",
      "LV_MAE_48h: 148.5316\n",
      "LV_RMSE_48h: 222.4894\n",
      "LV_MAE_72h: 147.5488\n",
      "LV_RMSE_72h: 229.4232\n",
      "LV_MAE_mean: 225.4044\n",
      "LV_RMSE_mean: 294.5585\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 349.5283\n",
      "RMSE_12h: 421.3924\n",
      "MAE_24h: 161.9603\n",
      "RMSE_24h: 240.4270\n",
      "MAE_48h: 165.5853\n",
      "RMSE_48h: 245.4671\n",
      "MAE_72h: 149.0122\n",
      "RMSE_72h: 221.8146\n",
      "MAE_mean: 206.5215\n",
      "RMSE_mean: 282.2753\n",
      "\n",
      "=== Station S3025041 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1377 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1354, 24, 400) Ytr2: (1354, 4) \n",
      "  Xva3: (197, 24, 400) Yva2: (197, 4) \n",
      "  Xte3: (348, 24, 400) Yte2: (348, 4)\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 3s 57ms/step - loss: 340.8621 - mae: 340.8494 - val_loss: 310.0533 - val_mae: 310.0405 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 335.0766 - mae: 335.0638 - val_loss: 302.5753 - val_mae: 302.5623 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 326.8107 - mae: 326.7975 - val_loss: 293.9949 - val_mae: 293.9814 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 317.7159 - mae: 317.7021 - val_loss: 285.2056 - val_mae: 285.1913 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 308.0767 - mae: 308.0620 - val_loss: 276.2030 - val_mae: 276.1878 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 298.5807 - mae: 298.5649 - val_loss: 266.9183 - val_mae: 266.9018 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 288.7174 - mae: 288.7003 - val_loss: 257.2560 - val_mae: 257.2380 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 278.3625 - mae: 278.3437 - val_loss: 247.6512 - val_mae: 247.6314 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 268.7155 - mae: 268.6949 - val_loss: 237.9386 - val_mae: 237.9168 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 257.6052 - mae: 257.5826 - val_loss: 227.9562 - val_mae: 227.9324 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 247.5538 - mae: 247.5291 - val_loss: 220.6035 - val_mae: 220.5777 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 239.7579 - mae: 239.7311 - val_loss: 214.3091 - val_mae: 214.2813 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 232.4152 - mae: 232.3867 - val_loss: 208.3285 - val_mae: 208.2989 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 225.9579 - mae: 225.9276 - val_loss: 202.6952 - val_mae: 202.6639 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 220.2449 - mae: 220.2128 - val_loss: 195.1140 - val_mae: 195.0810 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 212.1938 - mae: 212.1599 - val_loss: 185.7482 - val_mae: 185.7132 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 203.1306 - mae: 203.0945 - val_loss: 177.2477 - val_mae: 177.2103 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 193.4465 - mae: 193.4080 - val_loss: 166.7659 - val_mae: 166.7258 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 183.4930 - mae: 183.4516 - val_loss: 158.4439 - val_mae: 158.4006 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 174.2111 - mae: 174.1664 - val_loss: 151.4945 - val_mae: 151.4479 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 469.9483\n",
      "LV_RMSE_12h: 562.4290\n",
      "LV_MAE_24h: 82.2845\n",
      "LV_RMSE_24h: 124.9449\n",
      "LV_MAE_48h: 102.4339\n",
      "LV_RMSE_48h: 156.9683\n",
      "LV_MAE_72h: 92.7155\n",
      "LV_RMSE_72h: 142.0532\n",
      "LV_MAE_mean: 186.8456\n",
      "LV_RMSE_mean: 246.5988\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 294.7846\n",
      "RMSE_12h: 400.8230\n",
      "MAE_24h: 115.4393\n",
      "RMSE_24h: 193.7111\n",
      "MAE_48h: 114.1207\n",
      "RMSE_48h: 189.7167\n",
      "MAE_72h: 124.8129\n",
      "RMSE_72h: 203.0382\n",
      "MAE_mean: 162.2894\n",
      "RMSE_mean: 246.8223\n",
      "\n",
      "=== Station S3025051 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1377 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1354, 24, 400) Ytr2: (1354, 4) \n",
      "  Xva3: (197, 24, 400) Yva2: (197, 4) \n",
      "  Xte3: (348, 24, 400) Yte2: (348, 4)\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 3s 58ms/step - loss: 371.2269 - mae: 371.2142 - val_loss: 345.4807 - val_mae: 345.4678 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 365.4529 - mae: 365.4400 - val_loss: 337.4338 - val_mae: 337.4207 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 356.1081 - mae: 356.0947 - val_loss: 327.4467 - val_mae: 327.4331 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 345.7004 - mae: 345.6865 - val_loss: 316.7490 - val_mae: 316.7345 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 334.2495 - mae: 334.2344 - val_loss: 306.0601 - val_mae: 306.0444 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 323.0466 - mae: 323.0304 - val_loss: 294.9733 - val_mae: 294.9561 - lr: 0.0010\n",
      "Epoch 7/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 13ms/step - loss: 311.3311 - mae: 311.3132 - val_loss: 283.9260 - val_mae: 283.9071 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 299.5354 - mae: 299.5156 - val_loss: 273.7242 - val_mae: 273.7034 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 289.3671 - mae: 289.3454 - val_loss: 264.7774 - val_mae: 264.7545 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 278.9771 - mae: 278.9533 - val_loss: 254.7991 - val_mae: 254.7740 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 267.8584 - mae: 267.8323 - val_loss: 243.1708 - val_mae: 243.1434 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 254.5289 - mae: 254.5005 - val_loss: 228.5708 - val_mae: 228.5410 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 238.1373 - mae: 238.1062 - val_loss: 212.6558 - val_mae: 212.6230 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 222.4990 - mae: 222.4648 - val_loss: 197.1387 - val_mae: 197.1025 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 206.0769 - mae: 206.0390 - val_loss: 179.9676 - val_mae: 179.9276 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 190.3828 - mae: 190.3412 - val_loss: 166.9255 - val_mae: 166.8817 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 180.5312 - mae: 180.4859 - val_loss: 159.9200 - val_mae: 159.8730 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 173.4796 - mae: 173.4315 - val_loss: 157.8277 - val_mae: 157.7784 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 170.6509 - mae: 170.6008 - val_loss: 155.9631 - val_mae: 155.9122 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 168.4270 - mae: 168.3755 - val_loss: 153.0291 - val_mae: 152.9770 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 465.4483\n",
      "LV_RMSE_12h: 527.3674\n",
      "LV_MAE_24h: 99.7098\n",
      "LV_RMSE_24h: 156.1503\n",
      "LV_MAE_48h: 135.5891\n",
      "LV_RMSE_48h: 209.4035\n",
      "LV_MAE_72h: 133.6494\n",
      "LV_RMSE_72h: 217.1463\n",
      "LV_MAE_mean: 208.5991\n",
      "LV_RMSE_mean: 277.5169\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 306.0008\n",
      "RMSE_12h: 381.6408\n",
      "MAE_24h: 116.0735\n",
      "RMSE_24h: 184.2494\n",
      "MAE_48h: 111.8336\n",
      "RMSE_48h: 179.3547\n",
      "MAE_72h: 110.1604\n",
      "RMSE_72h: 172.9346\n",
      "MAE_mean: 161.0171\n",
      "RMSE_mean: 229.5449\n",
      "\n",
      "=== Station S3025061 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1377 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1354, 24, 400) Ytr2: (1354, 4) \n",
      "  Xva3: (197, 24, 400) Yva2: (197, 4) \n",
      "  Xte3: (348, 24, 400) Yte2: (348, 4)\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 3s 62ms/step - loss: 363.9722 - mae: 363.9594 - val_loss: 335.1158 - val_mae: 335.1029 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 358.4904 - mae: 358.4774 - val_loss: 327.5793 - val_mae: 327.5662 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 349.8263 - mae: 349.8129 - val_loss: 317.9844 - val_mae: 317.9707 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 340.1492 - mae: 340.1351 - val_loss: 308.2311 - val_mae: 308.2165 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 329.4218 - mae: 329.4066 - val_loss: 298.3458 - val_mae: 298.3299 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 319.0153 - mae: 318.9988 - val_loss: 288.3557 - val_mae: 288.3382 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 308.3213 - mae: 308.3031 - val_loss: 278.3117 - val_mae: 278.2925 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 297.4734 - mae: 297.4533 - val_loss: 268.8658 - val_mae: 268.8445 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 288.0639 - mae: 288.0417 - val_loss: 260.9860 - val_mae: 260.9625 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 280.7030 - mae: 280.6786 - val_loss: 255.8723 - val_mae: 255.8467 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 275.9068 - mae: 275.8803 - val_loss: 252.9513 - val_mae: 252.9239 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 271.8625 - mae: 271.8344 - val_loss: 248.1871 - val_mae: 248.1583 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 264.0574 - mae: 264.0280 - val_loss: 236.1550 - val_mae: 236.1248 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 252.0720 - mae: 252.0411 - val_loss: 224.6848 - val_mae: 224.6529 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 241.5834 - mae: 241.5507 - val_loss: 215.9712 - val_mae: 215.9374 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 232.6764 - mae: 232.6418 - val_loss: 207.6198 - val_mae: 207.5840 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 222.4613 - mae: 222.4245 - val_loss: 196.4744 - val_mae: 196.4363 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 211.1878 - mae: 211.1484 - val_loss: 184.8781 - val_mae: 184.8370 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 200.4871 - mae: 200.4444 - val_loss: 175.6918 - val_mae: 175.6471 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 190.0579 - mae: 190.0115 - val_loss: 168.4987 - val_mae: 168.4502 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 497.9454\n",
      "LV_RMSE_12h: 601.1740\n",
      "LV_MAE_24h: 86.9770\n",
      "LV_RMSE_24h: 138.2892\n",
      "LV_MAE_48h: 112.2787\n",
      "LV_RMSE_48h: 180.9230\n",
      "LV_MAE_72h: 102.2328\n",
      "LV_RMSE_72h: 168.4129\n",
      "LV_MAE_mean: 199.8585\n",
      "LV_RMSE_mean: 272.1998\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 313.6346\n",
      "RMSE_12h: 432.7498\n",
      "MAE_24h: 120.8382\n",
      "RMSE_24h: 211.4944\n",
      "MAE_48h: 125.8203\n",
      "RMSE_48h: 215.7511\n",
      "MAE_72h: 129.3285\n",
      "RMSE_72h: 217.7772\n",
      "MAE_mean: 172.4054\n",
      "RMSE_mean: 269.4431\n",
      "\n",
      "=== Station S3025081 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1377 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1354, 24, 400) Ytr2: (1354, 4) \n",
      "  Xva3: (197, 24, 400) Yva2: (197, 4) \n",
      "  Xte3: (348, 24, 400) Yte2: (348, 4)\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 3s 59ms/step - loss: 1660.1722 - mae: 1660.1595 - val_loss: 1671.8961 - val_mae: 1671.8833 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1654.5168 - mae: 1654.5040 - val_loss: 1663.9752 - val_mae: 1663.9623 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1644.8138 - mae: 1644.8008 - val_loss: 1652.4423 - val_mae: 1652.4290 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 1631.8988 - mae: 1631.8851 - val_loss: 1637.0028 - val_mae: 1636.9885 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1614.5778 - mae: 1614.5627 - val_loss: 1617.5303 - val_mae: 1617.5148 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1592.8661 - mae: 1592.8499 - val_loss: 1593.6000 - val_mae: 1593.5826 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1567.1479 - mae: 1567.1298 - val_loss: 1564.9581 - val_mae: 1564.9387 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1536.5615 - mae: 1536.5411 - val_loss: 1531.9783 - val_mae: 1531.9564 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1502.6255 - mae: 1502.6022 - val_loss: 1497.1362 - val_mae: 1497.1113 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 1467.6250 - mae: 1467.5990 - val_loss: 1461.5859 - val_mae: 1461.5581 - lr: 0.0010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1433.1434 - mae: 1433.1140 - val_loss: 1426.9371 - val_mae: 1426.9058 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1399.6173 - mae: 1399.5841 - val_loss: 1394.3921 - val_mae: 1394.3569 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1369.0804 - mae: 1369.0435 - val_loss: 1362.3973 - val_mae: 1362.3585 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 1337.7205 - mae: 1337.6797 - val_loss: 1330.5719 - val_mae: 1330.5288 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1306.9998 - mae: 1306.9547 - val_loss: 1298.9695 - val_mae: 1298.9222 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1277.4562 - mae: 1277.4070 - val_loss: 1268.1549 - val_mae: 1268.1031 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1248.2922 - mae: 1248.2386 - val_loss: 1237.1250 - val_mae: 1237.0685 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1216.9330 - mae: 1216.8744 - val_loss: 1205.9691 - val_mae: 1205.9077 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1191.1154 - mae: 1191.0518 - val_loss: 1176.5787 - val_mae: 1176.5123 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1165.5223 - mae: 1165.4536 - val_loss: 1149.8491 - val_mae: 1149.7777 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 1606.8160\n",
      "LV_RMSE_12h: 1756.8817\n",
      "LV_MAE_24h: 285.3419\n",
      "LV_RMSE_24h: 488.7240\n",
      "LV_MAE_48h: 406.1810\n",
      "LV_RMSE_48h: 656.1350\n",
      "LV_MAE_72h: 332.8822\n",
      "LV_RMSE_72h: 579.0251\n",
      "LV_MAE_mean: 657.8052\n",
      "LV_RMSE_mean: 870.1915\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 1006.9224\n",
      "RMSE_12h: 1232.3683\n",
      "MAE_24h: 1025.9238\n",
      "RMSE_24h: 1253.4462\n",
      "MAE_48h: 1037.3235\n",
      "RMSE_48h: 1270.7521\n",
      "MAE_72h: 1024.4828\n",
      "RMSE_72h: 1248.4443\n",
      "MAE_mean: 1023.6631\n",
      "RMSE_mean: 1251.2527\n",
      "\n",
      "=== Station S3025082 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1377 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1354, 24, 400) Ytr2: (1354, 4) \n",
      "  Xva3: (197, 24, 400) Yva2: (197, 4) \n",
      "  Xte3: (348, 24, 400) Yte2: (348, 4)\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 3s 58ms/step - loss: 442.0320 - mae: 442.0193 - val_loss: 433.3593 - val_mae: 433.3466 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 435.8349 - mae: 435.8222 - val_loss: 425.0976 - val_mae: 425.0847 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 426.6176 - mae: 426.6046 - val_loss: 415.4531 - val_mae: 415.4399 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 416.6937 - mae: 416.6803 - val_loss: 405.1102 - val_mae: 405.0963 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 406.0059 - mae: 405.9915 - val_loss: 393.9606 - val_mae: 393.9457 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 394.5693 - mae: 394.5539 - val_loss: 381.7481 - val_mae: 381.7319 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 382.2384 - mae: 382.2216 - val_loss: 368.2026 - val_mae: 368.1849 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 369.6176 - mae: 369.5991 - val_loss: 354.4342 - val_mae: 354.4146 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 356.7727 - mae: 356.7523 - val_loss: 341.3784 - val_mae: 341.3569 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 344.1093 - mae: 344.0868 - val_loss: 328.6926 - val_mae: 328.6689 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 332.9348 - mae: 332.9101 - val_loss: 316.5525 - val_mae: 316.5264 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 320.9433 - mae: 320.9162 - val_loss: 303.0747 - val_mae: 303.0462 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 307.1124 - mae: 307.0827 - val_loss: 286.0966 - val_mae: 286.0654 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 289.3946 - mae: 289.3621 - val_loss: 267.0370 - val_mae: 267.0028 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 272.0764 - mae: 272.0408 - val_loss: 247.5806 - val_mae: 247.5432 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 253.9649 - mae: 253.9259 - val_loss: 228.9308 - val_mae: 228.8897 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 235.8871 - mae: 235.8443 - val_loss: 211.7425 - val_mae: 211.6975 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 219.6077 - mae: 219.5609 - val_loss: 196.7292 - val_mae: 196.6802 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 206.8890 - mae: 206.8383 - val_loss: 185.9886 - val_mae: 185.9356 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 196.3180 - mae: 196.2635 - val_loss: 177.5371 - val_mae: 177.4807 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 561.3477\n",
      "LV_RMSE_12h: 621.6244\n",
      "LV_MAE_24h: 95.3994\n",
      "LV_RMSE_24h: 142.5780\n",
      "LV_MAE_48h: 118.4080\n",
      "LV_RMSE_48h: 168.1422\n",
      "LV_MAE_72h: 114.9770\n",
      "LV_RMSE_72h: 168.5288\n",
      "LV_MAE_mean: 222.5330\n",
      "LV_RMSE_mean: 275.2184\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 397.1278\n",
      "RMSE_12h: 469.4864\n",
      "MAE_24h: 140.5712\n",
      "RMSE_24h: 191.1048\n",
      "MAE_48h: 141.7561\n",
      "RMSE_48h: 194.4149\n",
      "MAE_72h: 133.0634\n",
      "RMSE_72h: 184.5193\n",
      "MAE_mean: 203.1296\n",
      "RMSE_mean: 259.8813\n",
      "\n",
      "=== Station S3025083 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1377 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1354, 24, 400) Ytr2: (1354, 4) \n",
      "  Xva3: (197, 24, 400) Yva2: (197, 4) \n",
      "  Xte3: (348, 24, 400) Yte2: (348, 4)\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 3s 61ms/step - loss: 1701.9650 - mae: 1701.9521 - val_loss: 1718.5791 - val_mae: 1718.5664 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1696.1823 - mae: 1696.1696 - val_loss: 1710.6329 - val_mae: 1710.6199 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1686.7111 - mae: 1686.6979 - val_loss: 1699.4326 - val_mae: 1699.4191 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 1674.2188 - mae: 1674.2047 - val_loss: 1684.9703 - val_mae: 1684.9562 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1657.8693 - mae: 1657.8547 - val_loss: 1666.6492 - val_mae: 1666.6339 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 1637.8630 - mae: 1637.8469 - val_loss: 1644.1265 - val_mae: 1644.1096 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 1613.2341 - mae: 1613.2164 - val_loss: 1617.3496 - val_mae: 1617.3307 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1585.6498 - mae: 1585.6300 - val_loss: 1587.6464 - val_mae: 1587.6254 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 1556.4812 - mae: 1556.4590 - val_loss: 1557.3093 - val_mae: 1557.2855 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 1526.8328 - mae: 1526.8079 - val_loss: 1528.2494 - val_mae: 1528.2227 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 1497.4210 - mae: 1497.3929 - val_loss: 1498.8920 - val_mae: 1498.8624 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 1469.7798 - mae: 1469.7487 - val_loss: 1469.4252 - val_mae: 1469.3923 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1441.2915 - mae: 1441.2568 - val_loss: 1439.7101 - val_mae: 1439.6736 - lr: 0.0010\n",
      "Epoch 14/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 13ms/step - loss: 1412.9144 - mae: 1412.8763 - val_loss: 1411.0289 - val_mae: 1410.9888 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1383.2881 - mae: 1383.2461 - val_loss: 1383.4843 - val_mae: 1383.4402 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1358.8774 - mae: 1358.8315 - val_loss: 1356.4497 - val_mae: 1356.4015 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1331.3115 - mae: 1331.2616 - val_loss: 1327.8611 - val_mae: 1327.8086 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1300.7612 - mae: 1300.7069 - val_loss: 1298.3110 - val_mae: 1298.2542 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 1273.5969 - mae: 1273.5378 - val_loss: 1267.3666 - val_mae: 1267.3048 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1246.8627 - mae: 1246.7987 - val_loss: 1236.0498 - val_mae: 1235.9832 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 1813.6034\n",
      "LV_RMSE_12h: 2050.6438\n",
      "LV_MAE_24h: 302.1035\n",
      "LV_RMSE_24h: 470.2224\n",
      "LV_MAE_48h: 400.1351\n",
      "LV_RMSE_48h: 639.2029\n",
      "LV_MAE_72h: 339.2328\n",
      "LV_RMSE_72h: 555.0784\n",
      "LV_MAE_mean: 713.7686\n",
      "LV_RMSE_mean: 928.7869\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 1143.5453\n",
      "RMSE_12h: 1443.6316\n",
      "MAE_24h: 1098.1199\n",
      "RMSE_24h: 1398.4609\n",
      "MAE_48h: 1117.7455\n",
      "RMSE_48h: 1425.7054\n",
      "MAE_72h: 1111.3810\n",
      "RMSE_72h: 1413.0171\n",
      "MAE_mean: 1117.6979\n",
      "RMSE_mean: 1420.2037\n",
      "\n",
      "=== Station S3025084 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1377 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1354, 24, 400) Ytr2: (1354, 4) \n",
      "  Xva3: (197, 24, 400) Yva2: (197, 4) \n",
      "  Xte3: (348, 24, 400) Yte2: (348, 4)\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 3s 61ms/step - loss: 407.1414 - mae: 407.1285 - val_loss: 415.3670 - val_mae: 415.3542 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 401.7267 - mae: 401.7138 - val_loss: 407.8940 - val_mae: 407.8810 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 392.9084 - mae: 392.8952 - val_loss: 397.7702 - val_mae: 397.7566 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 382.4935 - mae: 382.4796 - val_loss: 386.7350 - val_mae: 386.7206 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 370.8715 - mae: 370.8565 - val_loss: 375.1086 - val_mae: 375.0929 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 359.0764 - mae: 359.0602 - val_loss: 362.3098 - val_mae: 362.2927 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 346.3287 - mae: 346.3109 - val_loss: 349.1532 - val_mae: 349.1343 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 333.5521 - mae: 333.5323 - val_loss: 335.7253 - val_mae: 335.7043 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 319.6326 - mae: 319.6107 - val_loss: 321.7011 - val_mae: 321.6779 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 305.8720 - mae: 305.8476 - val_loss: 307.6387 - val_mae: 307.6129 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 292.1031 - mae: 292.0760 - val_loss: 293.8405 - val_mae: 293.8119 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 279.1627 - mae: 279.1328 - val_loss: 279.1553 - val_mae: 279.1239 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 265.3620 - mae: 265.3293 - val_loss: 264.4953 - val_mae: 264.4610 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 251.2002 - mae: 251.1647 - val_loss: 248.0347 - val_mae: 247.9976 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 236.0495 - mae: 236.0110 - val_loss: 229.4011 - val_mae: 229.3609 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 218.0523 - mae: 218.0108 - val_loss: 213.0120 - val_mae: 212.9686 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 202.5568 - mae: 202.5120 - val_loss: 202.0247 - val_mae: 201.9780 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 193.1082 - mae: 193.0602 - val_loss: 190.9055 - val_mae: 190.8557 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 0s 19ms/step - loss: 185.1658 - mae: 185.1147 - val_loss: 183.9458 - val_mae: 183.8929 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 178.8178 - mae: 178.7637 - val_loss: 175.9727 - val_mae: 175.9170 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 540.5948\n",
      "LV_RMSE_12h: 627.0607\n",
      "LV_MAE_24h: 86.1149\n",
      "LV_RMSE_24h: 117.1398\n",
      "LV_MAE_48h: 104.1063\n",
      "LV_RMSE_48h: 148.8354\n",
      "LV_MAE_72h: 95.9799\n",
      "LV_RMSE_72h: 135.7325\n",
      "LV_MAE_mean: 206.6990\n",
      "LV_RMSE_mean: 257.1921\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 366.0752\n",
      "RMSE_12h: 456.3818\n",
      "MAE_24h: 124.1612\n",
      "RMSE_24h: 183.0517\n",
      "MAE_48h: 127.1234\n",
      "RMSE_48h: 186.2941\n",
      "MAE_72h: 127.2136\n",
      "RMSE_72h: 184.7156\n",
      "MAE_mean: 186.1434\n",
      "RMSE_mean: 252.6108\n",
      "\n",
      "=== Station S3025085 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1376 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1353, 24, 400) Ytr2: (1353, 4) \n",
      "  Xva3: (197, 24, 400) Yva2: (197, 4) \n",
      "  Xte3: (348, 24, 400) Yte2: (348, 4)\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 3s 59ms/step - loss: 170.2419 - mae: 170.2291 - val_loss: 179.6933 - val_mae: 179.6804 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 163.4071 - mae: 163.3941 - val_loss: 170.4808 - val_mae: 170.4677 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 153.7041 - mae: 153.6907 - val_loss: 160.2136 - val_mae: 160.1999 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 144.0135 - mae: 143.9995 - val_loss: 150.9142 - val_mae: 150.8998 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 135.7247 - mae: 135.7098 - val_loss: 142.5416 - val_mae: 142.5261 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 127.9664 - mae: 127.9505 - val_loss: 135.2173 - val_mae: 135.2007 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 121.5206 - mae: 121.5035 - val_loss: 128.9182 - val_mae: 128.9004 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 116.0561 - mae: 116.0378 - val_loss: 123.1804 - val_mae: 123.1614 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 111.4478 - mae: 111.4282 - val_loss: 118.2333 - val_mae: 118.2131 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 106.7440 - mae: 106.7233 - val_loss: 112.5431 - val_mae: 112.5218 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 101.2475 - mae: 101.2257 - val_loss: 106.1375 - val_mae: 106.1150 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 94.5586 - mae: 94.5356 - val_loss: 99.0859 - val_mae: 99.0623 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 88.7612 - mae: 88.7370 - val_loss: 92.4898 - val_mae: 92.4650 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 82.4202 - mae: 82.3949 - val_loss: 85.3045 - val_mae: 85.2784 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 76.2564 - mae: 76.2298 - val_loss: 79.1951 - val_mae: 79.1676 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 71.9724 - mae: 71.9444 - val_loss: 74.0529 - val_mae: 74.0241 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 69.5071 - mae: 69.4778 - val_loss: 71.7871 - val_mae: 71.7570 - lr: 0.0010\n",
      "Epoch 18/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 14ms/step - loss: 66.8290 - mae: 66.7984 - val_loss: 69.8669 - val_mae: 69.8357 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 64.4644 - mae: 64.4326 - val_loss: 67.3707 - val_mae: 67.3383 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 62.5016 - mae: 62.4687 - val_loss: 64.5854 - val_mae: 64.5519 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 189.5259\n",
      "LV_RMSE_12h: 220.8863\n",
      "LV_MAE_24h: 52.3362\n",
      "LV_RMSE_24h: 76.7621\n",
      "LV_MAE_48h: 65.5402\n",
      "LV_RMSE_48h: 93.4723\n",
      "LV_MAE_72h: 53.3362\n",
      "LV_RMSE_72h: 73.8757\n",
      "LV_MAE_mean: 90.1846\n",
      "LV_RMSE_mean: 116.2491\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 112.0533\n",
      "RMSE_12h: 141.8259\n",
      "MAE_24h: 47.3247\n",
      "RMSE_24h: 68.8445\n",
      "MAE_48h: 47.3964\n",
      "RMSE_48h: 69.3953\n",
      "MAE_72h: 46.0986\n",
      "RMSE_72h: 67.1528\n",
      "MAE_mean: 63.2183\n",
      "RMSE_mean: 86.8046\n",
      "\n",
      "=== Station S3026011 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1377 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1354, 24, 400) Ytr2: (1354, 4) \n",
      "  Xva3: (197, 24, 400) Yva2: (197, 4) \n",
      "  Xte3: (348, 24, 400) Yte2: (348, 4)\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 3s 62ms/step - loss: 1284.6873 - mae: 1284.6743 - val_loss: 1233.8909 - val_mae: 1233.8781 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1278.0323 - mae: 1278.0195 - val_loss: 1224.8486 - val_mae: 1224.8357 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1267.2238 - mae: 1267.2104 - val_loss: 1212.0947 - val_mae: 1212.0809 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1253.1604 - mae: 1253.1461 - val_loss: 1195.6445 - val_mae: 1195.6299 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1234.3286 - mae: 1234.3135 - val_loss: 1174.4919 - val_mae: 1174.4761 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1211.3590 - mae: 1211.3424 - val_loss: 1148.8373 - val_mae: 1148.8196 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1183.7751 - mae: 1183.7563 - val_loss: 1118.3206 - val_mae: 1118.3007 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 1150.9187 - mae: 1150.8976 - val_loss: 1082.7316 - val_mae: 1082.7091 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1112.9625 - mae: 1112.9385 - val_loss: 1042.5377 - val_mae: 1042.5121 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1070.7563 - mae: 1070.7290 - val_loss: 999.2527 - val_mae: 999.2233 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1026.1543 - mae: 1026.1232 - val_loss: 955.0068 - val_mae: 954.9734 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 981.4592 - mae: 981.4240 - val_loss: 914.8520 - val_mae: 914.8143 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 937.2836 - mae: 937.2439 - val_loss: 877.4498 - val_mae: 877.4075 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 894.4213 - mae: 894.3770 - val_loss: 841.8839 - val_mae: 841.8368 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 851.6140 - mae: 851.5650 - val_loss: 807.6122 - val_mae: 807.5602 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 812.5508 - mae: 812.4967 - val_loss: 777.1082 - val_mae: 777.0509 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 774.9819 - mae: 774.9224 - val_loss: 750.2010 - val_mae: 750.1387 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 741.7280 - mae: 741.6635 - val_loss: 727.2609 - val_mae: 727.1936 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 717.9621 - mae: 717.8925 - val_loss: 706.2537 - val_mae: 706.1815 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 692.8400 - mae: 692.7658 - val_loss: 687.1671 - val_mae: 687.0903 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 903.5690\n",
      "LV_RMSE_12h: 1096.6211\n",
      "LV_MAE_24h: 177.4138\n",
      "LV_RMSE_24h: 275.6577\n",
      "LV_MAE_48h: 275.0115\n",
      "LV_RMSE_48h: 393.1933\n",
      "LV_MAE_72h: 305.4684\n",
      "LV_RMSE_72h: 424.5325\n",
      "LV_MAE_mean: 415.3657\n",
      "LV_RMSE_mean: 547.5012\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 518.8956\n",
      "RMSE_12h: 669.3073\n",
      "MAE_24h: 511.0864\n",
      "RMSE_24h: 665.0586\n",
      "MAE_48h: 517.7732\n",
      "RMSE_48h: 680.5754\n",
      "MAE_72h: 522.6621\n",
      "RMSE_72h: 689.2704\n",
      "MAE_mean: 517.6044\n",
      "RMSE_mean: 676.0530\n",
      "\n",
      "=== Station S3026012 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1377 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1354, 24, 400) Ytr2: (1354, 4) \n",
      "  Xva3: (197, 24, 400) Yva2: (197, 4) \n",
      "  Xte3: (348, 24, 400) Yte2: (348, 4)\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 3s 60ms/step - loss: 1232.1710 - mae: 1232.1581 - val_loss: 1205.9869 - val_mae: 1205.9742 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 1227.0552 - mae: 1227.0424 - val_loss: 1198.7200 - val_mae: 1198.7070 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1218.2502 - mae: 1218.2372 - val_loss: 1188.1324 - val_mae: 1188.1191 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1206.3972 - mae: 1206.3837 - val_loss: 1174.0181 - val_mae: 1174.0040 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 1190.3317 - mae: 1190.3173 - val_loss: 1155.9648 - val_mae: 1155.9497 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1170.3407 - mae: 1170.3247 - val_loss: 1133.7023 - val_mae: 1133.6854 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1146.3560 - mae: 1146.3386 - val_loss: 1107.1053 - val_mae: 1107.0868 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1117.6190 - mae: 1117.5994 - val_loss: 1075.9941 - val_mae: 1075.9731 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1085.2733 - mae: 1085.2513 - val_loss: 1040.3909 - val_mae: 1040.3672 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1046.5120 - mae: 1046.4869 - val_loss: 1000.7823 - val_mae: 1000.7555 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1006.4034 - mae: 1006.3752 - val_loss: 960.2882 - val_mae: 960.2578 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 963.7657 - mae: 963.7336 - val_loss: 920.9630 - val_mae: 920.9288 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 922.2475 - mae: 922.2114 - val_loss: 882.1867 - val_mae: 882.1483 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 880.6762 - mae: 880.6360 - val_loss: 845.0263 - val_mae: 844.9835 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 838.1522 - mae: 838.1075 - val_loss: 809.7413 - val_mae: 809.6940 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 799.4742 - mae: 799.4249 - val_loss: 776.1714 - val_mae: 776.1192 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 761.7698 - mae: 761.7156 - val_loss: 743.5001 - val_mae: 743.4429 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 721.6818 - mae: 721.6226 - val_loss: 713.3682 - val_mae: 713.3061 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 692.3594 - mae: 692.2952 - val_loss: 686.7523 - val_mae: 686.6854 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 666.0788 - mae: 666.0098 - val_loss: 662.5897 - val_mae: 662.5180 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 744.6322\n",
      "LV_RMSE_12h: 894.2341\n",
      "LV_MAE_24h: 166.9167\n",
      "LV_RMSE_24h: 281.5022\n",
      "LV_MAE_48h: 250.4598\n",
      "LV_RMSE_48h: 382.8803\n",
      "LV_MAE_72h: 294.0489\n",
      "LV_RMSE_72h: 425.3582\n",
      "LV_MAE_mean: 364.0144\n",
      "LV_RMSE_mean: 495.9937\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 439.1700\n",
      "RMSE_12h: 578.5500\n",
      "MAE_24h: 427.9634\n",
      "RMSE_24h: 562.3219\n",
      "MAE_48h: 436.2180\n",
      "RMSE_48h: 575.6958\n",
      "MAE_72h: 440.0638\n",
      "RMSE_72h: 582.0835\n",
      "MAE_mean: 435.8538\n",
      "RMSE_mean: 574.6628\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Station S3026021 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1377 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1354, 24, 400) Ytr2: (1354, 4) \n",
      "  Xva3: (197, 24, 400) Yva2: (197, 4) \n",
      "  Xte3: (348, 24, 400) Yte2: (348, 4)\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 3s 59ms/step - loss: 1103.3555 - mae: 1103.3425 - val_loss: 1049.0642 - val_mae: 1049.0513 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1097.6162 - mae: 1097.6033 - val_loss: 1040.7775 - val_mae: 1040.7643 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1087.5470 - mae: 1087.5336 - val_loss: 1028.6884 - val_mae: 1028.6747 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1073.9417 - mae: 1073.9275 - val_loss: 1012.4264 - val_mae: 1012.4117 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1055.3438 - mae: 1055.3286 - val_loss: 991.4000 - val_mae: 991.3839 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1032.0161 - mae: 1031.9994 - val_loss: 965.2208 - val_mae: 965.2029 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1003.9194 - mae: 1003.9005 - val_loss: 933.7176 - val_mae: 933.6972 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 969.3619 - mae: 969.3403 - val_loss: 896.8992 - val_mae: 896.8760 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 930.9944 - mae: 930.9697 - val_loss: 857.0488 - val_mae: 857.0222 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 888.8357 - mae: 888.8075 - val_loss: 816.3621 - val_mae: 816.3318 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 847.7533 - mae: 847.7212 - val_loss: 777.5522 - val_mae: 777.5176 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 809.3873 - mae: 809.3509 - val_loss: 743.2518 - val_mae: 743.2130 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 777.1216 - mae: 777.0810 - val_loss: 713.9539 - val_mae: 713.9108 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 749.3754 - mae: 749.3306 - val_loss: 688.6685 - val_mae: 688.6213 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 722.1743 - mae: 722.1254 - val_loss: 664.9603 - val_mae: 664.9091 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 700.4293 - mae: 700.3762 - val_loss: 642.4232 - val_mae: 642.3677 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 678.3667 - mae: 678.3093 - val_loss: 620.3701 - val_mae: 620.3103 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 654.1677 - mae: 654.1060 - val_loss: 599.0668 - val_mae: 599.0026 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 632.9952 - mae: 632.9291 - val_loss: 574.9910 - val_mae: 574.9222 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 605.8235 - mae: 605.7526 - val_loss: 542.8901 - val_mae: 542.8165 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 1051.4971\n",
      "LV_RMSE_12h: 1194.2067\n",
      "LV_MAE_24h: 178.7414\n",
      "LV_RMSE_24h: 249.0041\n",
      "LV_MAE_48h: 224.1552\n",
      "LV_RMSE_48h: 317.4717\n",
      "LV_MAE_72h: 207.6063\n",
      "LV_RMSE_72h: 286.1035\n",
      "LV_MAE_mean: 415.5000\n",
      "LV_RMSE_mean: 511.6965\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 642.5107\n",
      "RMSE_12h: 795.7295\n",
      "MAE_24h: 510.7297\n",
      "RMSE_24h: 676.9020\n",
      "MAE_48h: 499.9765\n",
      "RMSE_48h: 660.4620\n",
      "MAE_72h: 493.1398\n",
      "RMSE_72h: 652.1105\n",
      "MAE_mean: 536.5892\n",
      "RMSE_mean: 696.3010\n",
      "\n",
      "=== Station S3026022 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1223 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1200, 24, 400) Ytr2: (1200, 4) \n",
      "  Xva3: (175, 24, 400) Yva2: (175, 4) \n",
      "  Xte3: (304, 24, 400) Yte2: (304, 4)\n",
      "Epoch 1/20\n",
      "10/10 [==============================] - 3s 68ms/step - loss: 180.5152 - mae: 180.5025 - val_loss: 184.6718 - val_mae: 184.6590 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 173.8693 - mae: 173.8564 - val_loss: 175.7404 - val_mae: 175.7273 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 163.5160 - mae: 163.5027 - val_loss: 164.2345 - val_mae: 164.2209 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 151.4714 - mae: 151.4575 - val_loss: 151.5581 - val_mae: 151.5437 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 137.9506 - mae: 137.9357 - val_loss: 137.1656 - val_mae: 137.1501 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 123.4674 - mae: 123.4514 - val_loss: 122.1385 - val_mae: 122.1215 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 108.6812 - mae: 108.6635 - val_loss: 107.0760 - val_mae: 107.0574 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 94.5646 - mae: 94.5453 - val_loss: 94.8798 - val_mae: 94.8594 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 85.1341 - mae: 85.1130 - val_loss: 87.8313 - val_mae: 87.8093 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 81.4848 - mae: 81.4623 - val_loss: 85.3527 - val_mae: 85.3295 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 80.6332 - mae: 80.6099 - val_loss: 84.7688 - val_mae: 84.7453 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 80.2457 - mae: 80.2222 - val_loss: 83.8005 - val_mae: 83.7772 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 78.0384 - mae: 78.0151 - val_loss: 80.2082 - val_mae: 80.1849 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 73.9930 - mae: 73.9695 - val_loss: 76.5142 - val_mae: 76.4905 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 71.2446 - mae: 71.2207 - val_loss: 72.8228 - val_mae: 72.7986 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 68.8076 - mae: 68.7832 - val_loss: 70.6523 - val_mae: 70.6276 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 67.5058 - mae: 67.4810 - val_loss: 68.8257 - val_mae: 68.8008 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 65.7251 - mae: 65.7000 - val_loss: 67.6059 - val_mae: 67.5806 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 64.1733 - mae: 64.1478 - val_loss: 66.2945 - val_mae: 66.2687 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 62.7359 - mae: 62.7099 - val_loss: 64.6104 - val_mae: 64.5842 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 124.1513\n",
      "LV_RMSE_12h: 154.8260\n",
      "LV_MAE_24h: 49.2467\n",
      "LV_RMSE_24h: 78.4639\n",
      "LV_MAE_48h: 62.1743\n",
      "LV_RMSE_48h: 94.2961\n",
      "LV_MAE_72h: 54.9770\n",
      "LV_RMSE_72h: 75.8476\n",
      "LV_MAE_mean: 72.6373\n",
      "LV_RMSE_mean: 100.8584\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 91.6733\n",
      "RMSE_12h: 120.0987\n",
      "MAE_24h: 46.7602\n",
      "RMSE_24h: 70.9463\n",
      "MAE_48h: 47.4277\n",
      "RMSE_48h: 71.8375\n",
      "MAE_72h: 48.1380\n",
      "RMSE_72h: 72.2884\n",
      "MAE_mean: 58.4998\n",
      "RMSE_mean: 83.7927\n",
      "\n",
      "=== Station S3026023 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1377 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1354, 24, 400) Ytr2: (1354, 4) \n",
      "  Xva3: (197, 24, 400) Yva2: (197, 4) \n",
      "  Xte3: (348, 24, 400) Yte2: (348, 4)\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 3s 61ms/step - loss: 1111.7758 - mae: 1111.7631 - val_loss: 1064.8480 - val_mae: 1064.8353 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1107.1982 - mae: 1107.1854 - val_loss: 1058.0259 - val_mae: 1058.0131 - lr: 0.0010\n",
      "Epoch 3/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 13ms/step - loss: 1098.8367 - mae: 1098.8236 - val_loss: 1048.0804 - val_mae: 1048.0671 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1087.7089 - mae: 1087.6952 - val_loss: 1035.4602 - val_mae: 1035.4462 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1073.6501 - mae: 1073.6357 - val_loss: 1019.5540 - val_mae: 1019.5389 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1055.9132 - mae: 1055.8978 - val_loss: 1000.0170 - val_mae: 1000.0006 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1034.8511 - mae: 1034.8339 - val_loss: 976.7311 - val_mae: 976.7131 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1010.0584 - mae: 1010.0396 - val_loss: 949.3774 - val_mae: 949.3575 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 981.0880 - mae: 981.0668 - val_loss: 918.1505 - val_mae: 918.1281 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 947.9450 - mae: 947.9215 - val_loss: 883.7004 - val_mae: 883.6751 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 912.1515 - mae: 912.1249 - val_loss: 848.0821 - val_mae: 848.0538 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 877.6075 - mae: 877.5778 - val_loss: 814.5920 - val_mae: 814.5604 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 845.4709 - mae: 845.4378 - val_loss: 783.5219 - val_mae: 783.4868 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 814.0856 - mae: 814.0490 - val_loss: 754.9221 - val_mae: 754.8834 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 784.1169 - mae: 784.0767 - val_loss: 727.9531 - val_mae: 727.9108 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 759.6790 - mae: 759.6352 - val_loss: 703.6040 - val_mae: 703.5580 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 735.8260 - mae: 735.7784 - val_loss: 679.9564 - val_mae: 679.9067 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 710.1472 - mae: 710.0959 - val_loss: 657.8904 - val_mae: 657.8369 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 690.4899 - mae: 690.4347 - val_loss: 636.2051 - val_mae: 636.1476 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 668.0041 - mae: 667.9449 - val_loss: 615.3751 - val_mae: 615.3136 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 919.5891\n",
      "LV_RMSE_12h: 1007.0914\n",
      "LV_MAE_24h: 174.6035\n",
      "LV_RMSE_24h: 269.3351\n",
      "LV_MAE_48h: 223.2586\n",
      "LV_RMSE_48h: 342.2437\n",
      "LV_MAE_72h: 199.4167\n",
      "LV_RMSE_72h: 291.5251\n",
      "LV_MAE_mean: 379.2169\n",
      "LV_RMSE_mean: 477.5488\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 561.7260\n",
      "RMSE_12h: 675.1184\n",
      "MAE_24h: 552.3159\n",
      "RMSE_24h: 658.1339\n",
      "MAE_48h: 551.8990\n",
      "RMSE_48h: 658.3398\n",
      "MAE_72h: 551.1647\n",
      "RMSE_72h: 659.8911\n",
      "MAE_mean: 554.2764\n",
      "RMSE_mean: 662.8708\n",
      "\n",
      "=== Station S3026024 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1242 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1219, 24, 400) Ytr2: (1219, 4) \n",
      "  Xva3: (178, 24, 400) Yva2: (178, 4) \n",
      "  Xte3: (309, 24, 400) Yte2: (309, 4)\n",
      "Epoch 1/20\n",
      "10/10 [==============================] - 3s 65ms/step - loss: 120.9734 - mae: 120.9607 - val_loss: 119.2072 - val_mae: 119.1946 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 115.7781 - mae: 115.7654 - val_loss: 112.1639 - val_mae: 112.1511 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 107.7785 - mae: 107.7655 - val_loss: 103.1344 - val_mae: 103.1212 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 98.2110 - mae: 98.1976 - val_loss: 93.1277 - val_mae: 93.1139 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 87.5250 - mae: 87.5109 - val_loss: 82.0859 - val_mae: 82.0713 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 76.5257 - mae: 76.5107 - val_loss: 70.6735 - val_mae: 70.6579 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 65.9224 - mae: 65.9063 - val_loss: 60.4363 - val_mae: 60.4194 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 57.8833 - mae: 57.8659 - val_loss: 53.1357 - val_mae: 53.1177 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 53.0277 - mae: 53.0092 - val_loss: 49.1557 - val_mae: 49.1367 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 51.3999 - mae: 51.3806 - val_loss: 47.6317 - val_mae: 47.6122 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 50.5039 - mae: 50.4843 - val_loss: 46.2396 - val_mae: 46.2200 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 48.8018 - mae: 48.7822 - val_loss: 44.3187 - val_mae: 44.2992 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 46.0997 - mae: 46.0802 - val_loss: 42.1019 - val_mae: 42.0823 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 43.7243 - mae: 43.7045 - val_loss: 39.8272 - val_mae: 39.8073 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 42.5933 - mae: 42.5732 - val_loss: 38.3243 - val_mae: 38.3040 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 41.4312 - mae: 41.4109 - val_loss: 37.1700 - val_mae: 37.1496 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 40.1713 - mae: 40.1508 - val_loss: 36.4141 - val_mae: 36.3935 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 39.6059 - mae: 39.5852 - val_loss: 35.6460 - val_mae: 35.6251 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 38.4656 - mae: 38.4446 - val_loss: 34.8305 - val_mae: 34.8093 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 37.6953 - mae: 37.6739 - val_loss: 33.9278 - val_mae: 33.9062 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 79.2751\n",
      "LV_RMSE_12h: 90.5322\n",
      "LV_MAE_24h: 29.7638\n",
      "LV_RMSE_24h: 39.2873\n",
      "LV_MAE_48h: 33.5469\n",
      "LV_RMSE_48h: 44.3238\n",
      "LV_MAE_72h: 31.9741\n",
      "LV_RMSE_72h: 43.6805\n",
      "LV_MAE_mean: 43.6400\n",
      "LV_RMSE_mean: 54.4559\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 55.6684\n",
      "RMSE_12h: 64.7556\n",
      "MAE_24h: 25.4238\n",
      "RMSE_24h: 33.2251\n",
      "MAE_48h: 25.3220\n",
      "RMSE_48h: 33.0735\n",
      "MAE_72h: 26.8983\n",
      "RMSE_72h: 34.6141\n",
      "MAE_mean: 33.3282\n",
      "RMSE_mean: 41.4171\n",
      "\n",
      "=== Station S3026051 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1377 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1354, 24, 400) Ytr2: (1354, 4) \n",
      "  Xva3: (197, 24, 400) Yva2: (197, 4) \n",
      "  Xte3: (348, 24, 400) Yte2: (348, 4)\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 3s 60ms/step - loss: 1663.2834 - mae: 1663.2706 - val_loss: 1632.8647 - val_mae: 1632.8518 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1656.0800 - mae: 1656.0673 - val_loss: 1622.8198 - val_mae: 1622.8066 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1644.3313 - mae: 1644.3177 - val_loss: 1609.2615 - val_mae: 1609.2477 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1629.2493 - mae: 1629.2350 - val_loss: 1591.5867 - val_mae: 1591.5719 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1609.1370 - mae: 1609.1215 - val_loss: 1569.1536 - val_mae: 1569.1372 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1584.7118 - mae: 1584.6946 - val_loss: 1541.7493 - val_mae: 1541.7310 - lr: 0.0010\n",
      "Epoch 7/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 13ms/step - loss: 1555.2317 - mae: 1555.2125 - val_loss: 1508.9349 - val_mae: 1508.9142 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1519.5156 - mae: 1519.4937 - val_loss: 1470.4359 - val_mae: 1470.4122 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1479.3362 - mae: 1479.3110 - val_loss: 1426.5242 - val_mae: 1426.4969 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1433.2184 - mae: 1433.1896 - val_loss: 1380.4396 - val_mae: 1380.4086 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1386.8816 - mae: 1386.8488 - val_loss: 1336.1820 - val_mae: 1336.1466 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1343.4733 - mae: 1343.4362 - val_loss: 1293.2650 - val_mae: 1293.2252 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1300.4536 - mae: 1300.4116 - val_loss: 1253.4181 - val_mae: 1253.3737 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 1260.6227 - mae: 1260.5762 - val_loss: 1215.3071 - val_mae: 1215.2578 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 1220.2513 - mae: 1220.1997 - val_loss: 1178.8239 - val_mae: 1178.7694 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 1185.8964 - mae: 1185.8398 - val_loss: 1145.3762 - val_mae: 1145.3167 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1153.4104 - mae: 1153.3486 - val_loss: 1114.5253 - val_mae: 1114.4604 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1118.4579 - mae: 1118.3906 - val_loss: 1082.4854 - val_mae: 1082.4153 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 1088.2650 - mae: 1088.1926 - val_loss: 1050.8033 - val_mae: 1050.7277 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1055.5212 - mae: 1055.4432 - val_loss: 1019.3984 - val_mae: 1019.3171 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 1657.7299\n",
      "LV_RMSE_12h: 1951.0981\n",
      "LV_MAE_24h: 296.5258\n",
      "LV_RMSE_24h: 449.4717\n",
      "LV_MAE_48h: 391.7040\n",
      "LV_RMSE_48h: 585.4225\n",
      "LV_MAE_72h: 336.7471\n",
      "LV_RMSE_72h: 493.2320\n",
      "LV_MAE_mean: 670.6767\n",
      "LV_RMSE_mean: 869.8061\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 980.8727\n",
      "RMSE_12h: 1290.3773\n",
      "MAE_24h: 940.4611\n",
      "RMSE_24h: 1245.6556\n",
      "MAE_48h: 963.6943\n",
      "RMSE_48h: 1283.4153\n",
      "MAE_72h: 956.5229\n",
      "RMSE_72h: 1275.5457\n",
      "MAE_mean: 960.3878\n",
      "RMSE_mean: 1273.7485\n",
      "\n",
      "=== Station S3026052 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1377 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1354, 24, 400) Ytr2: (1354, 4) \n",
      "  Xva3: (197, 24, 400) Yva2: (197, 4) \n",
      "  Xte3: (348, 24, 400) Yte2: (348, 4)\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 3s 58ms/step - loss: 1678.4824 - mae: 1678.4697 - val_loss: 1693.4020 - val_mae: 1693.3893 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1673.7294 - mae: 1673.7164 - val_loss: 1686.4655 - val_mae: 1686.4525 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1665.2753 - mae: 1665.2622 - val_loss: 1676.4829 - val_mae: 1676.4694 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1654.2035 - mae: 1654.1899 - val_loss: 1663.5150 - val_mae: 1663.5010 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1639.3263 - mae: 1639.3116 - val_loss: 1646.8074 - val_mae: 1646.7924 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1620.9423 - mae: 1620.9265 - val_loss: 1626.2271 - val_mae: 1626.2103 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1598.7078 - mae: 1598.6902 - val_loss: 1601.5625 - val_mae: 1601.5443 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1572.4701 - mae: 1572.4509 - val_loss: 1572.6906 - val_mae: 1572.6700 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1541.2241 - mae: 1541.2025 - val_loss: 1539.4847 - val_mae: 1539.4618 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1506.0604 - mae: 1506.0361 - val_loss: 1501.8696 - val_mae: 1501.8434 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1466.4420 - mae: 1466.4144 - val_loss: 1459.8745 - val_mae: 1459.8450 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 1424.3157 - mae: 1424.2845 - val_loss: 1413.9133 - val_mae: 1413.8801 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1377.2150 - mae: 1377.1798 - val_loss: 1366.7419 - val_mae: 1366.7045 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1331.0780 - mae: 1331.0386 - val_loss: 1321.4731 - val_mae: 1321.4315 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1286.7513 - mae: 1286.7076 - val_loss: 1279.1967 - val_mae: 1279.1504 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1245.1318 - mae: 1245.0835 - val_loss: 1238.5663 - val_mae: 1238.5154 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1207.5471 - mae: 1207.4941 - val_loss: 1200.8663 - val_mae: 1200.8105 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1169.0424 - mae: 1168.9846 - val_loss: 1166.4794 - val_mae: 1166.4189 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 1134.4904 - mae: 1134.4280 - val_loss: 1133.5889 - val_mae: 1133.5237 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1104.3834 - mae: 1104.3160 - val_loss: 1103.4589 - val_mae: 1103.3888 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 1596.8793\n",
      "LV_RMSE_12h: 1776.8245\n",
      "LV_MAE_24h: 354.6264\n",
      "LV_RMSE_24h: 534.0552\n",
      "LV_MAE_48h: 457.6178\n",
      "LV_RMSE_48h: 695.0616\n",
      "LV_MAE_72h: 403.5057\n",
      "LV_RMSE_72h: 625.5969\n",
      "LV_MAE_mean: 703.1573\n",
      "LV_RMSE_mean: 907.8845\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 1055.3877\n",
      "RMSE_12h: 1334.7340\n",
      "MAE_24h: 1095.8461\n",
      "RMSE_24h: 1376.2014\n",
      "MAE_48h: 1093.6659\n",
      "RMSE_48h: 1373.2087\n",
      "MAE_72h: 1065.5255\n",
      "RMSE_72h: 1333.9318\n",
      "MAE_mean: 1077.6063\n",
      "RMSE_mean: 1354.5190\n",
      "\n",
      "=== Station S3026053 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1376 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1353, 24, 400) Ytr2: (1353, 4) \n",
      "  Xva3: (197, 24, 400) Yva2: (197, 4) \n",
      "  Xte3: (348, 24, 400) Yte2: (348, 4)\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 3s 60ms/step - loss: 288.1742 - mae: 288.1613 - val_loss: 294.7253 - val_mae: 294.7125 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 282.0798 - mae: 282.0669 - val_loss: 285.8505 - val_mae: 285.8375 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 271.0586 - mae: 271.0453 - val_loss: 272.5709 - val_mae: 272.5573 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 256.2280 - mae: 256.2141 - val_loss: 255.6822 - val_mae: 255.6678 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 238.0791 - mae: 238.0642 - val_loss: 236.0180 - val_mae: 236.0023 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 217.9436 - mae: 217.9272 - val_loss: 216.4677 - val_mae: 216.4503 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 198.2859 - mae: 198.2678 - val_loss: 198.2875 - val_mae: 198.2683 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 180.9240 - mae: 180.9039 - val_loss: 183.2055 - val_mae: 183.1842 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 167.2355 - mae: 167.2133 - val_loss: 170.8593 - val_mae: 170.8359 - lr: 0.0010\n",
      "Epoch 10/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 14ms/step - loss: 155.6764 - mae: 155.6522 - val_loss: 161.6243 - val_mae: 161.5990 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 147.9126 - mae: 147.8865 - val_loss: 155.3123 - val_mae: 155.2852 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 144.2769 - mae: 144.2491 - val_loss: 151.4365 - val_mae: 151.4080 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 141.7737 - mae: 141.7448 - val_loss: 148.8873 - val_mae: 148.8578 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 138.7177 - mae: 138.6878 - val_loss: 144.0777 - val_mae: 144.0474 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 132.3474 - mae: 132.3168 - val_loss: 134.7323 - val_mae: 134.7012 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 125.4210 - mae: 125.3895 - val_loss: 127.7002 - val_mae: 127.6680 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 119.8936 - mae: 119.8608 - val_loss: 122.2536 - val_mae: 122.2201 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 115.3224 - mae: 115.2884 - val_loss: 118.4351 - val_mae: 118.4003 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 112.9304 - mae: 112.8951 - val_loss: 115.5165 - val_mae: 115.4804 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 109.0490 - mae: 109.0123 - val_loss: 111.6839 - val_mae: 111.6465 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 247.8103\n",
      "LV_RMSE_12h: 286.1934\n",
      "LV_MAE_24h: 72.8937\n",
      "LV_RMSE_24h: 104.6972\n",
      "LV_MAE_48h: 91.0086\n",
      "LV_RMSE_48h: 125.9701\n",
      "LV_MAE_72h: 79.8621\n",
      "LV_RMSE_72h: 114.1609\n",
      "LV_MAE_mean: 122.8937\n",
      "LV_RMSE_mean: 157.7554\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 178.6038\n",
      "RMSE_12h: 212.4147\n",
      "MAE_24h: 83.3248\n",
      "RMSE_24h: 104.4099\n",
      "MAE_48h: 82.4735\n",
      "RMSE_48h: 104.0270\n",
      "MAE_72h: 83.7047\n",
      "RMSE_72h: 104.7403\n",
      "MAE_mean: 107.0267\n",
      "RMSE_mean: 131.3980\n",
      "\n",
      "=== Station S3026054 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1132 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1109, 24, 400) Ytr2: (1109, 4) \n",
      "  Xva3: (162, 24, 400) Yva2: (162, 4) \n",
      "  Xte3: (278, 24, 400) Yte2: (278, 4)\n",
      "Epoch 1/20\n",
      "9/9 [==============================] - 3s 67ms/step - loss: 47.6649 - mae: 47.6521 - val_loss: 48.1576 - val_mae: 48.1448 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 44.0263 - mae: 44.0134 - val_loss: 43.8056 - val_mae: 43.7926 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 39.1315 - mae: 39.1184 - val_loss: 39.3665 - val_mae: 39.3532 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 34.9049 - mae: 34.8914 - val_loss: 35.7713 - val_mae: 35.7575 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 31.8873 - mae: 31.8732 - val_loss: 33.2906 - val_mae: 33.2762 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 29.8250 - mae: 29.8104 - val_loss: 31.7300 - val_mae: 31.7152 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 28.6397 - mae: 28.6248 - val_loss: 30.1763 - val_mae: 30.1612 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 27.0683 - mae: 27.0533 - val_loss: 28.3613 - val_mae: 28.3462 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 25.4128 - mae: 25.3976 - val_loss: 26.3364 - val_mae: 26.3212 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 23.6831 - mae: 23.6677 - val_loss: 24.3781 - val_mae: 24.3626 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 22.2134 - mae: 22.1977 - val_loss: 22.4241 - val_mae: 22.4083 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 20.9591 - mae: 20.9432 - val_loss: 21.1267 - val_mae: 21.1106 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 20.0756 - mae: 20.0594 - val_loss: 20.1293 - val_mae: 20.1129 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 19.2323 - mae: 19.2157 - val_loss: 18.9369 - val_mae: 18.9201 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 18.1850 - mae: 18.1680 - val_loss: 17.8916 - val_mae: 17.8743 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 17.2609 - mae: 17.2433 - val_loss: 16.6292 - val_mae: 16.6114 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 16.7137 - mae: 16.6956 - val_loss: 16.1583 - val_mae: 16.1399 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 16.2416 - mae: 16.2230 - val_loss: 15.8210 - val_mae: 15.8023 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 15.7842 - mae: 15.7654 - val_loss: 15.2146 - val_mae: 15.1956 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 15.3766 - mae: 15.3574 - val_loss: 15.0017 - val_mae: 14.9824 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 51.1691\n",
      "LV_RMSE_12h: 59.7667\n",
      "LV_MAE_24h: 15.7446\n",
      "LV_RMSE_24h: 23.5350\n",
      "LV_MAE_48h: 21.2446\n",
      "LV_RMSE_48h: 31.4622\n",
      "LV_MAE_72h: 19.1187\n",
      "LV_RMSE_72h: 31.0925\n",
      "LV_MAE_mean: 26.8192\n",
      "LV_RMSE_mean: 36.4641\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 14.7568\n",
      "RMSE_12h: 23.7816\n",
      "MAE_24h: 16.3947\n",
      "RMSE_24h: 24.1127\n",
      "MAE_48h: 15.3546\n",
      "RMSE_48h: 23.0345\n",
      "MAE_72h: 14.6031\n",
      "RMSE_72h: 21.1939\n",
      "MAE_mean: 15.2773\n",
      "RMSE_mean: 23.0307\n",
      "\n",
      "=== Station S3026061 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1377 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1354, 24, 400) Ytr2: (1354, 4) \n",
      "  Xva3: (197, 24, 400) Yva2: (197, 4) \n",
      "  Xte3: (348, 24, 400) Yte2: (348, 4)\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 3s 59ms/step - loss: 168.5907 - mae: 168.5779 - val_loss: 153.0814 - val_mae: 153.0685 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 164.1992 - mae: 164.1862 - val_loss: 147.5057 - val_mae: 147.4927 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 158.2132 - mae: 158.2001 - val_loss: 141.6653 - val_mae: 141.6519 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 152.2550 - mae: 152.2413 - val_loss: 136.0706 - val_mae: 136.0566 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 146.0692 - mae: 146.0548 - val_loss: 130.7287 - val_mae: 130.7138 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 140.4606 - mae: 140.4453 - val_loss: 125.6857 - val_mae: 125.6697 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 134.9483 - mae: 134.9318 - val_loss: 120.7995 - val_mae: 120.7823 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 129.4320 - mae: 129.4144 - val_loss: 115.5696 - val_mae: 115.5513 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 123.8317 - mae: 123.8129 - val_loss: 110.1625 - val_mae: 110.1429 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 117.7173 - mae: 117.6972 - val_loss: 103.8324 - val_mae: 103.8115 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 111.2756 - mae: 111.2540 - val_loss: 97.7608 - val_mae: 97.7383 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 104.4625 - mae: 104.4393 - val_loss: 92.1620 - val_mae: 92.1377 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 98.6878 - mae: 98.6627 - val_loss: 85.8166 - val_mae: 85.7904 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 92.3690 - mae: 92.3418 - val_loss: 80.9974 - val_mae: 80.9689 - lr: 0.0010\n",
      "Epoch 15/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 15ms/step - loss: 86.8627 - mae: 86.8332 - val_loss: 76.4695 - val_mae: 76.4386 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 82.3652 - mae: 82.3332 - val_loss: 72.8674 - val_mae: 72.8340 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 78.6408 - mae: 78.6064 - val_loss: 71.0957 - val_mae: 71.0599 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 75.7548 - mae: 75.7181 - val_loss: 68.8722 - val_mae: 68.8342 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 72.8267 - mae: 72.7877 - val_loss: 65.0235 - val_mae: 64.9834 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 69.4539 - mae: 69.4128 - val_loss: 62.8293 - val_mae: 62.7870 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 234.5891\n",
      "LV_RMSE_12h: 288.0907\n",
      "LV_MAE_24h: 49.8506\n",
      "LV_RMSE_24h: 82.7668\n",
      "LV_MAE_48h: 64.6264\n",
      "LV_RMSE_48h: 109.7314\n",
      "LV_MAE_72h: 56.3506\n",
      "LV_RMSE_72h: 96.8032\n",
      "LV_MAE_mean: 101.3542\n",
      "LV_RMSE_mean: 144.3480\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 102.2929\n",
      "RMSE_12h: 170.3608\n",
      "MAE_24h: 50.3076\n",
      "RMSE_24h: 80.3732\n",
      "MAE_48h: 49.0934\n",
      "RMSE_48h: 78.5578\n",
      "MAE_72h: 49.4005\n",
      "RMSE_72h: 79.3241\n",
      "MAE_mean: 62.7736\n",
      "RMSE_mean: 102.1540\n",
      "\n",
      "=== Station S3026091 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1377 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1354, 24, 400) Ytr2: (1354, 4) \n",
      "  Xva3: (197, 24, 400) Yva2: (197, 4) \n",
      "  Xte3: (348, 24, 400) Yte2: (348, 4)\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 3s 57ms/step - loss: 1817.1296 - mae: 1817.1168 - val_loss: 1750.4296 - val_mae: 1750.4167 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1810.8438 - mae: 1810.8308 - val_loss: 1741.5784 - val_mae: 1741.5652 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 1800.3512 - mae: 1800.3376 - val_loss: 1729.2504 - val_mae: 1729.2366 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1786.3724 - mae: 1786.3584 - val_loss: 1712.6548 - val_mae: 1712.6403 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1767.4834 - mae: 1767.4679 - val_loss: 1691.1494 - val_mae: 1691.1333 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1743.5388 - mae: 1743.5220 - val_loss: 1664.5320 - val_mae: 1664.5142 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1714.7803 - mae: 1714.7612 - val_loss: 1632.5762 - val_mae: 1632.5555 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 1680.4161 - mae: 1680.3944 - val_loss: 1594.9448 - val_mae: 1594.9215 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1640.5833 - mae: 1640.5583 - val_loss: 1551.7861 - val_mae: 1551.7594 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1594.5006 - mae: 1594.4723 - val_loss: 1503.9364 - val_mae: 1503.9056 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1546.1505 - mae: 1546.1178 - val_loss: 1453.3778 - val_mae: 1453.3428 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1492.4930 - mae: 1492.4561 - val_loss: 1401.5391 - val_mae: 1401.4990 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1440.7445 - mae: 1440.7025 - val_loss: 1350.5930 - val_mae: 1350.5477 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1390.0166 - mae: 1389.9691 - val_loss: 1301.0573 - val_mae: 1301.0068 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1336.1068 - mae: 1336.0540 - val_loss: 1250.4331 - val_mae: 1250.3770 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1286.4529 - mae: 1286.3940 - val_loss: 1198.9453 - val_mae: 1198.8831 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1232.9111 - mae: 1232.8461 - val_loss: 1145.9762 - val_mae: 1145.9075 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1174.4324 - mae: 1174.3608 - val_loss: 1091.9038 - val_mae: 1091.8282 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1122.8888 - mae: 1122.8102 - val_loss: 1038.2300 - val_mae: 1038.1473 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 1069.7961 - mae: 1069.7103 - val_loss: 986.1975 - val_mae: 986.1075 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 1191.5891\n",
      "LV_RMSE_12h: 1364.1094\n",
      "LV_MAE_24h: 249.1954\n",
      "LV_RMSE_24h: 356.6219\n",
      "LV_MAE_48h: 327.3592\n",
      "LV_RMSE_48h: 447.3017\n",
      "LV_MAE_72h: 307.9540\n",
      "LV_RMSE_72h: 402.9196\n",
      "LV_MAE_mean: 519.0245\n",
      "LV_RMSE_mean: 642.7382\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 933.9537\n",
      "RMSE_12h: 1088.8942\n",
      "MAE_24h: 958.6255\n",
      "RMSE_24h: 1113.0586\n",
      "MAE_48h: 918.2247\n",
      "RMSE_48h: 1066.5575\n",
      "MAE_72h: 895.1856\n",
      "RMSE_72h: 1042.4346\n",
      "MAE_mean: 926.4974\n",
      "RMSE_mean: 1077.7362\n",
      "\n",
      "=== Station S3026092 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1376 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1353, 24, 400) Ytr2: (1353, 4) \n",
      "  Xva3: (197, 24, 400) Yva2: (197, 4) \n",
      "  Xte3: (348, 24, 400) Yte2: (348, 4)\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 3s 59ms/step - loss: 171.9116 - mae: 171.8988 - val_loss: 177.1974 - val_mae: 177.1846 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 165.1902 - mae: 165.1772 - val_loss: 168.1011 - val_mae: 168.0880 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 154.5023 - mae: 154.4889 - val_loss: 155.3575 - val_mae: 155.3437 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 140.8364 - mae: 140.8223 - val_loss: 139.7297 - val_mae: 139.7150 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 126.4350 - mae: 126.4198 - val_loss: 124.6488 - val_mae: 124.6329 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 113.7203 - mae: 113.7038 - val_loss: 112.3998 - val_mae: 112.3825 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 102.8819 - mae: 102.8640 - val_loss: 101.8492 - val_mae: 101.8304 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 94.1658 - mae: 94.1464 - val_loss: 93.8126 - val_mae: 93.7923 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 89.4393 - mae: 89.4185 - val_loss: 90.4780 - val_mae: 90.4565 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 88.2763 - mae: 88.2545 - val_loss: 89.6743 - val_mae: 89.6523 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 84.9918 - mae: 84.9697 - val_loss: 83.8748 - val_mae: 83.8526 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 79.8991 - mae: 79.8768 - val_loss: 79.9417 - val_mae: 79.9192 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 75.1498 - mae: 75.1270 - val_loss: 76.3121 - val_mae: 76.2890 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 71.8436 - mae: 71.8200 - val_loss: 72.9194 - val_mae: 72.8953 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 68.5459 - mae: 68.5213 - val_loss: 69.3606 - val_mae: 69.3353 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 64.8919 - mae: 64.8661 - val_loss: 66.6621 - val_mae: 66.6355 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 62.8268 - mae: 62.7996 - val_loss: 64.5282 - val_mae: 64.5002 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 59.7117 - mae: 59.6831 - val_loss: 62.3967 - val_mae: 62.3672 - lr: 0.0010\n",
      "Epoch 19/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 12ms/step - loss: 57.3007 - mae: 57.2706 - val_loss: 59.6494 - val_mae: 59.6184 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 54.3694 - mae: 54.3378 - val_loss: 57.1097 - val_mae: 57.0771 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 82.2960\n",
      "LV_RMSE_12h: 101.0232\n",
      "LV_MAE_24h: 40.0517\n",
      "LV_RMSE_24h: 71.1918\n",
      "LV_MAE_48h: 53.0603\n",
      "LV_RMSE_48h: 91.3967\n",
      "LV_MAE_72h: 56.5287\n",
      "LV_RMSE_72h: 94.1191\n",
      "LV_MAE_mean: 57.9842\n",
      "LV_RMSE_mean: 89.4327\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 83.0605\n",
      "RMSE_12h: 107.0106\n",
      "MAE_24h: 55.5478\n",
      "RMSE_24h: 86.5756\n",
      "MAE_48h: 55.2107\n",
      "RMSE_48h: 86.3220\n",
      "MAE_72h: 54.9478\n",
      "RMSE_72h: 85.2157\n",
      "MAE_mean: 62.1917\n",
      "RMSE_mean: 91.2810\n",
      "\n",
      "=== Station S3026093 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1376 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1353, 24, 400) Ytr2: (1353, 4) \n",
      "  Xva3: (197, 24, 400) Yva2: (197, 4) \n",
      "  Xte3: (348, 24, 400) Yte2: (348, 4)\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 3s 58ms/step - loss: 32.4481 - mae: 32.4353 - val_loss: 28.5914 - val_mae: 28.5786 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 26.7548 - mae: 26.7419 - val_loss: 21.5621 - val_mae: 21.5491 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 20.7511 - mae: 20.7380 - val_loss: 17.2497 - val_mae: 17.2363 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 18.1496 - mae: 18.1360 - val_loss: 16.1416 - val_mae: 16.1280 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 17.4991 - mae: 17.4854 - val_loss: 15.4258 - val_mae: 15.4121 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 16.7646 - mae: 16.7510 - val_loss: 14.6506 - val_mae: 14.6370 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 16.0752 - mae: 16.0617 - val_loss: 13.8194 - val_mae: 13.8058 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 15.1245 - mae: 15.1109 - val_loss: 13.0086 - val_mae: 12.9950 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 14.5322 - mae: 14.5186 - val_loss: 12.5463 - val_mae: 12.5326 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 13.9081 - mae: 13.8943 - val_loss: 11.9281 - val_mae: 11.9143 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 13.3092 - mae: 13.2954 - val_loss: 11.4914 - val_mae: 11.4774 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 12.9142 - mae: 12.9002 - val_loss: 10.9673 - val_mae: 10.9532 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 12.4679 - mae: 12.4538 - val_loss: 10.4986 - val_mae: 10.4843 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 12.0428 - mae: 12.0285 - val_loss: 10.1421 - val_mae: 10.1277 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 11.8264 - mae: 11.8118 - val_loss: 9.8572 - val_mae: 9.8426 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 11.4736 - mae: 11.4589 - val_loss: 9.6786 - val_mae: 9.6639 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 11.4159 - mae: 11.4011 - val_loss: 9.4331 - val_mae: 9.4182 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 11.1630 - mae: 11.1480 - val_loss: 9.2271 - val_mae: 9.2121 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 10.9229 - mae: 10.9079 - val_loss: 9.0715 - val_mae: 9.0564 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 10.6836 - mae: 10.6685 - val_loss: 8.9526 - val_mae: 8.9374 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 23.7184\n",
      "LV_RMSE_12h: 27.9797\n",
      "LV_MAE_24h: 10.3305\n",
      "LV_RMSE_24h: 14.4643\n",
      "LV_MAE_48h: 11.4770\n",
      "LV_RMSE_48h: 15.7670\n",
      "LV_MAE_72h: 10.7672\n",
      "LV_RMSE_72h: 14.1493\n",
      "LV_MAE_mean: 14.0733\n",
      "LV_RMSE_mean: 18.0901\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 9.1660\n",
      "RMSE_12h: 12.5827\n",
      "MAE_24h: 9.4853\n",
      "RMSE_24h: 13.1608\n",
      "MAE_48h: 8.7430\n",
      "RMSE_48h: 12.1984\n",
      "MAE_72h: 8.9670\n",
      "RMSE_72h: 12.2062\n",
      "MAE_mean: 9.0903\n",
      "RMSE_mean: 12.5370\n",
      "\n",
      "=== Station S3026094 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1360 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1337, 24, 400) Ytr2: (1337, 4) \n",
      "  Xva3: (195, 24, 400) Yva2: (195, 4) \n",
      "  Xte3: (342, 24, 400) Yte2: (342, 4)\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 3s 58ms/step - loss: 11.5342 - mae: 11.5215 - val_loss: 8.3400 - val_mae: 8.3273 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 8.1452 - mae: 8.1325 - val_loss: 5.9601 - val_mae: 5.9473 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 6.5657 - mae: 6.5529 - val_loss: 5.7516 - val_mae: 5.7387 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 6.1963 - mae: 6.1836 - val_loss: 5.2733 - val_mae: 5.2606 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 5.8437 - mae: 5.8310 - val_loss: 5.1748 - val_mae: 5.1622 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 5.7091 - mae: 5.6965 - val_loss: 4.9809 - val_mae: 4.9683 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 5.5086 - mae: 5.4961 - val_loss: 4.9339 - val_mae: 4.9213 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 5.3626 - mae: 5.3501 - val_loss: 4.8538 - val_mae: 4.8413 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 5.2947 - mae: 5.2822 - val_loss: 4.7799 - val_mae: 4.7675 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 5.2340 - mae: 5.2216 - val_loss: 4.7100 - val_mae: 4.6977 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 5.2002 - mae: 5.1879 - val_loss: 4.6537 - val_mae: 4.6414 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 5.1580 - mae: 5.1457 - val_loss: 4.7340 - val_mae: 4.7218 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 5.1192 - mae: 5.1070 - val_loss: 4.6907 - val_mae: 4.6785 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 5.0510 - mae: 5.0388 - val_loss: 4.5755 - val_mae: 4.5633 - lr: 5.0000e-04\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 5.0245 - mae: 5.0123 - val_loss: 4.6201 - val_mae: 4.6079 - lr: 5.0000e-04\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 4.9834 - mae: 4.9712 - val_loss: 4.5103 - val_mae: 4.4981 - lr: 5.0000e-04\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 4.9450 - mae: 4.9328 - val_loss: 4.5587 - val_mae: 4.5465 - lr: 5.0000e-04\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 4.9069 - mae: 4.8948 - val_loss: 4.5010 - val_mae: 4.4889 - lr: 5.0000e-04\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 4.9434 - mae: 4.9312 - val_loss: 4.5410 - val_mae: 4.5288 - lr: 5.0000e-04\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 4.8833 - mae: 4.8712 - val_loss: 4.4672 - val_mae: 4.4551 - lr: 5.0000e-04\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 7.5029\n",
      "LV_RMSE_12h: 9.5917\n",
      "LV_MAE_24h: 4.8538\n",
      "LV_RMSE_24h: 6.6399\n",
      "LV_MAE_48h: 5.2661\n",
      "LV_RMSE_48h: 7.2875\n",
      "LV_MAE_72h: 5.1754\n",
      "LV_RMSE_72h: 6.9092\n",
      "LV_MAE_mean: 5.6996\n",
      "LV_RMSE_mean: 7.6071\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 4.2496\n",
      "RMSE_12h: 5.7043\n",
      "MAE_24h: 4.5016\n",
      "RMSE_24h: 6.0708\n",
      "MAE_48h: 4.5870\n",
      "RMSE_48h: 6.1915\n",
      "MAE_72h: 4.6506\n",
      "RMSE_72h: 6.1135\n",
      "MAE_mean: 4.4972\n",
      "RMSE_mean: 6.0201\n",
      "\n",
      "=== Station S3026101 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1377 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1354, 24, 400) Ytr2: (1354, 4) \n",
      "  Xva3: (197, 24, 400) Yva2: (197, 4) \n",
      "  Xte3: (348, 24, 400) Yte2: (348, 4)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "11/11 [==============================] - 3s 58ms/step - loss: 1850.6729 - mae: 1850.6599 - val_loss: 1773.5403 - val_mae: 1773.5275 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1845.6088 - mae: 1845.5961 - val_loss: 1766.0182 - val_mae: 1766.0052 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1835.8680 - mae: 1835.8545 - val_loss: 1753.8644 - val_mae: 1753.8506 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1822.3696 - mae: 1822.3552 - val_loss: 1738.0652 - val_mae: 1738.0508 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1804.3361 - mae: 1804.3207 - val_loss: 1717.7164 - val_mae: 1717.7006 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1781.8237 - mae: 1781.8070 - val_loss: 1692.6053 - val_mae: 1692.5879 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1754.9446 - mae: 1754.9261 - val_loss: 1662.5747 - val_mae: 1662.5549 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1722.3589 - mae: 1722.3383 - val_loss: 1627.4027 - val_mae: 1627.3802 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1685.1163 - mae: 1685.0925 - val_loss: 1587.0123 - val_mae: 1586.9867 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1642.1913 - mae: 1642.1643 - val_loss: 1541.5377 - val_mae: 1541.5085 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 1595.5198 - mae: 1595.4888 - val_loss: 1491.7173 - val_mae: 1491.6840 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1544.1472 - mae: 1544.1119 - val_loss: 1439.3367 - val_mae: 1439.2986 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1490.0286 - mae: 1489.9885 - val_loss: 1388.1346 - val_mae: 1388.0918 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1438.5060 - mae: 1438.4612 - val_loss: 1337.4188 - val_mae: 1337.3708 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1385.3914 - mae: 1385.3411 - val_loss: 1286.2736 - val_mae: 1286.2200 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1332.9558 - mae: 1332.9000 - val_loss: 1233.9369 - val_mae: 1233.8776 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1279.5123 - mae: 1279.4506 - val_loss: 1180.4639 - val_mae: 1180.3984 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 1224.1882 - mae: 1224.1202 - val_loss: 1127.4374 - val_mae: 1127.3656 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1173.7017 - mae: 1173.6270 - val_loss: 1076.5905 - val_mae: 1076.5122 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1124.0518 - mae: 1123.9706 - val_loss: 1030.3485 - val_mae: 1030.2635 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 1407.0144\n",
      "LV_RMSE_12h: 1620.1381\n",
      "LV_MAE_24h: 233.0402\n",
      "LV_RMSE_24h: 315.7461\n",
      "LV_MAE_48h: 302.8247\n",
      "LV_RMSE_48h: 404.0204\n",
      "LV_MAE_72h: 297.7328\n",
      "LV_RMSE_72h: 385.1964\n",
      "LV_MAE_mean: 560.1530\n",
      "LV_RMSE_mean: 681.2753\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 1006.3430\n",
      "RMSE_12h: 1228.4077\n",
      "MAE_24h: 1001.4488\n",
      "RMSE_24h: 1213.3973\n",
      "MAE_48h: 1021.7509\n",
      "RMSE_48h: 1240.5834\n",
      "MAE_72h: 1015.9213\n",
      "RMSE_72h: 1237.7766\n",
      "MAE_mean: 1011.3660\n",
      "RMSE_mean: 1230.0413\n",
      "\n",
      "=== Station S3026102 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1376 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1353, 24, 400) Ytr2: (1353, 4) \n",
      "  Xva3: (197, 24, 400) Yva2: (197, 4) \n",
      "  Xte3: (348, 24, 400) Yte2: (348, 4)\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 3s 59ms/step - loss: 35.0583 - mae: 35.0453 - val_loss: 31.7636 - val_mae: 31.7506 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 28.8658 - mae: 28.8528 - val_loss: 24.1050 - val_mae: 24.0918 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 22.0663 - mae: 22.0530 - val_loss: 18.8648 - val_mae: 18.8513 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 19.0519 - mae: 19.0382 - val_loss: 17.9382 - val_mae: 17.9244 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 18.5561 - mae: 18.5422 - val_loss: 17.2846 - val_mae: 17.2709 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 17.6466 - mae: 17.6329 - val_loss: 16.4921 - val_mae: 16.4785 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 16.8343 - mae: 16.8207 - val_loss: 15.7718 - val_mae: 15.7582 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 16.0760 - mae: 16.0623 - val_loss: 15.3226 - val_mae: 15.3089 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 15.5011 - mae: 15.4873 - val_loss: 14.8284 - val_mae: 14.8146 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 14.9159 - mae: 14.9020 - val_loss: 14.3642 - val_mae: 14.3502 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 14.5179 - mae: 14.5038 - val_loss: 13.9143 - val_mae: 13.9001 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 13.9962 - mae: 13.9819 - val_loss: 13.4931 - val_mae: 13.4787 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 13.6352 - mae: 13.6207 - val_loss: 13.0644 - val_mae: 13.0498 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 13.3031 - mae: 13.2885 - val_loss: 12.5595 - val_mae: 12.5447 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 12.7888 - mae: 12.7739 - val_loss: 12.0361 - val_mae: 12.0211 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 12.2919 - mae: 12.2767 - val_loss: 11.5555 - val_mae: 11.5402 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 11.8722 - mae: 11.8567 - val_loss: 11.1061 - val_mae: 11.0904 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 11.4888 - mae: 11.4730 - val_loss: 10.8014 - val_mae: 10.7854 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 11.2162 - mae: 11.2001 - val_loss: 10.4556 - val_mae: 10.4393 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 10.8831 - mae: 10.8667 - val_loss: 10.3287 - val_mae: 10.3121 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 27.6925\n",
      "LV_RMSE_12h: 35.6039\n",
      "LV_MAE_24h: 12.6063\n",
      "LV_RMSE_24h: 18.9998\n",
      "LV_MAE_48h: 15.3678\n",
      "LV_RMSE_48h: 22.9183\n",
      "LV_MAE_72h: 13.3851\n",
      "LV_RMSE_72h: 20.2821\n",
      "LV_MAE_mean: 17.2629\n",
      "LV_RMSE_mean: 24.4510\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 10.5521\n",
      "RMSE_12h: 16.2304\n",
      "MAE_24h: 11.1441\n",
      "RMSE_24h: 16.5971\n",
      "MAE_48h: 10.9796\n",
      "RMSE_48h: 16.5774\n",
      "MAE_72h: 11.0404\n",
      "RMSE_72h: 16.2468\n",
      "MAE_mean: 10.9290\n",
      "RMSE_mean: 16.4129\n",
      "\n",
      "=== Station S3026103 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1376 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1353, 24, 400) Ytr2: (1353, 4) \n",
      "  Xva3: (197, 24, 400) Yva2: (197, 4) \n",
      "  Xte3: (348, 24, 400) Yte2: (348, 4)\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 3s 58ms/step - loss: 157.1823 - mae: 157.1696 - val_loss: 162.0201 - val_mae: 162.0074 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 151.6345 - mae: 151.6217 - val_loss: 153.8350 - val_mae: 153.8221 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 141.7835 - mae: 141.7703 - val_loss: 141.9455 - val_mae: 141.9321 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 127.9757 - mae: 127.9619 - val_loss: 126.1779 - val_mae: 126.1636 - lr: 0.0010\n",
      "Epoch 5/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 13ms/step - loss: 111.3417 - mae: 111.3269 - val_loss: 108.3379 - val_mae: 108.3224 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 94.4142 - mae: 94.3981 - val_loss: 93.4587 - val_mae: 93.4418 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 82.1834 - mae: 82.1658 - val_loss: 85.4001 - val_mae: 85.3817 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 74.8989 - mae: 74.8800 - val_loss: 82.2733 - val_mae: 82.2537 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 72.5077 - mae: 72.4877 - val_loss: 81.1992 - val_mae: 81.1788 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 72.1197 - mae: 72.0992 - val_loss: 80.8189 - val_mae: 80.7983 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 72.1323 - mae: 72.1116 - val_loss: 80.2966 - val_mae: 80.2758 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 70.1618 - mae: 70.1411 - val_loss: 76.6663 - val_mae: 76.6455 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 66.0248 - mae: 66.0040 - val_loss: 70.6766 - val_mae: 70.6556 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 62.4593 - mae: 62.4381 - val_loss: 68.7644 - val_mae: 68.7429 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 61.2119 - mae: 61.1901 - val_loss: 67.9466 - val_mae: 67.9245 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 59.8945 - mae: 59.8721 - val_loss: 65.8490 - val_mae: 65.8263 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 58.3393 - mae: 58.3164 - val_loss: 63.2145 - val_mae: 63.1912 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 55.4873 - mae: 55.4637 - val_loss: 59.8519 - val_mae: 59.8278 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 52.1258 - mae: 52.1012 - val_loss: 56.5104 - val_mae: 56.4852 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 50.0095 - mae: 49.9839 - val_loss: 54.0748 - val_mae: 54.0486 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 68.0374\n",
      "LV_RMSE_12h: 88.9475\n",
      "LV_MAE_24h: 41.5115\n",
      "LV_RMSE_24h: 70.9907\n",
      "LV_MAE_48h: 55.4770\n",
      "LV_RMSE_48h: 91.3671\n",
      "LV_MAE_72h: 53.6322\n",
      "LV_RMSE_72h: 88.6354\n",
      "LV_MAE_mean: 54.6645\n",
      "LV_RMSE_mean: 84.9852\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 71.6998\n",
      "RMSE_12h: 103.1042\n",
      "MAE_24h: 52.2616\n",
      "RMSE_24h: 89.2438\n",
      "MAE_48h: 51.5580\n",
      "RMSE_48h: 86.4802\n",
      "MAE_72h: 51.7586\n",
      "RMSE_72h: 84.7425\n",
      "MAE_mean: 56.8195\n",
      "RMSE_mean: 90.8927\n",
      "\n",
      "=== Station S3026104 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1326 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1303, 24, 400) Ytr2: (1303, 4) \n",
      "  Xva3: (190, 24, 400) Yva2: (190, 4) \n",
      "  Xte3: (333, 24, 400) Yte2: (333, 4)\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 3s 58ms/step - loss: 14.8844 - mae: 14.8716 - val_loss: 8.8375 - val_mae: 8.8246 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 12.7849 - mae: 12.7720 - val_loss: 8.2170 - val_mae: 8.2040 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 12.3246 - mae: 12.3117 - val_loss: 7.5597 - val_mae: 7.5468 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 11.8152 - mae: 11.8023 - val_loss: 7.1394 - val_mae: 7.1265 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 11.3604 - mae: 11.3474 - val_loss: 6.7210 - val_mae: 6.7080 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 10.8842 - mae: 10.8711 - val_loss: 6.3659 - val_mae: 6.3528 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 10.5747 - mae: 10.5615 - val_loss: 6.0974 - val_mae: 6.0840 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 10.3171 - mae: 10.3037 - val_loss: 5.9271 - val_mae: 5.9136 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 10.1575 - mae: 10.1440 - val_loss: 5.8603 - val_mae: 5.8467 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 10.0115 - mae: 9.9978 - val_loss: 5.7658 - val_mae: 5.7521 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 9.8894 - mae: 9.8756 - val_loss: 5.6997 - val_mae: 5.6859 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 9.8666 - mae: 9.8527 - val_loss: 5.6376 - val_mae: 5.6236 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 9.7987 - mae: 9.7847 - val_loss: 5.5790 - val_mae: 5.5650 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 9.8115 - mae: 9.7975 - val_loss: 5.6780 - val_mae: 5.6640 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 9.7676 - mae: 9.7536 - val_loss: 5.5161 - val_mae: 5.5020 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 9.6525 - mae: 9.6384 - val_loss: 5.5179 - val_mae: 5.5038 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 9.6162 - mae: 9.6020 - val_loss: 5.4422 - val_mae: 5.4280 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 9.5443 - mae: 9.5300 - val_loss: 5.5056 - val_mae: 5.4914 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 9.5469 - mae: 9.5326 - val_loss: 5.4858 - val_mae: 5.4715 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 9.5019 - mae: 9.4876 - val_loss: 5.4097 - val_mae: 5.3953 - lr: 5.0000e-04\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 13.8438\n",
      "LV_RMSE_12h: 24.5826\n",
      "LV_MAE_24h: 9.1141\n",
      "LV_RMSE_24h: 18.2851\n",
      "LV_MAE_48h: 8.1261\n",
      "LV_RMSE_48h: 15.9675\n",
      "LV_MAE_72h: 8.9640\n",
      "LV_RMSE_72h: 17.3277\n",
      "LV_MAE_mean: 10.0120\n",
      "LV_RMSE_mean: 19.0407\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 6.8293\n",
      "RMSE_12h: 14.3946\n",
      "MAE_24h: 7.0423\n",
      "RMSE_24h: 14.4897\n",
      "MAE_48h: 6.4661\n",
      "RMSE_48h: 12.7547\n",
      "MAE_72h: 6.4960\n",
      "RMSE_72h: 12.7511\n",
      "MAE_mean: 6.7084\n",
      "RMSE_mean: 13.5975\n",
      "\n",
      "=== Station S3026111 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1376 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1353, 24, 400) Ytr2: (1353, 4) \n",
      "  Xva3: (197, 24, 400) Yva2: (197, 4) \n",
      "  Xte3: (348, 24, 400) Yte2: (348, 4)\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 3s 59ms/step - loss: 873.8559 - mae: 873.8431 - val_loss: 905.4039 - val_mae: 905.3911 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 869.2382 - mae: 869.2254 - val_loss: 898.5641 - val_mae: 898.5511 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 860.7498 - mae: 860.7366 - val_loss: 887.9827 - val_mae: 887.9692 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 848.4493 - mae: 848.4354 - val_loss: 873.6856 - val_mae: 873.6713 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 832.4011 - mae: 832.3862 - val_loss: 855.1272 - val_mae: 855.1116 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 811.9904 - mae: 811.9741 - val_loss: 832.0754 - val_mae: 832.0580 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 787.2161 - mae: 787.1979 - val_loss: 804.9550 - val_mae: 804.9356 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 758.9701 - mae: 758.9498 - val_loss: 776.6367 - val_mae: 776.6149 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 731.2543 - mae: 731.2313 - val_loss: 749.6091 - val_mae: 749.5847 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 704.3487 - mae: 704.3229 - val_loss: 724.4305 - val_mae: 724.4031 - lr: 0.0010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 679.6266 - mae: 679.5978 - val_loss: 700.1107 - val_mae: 700.0803 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 656.7925 - mae: 656.7606 - val_loss: 677.4087 - val_mae: 677.3750 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 635.5510 - mae: 635.5159 - val_loss: 656.7839 - val_mae: 656.7470 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 615.7841 - mae: 615.7457 - val_loss: 636.0248 - val_mae: 635.9846 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 597.5571 - mae: 597.5154 - val_loss: 615.4205 - val_mae: 615.3768 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 578.7588 - mae: 578.7135 - val_loss: 594.0936 - val_mae: 594.0463 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 558.8652 - mae: 558.8164 - val_loss: 572.1638 - val_mae: 572.1129 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 536.9449 - mae: 536.8923 - val_loss: 550.2325 - val_mae: 550.1778 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 518.3427 - mae: 518.2861 - val_loss: 526.4642 - val_mae: 526.4055 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 498.5839 - mae: 498.5234 - val_loss: 506.1530 - val_mae: 506.0903 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 968.1293\n",
      "LV_RMSE_12h: 1165.0098\n",
      "LV_MAE_24h: 239.6695\n",
      "LV_RMSE_24h: 371.3644\n",
      "LV_MAE_48h: 319.8764\n",
      "LV_RMSE_48h: 470.7337\n",
      "LV_MAE_72h: 282.1178\n",
      "LV_RMSE_72h: 410.8419\n",
      "LV_MAE_mean: 452.4483\n",
      "LV_RMSE_mean: 604.4874\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 602.2795\n",
      "RMSE_12h: 805.2899\n",
      "MAE_24h: 412.5983\n",
      "RMSE_24h: 607.9808\n",
      "MAE_48h: 422.2762\n",
      "RMSE_48h: 625.9102\n",
      "MAE_72h: 413.8944\n",
      "RMSE_72h: 616.4903\n",
      "MAE_mean: 462.7621\n",
      "RMSE_mean: 663.9178\n",
      "\n",
      "=== Station S3026121 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1376 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1353, 24, 400) Ytr2: (1353, 4) \n",
      "  Xva3: (197, 24, 400) Yva2: (197, 4) \n",
      "  Xte3: (348, 24, 400) Yte2: (348, 4)\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 3s 58ms/step - loss: 374.4063 - mae: 374.3935 - val_loss: 411.4604 - val_mae: 411.4476 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 368.0635 - mae: 368.0506 - val_loss: 401.7882 - val_mae: 401.7751 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 356.3638 - mae: 356.3504 - val_loss: 387.8677 - val_mae: 387.8541 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 340.9584 - mae: 340.9443 - val_loss: 371.0826 - val_mae: 371.0680 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 324.2896 - mae: 324.2743 - val_loss: 354.8009 - val_mae: 354.7849 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 308.0781 - mae: 308.0614 - val_loss: 339.3262 - val_mae: 339.3086 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 292.7162 - mae: 292.6978 - val_loss: 323.8946 - val_mae: 323.8752 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 278.0894 - mae: 278.0693 - val_loss: 309.8470 - val_mae: 309.8257 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 265.5746 - mae: 265.5524 - val_loss: 297.4705 - val_mae: 297.4471 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 252.9995 - mae: 252.9751 - val_loss: 285.6352 - val_mae: 285.6096 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 242.5637 - mae: 242.5371 - val_loss: 274.0318 - val_mae: 274.0040 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 231.6897 - mae: 231.6609 - val_loss: 260.0273 - val_mae: 259.9971 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 217.1668 - mae: 217.1357 - val_loss: 243.5901 - val_mae: 243.5576 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 201.4859 - mae: 201.4523 - val_loss: 226.8065 - val_mae: 226.7714 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 188.0759 - mae: 188.0396 - val_loss: 213.3669 - val_mae: 213.3290 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 174.6612 - mae: 174.6220 - val_loss: 197.9658 - val_mae: 197.9250 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 161.2873 - mae: 161.2451 - val_loss: 182.9870 - val_mae: 182.9429 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 150.8049 - mae: 150.7595 - val_loss: 168.4235 - val_mae: 168.3763 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 140.4714 - mae: 140.4229 - val_loss: 156.6118 - val_mae: 156.5616 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 134.1700 - mae: 134.1187 - val_loss: 148.0925 - val_mae: 148.0399 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 514.3822\n",
      "LV_RMSE_12h: 567.1849\n",
      "LV_MAE_24h: 101.8448\n",
      "LV_RMSE_24h: 164.7758\n",
      "LV_MAE_48h: 122.0632\n",
      "LV_RMSE_48h: 180.8344\n",
      "LV_MAE_72h: 112.7644\n",
      "LV_RMSE_72h: 173.6526\n",
      "LV_MAE_mean: 212.7637\n",
      "LV_RMSE_mean: 271.6119\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 346.2394\n",
      "RMSE_12h: 423.9938\n",
      "MAE_24h: 113.7492\n",
      "RMSE_24h: 158.4234\n",
      "MAE_48h: 112.6059\n",
      "RMSE_48h: 157.5210\n",
      "MAE_72h: 114.1061\n",
      "RMSE_72h: 158.3751\n",
      "MAE_mean: 171.6752\n",
      "RMSE_mean: 224.5783\n",
      "\n",
      "=== Station S3026151 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1377 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1354, 24, 400) Ytr2: (1354, 4) \n",
      "  Xva3: (197, 24, 400) Yva2: (197, 4) \n",
      "  Xte3: (348, 24, 400) Yte2: (348, 4)\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 3s 60ms/step - loss: 1271.0923 - mae: 1271.0795 - val_loss: 1242.4752 - val_mae: 1242.4624 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1264.3038 - mae: 1264.2909 - val_loss: 1233.0635 - val_mae: 1233.0507 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1253.4268 - mae: 1253.4136 - val_loss: 1220.6591 - val_mae: 1220.6456 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1239.8767 - mae: 1239.8630 - val_loss: 1204.8521 - val_mae: 1204.8379 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1221.8669 - mae: 1221.8523 - val_loss: 1184.7853 - val_mae: 1184.7700 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1199.7670 - mae: 1199.7510 - val_loss: 1160.4169 - val_mae: 1160.4000 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1173.9188 - mae: 1173.9012 - val_loss: 1131.7159 - val_mae: 1131.6974 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1143.3729 - mae: 1143.3531 - val_loss: 1098.4275 - val_mae: 1098.4064 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1109.1696 - mae: 1109.1473 - val_loss: 1061.3840 - val_mae: 1061.3602 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1074.1823 - mae: 1074.1573 - val_loss: 1026.2832 - val_mae: 1026.2563 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1041.7198 - mae: 1041.6915 - val_loss: 993.9754 - val_mae: 993.9454 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1010.0189 - mae: 1009.9875 - val_loss: 962.7550 - val_mae: 962.7216 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 980.9064 - mae: 980.8716 - val_loss: 934.2695 - val_mae: 934.2326 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 953.7389 - mae: 953.7005 - val_loss: 908.0681 - val_mae: 908.0277 - lr: 0.0010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 926.6556 - mae: 926.6135 - val_loss: 883.0339 - val_mae: 882.9897 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 902.8442 - mae: 902.7983 - val_loss: 858.2878 - val_mae: 858.2397 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 877.4092 - mae: 877.3594 - val_loss: 833.1318 - val_mae: 833.0797 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 849.9636 - mae: 849.9096 - val_loss: 807.7371 - val_mae: 807.6807 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 822.7881 - mae: 822.7298 - val_loss: 776.6993 - val_mae: 776.6385 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 791.7485 - mae: 791.6857 - val_loss: 745.8608 - val_mae: 745.7953 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 1214.9482\n",
      "LV_RMSE_12h: 1322.7114\n",
      "LV_MAE_24h: 227.3621\n",
      "LV_RMSE_24h: 383.7143\n",
      "LV_MAE_48h: 314.0805\n",
      "LV_RMSE_48h: 509.2314\n",
      "LV_MAE_72h: 254.3937\n",
      "LV_RMSE_72h: 441.4933\n",
      "LV_MAE_mean: 502.6961\n",
      "LV_RMSE_mean: 664.2876\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 794.5435\n",
      "RMSE_12h: 968.1023\n",
      "MAE_24h: 660.1886\n",
      "RMSE_24h: 843.5527\n",
      "MAE_48h: 653.8505\n",
      "RMSE_48h: 833.5204\n",
      "MAE_72h: 654.3531\n",
      "RMSE_72h: 830.9300\n",
      "MAE_mean: 690.7339\n",
      "RMSE_mean: 869.0263\n",
      "\n",
      "=== Station S3027011 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1377 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1354, 24, 400) Ytr2: (1354, 4) \n",
      "  Xva3: (197, 24, 400) Yva2: (197, 4) \n",
      "  Xte3: (348, 24, 400) Yte2: (348, 4)\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 3s 59ms/step - loss: 1834.3812 - mae: 1834.3685 - val_loss: 1776.4592 - val_mae: 1776.4465 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1828.0620 - mae: 1828.0491 - val_loss: 1767.8094 - val_mae: 1767.7966 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1817.6001 - mae: 1817.5872 - val_loss: 1755.3221 - val_mae: 1755.3088 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1803.7029 - mae: 1803.6891 - val_loss: 1739.4750 - val_mae: 1739.4608 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1786.0482 - mae: 1786.0338 - val_loss: 1719.7255 - val_mae: 1719.7101 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1764.4509 - mae: 1764.4347 - val_loss: 1695.6234 - val_mae: 1695.6064 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1738.4930 - mae: 1738.4752 - val_loss: 1666.8971 - val_mae: 1666.8781 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1707.4985 - mae: 1707.4783 - val_loss: 1633.2623 - val_mae: 1633.2410 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 1672.4487 - mae: 1672.4261 - val_loss: 1594.8312 - val_mae: 1594.8070 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1630.8237 - mae: 1630.7979 - val_loss: 1551.4607 - val_mae: 1551.4331 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1585.8414 - mae: 1585.8120 - val_loss: 1503.4778 - val_mae: 1503.4462 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 1537.4865 - mae: 1537.4532 - val_loss: 1454.7151 - val_mae: 1454.6796 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1489.2847 - mae: 1489.2473 - val_loss: 1408.7584 - val_mae: 1408.7184 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1444.9354 - mae: 1444.8933 - val_loss: 1365.8857 - val_mae: 1365.8414 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1399.7921 - mae: 1399.7452 - val_loss: 1325.9678 - val_mae: 1325.9185 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1362.5952 - mae: 1362.5438 - val_loss: 1288.4681 - val_mae: 1288.4141 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1325.0645 - mae: 1325.0082 - val_loss: 1252.3444 - val_mae: 1252.2854 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1286.0577 - mae: 1285.9967 - val_loss: 1216.3982 - val_mae: 1216.3341 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1252.1926 - mae: 1252.1261 - val_loss: 1179.7745 - val_mae: 1179.7053 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1216.3010 - mae: 1216.2292 - val_loss: 1143.4360 - val_mae: 1143.3612 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 1630.0287\n",
      "LV_RMSE_12h: 1799.9148\n",
      "LV_MAE_24h: 269.7040\n",
      "LV_RMSE_24h: 432.6966\n",
      "LV_MAE_48h: 359.4511\n",
      "LV_RMSE_48h: 544.7259\n",
      "LV_MAE_72h: 302.9109\n",
      "LV_RMSE_72h: 469.8139\n",
      "LV_MAE_mean: 640.5237\n",
      "LV_RMSE_mean: 811.7878\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 1108.0103\n",
      "RMSE_12h: 1327.9670\n",
      "MAE_24h: 1112.8734\n",
      "RMSE_24h: 1322.8300\n",
      "MAE_48h: 1122.5728\n",
      "RMSE_48h: 1338.6144\n",
      "MAE_72h: 1154.7568\n",
      "RMSE_72h: 1381.0175\n",
      "MAE_mean: 1124.5533\n",
      "RMSE_mean: 1342.6072\n",
      "\n",
      "=== Station S3027012 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1288 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1265, 24, 400) Ytr2: (1265, 4) \n",
      "  Xva3: (185, 24, 400) Yva2: (185, 4) \n",
      "  Xte3: (321, 24, 400) Yte2: (321, 4)\n",
      "Epoch 1/20\n",
      "10/10 [==============================] - 3s 67ms/step - loss: 48.8347 - mae: 48.8220 - val_loss: 41.0593 - val_mae: 41.0466 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 44.6517 - mae: 44.6389 - val_loss: 36.7176 - val_mae: 36.7048 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 40.3742 - mae: 40.3613 - val_loss: 33.2203 - val_mae: 33.2072 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 36.4395 - mae: 36.4262 - val_loss: 29.9570 - val_mae: 29.9434 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 32.5461 - mae: 32.5323 - val_loss: 27.0940 - val_mae: 27.0799 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 29.3945 - mae: 29.3801 - val_loss: 24.8341 - val_mae: 24.8194 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 26.4517 - mae: 26.4367 - val_loss: 22.6804 - val_mae: 22.6651 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 24.0346 - mae: 24.0191 - val_loss: 21.4864 - val_mae: 21.4707 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 22.6710 - mae: 22.6552 - val_loss: 20.7555 - val_mae: 20.7396 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 21.7269 - mae: 21.7109 - val_loss: 19.9606 - val_mae: 19.9444 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 21.2787 - mae: 21.2625 - val_loss: 19.7527 - val_mae: 19.7363 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 20.6759 - mae: 20.6594 - val_loss: 19.3148 - val_mae: 19.2981 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 19.9320 - mae: 19.9152 - val_loss: 18.1326 - val_mae: 18.1156 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 18.8053 - mae: 18.7881 - val_loss: 17.3485 - val_mae: 17.3311 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 18.0903 - mae: 18.0727 - val_loss: 16.8169 - val_mae: 16.7990 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 17.0689 - mae: 17.0508 - val_loss: 16.1251 - val_mae: 16.1067 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 15.9931 - mae: 15.9744 - val_loss: 15.6925 - val_mae: 15.6735 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 15.7819 - mae: 15.7627 - val_loss: 15.3683 - val_mae: 15.3488 - lr: 0.0010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/20\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 15.5107 - mae: 15.4910 - val_loss: 15.8962 - val_mae: 15.8763 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 15.3201 - mae: 15.3002 - val_loss: 15.8039 - val_mae: 15.7838 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 54.3084\n",
      "LV_RMSE_12h: 61.1489\n",
      "LV_MAE_24h: 15.0935\n",
      "LV_RMSE_24h: 21.3185\n",
      "LV_MAE_48h: 18.1495\n",
      "LV_RMSE_48h: 25.2152\n",
      "LV_MAE_72h: 17.3209\n",
      "LV_RMSE_72h: 24.2413\n",
      "LV_MAE_mean: 26.2181\n",
      "LV_RMSE_mean: 32.9810\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 14.2544\n",
      "RMSE_12h: 20.3282\n",
      "MAE_24h: 14.8420\n",
      "RMSE_24h: 21.2979\n",
      "MAE_48h: 14.3727\n",
      "RMSE_48h: 20.8845\n",
      "MAE_72h: 14.7099\n",
      "RMSE_72h: 21.2983\n",
      "MAE_mean: 14.5448\n",
      "RMSE_mean: 20.9522\n",
      "\n",
      "=== Station S3027021 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1377 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1354, 24, 400) Ytr2: (1354, 4) \n",
      "  Xva3: (197, 24, 400) Yva2: (197, 4) \n",
      "  Xte3: (348, 24, 400) Yte2: (348, 4)\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 3s 59ms/step - loss: 1817.3394 - mae: 1817.3268 - val_loss: 1769.4570 - val_mae: 1769.4443 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1809.7017 - mae: 1809.6888 - val_loss: 1759.7510 - val_mae: 1759.7382 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1798.6445 - mae: 1798.6315 - val_loss: 1747.0712 - val_mae: 1747.0579 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1784.7316 - mae: 1784.7179 - val_loss: 1731.2690 - val_mae: 1731.2551 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1767.1982 - mae: 1767.1835 - val_loss: 1711.7849 - val_mae: 1711.7697 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 1745.8602 - mae: 1745.8444 - val_loss: 1688.6213 - val_mae: 1688.6047 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 1721.1091 - mae: 1721.0918 - val_loss: 1661.4546 - val_mae: 1661.4360 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1691.8030 - mae: 1691.7836 - val_loss: 1630.1072 - val_mae: 1630.0867 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1658.9304 - mae: 1658.9086 - val_loss: 1594.3304 - val_mae: 1594.3073 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1620.7194 - mae: 1620.6948 - val_loss: 1554.0435 - val_mae: 1554.0173 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1579.8248 - mae: 1579.7969 - val_loss: 1509.4379 - val_mae: 1509.4083 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1532.3510 - mae: 1532.3195 - val_loss: 1460.6754 - val_mae: 1460.6420 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1483.6055 - mae: 1483.5702 - val_loss: 1410.8937 - val_mae: 1410.8560 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1433.3682 - mae: 1433.3287 - val_loss: 1362.8672 - val_mae: 1362.8252 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1384.7020 - mae: 1384.6582 - val_loss: 1317.7159 - val_mae: 1317.6693 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1340.1549 - mae: 1340.1062 - val_loss: 1276.3872 - val_mae: 1276.3359 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1297.4240 - mae: 1297.3706 - val_loss: 1236.9167 - val_mae: 1236.8607 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1252.7789 - mae: 1252.7208 - val_loss: 1198.0841 - val_mae: 1198.0233 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1218.3550 - mae: 1218.2917 - val_loss: 1159.7471 - val_mae: 1159.6812 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1182.7646 - mae: 1182.6967 - val_loss: 1123.7128 - val_mae: 1123.6417 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 1520.4885\n",
      "LV_RMSE_12h: 1723.1412\n",
      "LV_MAE_24h: 231.3075\n",
      "LV_RMSE_24h: 327.5998\n",
      "LV_MAE_48h: 282.0690\n",
      "LV_RMSE_48h: 391.2914\n",
      "LV_MAE_72h: 245.8793\n",
      "LV_RMSE_72h: 352.4467\n",
      "LV_MAE_mean: 569.9361\n",
      "LV_RMSE_mean: 698.6198\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 1067.0596\n",
      "RMSE_12h: 1289.5350\n",
      "MAE_24h: 1123.2740\n",
      "RMSE_24h: 1348.9371\n",
      "MAE_48h: 1099.6211\n",
      "RMSE_48h: 1322.7231\n",
      "MAE_72h: 1075.2102\n",
      "RMSE_72h: 1293.4199\n",
      "MAE_mean: 1091.2913\n",
      "RMSE_mean: 1313.6538\n",
      "\n",
      "=== Station S3027022 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1288 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1265, 24, 400) Ytr2: (1265, 4) \n",
      "  Xva3: (185, 24, 400) Yva2: (185, 4) \n",
      "  Xte3: (321, 24, 400) Yte2: (321, 4)\n",
      "Epoch 1/20\n",
      "10/10 [==============================] - 3s 66ms/step - loss: 10.7641 - mae: 10.7513 - val_loss: 8.1915 - val_mae: 8.1788 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 8.1048 - mae: 8.0920 - val_loss: 6.4458 - val_mae: 6.4329 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 6.5076 - mae: 6.4946 - val_loss: 5.8872 - val_mae: 5.8741 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 5.9769 - mae: 5.9638 - val_loss: 5.5632 - val_mae: 5.5500 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 5.7263 - mae: 5.7131 - val_loss: 5.4281 - val_mae: 5.4149 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 5.5883 - mae: 5.5751 - val_loss: 5.2442 - val_mae: 5.2310 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 5.3871 - mae: 5.3739 - val_loss: 5.0193 - val_mae: 5.0061 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 5.1518 - mae: 5.1386 - val_loss: 4.8753 - val_mae: 4.8621 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 4.9272 - mae: 4.9140 - val_loss: 4.7089 - val_mae: 4.6956 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 4.7976 - mae: 4.7842 - val_loss: 4.8397 - val_mae: 4.8263 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 4.7111 - mae: 4.6977 - val_loss: 4.5672 - val_mae: 4.5538 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 4.5282 - mae: 4.5148 - val_loss: 4.4934 - val_mae: 4.4800 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 4.4555 - mae: 4.4420 - val_loss: 4.5203 - val_mae: 4.5067 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 4.3063 - mae: 4.2927 - val_loss: 4.4845 - val_mae: 4.4709 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 4.2840 - mae: 4.2704 - val_loss: 4.4741 - val_mae: 4.4605 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 4.1669 - mae: 4.1533 - val_loss: 4.3526 - val_mae: 4.3389 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 4.0996 - mae: 4.0858 - val_loss: 4.1480 - val_mae: 4.1343 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 4.0151 - mae: 4.0013 - val_loss: 4.2556 - val_mae: 4.2418 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 3.9802 - mae: 3.9664 - val_loss: 4.2997 - val_mae: 4.2858 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 3.9616 - mae: 3.9478 - val_loss: 4.1726 - val_mae: 4.1587 - lr: 5.0000e-04\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 9.3178\n",
      "LV_RMSE_12h: 12.7737\n",
      "LV_MAE_24h: 6.3364\n",
      "LV_RMSE_24h: 9.3225\n",
      "LV_MAE_48h: 7.3240\n",
      "LV_RMSE_48h: 10.3387\n",
      "LV_MAE_72h: 6.0249\n",
      "LV_RMSE_72h: 9.3202\n",
      "LV_MAE_mean: 7.2508\n",
      "LV_RMSE_mean: 10.4388\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 4.8835\n",
      "RMSE_12h: 7.0002\n",
      "MAE_24h: 4.6677\n",
      "RMSE_24h: 6.9189\n",
      "MAE_48h: 4.8641\n",
      "RMSE_48h: 7.1862\n",
      "MAE_72h: 5.0031\n",
      "RMSE_72h: 7.1348\n",
      "MAE_mean: 4.8546\n",
      "RMSE_mean: 7.0600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Station S3027031 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1377 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1354, 24, 400) Ytr2: (1354, 4) \n",
      "  Xva3: (197, 24, 400) Yva2: (197, 4) \n",
      "  Xte3: (348, 24, 400) Yte2: (348, 4)\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 3s 58ms/step - loss: 1787.7662 - mae: 1787.7533 - val_loss: 1766.7675 - val_mae: 1766.7546 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1782.0861 - mae: 1782.0731 - val_loss: 1758.3406 - val_mae: 1758.3275 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1771.6595 - mae: 1771.6464 - val_loss: 1745.8982 - val_mae: 1745.8845 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1757.8566 - mae: 1757.8429 - val_loss: 1729.9921 - val_mae: 1729.9778 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1739.8160 - mae: 1739.8013 - val_loss: 1709.7946 - val_mae: 1709.7789 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1717.6368 - mae: 1717.6206 - val_loss: 1684.9816 - val_mae: 1684.9645 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1690.8207 - mae: 1690.8026 - val_loss: 1655.4442 - val_mae: 1655.4249 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1659.2865 - mae: 1659.2659 - val_loss: 1620.9570 - val_mae: 1620.9353 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1622.2742 - mae: 1622.2513 - val_loss: 1581.1211 - val_mae: 1581.0963 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1580.3556 - mae: 1580.3293 - val_loss: 1536.0879 - val_mae: 1536.0594 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1532.9618 - mae: 1532.9316 - val_loss: 1485.8649 - val_mae: 1485.8326 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1482.2843 - mae: 1482.2504 - val_loss: 1431.3228 - val_mae: 1431.2861 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1426.7668 - mae: 1426.7281 - val_loss: 1377.2687 - val_mae: 1377.2273 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1372.5327 - mae: 1372.4891 - val_loss: 1325.6287 - val_mae: 1325.5822 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1320.0100 - mae: 1319.9613 - val_loss: 1277.6138 - val_mae: 1277.5620 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1272.3824 - mae: 1272.3286 - val_loss: 1233.8210 - val_mae: 1233.7639 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 1227.7896 - mae: 1227.7300 - val_loss: 1190.9546 - val_mae: 1190.8920 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1184.1189 - mae: 1184.0540 - val_loss: 1148.9921 - val_mae: 1148.9238 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1141.1078 - mae: 1141.0371 - val_loss: 1108.5187 - val_mae: 1108.4447 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1103.3401 - mae: 1103.2638 - val_loss: 1071.6136 - val_mae: 1071.5339 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 1502.3477\n",
      "LV_RMSE_12h: 1703.4070\n",
      "LV_MAE_24h: 239.4109\n",
      "LV_RMSE_24h: 338.5812\n",
      "LV_MAE_48h: 288.1092\n",
      "LV_RMSE_48h: 388.9338\n",
      "LV_MAE_72h: 261.5661\n",
      "LV_RMSE_72h: 370.2529\n",
      "LV_MAE_mean: 572.8585\n",
      "LV_RMSE_mean: 700.2937\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 1027.0046\n",
      "RMSE_12h: 1232.7543\n",
      "MAE_24h: 1037.9821\n",
      "RMSE_24h: 1235.7804\n",
      "MAE_48h: 1053.4854\n",
      "RMSE_48h: 1260.8412\n",
      "MAE_72h: 1053.9508\n",
      "RMSE_72h: 1264.6086\n",
      "MAE_mean: 1043.1057\n",
      "RMSE_mean: 1248.4961\n",
      "\n",
      "=== Station S3027032 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1377 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1354, 24, 400) Ytr2: (1354, 4) \n",
      "  Xva3: (197, 24, 400) Yva2: (197, 4) \n",
      "  Xte3: (348, 24, 400) Yte2: (348, 4)\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 4s 63ms/step - loss: 1852.8362 - mae: 1852.8237 - val_loss: 1800.7162 - val_mae: 1800.7034 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1847.4147 - mae: 1847.4020 - val_loss: 1792.4659 - val_mae: 1792.4529 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1837.1041 - mae: 1837.0908 - val_loss: 1779.8379 - val_mae: 1779.8242 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1822.8091 - mae: 1822.7947 - val_loss: 1763.2236 - val_mae: 1763.2091 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1804.1920 - mae: 1804.1768 - val_loss: 1741.9078 - val_mae: 1741.8916 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1780.4899 - mae: 1780.4730 - val_loss: 1715.2830 - val_mae: 1715.2649 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1751.6562 - mae: 1751.6372 - val_loss: 1683.3342 - val_mae: 1683.3137 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1717.1487 - mae: 1717.1268 - val_loss: 1645.8071 - val_mae: 1645.7836 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1677.3990 - mae: 1677.3740 - val_loss: 1602.5948 - val_mae: 1602.5682 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1630.5883 - mae: 1630.5597 - val_loss: 1553.5752 - val_mae: 1553.5444 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1580.1044 - mae: 1580.0717 - val_loss: 1499.4524 - val_mae: 1499.4172 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1526.5397 - mae: 1526.5024 - val_loss: 1444.3871 - val_mae: 1444.3468 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1472.1575 - mae: 1472.1151 - val_loss: 1390.3558 - val_mae: 1390.3105 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1419.7572 - mae: 1419.7095 - val_loss: 1338.3950 - val_mae: 1338.3442 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1371.6611 - mae: 1371.6082 - val_loss: 1290.2256 - val_mae: 1290.1693 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1325.4482 - mae: 1325.3896 - val_loss: 1247.2708 - val_mae: 1247.2089 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1282.2903 - mae: 1282.2260 - val_loss: 1206.4952 - val_mae: 1206.4275 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1239.4203 - mae: 1239.3499 - val_loss: 1166.2726 - val_mae: 1166.1987 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1202.9620 - mae: 1202.8856 - val_loss: 1126.0338 - val_mae: 1125.9540 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1161.8979 - mae: 1161.8153 - val_loss: 1087.7175 - val_mae: 1087.6312 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 1607.1093\n",
      "LV_RMSE_12h: 1788.5220\n",
      "LV_MAE_24h: 325.9770\n",
      "LV_RMSE_24h: 490.5002\n",
      "LV_MAE_48h: 406.8448\n",
      "LV_RMSE_48h: 591.0184\n",
      "LV_MAE_72h: 351.9799\n",
      "LV_RMSE_72h: 522.8187\n",
      "LV_MAE_mean: 672.9778\n",
      "LV_RMSE_mean: 848.2148\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 1114.3712\n",
      "RMSE_12h: 1337.4071\n",
      "MAE_24h: 1108.3110\n",
      "RMSE_24h: 1318.1306\n",
      "MAE_48h: 1112.1394\n",
      "RMSE_48h: 1324.0330\n",
      "MAE_72h: 1111.0297\n",
      "RMSE_72h: 1321.4849\n",
      "MAE_mean: 1111.4628\n",
      "RMSE_mean: 1325.2639\n",
      "\n",
      "=== Station S3027041 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1377 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1354, 24, 400) Ytr2: (1354, 4) \n",
      "  Xva3: (197, 24, 400) Yva2: (197, 4) \n",
      "  Xte3: (348, 24, 400) Yte2: (348, 4)\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 3s 59ms/step - loss: 1817.4043 - mae: 1817.3916 - val_loss: 1743.6938 - val_mae: 1743.6812 - lr: 0.0010\n",
      "Epoch 2/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 13ms/step - loss: 1811.6960 - mae: 1811.6833 - val_loss: 1735.1677 - val_mae: 1735.1548 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1801.4683 - mae: 1801.4553 - val_loss: 1723.5054 - val_mae: 1723.4921 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1788.7760 - mae: 1788.7623 - val_loss: 1708.8635 - val_mae: 1708.8496 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1772.3231 - mae: 1772.3087 - val_loss: 1690.6193 - val_mae: 1690.6042 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1752.5864 - mae: 1752.5707 - val_loss: 1668.4292 - val_mae: 1668.4126 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1728.1722 - mae: 1728.1549 - val_loss: 1642.0726 - val_mae: 1642.0542 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1700.2858 - mae: 1700.2665 - val_loss: 1611.4125 - val_mae: 1611.3918 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1667.6298 - mae: 1667.6078 - val_loss: 1576.3894 - val_mae: 1576.3661 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1630.3948 - mae: 1630.3702 - val_loss: 1536.6337 - val_mae: 1536.6074 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1589.0497 - mae: 1589.0216 - val_loss: 1492.2273 - val_mae: 1492.1974 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1543.3160 - mae: 1543.2847 - val_loss: 1444.4331 - val_mae: 1444.3993 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1494.5553 - mae: 1494.5197 - val_loss: 1395.3232 - val_mae: 1395.2852 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1446.0985 - mae: 1446.0585 - val_loss: 1347.4917 - val_mae: 1347.4492 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 1399.8804 - mae: 1399.8358 - val_loss: 1302.0186 - val_mae: 1301.9716 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1357.4677 - mae: 1357.4186 - val_loss: 1258.4122 - val_mae: 1258.3606 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1317.6703 - mae: 1317.6163 - val_loss: 1217.8447 - val_mae: 1217.7882 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1277.7311 - mae: 1277.6724 - val_loss: 1180.2737 - val_mae: 1180.2122 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1239.7627 - mae: 1239.6990 - val_loss: 1143.6509 - val_mae: 1143.5842 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1206.1240 - mae: 1206.0551 - val_loss: 1107.4873 - val_mae: 1107.4154 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 1559.9799\n",
      "LV_RMSE_12h: 1728.5758\n",
      "LV_MAE_24h: 278.8678\n",
      "LV_RMSE_24h: 431.9521\n",
      "LV_MAE_48h: 367.3965\n",
      "LV_RMSE_48h: 536.5060\n",
      "LV_MAE_72h: 312.9828\n",
      "LV_RMSE_72h: 464.7385\n",
      "LV_MAE_mean: 629.8067\n",
      "LV_RMSE_mean: 790.4431\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 1086.5858\n",
      "RMSE_12h: 1311.8879\n",
      "MAE_24h: 1122.7852\n",
      "RMSE_24h: 1350.0322\n",
      "MAE_48h: 1088.6810\n",
      "RMSE_48h: 1304.6466\n",
      "MAE_72h: 1137.4011\n",
      "RMSE_72h: 1370.2649\n",
      "MAE_mean: 1108.8633\n",
      "RMSE_mean: 1334.2080\n",
      "\n",
      "=== Station S3027042 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1288 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1265, 24, 400) Ytr2: (1265, 4) \n",
      "  Xva3: (185, 24, 400) Yva2: (185, 4) \n",
      "  Xte3: (321, 24, 400) Yte2: (321, 4)\n",
      "Epoch 1/20\n",
      "10/10 [==============================] - 3s 63ms/step - loss: 51.8994 - mae: 51.8865 - val_loss: 43.5380 - val_mae: 43.5250 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 47.8033 - mae: 47.7903 - val_loss: 39.3324 - val_mae: 39.3192 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 42.7337 - mae: 42.7203 - val_loss: 35.4641 - val_mae: 35.4504 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 38.5540 - mae: 38.5401 - val_loss: 33.2932 - val_mae: 33.2789 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 35.6339 - mae: 35.6193 - val_loss: 31.8969 - val_mae: 31.8819 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 33.6486 - mae: 33.6334 - val_loss: 30.4477 - val_mae: 30.4322 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 31.6378 - mae: 31.6222 - val_loss: 28.8619 - val_mae: 28.8462 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 29.6828 - mae: 29.6669 - val_loss: 27.2465 - val_mae: 27.2305 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 28.0271 - mae: 28.0110 - val_loss: 25.7422 - val_mae: 25.7259 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 26.5961 - mae: 26.5796 - val_loss: 24.5479 - val_mae: 24.5312 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 25.5747 - mae: 25.5577 - val_loss: 23.9656 - val_mae: 23.9484 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 24.5810 - mae: 24.5636 - val_loss: 23.1442 - val_mae: 23.1264 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 23.4960 - mae: 23.4780 - val_loss: 22.3261 - val_mae: 22.3078 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 22.5720 - mae: 22.5534 - val_loss: 21.7609 - val_mae: 21.7420 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 21.4532 - mae: 21.4340 - val_loss: 20.8278 - val_mae: 20.8082 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 20.8312 - mae: 20.8113 - val_loss: 20.3358 - val_mae: 20.3155 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 20.0644 - mae: 20.0438 - val_loss: 20.0382 - val_mae: 20.0173 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 19.5306 - mae: 19.5094 - val_loss: 20.0744 - val_mae: 20.0530 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 19.2082 - mae: 19.1865 - val_loss: 20.6394 - val_mae: 20.6175 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 18.7670 - mae: 18.7450 - val_loss: 19.4497 - val_mae: 19.4276 - lr: 5.0000e-04\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 51.9065\n",
      "LV_RMSE_12h: 63.0142\n",
      "LV_MAE_24h: 16.8162\n",
      "LV_RMSE_24h: 26.0516\n",
      "LV_MAE_48h: 22.0093\n",
      "LV_RMSE_48h: 35.6861\n",
      "LV_MAE_72h: 21.0748\n",
      "LV_RMSE_72h: 35.6326\n",
      "LV_MAE_mean: 27.9517\n",
      "LV_RMSE_mean: 40.0961\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 18.7956\n",
      "RMSE_12h: 29.7928\n",
      "MAE_24h: 17.6918\n",
      "RMSE_24h: 27.4746\n",
      "MAE_48h: 17.4783\n",
      "RMSE_48h: 28.5481\n",
      "MAE_72h: 16.4909\n",
      "RMSE_72h: 27.5720\n",
      "MAE_mean: 17.6142\n",
      "RMSE_mean: 28.3469\n",
      "\n",
      "=== Station S3027051 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1377 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1354, 24, 400) Ytr2: (1354, 4) \n",
      "  Xva3: (197, 24, 400) Yva2: (197, 4) \n",
      "  Xte3: (348, 24, 400) Yte2: (348, 4)\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 3s 56ms/step - loss: 1783.8790 - mae: 1783.8663 - val_loss: 1701.3029 - val_mae: 1701.2899 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1778.1722 - mae: 1778.1593 - val_loss: 1693.2922 - val_mae: 1693.2791 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1768.5594 - mae: 1768.5461 - val_loss: 1681.8661 - val_mae: 1681.8527 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1755.6438 - mae: 1755.6298 - val_loss: 1666.7510 - val_mae: 1666.7367 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1738.5083 - mae: 1738.4935 - val_loss: 1647.7107 - val_mae: 1647.6951 - lr: 0.0010\n",
      "Epoch 6/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 12ms/step - loss: 1717.5854 - mae: 1717.5695 - val_loss: 1624.2617 - val_mae: 1624.2446 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1692.4528 - mae: 1692.4344 - val_loss: 1596.0715 - val_mae: 1596.0524 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1661.9463 - mae: 1661.9261 - val_loss: 1563.1600 - val_mae: 1563.1383 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1627.2467 - mae: 1627.2241 - val_loss: 1525.4315 - val_mae: 1525.4069 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1587.3724 - mae: 1587.3464 - val_loss: 1482.8007 - val_mae: 1482.7726 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1542.3835 - mae: 1542.3540 - val_loss: 1435.1310 - val_mae: 1435.0990 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1493.3040 - mae: 1493.2700 - val_loss: 1382.7289 - val_mae: 1382.6926 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 1439.4203 - mae: 1439.3820 - val_loss: 1329.2721 - val_mae: 1329.2311 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 1385.1248 - mae: 1385.0817 - val_loss: 1275.1611 - val_mae: 1275.1150 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1330.4957 - mae: 1330.4474 - val_loss: 1223.1366 - val_mae: 1223.0852 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1283.0674 - mae: 1283.0138 - val_loss: 1176.7379 - val_mae: 1176.6812 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1237.3552 - mae: 1237.2960 - val_loss: 1133.0986 - val_mae: 1133.0366 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1192.7942 - mae: 1192.7296 - val_loss: 1091.7690 - val_mae: 1091.7014 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1152.8615 - mae: 1152.7911 - val_loss: 1052.3733 - val_mae: 1052.2999 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1114.3804 - mae: 1114.3047 - val_loss: 1016.2095 - val_mae: 1016.1306 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 1426.1552\n",
      "LV_RMSE_12h: 1629.7161\n",
      "LV_MAE_24h: 270.0000\n",
      "LV_RMSE_24h: 365.9311\n",
      "LV_MAE_48h: 319.7242\n",
      "LV_RMSE_48h: 423.9715\n",
      "LV_MAE_72h: 292.2989\n",
      "LV_RMSE_72h: 403.4520\n",
      "LV_MAE_mean: 577.0446\n",
      "LV_RMSE_mean: 705.7677\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 997.1431\n",
      "RMSE_12h: 1212.6876\n",
      "MAE_24h: 1006.7165\n",
      "RMSE_24h: 1212.2043\n",
      "MAE_48h: 1020.2198\n",
      "RMSE_48h: 1234.5339\n",
      "MAE_72h: 1008.5703\n",
      "RMSE_72h: 1221.9192\n",
      "MAE_mean: 1008.1625\n",
      "RMSE_mean: 1220.3363\n",
      "\n",
      "=== Station S3027052 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1288 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1265, 24, 400) Ytr2: (1265, 4) \n",
      "  Xva3: (185, 24, 400) Yva2: (185, 4) \n",
      "  Xte3: (321, 24, 400) Yte2: (321, 4)\n",
      "Epoch 1/20\n",
      "10/10 [==============================] - 3s 67ms/step - loss: 93.0407 - mae: 93.0279 - val_loss: 74.4179 - val_mae: 74.4050 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 87.8338 - mae: 87.8208 - val_loss: 68.0478 - val_mae: 68.0348 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 80.0552 - mae: 80.0419 - val_loss: 62.0565 - val_mae: 62.0430 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 73.6058 - mae: 73.5919 - val_loss: 58.6537 - val_mae: 58.6395 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 69.1477 - mae: 69.1332 - val_loss: 57.2574 - val_mae: 57.2425 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 67.0216 - mae: 67.0064 - val_loss: 57.2816 - val_mae: 57.2661 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 65.6962 - mae: 65.6805 - val_loss: 57.6228 - val_mae: 57.6068 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 64.9350 - mae: 64.9190 - val_loss: 57.6537 - val_mae: 57.6376 - lr: 5.0000e-04\n",
      "Epoch 9/20\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 64.2674 - mae: 64.2512 - val_loss: 57.0413 - val_mae: 57.0251 - lr: 5.0000e-04\n",
      "Epoch 10/20\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 63.3279 - mae: 63.3117 - val_loss: 55.5955 - val_mae: 55.5792 - lr: 5.0000e-04\n",
      "Epoch 11/20\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 61.9363 - mae: 61.9199 - val_loss: 54.0611 - val_mae: 54.0447 - lr: 5.0000e-04\n",
      "Epoch 12/20\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 60.1203 - mae: 60.1038 - val_loss: 51.1154 - val_mae: 51.0988 - lr: 5.0000e-04\n",
      "Epoch 13/20\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 57.2387 - mae: 57.2220 - val_loss: 49.1179 - val_mae: 49.1010 - lr: 5.0000e-04\n",
      "Epoch 14/20\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 55.1363 - mae: 55.1192 - val_loss: 47.6904 - val_mae: 47.6731 - lr: 5.0000e-04\n",
      "Epoch 15/20\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 53.0519 - mae: 53.0345 - val_loss: 46.1849 - val_mae: 46.1672 - lr: 5.0000e-04\n",
      "Epoch 16/20\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 51.2505 - mae: 51.2325 - val_loss: 44.8120 - val_mae: 44.7938 - lr: 5.0000e-04\n",
      "Epoch 17/20\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 49.3080 - mae: 49.2896 - val_loss: 43.6947 - val_mae: 43.6761 - lr: 5.0000e-04\n",
      "Epoch 18/20\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 48.3357 - mae: 48.3169 - val_loss: 42.4012 - val_mae: 42.3822 - lr: 5.0000e-04\n",
      "Epoch 19/20\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 47.3888 - mae: 47.3697 - val_loss: 41.3383 - val_mae: 41.3189 - lr: 5.0000e-04\n",
      "Epoch 20/20\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 46.3737 - mae: 46.3542 - val_loss: 40.6682 - val_mae: 40.6484 - lr: 5.0000e-04\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 93.6947\n",
      "LV_RMSE_12h: 124.0809\n",
      "LV_MAE_24h: 34.6137\n",
      "LV_RMSE_24h: 65.1745\n",
      "LV_MAE_48h: 44.1184\n",
      "LV_RMSE_48h: 78.3523\n",
      "LV_MAE_72h: 37.4829\n",
      "LV_RMSE_72h: 65.7668\n",
      "LV_MAE_mean: 52.4774\n",
      "LV_RMSE_mean: 83.3436\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 57.6537\n",
      "RMSE_12h: 87.3416\n",
      "MAE_24h: 35.2499\n",
      "RMSE_24h: 58.0495\n",
      "MAE_48h: 35.4188\n",
      "RMSE_48h: 59.1786\n",
      "MAE_72h: 32.7257\n",
      "RMSE_72h: 56.0679\n",
      "MAE_mean: 40.2620\n",
      "RMSE_mean: 65.1594\n",
      "\n",
      "=== Station S3027071 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1377 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1354, 24, 400) Ytr2: (1354, 4) \n",
      "  Xva3: (197, 24, 400) Yva2: (197, 4) \n",
      "  Xte3: (348, 24, 400) Yte2: (348, 4)\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 3s 59ms/step - loss: 332.2008 - mae: 332.1882 - val_loss: 306.6924 - val_mae: 306.6797 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 326.5206 - mae: 326.5079 - val_loss: 299.1592 - val_mae: 299.1463 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 317.7210 - mae: 317.7079 - val_loss: 289.6654 - val_mae: 289.6519 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 307.5490 - mae: 307.5352 - val_loss: 279.4788 - val_mae: 279.4645 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 296.7021 - mae: 296.6874 - val_loss: 268.9226 - val_mae: 268.9072 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 285.5831 - mae: 285.5671 - val_loss: 258.0922 - val_mae: 258.0754 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 274.1788 - mae: 274.1613 - val_loss: 247.3316 - val_mae: 247.3132 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 263.4055 - mae: 263.3862 - val_loss: 237.8868 - val_mae: 237.8664 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 253.1478 - mae: 253.1267 - val_loss: 229.8879 - val_mae: 229.8656 - lr: 0.0010\n",
      "Epoch 10/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 13ms/step - loss: 244.2506 - mae: 244.2275 - val_loss: 222.2286 - val_mae: 222.2043 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 235.3145 - mae: 235.2893 - val_loss: 211.2381 - val_mae: 211.2117 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 221.2147 - mae: 221.1874 - val_loss: 195.2177 - val_mae: 195.1890 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 204.8242 - mae: 204.7944 - val_loss: 179.7979 - val_mae: 179.7665 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 189.5316 - mae: 189.4988 - val_loss: 165.1059 - val_mae: 165.0712 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 175.1888 - mae: 175.1526 - val_loss: 152.4324 - val_mae: 152.3943 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 163.3526 - mae: 163.3130 - val_loss: 144.5625 - val_mae: 144.5212 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 156.6539 - mae: 156.6114 - val_loss: 138.7669 - val_mae: 138.7230 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 151.3312 - mae: 151.2865 - val_loss: 135.0223 - val_mae: 134.9766 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 147.9017 - mae: 147.8554 - val_loss: 132.9298 - val_mae: 132.8826 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 144.9446 - mae: 144.8968 - val_loss: 128.7725 - val_mae: 128.7239 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 411.8391\n",
      "LV_RMSE_12h: 466.6105\n",
      "LV_MAE_24h: 86.3879\n",
      "LV_RMSE_24h: 133.0120\n",
      "LV_MAE_48h: 117.0259\n",
      "LV_RMSE_48h: 178.0031\n",
      "LV_MAE_72h: 114.9310\n",
      "LV_RMSE_72h: 184.7457\n",
      "LV_MAE_mean: 182.5460\n",
      "LV_RMSE_mean: 240.5928\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 262.1798\n",
      "RMSE_12h: 325.9301\n",
      "MAE_24h: 102.0063\n",
      "RMSE_24h: 160.4117\n",
      "MAE_48h: 96.4217\n",
      "RMSE_48h: 152.9935\n",
      "MAE_72h: 96.6296\n",
      "RMSE_72h: 151.1544\n",
      "MAE_mean: 139.3093\n",
      "RMSE_mean: 197.6224\n",
      "\n",
      "=== Station S3027081 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1377 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1354, 24, 400) Ytr2: (1354, 4) \n",
      "  Xva3: (197, 24, 400) Yva2: (197, 4) \n",
      "  Xte3: (348, 24, 400) Yte2: (348, 4)\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 3s 59ms/step - loss: 323.6338 - mae: 323.6211 - val_loss: 299.0427 - val_mae: 299.0300 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 318.9047 - mae: 318.8920 - val_loss: 292.6299 - val_mae: 292.6169 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 311.5858 - mae: 311.5728 - val_loss: 284.7067 - val_mae: 284.6934 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 303.1907 - mae: 303.1770 - val_loss: 276.3568 - val_mae: 276.3427 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 293.9366 - mae: 293.9220 - val_loss: 267.5240 - val_mae: 267.5089 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 284.5669 - mae: 284.5511 - val_loss: 258.5239 - val_mae: 258.5073 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 275.1668 - mae: 275.1495 - val_loss: 249.5768 - val_mae: 249.5585 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 265.6802 - mae: 265.6612 - val_loss: 241.0245 - val_mae: 241.0044 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 256.8953 - mae: 256.8744 - val_loss: 233.7839 - val_mae: 233.7619 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 249.8665 - mae: 249.8438 - val_loss: 227.9277 - val_mae: 227.9039 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 242.9967 - mae: 242.9721 - val_loss: 220.0049 - val_mae: 219.9794 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 235.0718 - mae: 235.0455 - val_loss: 212.6450 - val_mae: 212.6178 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 227.3398 - mae: 227.3119 - val_loss: 204.7825 - val_mae: 204.7536 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 219.3222 - mae: 219.2926 - val_loss: 197.6908 - val_mae: 197.6602 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 211.4218 - mae: 211.3903 - val_loss: 190.0642 - val_mae: 190.0317 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 204.0041 - mae: 203.9707 - val_loss: 182.8052 - val_mae: 182.7705 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 194.9728 - mae: 194.9370 - val_loss: 174.4223 - val_mae: 174.3852 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 186.1036 - mae: 186.0654 - val_loss: 165.9464 - val_mae: 165.9066 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 176.8130 - mae: 176.7718 - val_loss: 156.7371 - val_mae: 156.6940 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 168.0775 - mae: 168.0329 - val_loss: 150.8969 - val_mae: 150.8504 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 439.3362\n",
      "LV_RMSE_12h: 539.2956\n",
      "LV_MAE_24h: 80.8736\n",
      "LV_RMSE_24h: 131.8769\n",
      "LV_MAE_48h: 106.8908\n",
      "LV_RMSE_48h: 176.6509\n",
      "LV_MAE_72h: 97.9310\n",
      "LV_RMSE_72h: 167.2991\n",
      "LV_MAE_mean: 181.2579\n",
      "LV_RMSE_mean: 253.7806\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 265.4166\n",
      "RMSE_12h: 379.8284\n",
      "MAE_24h: 102.0722\n",
      "RMSE_24h: 187.0078\n",
      "MAE_48h: 105.9035\n",
      "RMSE_48h: 189.4712\n",
      "MAE_72h: 105.7144\n",
      "RMSE_72h: 188.4413\n",
      "MAE_mean: 144.7767\n",
      "RMSE_mean: 236.1872\n",
      "\n",
      "=== Station S3028011 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1377 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1354, 24, 400) Ytr2: (1354, 4) \n",
      "  Xva3: (197, 24, 400) Yva2: (197, 4) \n",
      "  Xte3: (348, 24, 400) Yte2: (348, 4)\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 3s 59ms/step - loss: 478.9969 - mae: 478.9842 - val_loss: 446.7555 - val_mae: 446.7428 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 472.9100 - mae: 472.8973 - val_loss: 437.9541 - val_mae: 437.9412 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 462.6059 - mae: 462.5929 - val_loss: 426.1852 - val_mae: 426.1719 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 450.1386 - mae: 450.1249 - val_loss: 412.9203 - val_mae: 412.9061 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 436.1031 - mae: 436.0884 - val_loss: 398.9841 - val_mae: 398.9688 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 421.5673 - mae: 421.5513 - val_loss: 384.8419 - val_mae: 384.8251 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 406.7083 - mae: 406.6908 - val_loss: 370.5624 - val_mae: 370.5439 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 391.9210 - mae: 391.9016 - val_loss: 355.8468 - val_mae: 355.8263 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 376.8622 - mae: 376.8407 - val_loss: 342.1066 - val_mae: 342.0837 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 362.1137 - mae: 362.0898 - val_loss: 329.2252 - val_mae: 329.1999 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 349.5551 - mae: 349.5287 - val_loss: 316.9753 - val_mae: 316.9474 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 335.7493 - mae: 335.7203 - val_loss: 304.7440 - val_mae: 304.7135 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 322.0388 - mae: 322.0070 - val_loss: 290.1375 - val_mae: 290.1041 - lr: 0.0010\n",
      "Epoch 14/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 13ms/step - loss: 306.1624 - mae: 306.1277 - val_loss: 273.9590 - val_mae: 273.9226 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 289.0893 - mae: 289.0516 - val_loss: 257.6863 - val_mae: 257.6468 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 273.3857 - mae: 273.3447 - val_loss: 240.2181 - val_mae: 240.1751 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 254.4524 - mae: 254.4077 - val_loss: 222.3870 - val_mae: 222.3402 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 237.8679 - mae: 237.8194 - val_loss: 208.5935 - val_mae: 208.5428 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 224.1519 - mae: 224.0996 - val_loss: 198.3467 - val_mae: 198.2923 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 216.1307 - mae: 216.0749 - val_loss: 191.2344 - val_mae: 191.1771 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 578.5057\n",
      "LV_RMSE_12h: 656.1777\n",
      "LV_MAE_24h: 120.2385\n",
      "LV_RMSE_24h: 175.5774\n",
      "LV_MAE_48h: 163.1782\n",
      "LV_RMSE_48h: 235.5435\n",
      "LV_MAE_72h: 164.7931\n",
      "LV_RMSE_72h: 246.0727\n",
      "LV_MAE_mean: 256.6789\n",
      "LV_RMSE_mean: 328.3428\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 406.9121\n",
      "RMSE_12h: 493.0750\n",
      "MAE_24h: 156.4239\n",
      "RMSE_24h: 228.2005\n",
      "MAE_48h: 156.2197\n",
      "RMSE_48h: 231.5060\n",
      "MAE_72h: 152.6937\n",
      "RMSE_72h: 224.8103\n",
      "MAE_mean: 218.0623\n",
      "RMSE_mean: 294.3979\n",
      "\n",
      "=== Station S3028015 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1351 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1328, 24, 400) Ytr2: (1328, 4) \n",
      "  Xva3: (194, 24, 400) Yva2: (194, 4) \n",
      "  Xte3: (339, 24, 400) Yte2: (339, 4)\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 3s 61ms/step - loss: 5.8170 - mae: 5.8043 - val_loss: 6.3056 - val_mae: 6.2928 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 5.3755 - mae: 5.3627 - val_loss: 6.1507 - val_mae: 6.1380 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 5.2344 - mae: 5.2218 - val_loss: 5.9981 - val_mae: 5.9855 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 5.1136 - mae: 5.1010 - val_loss: 5.8712 - val_mae: 5.8586 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 4.9764 - mae: 4.9637 - val_loss: 5.7275 - val_mae: 5.7148 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 4.8201 - mae: 4.8074 - val_loss: 5.5705 - val_mae: 5.5577 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 4.6803 - mae: 4.6675 - val_loss: 5.5023 - val_mae: 5.4894 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 4.5034 - mae: 4.4903 - val_loss: 5.2675 - val_mae: 5.2544 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 4.2864 - mae: 4.2731 - val_loss: 5.1184 - val_mae: 5.1049 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 4.1235 - mae: 4.1099 - val_loss: 4.9225 - val_mae: 4.9087 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 3.9212 - mae: 3.9073 - val_loss: 4.7964 - val_mae: 4.7822 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 3.8119 - mae: 3.7976 - val_loss: 4.6054 - val_mae: 4.5909 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 3.7448 - mae: 3.7301 - val_loss: 4.5686 - val_mae: 4.5537 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 3.6171 - mae: 3.6021 - val_loss: 4.6701 - val_mae: 4.6549 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 3.5651 - mae: 3.5498 - val_loss: 4.5926 - val_mae: 4.5772 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 3.4962 - mae: 3.4807 - val_loss: 4.2973 - val_mae: 4.2817 - lr: 5.0000e-04\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 3.3625 - mae: 3.3469 - val_loss: 4.3122 - val_mae: 4.2964 - lr: 5.0000e-04\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 3.2963 - mae: 3.2805 - val_loss: 4.2213 - val_mae: 4.2054 - lr: 5.0000e-04\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 3.2915 - mae: 3.2755 - val_loss: 4.2064 - val_mae: 4.1903 - lr: 5.0000e-04\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 3.2422 - mae: 3.2261 - val_loss: 4.1548 - val_mae: 4.1385 - lr: 5.0000e-04\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 7.2979\n",
      "LV_RMSE_12h: 19.6083\n",
      "LV_MAE_24h: 2.9469\n",
      "LV_RMSE_24h: 8.3013\n",
      "LV_MAE_48h: 3.8850\n",
      "LV_RMSE_48h: 12.0247\n",
      "LV_MAE_72h: 4.0295\n",
      "LV_RMSE_72h: 12.6314\n",
      "LV_MAE_mean: 4.5398\n",
      "LV_RMSE_mean: 13.1414\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 3.2476\n",
      "RMSE_12h: 9.3447\n",
      "MAE_24h: 4.2388\n",
      "RMSE_24h: 10.7193\n",
      "MAE_48h: 4.2809\n",
      "RMSE_48h: 10.6030\n",
      "MAE_72h: 4.0436\n",
      "RMSE_72h: 9.6519\n",
      "MAE_mean: 3.9527\n",
      "RMSE_mean: 10.0797\n",
      "\n",
      "=== Station S3028021 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1377 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1354, 24, 400) Ytr2: (1354, 4) \n",
      "  Xva3: (197, 24, 400) Yva2: (197, 4) \n",
      "  Xte3: (348, 24, 400) Yte2: (348, 4)\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 3s 60ms/step - loss: 485.4618 - mae: 485.4491 - val_loss: 439.0361 - val_mae: 439.0233 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 479.0697 - mae: 479.0569 - val_loss: 430.5804 - val_mae: 430.5674 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 469.4216 - mae: 469.4085 - val_loss: 419.8737 - val_mae: 419.8603 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 457.7998 - mae: 457.7861 - val_loss: 407.6716 - val_mae: 407.6575 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 444.2828 - mae: 444.2682 - val_loss: 394.8717 - val_mae: 394.8565 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 430.8609 - mae: 430.8452 - val_loss: 382.0836 - val_mae: 382.0671 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 417.2388 - mae: 417.2216 - val_loss: 368.9829 - val_mae: 368.9649 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 403.0934 - mae: 403.0746 - val_loss: 355.5564 - val_mae: 355.5367 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 389.5646 - mae: 389.5439 - val_loss: 342.5334 - val_mae: 342.5117 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 374.9696 - mae: 374.9469 - val_loss: 330.6363 - val_mae: 330.6123 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 362.2343 - mae: 362.2093 - val_loss: 318.8043 - val_mae: 318.7780 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 349.1063 - mae: 349.0789 - val_loss: 306.1358 - val_mae: 306.1071 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 335.0187 - mae: 334.9889 - val_loss: 293.1098 - val_mae: 293.0784 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 319.7025 - mae: 319.6700 - val_loss: 279.7040 - val_mae: 279.6700 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 304.8150 - mae: 304.7797 - val_loss: 266.0004 - val_mae: 265.9633 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 288.8810 - mae: 288.8426 - val_loss: 249.7224 - val_mae: 249.6822 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 273.3839 - mae: 273.3423 - val_loss: 235.3142 - val_mae: 235.2706 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 258.1314 - mae: 258.0863 - val_loss: 221.9431 - val_mae: 221.8959 - lr: 0.0010\n",
      "Epoch 19/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 12ms/step - loss: 243.1539 - mae: 243.1050 - val_loss: 209.3407 - val_mae: 209.2897 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 232.1443 - mae: 232.0917 - val_loss: 200.4220 - val_mae: 200.3672 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 573.1580\n",
      "LV_RMSE_12h: 649.7272\n",
      "LV_MAE_24h: 119.5747\n",
      "LV_RMSE_24h: 175.1597\n",
      "LV_MAE_48h: 162.6494\n",
      "LV_RMSE_48h: 234.7627\n",
      "LV_MAE_72h: 163.8592\n",
      "LV_RMSE_72h: 245.8071\n",
      "LV_MAE_mean: 254.8103\n",
      "LV_RMSE_mean: 326.3642\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 389.6536\n",
      "RMSE_12h: 465.4293\n",
      "MAE_24h: 165.5886\n",
      "RMSE_24h: 233.6208\n",
      "MAE_48h: 167.4069\n",
      "RMSE_48h: 239.0080\n",
      "MAE_72h: 167.8656\n",
      "RMSE_72h: 240.7907\n",
      "MAE_mean: 222.6286\n",
      "RMSE_mean: 294.7122\n",
      "\n",
      "=== Station S3028025 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 906 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (883, 24, 400) Ytr2: (883, 4) \n",
      "  Xva3: (130, 24, 400) Yva2: (130, 4) \n",
      "  Xte3: (213, 24, 400) Yte2: (213, 4)\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 3s 89ms/step - loss: 66.4902 - mae: 66.4774 - val_loss: 71.3947 - val_mae: 71.3818 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 63.4947 - mae: 63.4819 - val_loss: 67.5622 - val_mae: 67.5492 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 58.9407 - mae: 58.9277 - val_loss: 62.0583 - val_mae: 62.0452 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 53.1860 - mae: 53.1728 - val_loss: 55.8903 - val_mae: 55.8769 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 47.5042 - mae: 47.4906 - val_loss: 50.0022 - val_mae: 49.9884 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 42.2886 - mae: 42.2745 - val_loss: 45.3502 - val_mae: 45.3359 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 38.3486 - mae: 38.3341 - val_loss: 41.9969 - val_mae: 41.9820 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 35.9592 - mae: 35.9442 - val_loss: 39.9639 - val_mae: 39.9486 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 35.1789 - mae: 35.1634 - val_loss: 38.9162 - val_mae: 38.9006 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 34.7929 - mae: 34.7772 - val_loss: 38.5129 - val_mae: 38.4973 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 34.5228 - mae: 34.5072 - val_loss: 38.3989 - val_mae: 38.3833 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 34.2571 - mae: 34.2416 - val_loss: 38.2859 - val_mae: 38.2704 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 33.9023 - mae: 33.8868 - val_loss: 37.6232 - val_mae: 37.6078 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 32.9790 - mae: 32.9636 - val_loss: 36.3396 - val_mae: 36.3243 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 31.4385 - mae: 31.4231 - val_loss: 34.6787 - val_mae: 34.6632 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 30.3473 - mae: 30.3317 - val_loss: 32.9558 - val_mae: 32.9401 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 29.1206 - mae: 29.1048 - val_loss: 31.4070 - val_mae: 31.3911 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 28.2120 - mae: 28.1960 - val_loss: 30.3408 - val_mae: 30.3247 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 27.2351 - mae: 27.2189 - val_loss: 30.1159 - val_mae: 30.0997 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 26.6004 - mae: 26.5841 - val_loss: 28.8874 - val_mae: 28.8711 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 55.7559\n",
      "LV_RMSE_12h: 62.1254\n",
      "LV_MAE_24h: 19.0094\n",
      "LV_RMSE_24h: 27.6377\n",
      "LV_MAE_48h: 21.0094\n",
      "LV_RMSE_48h: 30.2770\n",
      "LV_MAE_72h: 15.7512\n",
      "LV_RMSE_72h: 21.1748\n",
      "LV_MAE_mean: 27.8815\n",
      "LV_RMSE_mean: 35.3037\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 36.5700\n",
      "RMSE_12h: 43.4775\n",
      "MAE_24h: 16.7683\n",
      "RMSE_24h: 22.6045\n",
      "MAE_48h: 15.6718\n",
      "RMSE_48h: 21.2346\n",
      "MAE_72h: 15.5115\n",
      "RMSE_72h: 20.5292\n",
      "MAE_mean: 21.1304\n",
      "RMSE_mean: 26.9615\n",
      "\n",
      "=== Station S3028031 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1377 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1354, 24, 400) Ytr2: (1354, 4) \n",
      "  Xva3: (197, 24, 400) Yva2: (197, 4) \n",
      "  Xte3: (348, 24, 400) Yte2: (348, 4)\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 3s 59ms/step - loss: 486.5202 - mae: 486.5072 - val_loss: 454.1085 - val_mae: 454.0955 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 481.0569 - mae: 481.0439 - val_loss: 446.3820 - val_mae: 446.3688 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 471.7429 - mae: 471.7295 - val_loss: 435.5139 - val_mae: 435.5002 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 459.9902 - mae: 459.9761 - val_loss: 422.8137 - val_mae: 422.7991 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 446.0436 - mae: 446.0285 - val_loss: 408.9833 - val_mae: 408.9673 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 431.3392 - mae: 431.3227 - val_loss: 394.4857 - val_mae: 394.4682 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 416.7582 - mae: 416.7399 - val_loss: 379.8447 - val_mae: 379.8252 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 401.4303 - mae: 401.4100 - val_loss: 365.3895 - val_mae: 365.3679 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 386.7314 - mae: 386.7088 - val_loss: 351.7522 - val_mae: 351.7282 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 372.3938 - mae: 372.3686 - val_loss: 339.5053 - val_mae: 339.4787 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 359.4438 - mae: 359.4160 - val_loss: 328.2423 - val_mae: 328.2130 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 347.4202 - mae: 347.3897 - val_loss: 316.2044 - val_mae: 316.1724 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 332.4559 - mae: 332.4226 - val_loss: 296.8333 - val_mae: 296.7982 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 311.2409 - mae: 311.2045 - val_loss: 276.3885 - val_mae: 276.3502 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 290.9829 - mae: 290.9429 - val_loss: 257.5280 - val_mae: 257.4860 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 272.5177 - mae: 272.4739 - val_loss: 238.9311 - val_mae: 238.8849 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 254.5051 - mae: 254.4569 - val_loss: 221.1351 - val_mae: 221.0845 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 237.4642 - mae: 237.4117 - val_loss: 207.5969 - val_mae: 207.5419 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 226.2081 - mae: 226.1513 - val_loss: 199.8426 - val_mae: 199.7836 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 218.9009 - mae: 218.8405 - val_loss: 195.1615 - val_mae: 195.0997 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 587.2012\n",
      "LV_RMSE_12h: 663.7562\n",
      "LV_MAE_24h: 119.9770\n",
      "LV_RMSE_24h: 182.6949\n",
      "LV_MAE_48h: 164.6552\n",
      "LV_RMSE_48h: 243.4025\n",
      "LV_MAE_72h: 166.9081\n",
      "LV_RMSE_72h: 254.9339\n",
      "LV_MAE_mean: 259.6853\n",
      "LV_RMSE_mean: 336.1969\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 416.9877\n",
      "RMSE_12h: 506.4646\n",
      "MAE_24h: 158.1823\n",
      "RMSE_24h: 235.7273\n",
      "MAE_48h: 147.2198\n",
      "RMSE_48h: 225.2371\n",
      "MAE_72h: 151.2877\n",
      "RMSE_72h: 227.0698\n",
      "MAE_mean: 218.4194\n",
      "RMSE_mean: 298.6247\n",
      "\n",
      "=== Station S3028041 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1377 rows, 1631 features...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1354, 24, 400) Ytr2: (1354, 4) \n",
      "  Xva3: (197, 24, 400) Yva2: (197, 4) \n",
      "  Xte3: (348, 24, 400) Yte2: (348, 4)\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 3s 57ms/step - loss: 343.3787 - mae: 343.3659 - val_loss: 310.5972 - val_mae: 310.5844 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 336.6468 - mae: 336.6339 - val_loss: 302.0677 - val_mae: 302.0547 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 327.3562 - mae: 327.3430 - val_loss: 292.4068 - val_mae: 292.3932 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 317.1440 - mae: 317.1301 - val_loss: 282.4238 - val_mae: 282.4094 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 305.8339 - mae: 305.8190 - val_loss: 272.3429 - val_mae: 272.3272 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 294.7670 - mae: 294.7506 - val_loss: 261.3451 - val_mae: 261.3279 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 282.9426 - mae: 282.9245 - val_loss: 250.0136 - val_mae: 249.9945 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 270.4968 - mae: 270.4767 - val_loss: 237.9555 - val_mae: 237.9342 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 257.6259 - mae: 257.6036 - val_loss: 225.3337 - val_mae: 225.3100 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 244.0666 - mae: 244.0419 - val_loss: 214.3143 - val_mae: 214.2882 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 232.1393 - mae: 232.1122 - val_loss: 203.7886 - val_mae: 203.7602 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 222.2178 - mae: 222.1884 - val_loss: 194.2761 - val_mae: 194.2454 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 212.9427 - mae: 212.9110 - val_loss: 185.3816 - val_mae: 185.3485 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 203.6386 - mae: 203.6044 - val_loss: 178.6559 - val_mae: 178.6202 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 194.5083 - mae: 194.4714 - val_loss: 167.1104 - val_mae: 167.0718 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 184.4509 - mae: 184.4109 - val_loss: 157.5485 - val_mae: 157.5066 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 174.1726 - mae: 174.1292 - val_loss: 151.5681 - val_mae: 151.5226 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 165.3121 - mae: 165.2651 - val_loss: 143.5375 - val_mae: 143.4884 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 158.3613 - mae: 158.3105 - val_loss: 134.9330 - val_mae: 134.8799 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 150.3206 - mae: 150.2659 - val_loss: 128.2925 - val_mae: 128.2358 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 482.1149\n",
      "LV_RMSE_12h: 572.8908\n",
      "LV_MAE_24h: 82.5402\n",
      "LV_RMSE_24h: 126.7685\n",
      "LV_MAE_48h: 102.6437\n",
      "LV_RMSE_48h: 156.2969\n",
      "LV_MAE_72h: 94.3218\n",
      "LV_RMSE_72h: 143.8277\n",
      "LV_MAE_mean: 190.4052\n",
      "LV_RMSE_mean: 249.9460\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 279.6185\n",
      "RMSE_12h: 388.7482\n",
      "MAE_24h: 95.8936\n",
      "RMSE_24h: 156.9845\n",
      "MAE_48h: 100.9407\n",
      "RMSE_48h: 160.9172\n",
      "MAE_72h: 101.8125\n",
      "RMSE_72h: 160.6768\n",
      "MAE_mean: 144.5663\n",
      "RMSE_mean: 216.8317\n",
      "\n",
      "=== Station S3028042 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1377 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1354, 24, 400) Ytr2: (1354, 4) \n",
      "  Xva3: (197, 24, 400) Yva2: (197, 4) \n",
      "  Xte3: (348, 24, 400) Yte2: (348, 4)\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 3s 62ms/step - loss: 1990.5043 - mae: 1990.4913 - val_loss: 1982.1982 - val_mae: 1982.1853 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1983.9900 - mae: 1983.9771 - val_loss: 1973.0017 - val_mae: 1972.9885 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1972.6632 - mae: 1972.6498 - val_loss: 1959.3296 - val_mae: 1959.3158 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1957.4402 - mae: 1957.4259 - val_loss: 1941.4618 - val_mae: 1941.4469 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1936.8062 - mae: 1936.7904 - val_loss: 1918.5153 - val_mae: 1918.4988 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1911.7710 - mae: 1911.7537 - val_loss: 1890.2384 - val_mae: 1890.2198 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1881.3643 - mae: 1881.3448 - val_loss: 1856.4032 - val_mae: 1856.3820 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1844.4070 - mae: 1844.3844 - val_loss: 1816.6753 - val_mae: 1816.6510 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1802.6945 - mae: 1802.6686 - val_loss: 1771.0590 - val_mae: 1771.0311 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1754.6514 - mae: 1754.6218 - val_loss: 1719.7738 - val_mae: 1719.7416 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1701.4269 - mae: 1701.3929 - val_loss: 1664.7668 - val_mae: 1664.7300 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1645.5157 - mae: 1645.4767 - val_loss: 1608.8914 - val_mae: 1608.8492 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1590.8317 - mae: 1590.7874 - val_loss: 1553.5005 - val_mae: 1553.4530 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1538.7058 - mae: 1538.6559 - val_loss: 1501.4746 - val_mae: 1501.4215 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1489.2578 - mae: 1489.2021 - val_loss: 1452.1196 - val_mae: 1452.0609 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1444.6294 - mae: 1444.5680 - val_loss: 1407.9874 - val_mae: 1407.9227 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1404.0587 - mae: 1403.9913 - val_loss: 1368.0930 - val_mae: 1368.0223 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1359.5573 - mae: 1359.4839 - val_loss: 1329.8024 - val_mae: 1329.7257 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1324.3364 - mae: 1324.2570 - val_loss: 1292.8063 - val_mae: 1292.7234 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1288.9519 - mae: 1288.8662 - val_loss: 1257.0507 - val_mae: 1256.9614 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 1951.9828\n",
      "LV_RMSE_12h: 2246.1653\n",
      "LV_MAE_24h: 390.9799\n",
      "LV_RMSE_24h: 571.5546\n",
      "LV_MAE_48h: 483.0632\n",
      "LV_RMSE_48h: 685.1820\n",
      "LV_MAE_72h: 372.0230\n",
      "LV_RMSE_72h: 529.3060\n",
      "LV_MAE_mean: 799.5122\n",
      "LV_RMSE_mean: 1008.0519\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 1221.5194\n",
      "RMSE_12h: 1571.3297\n",
      "MAE_24h: 1239.3157\n",
      "RMSE_24h: 1591.6351\n",
      "MAE_48h: 1204.9680\n",
      "RMSE_48h: 1552.2728\n",
      "MAE_72h: 1192.4275\n",
      "RMSE_72h: 1537.6432\n",
      "MAE_mean: 1214.5576\n",
      "RMSE_mean: 1563.2202\n",
      "\n",
      "=== Station S3028045 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1376 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1353, 24, 400) Ytr2: (1353, 4) \n",
      "  Xva3: (197, 24, 400) Yva2: (197, 4) \n",
      "  Xte3: (348, 24, 400) Yte2: (348, 4)\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 3s 60ms/step - loss: 16.2166 - mae: 16.2039 - val_loss: 14.2150 - val_mae: 14.2022 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 12.9180 - mae: 12.9052 - val_loss: 10.7471 - val_mae: 10.7341 - lr: 0.0010\n",
      "Epoch 3/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 12ms/step - loss: 9.9158 - mae: 9.9026 - val_loss: 8.3049 - val_mae: 8.2916 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 8.2239 - mae: 8.2105 - val_loss: 7.1715 - val_mae: 7.1579 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 7.3948 - mae: 7.3812 - val_loss: 6.4689 - val_mae: 6.4551 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 7.0422 - mae: 7.0284 - val_loss: 6.2499 - val_mae: 6.2360 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 6.8229 - mae: 6.8091 - val_loss: 6.1831 - val_mae: 6.1692 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 6.6967 - mae: 6.6828 - val_loss: 6.0673 - val_mae: 6.0533 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 6.5358 - mae: 6.5218 - val_loss: 6.0393 - val_mae: 6.0253 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 6.4528 - mae: 6.4387 - val_loss: 6.0194 - val_mae: 6.0053 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 6.3066 - mae: 6.2925 - val_loss: 5.9619 - val_mae: 5.9478 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 6.2008 - mae: 6.1866 - val_loss: 6.0053 - val_mae: 5.9911 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 6.1794 - mae: 6.1652 - val_loss: 5.9084 - val_mae: 5.8942 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 6.1038 - mae: 6.0896 - val_loss: 5.9354 - val_mae: 5.9211 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 6.0695 - mae: 6.0552 - val_loss: 5.8641 - val_mae: 5.8498 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 6.0763 - mae: 6.0619 - val_loss: 5.8759 - val_mae: 5.8615 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 5.9526 - mae: 5.9381 - val_loss: 5.8602 - val_mae: 5.8458 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 5.9058 - mae: 5.8913 - val_loss: 5.8683 - val_mae: 5.8538 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 5.8499 - mae: 5.8354 - val_loss: 5.8145 - val_mae: 5.7999 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 5.8095 - mae: 5.7949 - val_loss: 5.8528 - val_mae: 5.8382 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 24.3362\n",
      "LV_RMSE_12h: 29.4470\n",
      "LV_MAE_24h: 7.4310\n",
      "LV_RMSE_24h: 11.8450\n",
      "LV_MAE_48h: 8.5632\n",
      "LV_RMSE_48h: 13.3969\n",
      "LV_MAE_72h: 8.3966\n",
      "LV_RMSE_72h: 13.9436\n",
      "LV_MAE_mean: 12.1818\n",
      "LV_RMSE_mean: 17.1581\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 6.1309\n",
      "RMSE_12h: 9.6225\n",
      "MAE_24h: 6.5367\n",
      "RMSE_24h: 9.9970\n",
      "MAE_48h: 6.5726\n",
      "RMSE_48h: 10.3041\n",
      "MAE_72h: 6.8349\n",
      "RMSE_72h: 10.7839\n",
      "MAE_mean: 6.5188\n",
      "RMSE_mean: 10.1769\n",
      "\n",
      "=== Station S3028046 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1376 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1353, 24, 400) Ytr2: (1353, 4) \n",
      "  Xva3: (197, 24, 400) Yva2: (197, 4) \n",
      "  Xte3: (348, 24, 400) Yte2: (348, 4)\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 3s 59ms/step - loss: 183.1359 - mae: 183.1232 - val_loss: 184.9299 - val_mae: 184.9172 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 177.6445 - mae: 177.6317 - val_loss: 177.1235 - val_mae: 177.1106 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 169.7575 - mae: 169.7445 - val_loss: 168.8538 - val_mae: 168.8405 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 161.9012 - mae: 161.8877 - val_loss: 160.9691 - val_mae: 160.9551 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 154.1726 - mae: 154.1582 - val_loss: 152.6899 - val_mae: 152.6749 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 145.7545 - mae: 145.7391 - val_loss: 144.5608 - val_mae: 144.5446 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 138.2333 - mae: 138.2166 - val_loss: 136.8673 - val_mae: 136.8497 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 130.6848 - mae: 130.6666 - val_loss: 128.8578 - val_mae: 128.8387 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 122.1379 - mae: 122.1181 - val_loss: 119.4691 - val_mae: 119.4484 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 112.0618 - mae: 112.0404 - val_loss: 108.4322 - val_mae: 108.4098 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 101.4521 - mae: 101.4289 - val_loss: 98.0904 - val_mae: 98.0660 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 90.2947 - mae: 90.2693 - val_loss: 85.5119 - val_mae: 85.4851 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 78.3265 - mae: 78.2986 - val_loss: 73.4953 - val_mae: 73.4659 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 69.9053 - mae: 69.8748 - val_loss: 65.0369 - val_mae: 65.0052 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 65.7427 - mae: 65.7104 - val_loss: 62.0077 - val_mae: 61.9747 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 63.9803 - mae: 63.9471 - val_loss: 60.1213 - val_mae: 60.0879 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 62.3417 - mae: 62.3080 - val_loss: 58.0920 - val_mae: 58.0579 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 60.5671 - mae: 60.5328 - val_loss: 56.6507 - val_mae: 56.6160 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 58.8852 - mae: 58.8502 - val_loss: 54.8061 - val_mae: 54.7706 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 56.7966 - mae: 56.7607 - val_loss: 52.1708 - val_mae: 52.1343 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 243.3391\n",
      "LV_RMSE_12h: 262.9930\n",
      "LV_MAE_24h: 35.4856\n",
      "LV_RMSE_24h: 54.1618\n",
      "LV_MAE_48h: 40.7184\n",
      "LV_RMSE_48h: 60.6693\n",
      "LV_MAE_72h: 37.5259\n",
      "LV_RMSE_72h: 55.8325\n",
      "LV_MAE_mean: 89.2672\n",
      "LV_RMSE_mean: 108.4142\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 123.2725\n",
      "RMSE_12h: 154.4779\n",
      "MAE_24h: 35.0354\n",
      "RMSE_24h: 51.4222\n",
      "MAE_48h: 34.7289\n",
      "RMSE_48h: 51.3345\n",
      "MAE_72h: 35.0949\n",
      "RMSE_72h: 51.0244\n",
      "MAE_mean: 57.0329\n",
      "RMSE_mean: 77.0647\n",
      "\n",
      "=== Station S3028051 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1377 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1354, 24, 400) Ytr2: (1354, 4) \n",
      "  Xva3: (197, 24, 400) Yva2: (197, 4) \n",
      "  Xte3: (348, 24, 400) Yte2: (348, 4)\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 3s 73ms/step - loss: 436.2274 - mae: 436.2147 - val_loss: 407.2573 - val_mae: 407.2447 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 431.0460 - mae: 431.0334 - val_loss: 400.1958 - val_mae: 400.1831 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 422.7721 - mae: 422.7593 - val_loss: 391.0190 - val_mae: 391.0060 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 413.0790 - mae: 413.0657 - val_loss: 381.0098 - val_mae: 380.9962 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 402.3256 - mae: 402.3116 - val_loss: 370.6279 - val_mae: 370.6133 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 391.2273 - mae: 391.2124 - val_loss: 359.9036 - val_mae: 359.8879 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 380.2573 - mae: 380.2411 - val_loss: 348.8223 - val_mae: 348.8053 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 368.6331 - mae: 368.6154 - val_loss: 337.5446 - val_mae: 337.5260 - lr: 0.0010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 356.6155 - mae: 356.5961 - val_loss: 326.6421 - val_mae: 326.6216 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 345.5767 - mae: 345.5554 - val_loss: 316.6777 - val_mae: 316.6553 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 334.3732 - mae: 334.3499 - val_loss: 304.9625 - val_mae: 304.9380 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 320.4905 - mae: 320.4651 - val_loss: 290.8240 - val_mae: 290.7972 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 305.1195 - mae: 305.0917 - val_loss: 275.1912 - val_mae: 275.1619 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 288.5658 - mae: 288.5353 - val_loss: 259.9434 - val_mae: 259.9112 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 272.5991 - mae: 272.5656 - val_loss: 244.9933 - val_mae: 244.9579 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 256.9455 - mae: 256.9087 - val_loss: 229.3150 - val_mae: 229.2762 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 242.0275 - mae: 241.9872 - val_loss: 214.5497 - val_mae: 214.5072 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 227.0901 - mae: 227.0460 - val_loss: 200.3225 - val_mae: 200.2763 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 214.9986 - mae: 214.9507 - val_loss: 189.9611 - val_mae: 189.9111 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 205.8564 - mae: 205.8048 - val_loss: 181.9591 - val_mae: 181.9058 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 534.3678\n",
      "LV_RMSE_12h: 604.5927\n",
      "LV_MAE_24h: 115.1207\n",
      "LV_RMSE_24h: 178.3130\n",
      "LV_MAE_48h: 156.8879\n",
      "LV_RMSE_48h: 238.0907\n",
      "LV_MAE_72h: 154.6006\n",
      "LV_RMSE_72h: 247.6582\n",
      "LV_MAE_mean: 240.2442\n",
      "LV_RMSE_mean: 317.1636\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 364.7159\n",
      "RMSE_12h: 445.9429\n",
      "MAE_24h: 146.0873\n",
      "RMSE_24h: 224.7619\n",
      "MAE_48h: 131.8075\n",
      "RMSE_48h: 208.8773\n",
      "MAE_72h: 138.7191\n",
      "RMSE_72h: 214.0408\n",
      "MAE_mean: 195.3325\n",
      "RMSE_mean: 273.4057\n",
      "\n",
      "=== Station S3028054 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1376 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1353, 24, 400) Ytr2: (1353, 4) \n",
      "  Xva3: (197, 24, 400) Yva2: (197, 4) \n",
      "  Xte3: (347, 24, 400) Yte2: (347, 4)\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 3s 61ms/step - loss: 396.2130 - mae: 396.2003 - val_loss: 402.1959 - val_mae: 402.1832 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 391.4336 - mae: 391.4208 - val_loss: 395.5151 - val_mae: 395.5023 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 383.2872 - mae: 383.2743 - val_loss: 385.3946 - val_mae: 385.3815 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 371.9272 - mae: 371.9139 - val_loss: 372.7934 - val_mae: 372.7798 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 359.3096 - mae: 359.2955 - val_loss: 359.5891 - val_mae: 359.5746 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 346.7538 - mae: 346.7389 - val_loss: 346.6838 - val_mae: 346.6682 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 334.4703 - mae: 334.4542 - val_loss: 334.2783 - val_mae: 334.2615 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 322.4861 - mae: 322.4686 - val_loss: 322.1426 - val_mae: 322.1242 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 311.2935 - mae: 311.2745 - val_loss: 310.5559 - val_mae: 310.5359 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 299.9115 - mae: 299.8908 - val_loss: 299.7902 - val_mae: 299.7684 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 290.4254 - mae: 290.4029 - val_loss: 289.9528 - val_mae: 289.9292 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 281.2943 - mae: 281.2699 - val_loss: 281.0223 - val_mae: 280.9967 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 271.9170 - mae: 271.8907 - val_loss: 270.5409 - val_mae: 270.5135 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 260.6448 - mae: 260.6165 - val_loss: 255.6033 - val_mae: 255.5738 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 244.9675 - mae: 244.9370 - val_loss: 239.2518 - val_mae: 239.2199 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 229.8490 - mae: 229.8159 - val_loss: 223.4899 - val_mae: 223.4552 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 214.2133 - mae: 214.1774 - val_loss: 207.2319 - val_mae: 207.1942 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 200.5244 - mae: 200.4854 - val_loss: 193.6970 - val_mae: 193.6563 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 188.9026 - mae: 188.8605 - val_loss: 181.4835 - val_mae: 181.4398 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 178.3000 - mae: 178.2551 - val_loss: 172.1396 - val_mae: 172.0930 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 450.4726\n",
      "LV_RMSE_12h: 520.9977\n",
      "LV_MAE_24h: 68.4409\n",
      "LV_RMSE_24h: 115.0415\n",
      "LV_MAE_48h: 89.9568\n",
      "LV_RMSE_48h: 141.5728\n",
      "LV_MAE_72h: 86.0807\n",
      "LV_RMSE_72h: 139.3043\n",
      "LV_MAE_mean: 173.7378\n",
      "LV_RMSE_mean: 229.2291\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 312.5426\n",
      "RMSE_12h: 377.9437\n",
      "MAE_24h: 119.7220\n",
      "RMSE_24h: 181.2645\n",
      "MAE_48h: 113.9709\n",
      "RMSE_48h: 172.4402\n",
      "MAE_72h: 116.6720\n",
      "RMSE_72h: 174.0654\n",
      "MAE_mean: 165.7269\n",
      "RMSE_mean: 226.4285\n",
      "\n",
      "=== Station S3028055 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1376 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1353, 24, 400) Ytr2: (1353, 4) \n",
      "  Xva3: (197, 24, 400) Yva2: (197, 4) \n",
      "  Xte3: (347, 24, 400) Yte2: (347, 4)\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 3s 57ms/step - loss: 45.9113 - mae: 45.8984 - val_loss: 41.5364 - val_mae: 41.5235 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 42.2142 - mae: 42.2013 - val_loss: 37.2634 - val_mae: 37.2503 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 37.9579 - mae: 37.9446 - val_loss: 33.3120 - val_mae: 33.2984 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 33.9867 - mae: 33.9729 - val_loss: 30.0011 - val_mae: 29.9869 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 30.4951 - mae: 30.4806 - val_loss: 27.2666 - val_mae: 27.2517 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 27.7251 - mae: 27.7099 - val_loss: 25.7506 - val_mae: 25.7351 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 26.3691 - mae: 26.3534 - val_loss: 24.5352 - val_mae: 24.5193 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 25.3122 - mae: 25.2961 - val_loss: 23.8249 - val_mae: 23.8087 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 24.5351 - mae: 24.5187 - val_loss: 23.4237 - val_mae: 23.4071 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 24.2116 - mae: 24.1949 - val_loss: 23.0055 - val_mae: 22.9887 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 23.9891 - mae: 23.9722 - val_loss: 22.7901 - val_mae: 22.7731 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 23.7033 - mae: 23.6863 - val_loss: 22.9997 - val_mae: 22.9827 - lr: 0.0010\n",
      "Epoch 13/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 15ms/step - loss: 23.6143 - mae: 23.5972 - val_loss: 22.7765 - val_mae: 22.7593 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 23.3459 - mae: 23.3286 - val_loss: 22.7840 - val_mae: 22.7667 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 23.2208 - mae: 23.2034 - val_loss: 22.7871 - val_mae: 22.7697 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 23.0449 - mae: 23.0273 - val_loss: 22.4660 - val_mae: 22.4484 - lr: 5.0000e-04\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 22.8925 - mae: 22.8749 - val_loss: 22.5222 - val_mae: 22.5045 - lr: 5.0000e-04\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 22.7302 - mae: 22.7125 - val_loss: 22.7004 - val_mae: 22.6826 - lr: 5.0000e-04\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 22.7121 - mae: 22.6943 - val_loss: 22.6580 - val_mae: 22.6402 - lr: 2.5000e-04\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 22.4260 - mae: 22.4082 - val_loss: 22.6174 - val_mae: 22.5995 - lr: 2.5000e-04\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 54.6110\n",
      "LV_RMSE_12h: 76.4786\n",
      "LV_MAE_24h: 22.2680\n",
      "LV_RMSE_24h: 39.4607\n",
      "LV_MAE_48h: 25.7522\n",
      "LV_RMSE_48h: 46.5426\n",
      "LV_MAE_72h: 26.9741\n",
      "LV_RMSE_72h: 51.4070\n",
      "LV_MAE_mean: 32.4013\n",
      "LV_RMSE_mean: 53.4722\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 19.5945\n",
      "RMSE_12h: 40.9003\n",
      "MAE_24h: 20.5597\n",
      "RMSE_24h: 41.2538\n",
      "MAE_48h: 20.5790\n",
      "RMSE_48h: 39.3202\n",
      "MAE_72h: 21.3825\n",
      "RMSE_72h: 39.9164\n",
      "MAE_mean: 20.5289\n",
      "RMSE_mean: 40.3477\n",
      "\n",
      "=== Station S3028061 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1377 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1354, 24, 400) Ytr2: (1354, 4) \n",
      "  Xva3: (197, 24, 400) Yva2: (197, 4) \n",
      "  Xte3: (348, 24, 400) Yte2: (348, 4)\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 3s 60ms/step - loss: 408.9477 - mae: 408.9350 - val_loss: 380.8694 - val_mae: 380.8566 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 402.2088 - mae: 402.1960 - val_loss: 372.2847 - val_mae: 372.2717 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 392.6264 - mae: 392.6131 - val_loss: 362.3302 - val_mae: 362.3166 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 382.1804 - mae: 382.1664 - val_loss: 351.8969 - val_mae: 351.8824 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 370.7989 - mae: 370.7839 - val_loss: 340.9225 - val_mae: 340.9068 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 359.2650 - mae: 359.2486 - val_loss: 329.5296 - val_mae: 329.5125 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 347.4871 - mae: 347.4691 - val_loss: 318.0273 - val_mae: 318.0084 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 335.6913 - mae: 335.6714 - val_loss: 306.9650 - val_mae: 306.9440 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 323.4238 - mae: 323.4019 - val_loss: 295.0873 - val_mae: 295.0642 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 308.7260 - mae: 308.7019 - val_loss: 278.1448 - val_mae: 278.1194 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 290.5818 - mae: 290.5552 - val_loss: 259.0095 - val_mae: 258.9813 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 271.3044 - mae: 271.2748 - val_loss: 243.5523 - val_mae: 243.5209 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 255.0505 - mae: 255.0176 - val_loss: 225.9782 - val_mae: 225.9433 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 237.9702 - mae: 237.9335 - val_loss: 209.4511 - val_mae: 209.4122 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 220.9334 - mae: 220.8927 - val_loss: 194.3151 - val_mae: 194.2720 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 207.5638 - mae: 207.5190 - val_loss: 181.7273 - val_mae: 181.6803 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 198.9017 - mae: 198.8533 - val_loss: 176.7845 - val_mae: 176.7345 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 193.7681 - mae: 193.7169 - val_loss: 174.9774 - val_mae: 174.9251 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 190.4710 - mae: 190.4179 - val_loss: 173.3719 - val_mae: 173.3179 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 189.5553 - mae: 189.5007 - val_loss: 170.9440 - val_mae: 170.8888 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 512.4626\n",
      "LV_RMSE_12h: 581.1407\n",
      "LV_MAE_24h: 110.0201\n",
      "LV_RMSE_24h: 171.6732\n",
      "LV_MAE_48h: 152.1293\n",
      "LV_RMSE_48h: 234.6400\n",
      "LV_MAE_72h: 148.5805\n",
      "LV_RMSE_72h: 243.7493\n",
      "LV_MAE_mean: 230.7981\n",
      "LV_RMSE_mean: 307.8008\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 341.9424\n",
      "RMSE_12h: 434.2036\n",
      "MAE_24h: 128.0623\n",
      "RMSE_24h: 204.1921\n",
      "MAE_48h: 124.0514\n",
      "RMSE_48h: 200.0223\n",
      "MAE_72h: 122.1091\n",
      "RMSE_72h: 194.3325\n",
      "MAE_mean: 179.0413\n",
      "RMSE_mean: 258.1876\n",
      "\n",
      "=== Station S3028062 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1376 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1353, 24, 400) Ytr2: (1353, 4) \n",
      "  Xva3: (197, 24, 400) Yva2: (197, 4) \n",
      "  Xte3: (347, 24, 400) Yte2: (347, 4)\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 3s 59ms/step - loss: 53.9601 - mae: 53.9472 - val_loss: 53.5300 - val_mae: 53.5171 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 48.8263 - mae: 48.8133 - val_loss: 46.7320 - val_mae: 46.7189 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 41.9266 - mae: 41.9133 - val_loss: 39.9549 - val_mae: 39.9413 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 36.3471 - mae: 36.3333 - val_loss: 35.6661 - val_mae: 35.6519 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 33.3557 - mae: 33.3412 - val_loss: 33.5732 - val_mae: 33.5584 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 31.7444 - mae: 31.7294 - val_loss: 32.6107 - val_mae: 32.5955 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 30.9739 - mae: 30.9586 - val_loss: 31.7241 - val_mae: 31.7088 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 29.9770 - mae: 29.9617 - val_loss: 30.0320 - val_mae: 30.0167 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 27.8340 - mae: 27.8187 - val_loss: 27.2042 - val_mae: 27.1887 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 25.2094 - mae: 25.1937 - val_loss: 24.4115 - val_mae: 24.3956 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 22.9514 - mae: 22.9353 - val_loss: 22.2492 - val_mae: 22.2329 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 21.4121 - mae: 21.3956 - val_loss: 20.7579 - val_mae: 20.7413 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 20.3381 - mae: 20.3213 - val_loss: 19.1687 - val_mae: 19.1517 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 19.0982 - mae: 19.0810 - val_loss: 17.8932 - val_mae: 17.8757 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 18.0995 - mae: 18.0817 - val_loss: 16.5032 - val_mae: 16.4850 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 16.8687 - mae: 16.8503 - val_loss: 15.5859 - val_mae: 15.5670 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 16.0175 - mae: 15.9984 - val_loss: 14.7197 - val_mae: 14.7002 - lr: 0.0010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 15.2293 - mae: 15.2096 - val_loss: 13.9938 - val_mae: 13.9738 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 14.7706 - mae: 14.7505 - val_loss: 13.0256 - val_mae: 13.0053 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 14.2260 - mae: 14.2056 - val_loss: 12.9855 - val_mae: 12.9649 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 63.9942\n",
      "LV_RMSE_12h: 73.8058\n",
      "LV_MAE_24h: 16.0548\n",
      "LV_RMSE_24h: 23.4893\n",
      "LV_MAE_48h: 18.8530\n",
      "LV_RMSE_48h: 26.4657\n",
      "LV_MAE_72h: 16.9856\n",
      "LV_RMSE_72h: 25.8369\n",
      "LV_MAE_mean: 28.9719\n",
      "LV_RMSE_mean: 37.3994\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 15.7949\n",
      "RMSE_12h: 23.2691\n",
      "MAE_24h: 15.0327\n",
      "RMSE_24h: 22.2188\n",
      "MAE_48h: 14.6336\n",
      "RMSE_48h: 21.6501\n",
      "MAE_72h: 14.5917\n",
      "RMSE_72h: 21.6072\n",
      "MAE_mean: 15.0132\n",
      "RMSE_mean: 22.1863\n",
      "\n",
      "=== Station S3028063 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1376 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1353, 24, 400) Ytr2: (1353, 4) \n",
      "  Xva3: (197, 24, 400) Yva2: (197, 4) \n",
      "  Xte3: (347, 24, 400) Yte2: (347, 4)\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 3s 60ms/step - loss: 174.5876 - mae: 174.5750 - val_loss: 177.4816 - val_mae: 177.4689 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 169.1488 - mae: 169.1360 - val_loss: 169.7931 - val_mae: 169.7802 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 160.4799 - mae: 160.4668 - val_loss: 160.4903 - val_mae: 160.4769 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 150.9361 - mae: 150.9223 - val_loss: 151.6008 - val_mae: 151.5866 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 142.3161 - mae: 142.3015 - val_loss: 142.7439 - val_mae: 142.7287 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 133.5135 - mae: 133.4977 - val_loss: 134.2602 - val_mae: 134.2438 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 125.1520 - mae: 125.1349 - val_loss: 125.8098 - val_mae: 125.7919 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 116.4743 - mae: 116.4557 - val_loss: 116.5494 - val_mae: 116.5299 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 107.1897 - mae: 107.1695 - val_loss: 106.1262 - val_mae: 106.1050 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 98.0635 - mae: 98.0415 - val_loss: 97.6281 - val_mae: 97.6052 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 90.6308 - mae: 90.6072 - val_loss: 88.9513 - val_mae: 88.9267 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 83.2516 - mae: 83.2263 - val_loss: 81.8516 - val_mae: 81.8253 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 77.4215 - mae: 77.3945 - val_loss: 75.2891 - val_mae: 75.2612 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 72.7949 - mae: 72.7663 - val_loss: 70.5556 - val_mae: 70.5263 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 69.5206 - mae: 69.4907 - val_loss: 67.9495 - val_mae: 67.9190 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 68.4413 - mae: 68.4103 - val_loss: 67.8122 - val_mae: 67.7805 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 66.4686 - mae: 66.4365 - val_loss: 64.5089 - val_mae: 64.4763 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 64.0642 - mae: 64.0311 - val_loss: 64.0005 - val_mae: 63.9668 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 62.5559 - mae: 62.5218 - val_loss: 61.2602 - val_mae: 61.2255 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 60.9710 - mae: 60.9359 - val_loss: 58.5601 - val_mae: 58.5242 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 200.9971\n",
      "LV_RMSE_12h: 229.7533\n",
      "LV_MAE_24h: 39.0951\n",
      "LV_RMSE_24h: 56.2400\n",
      "LV_MAE_48h: 50.0548\n",
      "LV_RMSE_48h: 69.5560\n",
      "LV_MAE_72h: 43.8790\n",
      "LV_RMSE_72h: 67.0819\n",
      "LV_MAE_mean: 83.5065\n",
      "LV_RMSE_mean: 105.6578\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 114.8569\n",
      "RMSE_12h: 147.9497\n",
      "MAE_24h: 37.6347\n",
      "RMSE_24h: 54.9766\n",
      "MAE_48h: 37.6985\n",
      "RMSE_48h: 55.4738\n",
      "MAE_72h: 37.0256\n",
      "RMSE_72h: 54.4018\n",
      "MAE_mean: 56.8039\n",
      "RMSE_mean: 78.2005\n",
      "\n",
      "=== Station S3028071 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1377 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1354, 24, 400) Ytr2: (1354, 4) \n",
      "  Xva3: (197, 24, 400) Yva2: (197, 4) \n",
      "  Xte3: (348, 24, 400) Yte2: (348, 4)\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 3s 58ms/step - loss: 1258.3320 - mae: 1258.3191 - val_loss: 1207.5570 - val_mae: 1207.5443 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1252.5935 - mae: 1252.5809 - val_loss: 1199.6602 - val_mae: 1199.6473 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1243.0502 - mae: 1243.0371 - val_loss: 1188.2383 - val_mae: 1188.2251 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1230.4763 - mae: 1230.4629 - val_loss: 1173.6206 - val_mae: 1173.6066 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1213.9927 - mae: 1213.9784 - val_loss: 1155.0647 - val_mae: 1155.0497 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1193.4410 - mae: 1193.4255 - val_loss: 1132.6119 - val_mae: 1132.5957 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1169.5305 - mae: 1169.5133 - val_loss: 1106.0465 - val_mae: 1106.0282 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1140.8241 - mae: 1140.8048 - val_loss: 1075.1713 - val_mae: 1075.1509 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1108.4846 - mae: 1108.4631 - val_loss: 1040.1334 - val_mae: 1040.1104 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1071.6335 - mae: 1071.6091 - val_loss: 1001.7354 - val_mae: 1001.7092 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1031.9698 - mae: 1031.9423 - val_loss: 960.9194 - val_mae: 960.8899 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 991.6027 - mae: 991.5715 - val_loss: 921.5885 - val_mae: 921.5554 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 951.7867 - mae: 951.7518 - val_loss: 886.4757 - val_mae: 886.4387 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 915.9802 - mae: 915.9415 - val_loss: 853.8486 - val_mae: 853.8077 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 882.2435 - mae: 882.2009 - val_loss: 823.2881 - val_mae: 823.2432 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 852.3649 - mae: 852.3183 - val_loss: 794.8494 - val_mae: 794.8004 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 824.3757 - mae: 824.3249 - val_loss: 769.3009 - val_mae: 769.2479 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 796.7437 - mae: 796.6888 - val_loss: 746.8890 - val_mae: 746.8318 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 777.4769 - mae: 777.4178 - val_loss: 725.9789 - val_mae: 725.9177 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 755.1323 - mae: 755.0693 - val_loss: 706.5596 - val_mae: 706.4943 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 1155.2443\n",
      "LV_RMSE_12h: 1318.2777\n",
      "LV_MAE_24h: 198.7184\n",
      "LV_RMSE_24h: 286.5408\n",
      "LV_MAE_48h: 255.2931\n",
      "LV_RMSE_48h: 366.5591\n",
      "LV_MAE_72h: 246.0661\n",
      "LV_RMSE_72h: 333.8512\n",
      "LV_MAE_mean: 463.8304\n",
      "LV_RMSE_mean: 576.3072\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 667.1323\n",
      "RMSE_12h: 837.6865\n",
      "MAE_24h: 669.9681\n",
      "RMSE_24h: 837.4662\n",
      "MAE_48h: 698.1677\n",
      "RMSE_48h: 886.1922\n",
      "MAE_72h: 676.7924\n",
      "RMSE_72h: 857.5294\n",
      "MAE_mean: 678.0151\n",
      "RMSE_mean: 854.7185\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Station S3028072 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1377 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1354, 24, 400) Ytr2: (1354, 4) \n",
      "  Xva3: (197, 24, 400) Yva2: (197, 4) \n",
      "  Xte3: (348, 24, 400) Yte2: (348, 4)\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 3s 61ms/step - loss: 1221.7294 - mae: 1221.7167 - val_loss: 1181.2678 - val_mae: 1181.2549 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1215.0604 - mae: 1215.0476 - val_loss: 1171.5133 - val_mae: 1171.5001 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1203.1606 - mae: 1203.1473 - val_loss: 1157.3320 - val_mae: 1157.3182 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1187.3794 - mae: 1187.3652 - val_loss: 1138.8065 - val_mae: 1138.7916 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1166.2690 - mae: 1166.2534 - val_loss: 1115.0791 - val_mae: 1115.0627 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1140.0072 - mae: 1139.9900 - val_loss: 1085.6525 - val_mae: 1085.6339 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1108.0284 - mae: 1108.0089 - val_loss: 1050.3141 - val_mae: 1050.2928 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1070.0876 - mae: 1070.0651 - val_loss: 1008.9017 - val_mae: 1008.8772 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1026.6995 - mae: 1026.6733 - val_loss: 963.2346 - val_mae: 963.2065 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 979.5039 - mae: 979.4739 - val_loss: 917.9637 - val_mae: 917.9314 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 934.7295 - mae: 934.6953 - val_loss: 874.1748 - val_mae: 874.1380 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 890.8060 - mae: 890.7670 - val_loss: 832.0460 - val_mae: 832.0045 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 849.7524 - mae: 849.7087 - val_loss: 793.5924 - val_mae: 793.5459 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 811.4154 - mae: 811.3667 - val_loss: 757.8972 - val_mae: 757.8456 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 772.5605 - mae: 772.5067 - val_loss: 722.9062 - val_mae: 722.8495 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 740.9141 - mae: 740.8550 - val_loss: 690.4037 - val_mae: 690.3416 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 707.7521 - mae: 707.6876 - val_loss: 659.4022 - val_mae: 659.3346 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 673.4054 - mae: 673.3353 - val_loss: 629.6900 - val_mae: 629.6169 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 647.7037 - mae: 647.6281 - val_loss: 603.3478 - val_mae: 603.2692 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 617.1225 - mae: 617.0415 - val_loss: 564.1443 - val_mae: 564.0604 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 967.1896\n",
      "LV_RMSE_12h: 1067.9127\n",
      "LV_MAE_24h: 186.8448\n",
      "LV_RMSE_24h: 279.7364\n",
      "LV_MAE_48h: 236.2931\n",
      "LV_RMSE_48h: 354.2088\n",
      "LV_MAE_72h: 221.0517\n",
      "LV_RMSE_72h: 308.2098\n",
      "LV_MAE_mean: 402.8448\n",
      "LV_RMSE_mean: 502.5169\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 591.0587\n",
      "RMSE_12h: 695.9321\n",
      "MAE_24h: 474.5151\n",
      "RMSE_24h: 580.6275\n",
      "MAE_48h: 479.0368\n",
      "RMSE_48h: 590.5073\n",
      "MAE_72h: 462.3472\n",
      "RMSE_72h: 569.2712\n",
      "MAE_mean: 501.7394\n",
      "RMSE_mean: 609.0845\n",
      "\n",
      "=== Station S3028074 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1365 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1342, 24, 400) Ytr2: (1342, 4) \n",
      "  Xva3: (196, 24, 400) Yva2: (196, 4) \n",
      "  Xte3: (343, 24, 400) Yte2: (343, 4)\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 3s 59ms/step - loss: 39.9159 - mae: 39.9031 - val_loss: 36.8545 - val_mae: 36.8418 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 35.4619 - mae: 35.4491 - val_loss: 31.4476 - val_mae: 31.4347 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 30.4411 - mae: 30.4280 - val_loss: 27.5034 - val_mae: 27.4902 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 28.1611 - mae: 28.1477 - val_loss: 26.2529 - val_mae: 26.2394 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 27.3336 - mae: 27.3201 - val_loss: 25.4720 - val_mae: 25.4585 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 26.3882 - mae: 26.3747 - val_loss: 24.0055 - val_mae: 23.9920 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 25.0031 - mae: 24.9897 - val_loss: 22.6927 - val_mae: 22.6791 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 23.4701 - mae: 23.4564 - val_loss: 21.1181 - val_mae: 21.1042 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 22.0995 - mae: 22.0855 - val_loss: 19.4775 - val_mae: 19.4632 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 20.9911 - mae: 20.9766 - val_loss: 18.4532 - val_mae: 18.4385 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 20.1403 - mae: 20.1254 - val_loss: 17.6697 - val_mae: 17.6546 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 19.5482 - mae: 19.5329 - val_loss: 17.1792 - val_mae: 17.1637 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 19.0617 - mae: 19.0461 - val_loss: 16.1982 - val_mae: 16.1824 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 18.6308 - mae: 18.6149 - val_loss: 15.7036 - val_mae: 15.6875 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 18.2763 - mae: 18.2601 - val_loss: 15.7384 - val_mae: 15.7220 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 17.9213 - mae: 17.9048 - val_loss: 15.0546 - val_mae: 15.0379 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 17.7786 - mae: 17.7617 - val_loss: 14.9720 - val_mae: 14.9550 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 17.3847 - mae: 17.3675 - val_loss: 15.0142 - val_mae: 14.9969 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 17.0999 - mae: 17.0825 - val_loss: 14.5158 - val_mae: 14.4982 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 16.8976 - mae: 16.8799 - val_loss: 14.8846 - val_mae: 14.8667 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 48.2799\n",
      "LV_RMSE_12h: 76.7114\n",
      "LV_MAE_24h: 21.0000\n",
      "LV_RMSE_24h: 56.8833\n",
      "LV_MAE_48h: 25.1691\n",
      "LV_RMSE_48h: 60.5969\n",
      "LV_MAE_72h: 23.2070\n",
      "LV_RMSE_72h: 56.8070\n",
      "LV_MAE_mean: 29.4140\n",
      "LV_RMSE_mean: 62.7496\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 16.7346\n",
      "RMSE_12h: 42.4023\n",
      "MAE_24h: 16.0424\n",
      "RMSE_24h: 42.0623\n",
      "MAE_48h: 16.8726\n",
      "RMSE_48h: 42.7317\n",
      "MAE_72h: 17.7829\n",
      "RMSE_72h: 42.9294\n",
      "MAE_mean: 16.8581\n",
      "RMSE_mean: 42.5314\n",
      "\n",
      "=== Station S3028081 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1377 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1354, 24, 400) Ytr2: (1354, 4) \n",
      "  Xva3: (197, 24, 400) Yva2: (197, 4) \n",
      "  Xte3: (348, 24, 400) Yte2: (348, 4)\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 3s 61ms/step - loss: 533.5457 - mae: 533.5330 - val_loss: 342.7377 - val_mae: 342.7249 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 530.1088 - mae: 530.0959 - val_loss: 335.4122 - val_mae: 335.3991 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 524.3599 - mae: 524.3467 - val_loss: 325.6136 - val_mae: 325.6001 - lr: 0.0010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 516.9734 - mae: 516.9597 - val_loss: 315.3292 - val_mae: 315.3149 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 508.5899 - mae: 508.5750 - val_loss: 304.5496 - val_mae: 304.5341 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 499.3528 - mae: 499.3368 - val_loss: 293.3467 - val_mae: 293.3298 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 489.3206 - mae: 489.3029 - val_loss: 281.8123 - val_mae: 281.7935 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 479.4292 - mae: 479.4097 - val_loss: 269.3465 - val_mae: 269.3257 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 468.2751 - mae: 468.2533 - val_loss: 256.5648 - val_mae: 256.5417 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 454.9429 - mae: 454.9187 - val_loss: 242.4688 - val_mae: 242.4431 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 440.5192 - mae: 440.4922 - val_loss: 226.5579 - val_mae: 226.5291 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 425.2824 - mae: 425.2522 - val_loss: 215.5326 - val_mae: 215.5005 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 412.0965 - mae: 412.0630 - val_loss: 207.2519 - val_mae: 207.2165 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 401.3764 - mae: 401.3396 - val_loss: 197.8242 - val_mae: 197.7854 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 391.0564 - mae: 391.0161 - val_loss: 189.1543 - val_mae: 189.1121 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 382.3774 - mae: 382.3336 - val_loss: 181.2814 - val_mae: 181.2356 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 372.7227 - mae: 372.6752 - val_loss: 174.3937 - val_mae: 174.3442 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 363.5678 - mae: 363.5168 - val_loss: 166.3441 - val_mae: 166.2910 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 355.8316 - mae: 355.7768 - val_loss: 158.3628 - val_mae: 158.3057 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 348.5242 - mae: 348.4654 - val_loss: 153.9747 - val_mae: 153.9137 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 552.8161\n",
      "LV_RMSE_12h: 643.0096\n",
      "LV_MAE_24h: 92.3046\n",
      "LV_RMSE_24h: 141.4754\n",
      "LV_MAE_48h: 117.3190\n",
      "LV_RMSE_48h: 180.0545\n",
      "LV_MAE_72h: 108.1609\n",
      "LV_RMSE_72h: 157.2513\n",
      "LV_MAE_mean: 217.6501\n",
      "LV_RMSE_mean: 280.4478\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 364.0853\n",
      "RMSE_12h: 470.1052\n",
      "MAE_24h: 125.1861\n",
      "RMSE_24h: 187.9294\n",
      "MAE_48h: 126.2723\n",
      "RMSE_48h: 188.1566\n",
      "MAE_72h: 125.8589\n",
      "RMSE_72h: 186.8781\n",
      "MAE_mean: 185.3506\n",
      "RMSE_mean: 258.2673\n",
      "\n",
      "=== Station S3028084 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1377 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1354, 24, 400) Ytr2: (1354, 4) \n",
      "  Xva3: (197, 24, 400) Yva2: (197, 4) \n",
      "  Xte3: (348, 24, 400) Yte2: (348, 4)\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 3s 58ms/step - loss: 1852.3538 - mae: 1852.3408 - val_loss: 1898.1667 - val_mae: 1898.1539 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1847.6381 - mae: 1847.6252 - val_loss: 1889.7189 - val_mae: 1889.7061 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1840.2086 - mae: 1840.1956 - val_loss: 1878.1847 - val_mae: 1878.1713 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1830.5168 - mae: 1830.5029 - val_loss: 1863.2454 - val_mae: 1863.2311 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1817.5231 - mae: 1817.5083 - val_loss: 1843.9274 - val_mae: 1843.9117 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1801.5039 - mae: 1801.4878 - val_loss: 1819.9233 - val_mae: 1819.9062 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1782.0797 - mae: 1782.0619 - val_loss: 1791.1744 - val_mae: 1791.1553 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1758.2911 - mae: 1758.2710 - val_loss: 1757.2644 - val_mae: 1757.2429 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1732.1171 - mae: 1732.0944 - val_loss: 1718.4506 - val_mae: 1718.4259 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 1701.1819 - mae: 1701.1560 - val_loss: 1674.8087 - val_mae: 1674.7806 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1667.6794 - mae: 1667.6499 - val_loss: 1625.9905 - val_mae: 1625.9586 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1630.5284 - mae: 1630.4945 - val_loss: 1574.9043 - val_mae: 1574.8680 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1591.7400 - mae: 1591.7017 - val_loss: 1524.0338 - val_mae: 1523.9927 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1549.9939 - mae: 1549.9507 - val_loss: 1474.7714 - val_mae: 1474.7252 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1507.7618 - mae: 1507.7134 - val_loss: 1427.5162 - val_mae: 1427.4645 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1464.9907 - mae: 1464.9365 - val_loss: 1381.1606 - val_mae: 1381.1031 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1424.3429 - mae: 1424.2827 - val_loss: 1336.8914 - val_mae: 1336.8278 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 1379.2847 - mae: 1379.2184 - val_loss: 1294.1741 - val_mae: 1294.1039 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1338.0114 - mae: 1337.9384 - val_loss: 1253.2219 - val_mae: 1253.1451 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1294.1884 - mae: 1294.1085 - val_loss: 1214.6902 - val_mae: 1214.6066 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 1821.9656\n",
      "LV_RMSE_12h: 2127.0793\n",
      "LV_MAE_24h: 299.9511\n",
      "LV_RMSE_24h: 450.1192\n",
      "LV_MAE_48h: 401.0948\n",
      "LV_RMSE_48h: 598.5692\n",
      "LV_MAE_72h: 349.3965\n",
      "LV_RMSE_72h: 535.6086\n",
      "LV_MAE_mean: 718.1020\n",
      "LV_RMSE_mean: 927.8441\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 1117.5485\n",
      "RMSE_12h: 1433.7083\n",
      "MAE_24h: 1157.8899\n",
      "RMSE_24h: 1477.5751\n",
      "MAE_48h: 1175.4052\n",
      "RMSE_48h: 1504.9987\n",
      "MAE_72h: 1161.2700\n",
      "RMSE_72h: 1488.6893\n",
      "MAE_mean: 1153.0284\n",
      "RMSE_mean: 1476.2428\n",
      "\n",
      "=== Station S3028085 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1376 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1353, 24, 400) Ytr2: (1353, 4) \n",
      "  Xva3: (197, 24, 400) Yva2: (197, 4) \n",
      "  Xte3: (348, 24, 400) Yte2: (348, 4)\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 3s 60ms/step - loss: 17.6284 - mae: 17.6156 - val_loss: 7.5760 - val_mae: 7.5632 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 14.9336 - mae: 14.9208 - val_loss: 6.6062 - val_mae: 6.5933 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 13.1810 - mae: 13.1680 - val_loss: 6.0693 - val_mae: 6.0563 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 12.2934 - mae: 12.2803 - val_loss: 5.3779 - val_mae: 5.3647 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 11.6710 - mae: 11.6578 - val_loss: 4.8063 - val_mae: 4.7931 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 11.2220 - mae: 11.2087 - val_loss: 4.4452 - val_mae: 4.4318 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 10.7406 - mae: 10.7272 - val_loss: 4.4807 - val_mae: 4.4672 - lr: 0.0010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 10.3733 - mae: 10.3597 - val_loss: 4.2257 - val_mae: 4.2120 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 10.0503 - mae: 10.0365 - val_loss: 4.1108 - val_mae: 4.0970 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 9.8041 - mae: 9.7902 - val_loss: 4.0909 - val_mae: 4.0769 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 9.6092 - mae: 9.5951 - val_loss: 4.0934 - val_mae: 4.0792 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 9.4155 - mae: 9.4013 - val_loss: 4.0192 - val_mae: 4.0049 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 9.2780 - mae: 9.2636 - val_loss: 4.0450 - val_mae: 4.0305 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 9.1005 - mae: 9.0859 - val_loss: 3.9443 - val_mae: 3.9296 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 8.9213 - mae: 8.9065 - val_loss: 3.8545 - val_mae: 3.8396 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 8.8842 - mae: 8.8693 - val_loss: 3.9229 - val_mae: 3.9078 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 8.7079 - mae: 8.6928 - val_loss: 3.9502 - val_mae: 3.9349 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 8.5677 - mae: 8.5524 - val_loss: 3.8345 - val_mae: 3.8192 - lr: 5.0000e-04\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 8.5610 - mae: 8.5456 - val_loss: 3.8853 - val_mae: 3.8699 - lr: 5.0000e-04\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 8.4854 - mae: 8.4700 - val_loss: 3.9214 - val_mae: 3.9059 - lr: 5.0000e-04\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 11.0776\n",
      "LV_RMSE_12h: 13.5533\n",
      "LV_MAE_24h: 3.6351\n",
      "LV_RMSE_24h: 5.3705\n",
      "LV_MAE_48h: 4.2787\n",
      "LV_RMSE_48h: 6.3746\n",
      "LV_MAE_72h: 4.3190\n",
      "LV_RMSE_72h: 6.7388\n",
      "LV_MAE_mean: 5.8276\n",
      "LV_RMSE_mean: 8.0093\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 3.8231\n",
      "RMSE_12h: 5.4492\n",
      "MAE_24h: 3.9103\n",
      "RMSE_24h: 5.9467\n",
      "MAE_48h: 3.8757\n",
      "RMSE_48h: 6.0016\n",
      "MAE_72h: 4.0156\n",
      "RMSE_72h: 6.1460\n",
      "MAE_mean: 3.9062\n",
      "RMSE_mean: 5.8859\n",
      "\n",
      "=== Station S3028086 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1376 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1353, 24, 400) Ytr2: (1353, 4) \n",
      "  Xva3: (197, 24, 400) Yva2: (197, 4) \n",
      "  Xte3: (348, 24, 400) Yte2: (348, 4)\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 3s 59ms/step - loss: 195.9632 - mae: 195.9505 - val_loss: 193.7433 - val_mae: 193.7305 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 189.7915 - mae: 189.7786 - val_loss: 185.6673 - val_mae: 185.6543 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 180.9530 - mae: 180.9399 - val_loss: 177.1805 - val_mae: 177.1671 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 172.1065 - mae: 172.0928 - val_loss: 169.0852 - val_mae: 169.0711 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 163.5488 - mae: 163.5343 - val_loss: 161.2240 - val_mae: 161.2090 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 155.1322 - mae: 155.1167 - val_loss: 153.8878 - val_mae: 153.8716 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 147.1241 - mae: 147.1073 - val_loss: 146.6536 - val_mae: 146.6362 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 138.6308 - mae: 138.6128 - val_loss: 138.7122 - val_mae: 138.6933 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 129.5423 - mae: 129.5227 - val_loss: 129.6201 - val_mae: 129.5996 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 118.5573 - mae: 118.5360 - val_loss: 118.9495 - val_mae: 118.9272 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 107.6013 - mae: 107.5782 - val_loss: 109.7400 - val_mae: 109.7157 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 98.6496 - mae: 98.6244 - val_loss: 101.0360 - val_mae: 101.0097 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 89.5101 - mae: 89.4829 - val_loss: 92.2683 - val_mae: 92.2399 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 82.2798 - mae: 82.2506 - val_loss: 83.3097 - val_mae: 83.2794 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 77.4141 - mae: 77.3832 - val_loss: 77.1965 - val_mae: 77.1649 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 73.6770 - mae: 73.6450 - val_loss: 74.1274 - val_mae: 74.0947 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 72.0208 - mae: 71.9878 - val_loss: 71.7865 - val_mae: 71.7532 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 70.5853 - mae: 70.5516 - val_loss: 70.1153 - val_mae: 70.0813 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 69.5225 - mae: 69.4883 - val_loss: 69.2810 - val_mae: 69.2465 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 68.2406 - mae: 68.2058 - val_loss: 66.7829 - val_mae: 66.7478 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 249.9109\n",
      "LV_RMSE_12h: 276.4244\n",
      "LV_MAE_24h: 39.5402\n",
      "LV_RMSE_24h: 61.2275\n",
      "LV_MAE_48h: 45.2615\n",
      "LV_RMSE_48h: 67.4961\n",
      "LV_MAE_72h: 41.1293\n",
      "LV_RMSE_72h: 62.3118\n",
      "LV_MAE_mean: 93.9605\n",
      "LV_RMSE_mean: 116.8649\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 149.3318\n",
      "RMSE_12h: 183.7399\n",
      "MAE_24h: 40.2313\n",
      "RMSE_24h: 57.9749\n",
      "MAE_48h: 38.3123\n",
      "RMSE_48h: 57.3115\n",
      "MAE_72h: 38.0520\n",
      "RMSE_72h: 56.7617\n",
      "MAE_mean: 66.4818\n",
      "RMSE_mean: 88.9470\n",
      "\n",
      "=== Station S3028087 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1376 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1353, 24, 400) Ytr2: (1353, 4) \n",
      "  Xva3: (197, 24, 400) Yva2: (197, 4) \n",
      "  Xte3: (348, 24, 400) Yte2: (348, 4)\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 3s 59ms/step - loss: 177.5491 - mae: 177.5364 - val_loss: 180.4079 - val_mae: 180.3952 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 172.6781 - mae: 172.6652 - val_loss: 173.1382 - val_mae: 173.1252 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 163.7827 - mae: 163.7695 - val_loss: 162.5271 - val_mae: 162.5136 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 152.7192 - mae: 152.7053 - val_loss: 151.0898 - val_mae: 151.0755 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 142.1599 - mae: 142.1450 - val_loss: 140.5740 - val_mae: 140.5585 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 132.1600 - mae: 132.1440 - val_loss: 131.3049 - val_mae: 131.2882 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 123.6185 - mae: 123.6011 - val_loss: 123.2666 - val_mae: 123.2485 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 115.7896 - mae: 115.7708 - val_loss: 116.2210 - val_mae: 116.2013 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 109.8928 - mae: 109.8726 - val_loss: 109.6702 - val_mae: 109.6491 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 101.7811 - mae: 101.7594 - val_loss: 99.2409 - val_mae: 99.2184 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 91.6745 - mae: 91.6514 - val_loss: 89.3448 - val_mae: 89.3208 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 82.9544 - mae: 82.9297 - val_loss: 80.4714 - val_mae: 80.4458 - lr: 0.0010\n",
      "Epoch 13/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 13ms/step - loss: 76.7521 - mae: 76.7258 - val_loss: 75.0787 - val_mae: 75.0517 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 72.2649 - mae: 72.2374 - val_loss: 71.5569 - val_mae: 71.5287 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 69.0787 - mae: 69.0499 - val_loss: 68.1937 - val_mae: 68.1642 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 66.1328 - mae: 66.1027 - val_loss: 64.7646 - val_mae: 64.7339 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 64.0047 - mae: 63.9734 - val_loss: 62.4070 - val_mae: 62.3751 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 62.2101 - mae: 62.1775 - val_loss: 59.5888 - val_mae: 59.5555 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 59.3272 - mae: 59.2934 - val_loss: 56.6067 - val_mae: 56.5721 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 56.7023 - mae: 56.6671 - val_loss: 54.9958 - val_mae: 54.9597 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 202.8822\n",
      "LV_RMSE_12h: 236.1345\n",
      "LV_MAE_24h: 39.3563\n",
      "LV_RMSE_24h: 57.8813\n",
      "LV_MAE_48h: 48.3736\n",
      "LV_RMSE_48h: 69.7372\n",
      "LV_MAE_72h: 42.9425\n",
      "LV_RMSE_72h: 62.7420\n",
      "LV_MAE_mean: 83.3886\n",
      "LV_RMSE_mean: 106.6237\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 110.8212\n",
      "RMSE_12h: 142.7923\n",
      "MAE_24h: 36.5726\n",
      "RMSE_24h: 53.0899\n",
      "MAE_48h: 36.8894\n",
      "RMSE_48h: 54.0548\n",
      "MAE_72h: 37.0193\n",
      "RMSE_72h: 54.1968\n",
      "MAE_mean: 55.3256\n",
      "RMSE_mean: 76.0335\n",
      "\n",
      "=== Station S3028091 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1377 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1354, 24, 400) Ytr2: (1354, 4) \n",
      "  Xva3: (197, 24, 400) Yva2: (197, 4) \n",
      "  Xte3: (348, 24, 400) Yte2: (348, 4)\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 3s 58ms/step - loss: 355.6026 - mae: 355.5898 - val_loss: 327.2553 - val_mae: 327.2426 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 352.2538 - mae: 352.2411 - val_loss: 322.4910 - val_mae: 322.4780 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 346.2804 - mae: 346.2672 - val_loss: 315.7834 - val_mae: 315.7699 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 338.7526 - mae: 338.7388 - val_loss: 307.4177 - val_mae: 307.4033 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 329.0724 - mae: 329.0574 - val_loss: 297.0666 - val_mae: 297.0509 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 317.4897 - mae: 317.4733 - val_loss: 284.6029 - val_mae: 284.5855 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 304.0742 - mae: 304.0559 - val_loss: 270.4873 - val_mae: 270.4679 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 288.5767 - mae: 288.5562 - val_loss: 254.9231 - val_mae: 254.9010 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 272.4066 - mae: 272.3832 - val_loss: 239.6795 - val_mae: 239.6544 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 256.9178 - mae: 256.8914 - val_loss: 225.5163 - val_mae: 225.4879 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 242.6446 - mae: 242.6149 - val_loss: 213.1923 - val_mae: 213.1606 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 230.4627 - mae: 230.4297 - val_loss: 202.8172 - val_mae: 202.7824 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 219.7813 - mae: 219.7450 - val_loss: 192.7370 - val_mae: 192.6988 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 208.8647 - mae: 208.8251 - val_loss: 182.8104 - val_mae: 182.7689 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 198.7517 - mae: 198.7087 - val_loss: 172.8715 - val_mae: 172.8265 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 189.7047 - mae: 189.6581 - val_loss: 163.8941 - val_mae: 163.8455 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 179.7544 - mae: 179.7041 - val_loss: 156.2961 - val_mae: 156.2436 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 170.4117 - mae: 170.3576 - val_loss: 148.1676 - val_mae: 148.1114 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 161.8512 - mae: 161.7932 - val_loss: 139.8510 - val_mae: 139.7908 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 154.6031 - mae: 154.5413 - val_loss: 133.1887 - val_mae: 133.1248 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 511.3678\n",
      "LV_RMSE_12h: 610.9009\n",
      "LV_MAE_24h: 88.2557\n",
      "LV_RMSE_24h: 137.0476\n",
      "LV_MAE_48h: 111.1063\n",
      "LV_RMSE_48h: 174.5549\n",
      "LV_MAE_72h: 100.8391\n",
      "LV_RMSE_72h: 158.7481\n",
      "LV_MAE_mean: 202.8922\n",
      "LV_RMSE_mean: 270.3129\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 244.4172\n",
      "RMSE_12h: 358.6080\n",
      "MAE_24h: 100.6874\n",
      "RMSE_24h: 169.3759\n",
      "MAE_48h: 102.6722\n",
      "RMSE_48h: 170.0959\n",
      "MAE_72h: 108.6957\n",
      "RMSE_72h: 178.0296\n",
      "MAE_mean: 139.1181\n",
      "RMSE_mean: 219.0273\n",
      "\n",
      "=== Station S3028101 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1377 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1354, 24, 400) Ytr2: (1354, 4) \n",
      "  Xva3: (197, 24, 400) Yva2: (197, 4) \n",
      "  Xte3: (348, 24, 400) Yte2: (348, 4)\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 3s 67ms/step - loss: 376.6837 - mae: 376.6709 - val_loss: 345.9706 - val_mae: 345.9580 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 371.0750 - mae: 371.0622 - val_loss: 338.9298 - val_mae: 338.9169 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 363.3732 - mae: 363.3600 - val_loss: 330.6233 - val_mae: 330.6098 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 354.6384 - mae: 354.6246 - val_loss: 321.6284 - val_mae: 321.6142 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 344.8696 - mae: 344.8548 - val_loss: 312.4089 - val_mae: 312.3936 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 335.0648 - mae: 335.0489 - val_loss: 302.8301 - val_mae: 302.8133 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 324.9817 - mae: 324.9642 - val_loss: 293.1320 - val_mae: 293.1135 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 314.8450 - mae: 314.8257 - val_loss: 283.7503 - val_mae: 283.7300 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 305.0741 - mae: 305.0529 - val_loss: 275.1240 - val_mae: 275.1016 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 296.1525 - mae: 296.1292 - val_loss: 268.5478 - val_mae: 268.5233 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 290.0325 - mae: 290.0072 - val_loss: 264.3459 - val_mae: 264.3194 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 285.6988 - mae: 285.6715 - val_loss: 261.5215 - val_mae: 261.4932 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 281.9604 - mae: 281.9315 - val_loss: 256.4710 - val_mae: 256.4413 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 275.3275 - mae: 275.2972 - val_loss: 249.2435 - val_mae: 249.2126 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 267.0904 - mae: 267.0588 - val_loss: 240.3849 - val_mae: 240.3526 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 257.9237 - mae: 257.8908 - val_loss: 228.0658 - val_mae: 228.0319 - lr: 0.0010\n",
      "Epoch 17/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 12ms/step - loss: 245.5178 - mae: 245.4830 - val_loss: 216.0239 - val_mae: 215.9878 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 232.9016 - mae: 232.8644 - val_loss: 203.8587 - val_mae: 203.8199 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 221.4875 - mae: 221.4473 - val_loss: 193.4624 - val_mae: 193.4203 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 209.8544 - mae: 209.8108 - val_loss: 182.6986 - val_mae: 182.6528 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 517.4282\n",
      "LV_RMSE_12h: 620.2721\n",
      "LV_MAE_24h: 89.5920\n",
      "LV_RMSE_24h: 140.9906\n",
      "LV_MAE_48h: 113.8736\n",
      "LV_RMSE_48h: 180.3478\n",
      "LV_MAE_72h: 103.9368\n",
      "LV_RMSE_72h: 164.7209\n",
      "LV_MAE_mean: 206.2076\n",
      "LV_RMSE_mean: 276.5829\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 335.2237\n",
      "RMSE_12h: 452.0232\n",
      "MAE_24h: 130.2451\n",
      "RMSE_24h: 225.2087\n",
      "MAE_48h: 139.8773\n",
      "RMSE_48h: 241.8302\n",
      "MAE_72h: 137.7163\n",
      "RMSE_72h: 235.3082\n",
      "MAE_mean: 185.7656\n",
      "RMSE_mean: 288.5926\n",
      "\n",
      "=== Station S3028102 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1376 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1353, 24, 400) Ytr2: (1353, 4) \n",
      "  Xva3: (197, 24, 400) Yva2: (197, 4) \n",
      "  Xte3: (347, 24, 400) Yte2: (347, 4)\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 3s 59ms/step - loss: 150.0804 - mae: 150.0677 - val_loss: 148.7603 - val_mae: 148.7476 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 146.0835 - mae: 146.0707 - val_loss: 142.9760 - val_mae: 142.9633 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 139.1181 - mae: 139.1051 - val_loss: 135.0979 - val_mae: 135.0848 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 131.4535 - mae: 131.4401 - val_loss: 127.4721 - val_mae: 127.4583 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 124.0762 - mae: 124.0620 - val_loss: 120.0637 - val_mae: 120.0490 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 116.7097 - mae: 116.6945 - val_loss: 113.8513 - val_mae: 113.8354 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 110.4093 - mae: 110.3929 - val_loss: 107.9071 - val_mae: 107.8901 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 104.6233 - mae: 104.6057 - val_loss: 102.2815 - val_mae: 102.2632 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 98.9519 - mae: 98.9330 - val_loss: 95.1566 - val_mae: 95.1370 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 90.1194 - mae: 90.0992 - val_loss: 86.2348 - val_mae: 86.2137 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 81.8842 - mae: 81.8624 - val_loss: 77.7474 - val_mae: 77.7247 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 73.5345 - mae: 73.5109 - val_loss: 70.1113 - val_mae: 70.0867 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 66.1420 - mae: 66.1166 - val_loss: 63.6245 - val_mae: 63.5981 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 60.7545 - mae: 60.7274 - val_loss: 59.5101 - val_mae: 59.4823 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 57.6405 - mae: 57.6122 - val_loss: 57.2208 - val_mae: 57.1920 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 56.5012 - mae: 56.4722 - val_loss: 55.3164 - val_mae: 55.2870 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 54.3598 - mae: 54.3302 - val_loss: 53.5526 - val_mae: 53.5226 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 53.0386 - mae: 53.0081 - val_loss: 52.1984 - val_mae: 52.1675 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 51.1132 - mae: 51.0819 - val_loss: 49.7625 - val_mae: 49.7306 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 49.1391 - mae: 49.1068 - val_loss: 48.0093 - val_mae: 47.9765 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 186.1210\n",
      "LV_RMSE_12h: 206.3511\n",
      "LV_MAE_24h: 29.7608\n",
      "LV_RMSE_24h: 46.4055\n",
      "LV_MAE_48h: 34.8847\n",
      "LV_RMSE_48h: 52.3676\n",
      "LV_MAE_72h: 32.8703\n",
      "LV_RMSE_72h: 49.8347\n",
      "LV_MAE_mean: 70.9092\n",
      "LV_RMSE_mean: 88.7397\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 92.8927\n",
      "RMSE_12h: 120.5152\n",
      "MAE_24h: 31.7511\n",
      "RMSE_24h: 45.5902\n",
      "MAE_48h: 31.1626\n",
      "RMSE_48h: 45.1357\n",
      "MAE_72h: 30.2982\n",
      "RMSE_72h: 43.9917\n",
      "MAE_mean: 46.5262\n",
      "RMSE_mean: 63.8082\n",
      "\n",
      "=== Station S3028103 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1376 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1353, 24, 400) Ytr2: (1353, 4) \n",
      "  Xva3: (197, 24, 400) Yva2: (197, 4) \n",
      "  Xte3: (347, 24, 400) Yte2: (347, 4)\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 3s 59ms/step - loss: 82.2856 - mae: 82.2729 - val_loss: 85.5014 - val_mae: 85.4886 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 77.1642 - mae: 77.1514 - val_loss: 79.2404 - val_mae: 79.2275 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 70.7012 - mae: 70.6881 - val_loss: 72.5238 - val_mae: 72.5105 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 64.1679 - mae: 64.1544 - val_loss: 66.1676 - val_mae: 66.1537 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 58.2642 - mae: 58.2498 - val_loss: 60.1711 - val_mae: 60.1563 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 52.0948 - mae: 52.0795 - val_loss: 53.8875 - val_mae: 53.8716 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 46.1594 - mae: 46.1431 - val_loss: 47.5436 - val_mae: 47.5266 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 40.2132 - mae: 40.1957 - val_loss: 41.5056 - val_mae: 41.4874 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 35.5876 - mae: 35.5690 - val_loss: 37.6919 - val_mae: 37.6727 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 32.3019 - mae: 32.2824 - val_loss: 35.5602 - val_mae: 35.5404 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 30.3973 - mae: 30.3774 - val_loss: 33.4824 - val_mae: 33.4623 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 29.2832 - mae: 29.2629 - val_loss: 32.1342 - val_mae: 32.1138 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 28.2123 - mae: 28.1916 - val_loss: 31.4076 - val_mae: 31.3867 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 26.9356 - mae: 26.9145 - val_loss: 29.8147 - val_mae: 29.7933 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 25.5387 - mae: 25.5170 - val_loss: 28.5729 - val_mae: 28.5508 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 24.4135 - mae: 24.3912 - val_loss: 27.0991 - val_mae: 27.0763 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 22.5175 - mae: 22.4943 - val_loss: 25.2433 - val_mae: 25.2196 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 21.2729 - mae: 21.2487 - val_loss: 23.0533 - val_mae: 23.0285 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 19.8224 - mae: 19.7973 - val_loss: 21.6296 - val_mae: 21.6039 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 19.0747 - mae: 19.0486 - val_loss: 20.8730 - val_mae: 20.8466 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 114.7637\n",
      "LV_RMSE_12h: 126.7777\n",
      "LV_MAE_24h: 21.0980\n",
      "LV_RMSE_24h: 31.3708\n",
      "LV_MAE_48h: 22.7061\n",
      "LV_RMSE_48h: 32.6488\n",
      "LV_MAE_72h: 21.2421\n",
      "LV_RMSE_72h: 31.6592\n",
      "LV_MAE_mean: 44.9524\n",
      "LV_RMSE_mean: 55.6141\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 22.1483\n",
      "RMSE_12h: 32.3211\n",
      "MAE_24h: 19.8059\n",
      "RMSE_24h: 29.1164\n",
      "MAE_48h: 19.2595\n",
      "RMSE_48h: 28.5729\n",
      "MAE_72h: 18.9854\n",
      "RMSE_72h: 27.8008\n",
      "MAE_mean: 20.0498\n",
      "RMSE_mean: 29.4528\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Station S3028105 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1376 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1353, 24, 400) Ytr2: (1353, 4) \n",
      "  Xva3: (197, 24, 400) Yva2: (197, 4) \n",
      "  Xte3: (347, 24, 400) Yte2: (347, 4)\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 3s 58ms/step - loss: 169.0886 - mae: 169.0757 - val_loss: 166.0267 - val_mae: 166.0138 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 164.3903 - mae: 164.3774 - val_loss: 159.4241 - val_mae: 159.4110 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 157.2231 - mae: 157.2099 - val_loss: 151.8197 - val_mae: 151.8062 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 149.8082 - mae: 149.7945 - val_loss: 144.2206 - val_mae: 144.2064 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 142.9147 - mae: 142.9001 - val_loss: 136.9743 - val_mae: 136.9593 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 135.6392 - mae: 135.6237 - val_loss: 130.3532 - val_mae: 130.3371 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 128.9786 - mae: 128.9621 - val_loss: 123.9215 - val_mae: 123.9043 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 121.8695 - mae: 121.8518 - val_loss: 115.6807 - val_mae: 115.6622 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 113.0377 - mae: 113.0186 - val_loss: 106.2949 - val_mae: 106.2750 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 103.5556 - mae: 103.5349 - val_loss: 96.9550 - val_mae: 96.9334 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 94.8564 - mae: 94.8341 - val_loss: 88.1651 - val_mae: 88.1417 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 86.1876 - mae: 86.1634 - val_loss: 78.9344 - val_mae: 78.9090 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 78.0588 - mae: 78.0326 - val_loss: 71.2642 - val_mae: 71.2369 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 72.9076 - mae: 72.8795 - val_loss: 66.5231 - val_mae: 66.4940 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 69.5380 - mae: 69.5084 - val_loss: 64.1825 - val_mae: 64.1522 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 68.1308 - mae: 68.1003 - val_loss: 62.7401 - val_mae: 62.7092 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 67.0871 - mae: 67.0560 - val_loss: 61.0842 - val_mae: 61.0529 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 65.8928 - mae: 65.8611 - val_loss: 59.5450 - val_mae: 59.5130 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 64.8432 - mae: 64.8109 - val_loss: 58.0259 - val_mae: 57.9932 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 63.2602 - mae: 63.2271 - val_loss: 56.4784 - val_mae: 56.4448 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 215.7839\n",
      "LV_RMSE_12h: 237.7859\n",
      "LV_MAE_24h: 33.5764\n",
      "LV_RMSE_24h: 51.5901\n",
      "LV_MAE_48h: 40.2507\n",
      "LV_RMSE_48h: 59.8672\n",
      "LV_MAE_72h: 37.8271\n",
      "LV_RMSE_72h: 60.4928\n",
      "LV_MAE_mean: 81.8595\n",
      "LV_RMSE_mean: 102.4340\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 125.8279\n",
      "RMSE_12h: 162.1120\n",
      "MAE_24h: 35.8514\n",
      "RMSE_24h: 54.2514\n",
      "MAE_48h: 35.3119\n",
      "RMSE_48h: 53.9846\n",
      "MAE_72h: 35.4280\n",
      "RMSE_72h: 53.9163\n",
      "MAE_mean: 58.1048\n",
      "RMSE_mean: 81.0661\n",
      "\n",
      "=== Station S3028111 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1377 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1354, 24, 400) Ytr2: (1354, 4) \n",
      "  Xva3: (197, 24, 400) Yva2: (197, 4) \n",
      "  Xte3: (348, 24, 400) Yte2: (348, 4)\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 3s 59ms/step - loss: 325.5802 - mae: 325.5674 - val_loss: 295.1628 - val_mae: 295.1501 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 320.7558 - mae: 320.7430 - val_loss: 288.9286 - val_mae: 288.9157 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 313.8862 - mae: 313.8731 - val_loss: 281.4785 - val_mae: 281.4653 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 305.8169 - mae: 305.8033 - val_loss: 273.4772 - val_mae: 273.4632 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 296.5971 - mae: 296.5827 - val_loss: 264.8820 - val_mae: 264.8671 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 287.2814 - mae: 287.2660 - val_loss: 255.8199 - val_mae: 255.8037 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 277.4997 - mae: 277.4829 - val_loss: 246.4097 - val_mae: 246.3921 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 267.2473 - mae: 267.2289 - val_loss: 236.3155 - val_mae: 236.2961 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 256.2609 - mae: 256.2408 - val_loss: 224.9466 - val_mae: 224.9253 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 243.5052 - mae: 243.4831 - val_loss: 213.7595 - val_mae: 213.7362 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 232.2262 - mae: 232.2019 - val_loss: 202.9763 - val_mae: 202.9508 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 220.3804 - mae: 220.3539 - val_loss: 194.6461 - val_mae: 194.6183 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 212.2563 - mae: 212.2276 - val_loss: 186.2561 - val_mae: 186.2262 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 204.3063 - mae: 204.2755 - val_loss: 178.2453 - val_mae: 178.2131 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 194.8276 - mae: 194.7943 - val_loss: 169.0580 - val_mae: 169.0233 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 186.5017 - mae: 186.4658 - val_loss: 160.7715 - val_mae: 160.7340 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 178.2009 - mae: 178.1621 - val_loss: 153.4653 - val_mae: 153.4248 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 169.4421 - mae: 169.4002 - val_loss: 146.9637 - val_mae: 146.9200 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 161.6281 - mae: 161.5829 - val_loss: 138.4569 - val_mae: 138.4097 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 153.8844 - mae: 153.8356 - val_loss: 131.8124 - val_mae: 131.7617 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 461.7701\n",
      "LV_RMSE_12h: 551.1738\n",
      "LV_MAE_24h: 78.4799\n",
      "LV_RMSE_24h: 123.3527\n",
      "LV_MAE_48h: 100.7759\n",
      "LV_RMSE_48h: 155.3611\n",
      "LV_MAE_72h: 90.8161\n",
      "LV_RMSE_72h: 139.3537\n",
      "LV_MAE_mean: 182.9605\n",
      "LV_RMSE_mean: 242.3103\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 266.7071\n",
      "RMSE_12h: 374.9509\n",
      "MAE_24h: 100.6147\n",
      "RMSE_24h: 169.8442\n",
      "MAE_48h: 103.3360\n",
      "RMSE_48h: 171.7312\n",
      "MAE_72h: 102.1612\n",
      "RMSE_72h: 167.8560\n",
      "MAE_mean: 143.2048\n",
      "RMSE_mean: 221.0956\n",
      "\n",
      "=== Station S3028114 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1377 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1354, 24, 400) Ytr2: (1354, 4) \n",
      "  Xva3: (197, 24, 400) Yva2: (197, 4) \n",
      "  Xte3: (348, 24, 400) Yte2: (348, 4)\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 3s 59ms/step - loss: 1950.7975 - mae: 1950.7847 - val_loss: 1874.5046 - val_mae: 1874.4917 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 1944.9396 - mae: 1944.9269 - val_loss: 1865.8715 - val_mae: 1865.8584 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1934.1672 - mae: 1934.1539 - val_loss: 1852.7014 - val_mae: 1852.6880 - lr: 0.0010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/20\n",
      "11/11 [==============================] - 0s 17ms/step - loss: 1919.5725 - mae: 1919.5583 - val_loss: 1835.9052 - val_mae: 1835.8905 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1900.6112 - mae: 1900.5962 - val_loss: 1814.5736 - val_mae: 1814.5579 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1877.1704 - mae: 1877.1538 - val_loss: 1788.4058 - val_mae: 1788.3882 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 0s 19ms/step - loss: 1849.0217 - mae: 1849.0035 - val_loss: 1757.1942 - val_mae: 1757.1743 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1815.5886 - mae: 1815.5676 - val_loss: 1720.7523 - val_mae: 1720.7300 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1777.1451 - mae: 1777.1215 - val_loss: 1679.0000 - val_mae: 1678.9742 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1732.5122 - mae: 1732.4850 - val_loss: 1631.8536 - val_mae: 1631.8242 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1683.9963 - mae: 1683.9657 - val_loss: 1580.8148 - val_mae: 1580.7814 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1632.5334 - mae: 1632.4979 - val_loss: 1530.3173 - val_mae: 1530.2793 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1582.9989 - mae: 1582.9589 - val_loss: 1482.6202 - val_mae: 1482.5774 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1535.5339 - mae: 1535.4891 - val_loss: 1438.1583 - val_mae: 1438.1107 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1489.6202 - mae: 1489.5703 - val_loss: 1395.6005 - val_mae: 1395.5477 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1449.2029 - mae: 1449.1479 - val_loss: 1356.2448 - val_mae: 1356.1869 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 1409.7411 - mae: 1409.6809 - val_loss: 1318.2891 - val_mae: 1318.2258 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1366.7609 - mae: 1366.6953 - val_loss: 1281.6238 - val_mae: 1281.5549 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1331.7349 - mae: 1331.6638 - val_loss: 1243.9736 - val_mae: 1243.8993 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1294.6117 - mae: 1294.5350 - val_loss: 1206.4257 - val_mae: 1206.3457 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 1823.0747\n",
      "LV_RMSE_12h: 2132.3535\n",
      "LV_MAE_24h: 300.0661\n",
      "LV_RMSE_24h: 451.6222\n",
      "LV_MAE_48h: 402.6523\n",
      "LV_RMSE_48h: 605.5048\n",
      "LV_MAE_72h: 352.5603\n",
      "LV_RMSE_72h: 540.3926\n",
      "LV_MAE_mean: 719.5884\n",
      "LV_RMSE_mean: 932.4683\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 1177.2186\n",
      "RMSE_12h: 1529.7183\n",
      "MAE_24h: 1136.9089\n",
      "RMSE_24h: 1479.0735\n",
      "MAE_48h: 1133.7349\n",
      "RMSE_48h: 1480.7317\n",
      "MAE_72h: 1127.5201\n",
      "RMSE_72h: 1473.7203\n",
      "MAE_mean: 1143.8456\n",
      "RMSE_mean: 1490.8109\n",
      "\n",
      "=== Station S3028115 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1376 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1353, 24, 400) Ytr2: (1353, 4) \n",
      "  Xva3: (197, 24, 400) Yva2: (197, 4) \n",
      "  Xte3: (348, 24, 400) Yte2: (348, 4)\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 3s 60ms/step - loss: 1.3242 - mae: 1.3115 - val_loss: 0.8613 - val_mae: 0.8487 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1.2428 - mae: 1.2303 - val_loss: 0.8289 - val_mae: 0.8164 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1.2107 - mae: 1.1983 - val_loss: 0.8230 - val_mae: 0.8106 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1.1931 - mae: 1.1807 - val_loss: 0.8304 - val_mae: 0.8181 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1.1828 - mae: 1.1706 - val_loss: 0.8158 - val_mae: 0.8036 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1.1686 - mae: 1.1564 - val_loss: 0.8194 - val_mae: 0.8073 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1.1468 - mae: 1.1348 - val_loss: 0.8318 - val_mae: 0.8197 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1.1384 - mae: 1.1263 - val_loss: 0.8269 - val_mae: 0.8149 - lr: 5.0000e-04\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1.1275 - mae: 1.1155 - val_loss: 0.8214 - val_mae: 0.8094 - lr: 5.0000e-04\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1.1228 - mae: 1.1109 - val_loss: 0.8250 - val_mae: 0.8131 - lr: 2.5000e-04\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 1.6609\n",
      "LV_RMSE_12h: 2.6931\n",
      "LV_MAE_24h: 1.0431\n",
      "LV_RMSE_24h: 1.9776\n",
      "LV_MAE_48h: 1.1207\n",
      "LV_RMSE_48h: 2.2361\n",
      "LV_MAE_72h: 1.2126\n",
      "LV_RMSE_72h: 2.3181\n",
      "LV_MAE_mean: 1.2593\n",
      "LV_RMSE_mean: 2.3062\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 0.8101\n",
      "RMSE_12h: 1.5451\n",
      "MAE_24h: 0.8160\n",
      "RMSE_24h: 1.6540\n",
      "MAE_48h: 0.8537\n",
      "RMSE_48h: 1.6632\n",
      "MAE_72h: 0.8183\n",
      "RMSE_72h: 1.6548\n",
      "MAE_mean: 0.8245\n",
      "RMSE_mean: 1.6293\n",
      "\n",
      "=== Station S3028116 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1376 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1353, 24, 400) Ytr2: (1353, 4) \n",
      "  Xva3: (197, 24, 400) Yva2: (197, 4) \n",
      "  Xte3: (348, 24, 400) Yte2: (348, 4)\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 3s 58ms/step - loss: 89.0953 - mae: 89.0827 - val_loss: 89.5496 - val_mae: 89.5371 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 84.6616 - mae: 84.6490 - val_loss: 83.6815 - val_mae: 83.6687 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 78.5022 - mae: 78.4893 - val_loss: 77.2344 - val_mae: 77.2212 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 72.0642 - mae: 72.0507 - val_loss: 71.0650 - val_mae: 71.0512 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 66.2551 - mae: 66.2409 - val_loss: 65.3073 - val_mae: 65.2927 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 60.5910 - mae: 60.5759 - val_loss: 60.0798 - val_mae: 60.0642 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 55.9802 - mae: 55.9641 - val_loss: 55.5341 - val_mae: 55.5175 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 52.2326 - mae: 52.2156 - val_loss: 52.0021 - val_mae: 51.9846 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 49.4613 - mae: 49.4435 - val_loss: 48.5798 - val_mae: 48.5616 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 45.8758 - mae: 45.8575 - val_loss: 44.7440 - val_mae: 44.7254 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 42.3431 - mae: 42.3242 - val_loss: 41.1189 - val_mae: 41.0997 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 39.3749 - mae: 39.3555 - val_loss: 38.0248 - val_mae: 38.0051 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 36.5232 - mae: 36.5033 - val_loss: 34.7483 - val_mae: 34.7280 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 33.6830 - mae: 33.6624 - val_loss: 32.1621 - val_mae: 32.1411 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 31.5877 - mae: 31.5663 - val_loss: 30.1242 - val_mae: 30.1022 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 29.8881 - mae: 29.8658 - val_loss: 28.1095 - val_mae: 28.0866 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 28.1338 - mae: 28.1106 - val_loss: 26.4385 - val_mae: 26.4147 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 26.8558 - mae: 26.8316 - val_loss: 25.0702 - val_mae: 25.0455 - lr: 0.0010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 24.9514 - mae: 24.9263 - val_loss: 23.3602 - val_mae: 23.3346 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 23.4790 - mae: 23.4530 - val_loss: 21.4612 - val_mae: 21.4346 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 115.9684\n",
      "LV_RMSE_12h: 129.6417\n",
      "LV_MAE_24h: 21.8103\n",
      "LV_RMSE_24h: 31.6288\n",
      "LV_MAE_48h: 25.2615\n",
      "LV_RMSE_48h: 36.0570\n",
      "LV_MAE_72h: 21.2989\n",
      "LV_RMSE_72h: 29.8319\n",
      "LV_MAE_mean: 46.0848\n",
      "LV_RMSE_mean: 56.7898\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 39.3581\n",
      "RMSE_12h: 52.1611\n",
      "MAE_24h: 17.5593\n",
      "RMSE_24h: 25.5714\n",
      "MAE_48h: 17.4764\n",
      "RMSE_48h: 25.4709\n",
      "MAE_72h: 17.6118\n",
      "RMSE_72h: 25.6190\n",
      "MAE_mean: 23.0014\n",
      "RMSE_mean: 32.2056\n",
      "\n",
      "=== Station S3028117 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1376 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1353, 24, 400) Ytr2: (1353, 4) \n",
      "  Xva3: (197, 24, 400) Yva2: (197, 4) \n",
      "  Xte3: (348, 24, 400) Yte2: (348, 4)\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 3s 58ms/step - loss: 178.7131 - mae: 178.7005 - val_loss: 180.2848 - val_mae: 180.2721 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 174.1260 - mae: 174.1132 - val_loss: 173.6088 - val_mae: 173.5959 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 165.8043 - mae: 165.7912 - val_loss: 163.4507 - val_mae: 163.4372 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 155.1815 - mae: 155.1678 - val_loss: 152.4058 - val_mae: 152.3916 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 144.7685 - mae: 144.7538 - val_loss: 141.8673 - val_mae: 141.8521 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 134.6753 - mae: 134.6595 - val_loss: 132.5187 - val_mae: 132.5021 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 126.1917 - mae: 126.1746 - val_loss: 124.6712 - val_mae: 124.6533 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 118.5419 - mae: 118.5233 - val_loss: 117.7924 - val_mae: 117.7730 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 112.6605 - mae: 112.6404 - val_loss: 111.7791 - val_mae: 111.7583 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 106.2635 - mae: 106.2420 - val_loss: 105.2168 - val_mae: 105.1946 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 99.0058 - mae: 98.9830 - val_loss: 96.3884 - val_mae: 96.3648 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 90.6584 - mae: 90.6341 - val_loss: 87.9794 - val_mae: 87.9544 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 83.9728 - mae: 83.9471 - val_loss: 81.7093 - val_mae: 81.6828 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 78.0260 - mae: 77.9989 - val_loss: 76.1484 - val_mae: 76.1205 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 73.4094 - mae: 73.3810 - val_loss: 72.8804 - val_mae: 72.8513 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 69.6677 - mae: 69.6381 - val_loss: 68.6264 - val_mae: 68.5960 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 66.1974 - mae: 66.1664 - val_loss: 66.0105 - val_mae: 65.9788 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 63.8560 - mae: 63.8237 - val_loss: 62.4563 - val_mae: 62.4232 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 60.7266 - mae: 60.6929 - val_loss: 59.9057 - val_mae: 59.8712 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 59.0672 - mae: 59.0321 - val_loss: 57.4258 - val_mae: 57.3899 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 202.5431\n",
      "LV_RMSE_12h: 236.5682\n",
      "LV_MAE_24h: 40.1695\n",
      "LV_RMSE_24h: 58.6317\n",
      "LV_MAE_48h: 49.9741\n",
      "LV_RMSE_48h: 71.3678\n",
      "LV_MAE_72h: 43.4368\n",
      "LV_RMSE_72h: 63.7383\n",
      "LV_MAE_mean: 84.0309\n",
      "LV_RMSE_mean: 107.5765\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 113.3276\n",
      "RMSE_12h: 144.5185\n",
      "MAE_24h: 39.0185\n",
      "RMSE_24h: 57.1642\n",
      "MAE_48h: 39.8560\n",
      "RMSE_48h: 58.5894\n",
      "MAE_72h: 40.0753\n",
      "RMSE_72h: 58.0115\n",
      "MAE_mean: 58.0693\n",
      "RMSE_mean: 79.5709\n",
      "\n",
      "=== Station S3028118 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1376 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1353, 24, 400) Ytr2: (1353, 4) \n",
      "  Xva3: (197, 24, 400) Yva2: (197, 4) \n",
      "  Xte3: (348, 24, 400) Yte2: (348, 4)\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 3s 58ms/step - loss: 224.3375 - mae: 224.3247 - val_loss: 226.0646 - val_mae: 226.0518 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 217.7063 - mae: 217.6934 - val_loss: 216.5801 - val_mae: 216.5669 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 207.1103 - mae: 207.0969 - val_loss: 205.2465 - val_mae: 205.2327 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 196.1948 - mae: 196.1806 - val_loss: 194.8753 - val_mae: 194.8606 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 186.4247 - mae: 186.4094 - val_loss: 185.3720 - val_mae: 185.3561 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 177.2444 - mae: 177.2279 - val_loss: 176.4520 - val_mae: 176.4347 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 168.7692 - mae: 168.7512 - val_loss: 168.5737 - val_mae: 168.5548 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 161.2878 - mae: 161.2682 - val_loss: 162.0351 - val_mae: 162.0145 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 155.4539 - mae: 155.4326 - val_loss: 156.0372 - val_mae: 156.0150 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 148.7403 - mae: 148.7175 - val_loss: 148.4774 - val_mae: 148.4537 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 141.0510 - mae: 141.0266 - val_loss: 139.3449 - val_mae: 139.3196 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 131.1410 - mae: 131.1149 - val_loss: 128.3898 - val_mae: 128.3627 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 120.9617 - mae: 120.9339 - val_loss: 117.9007 - val_mae: 117.8717 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 110.5157 - mae: 110.4858 - val_loss: 108.2055 - val_mae: 108.1743 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 101.3940 - mae: 101.3619 - val_loss: 100.8551 - val_mae: 100.8219 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 95.3188 - mae: 95.2850 - val_loss: 95.8173 - val_mae: 95.7826 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 91.6901 - mae: 91.6549 - val_loss: 93.1329 - val_mae: 93.0971 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 90.0563 - mae: 90.0201 - val_loss: 91.3750 - val_mae: 91.3383 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 87.9082 - mae: 87.8711 - val_loss: 89.1883 - val_mae: 89.1506 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 86.5366 - mae: 86.4987 - val_loss: 87.9060 - val_mae: 87.8677 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 268.3707\n",
      "LV_RMSE_12h: 307.7698\n",
      "LV_MAE_24h: 48.1408\n",
      "LV_RMSE_24h: 74.7201\n",
      "LV_MAE_48h: 63.8362\n",
      "LV_RMSE_48h: 94.7186\n",
      "LV_MAE_72h: 57.7241\n",
      "LV_RMSE_72h: 88.1284\n",
      "LV_MAE_mean: 109.5180\n",
      "LV_RMSE_mean: 141.3342\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 173.5691\n",
      "RMSE_12h: 222.4125\n",
      "MAE_24h: 54.0222\n",
      "RMSE_24h: 85.2002\n",
      "MAE_48h: 54.9904\n",
      "RMSE_48h: 86.4052\n",
      "MAE_72h: 53.9096\n",
      "RMSE_72h: 84.7820\n",
      "MAE_mean: 84.1228\n",
      "RMSE_mean: 119.7000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Station S3028121 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1377 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1354, 24, 400) Ytr2: (1354, 4) \n",
      "  Xva3: (197, 24, 400) Yva2: (197, 4) \n",
      "  Xte3: (348, 24, 400) Yte2: (348, 4)\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 3s 60ms/step - loss: 341.4367 - mae: 341.4240 - val_loss: 310.5878 - val_mae: 310.5750 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 335.2136 - mae: 335.2008 - val_loss: 302.5146 - val_mae: 302.5017 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 326.0855 - mae: 326.0724 - val_loss: 293.4619 - val_mae: 293.4485 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 316.6729 - mae: 316.6592 - val_loss: 284.2111 - val_mae: 284.1969 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 306.2262 - mae: 306.2115 - val_loss: 274.6887 - val_mae: 274.6734 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 295.7403 - mae: 295.7245 - val_loss: 264.7542 - val_mae: 264.7376 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 285.1133 - mae: 285.0960 - val_loss: 254.5953 - val_mae: 254.5770 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 274.2491 - mae: 274.2300 - val_loss: 244.4833 - val_mae: 244.4632 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 263.7079 - mae: 263.6870 - val_loss: 234.7505 - val_mae: 234.7283 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 253.5287 - mae: 253.5056 - val_loss: 225.9628 - val_mae: 225.9386 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 244.2468 - mae: 244.2217 - val_loss: 218.4523 - val_mae: 218.4261 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 236.1828 - mae: 236.1557 - val_loss: 210.7403 - val_mae: 210.7123 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 228.5164 - mae: 228.4877 - val_loss: 203.1715 - val_mae: 203.1418 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 218.9884 - mae: 218.9578 - val_loss: 192.7749 - val_mae: 192.7433 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 208.0660 - mae: 208.0335 - val_loss: 181.9030 - val_mae: 181.8691 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 199.0163 - mae: 198.9813 - val_loss: 174.0094 - val_mae: 173.9730 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 189.5601 - mae: 189.5225 - val_loss: 166.5157 - val_mae: 166.4765 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 180.8692 - mae: 180.8286 - val_loss: 157.0105 - val_mae: 156.9682 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 172.5556 - mae: 172.5117 - val_loss: 149.6508 - val_mae: 149.6050 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 164.8662 - mae: 164.8189 - val_loss: 142.8186 - val_mae: 142.7694 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 479.6465\n",
      "LV_RMSE_12h: 570.2838\n",
      "LV_MAE_24h: 81.7902\n",
      "LV_RMSE_24h: 126.7133\n",
      "LV_MAE_48h: 102.8649\n",
      "LV_RMSE_48h: 157.1608\n",
      "LV_MAE_72h: 94.2241\n",
      "LV_RMSE_72h: 143.2895\n",
      "LV_MAE_mean: 189.6315\n",
      "LV_RMSE_mean: 249.3619\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 296.0784\n",
      "RMSE_12h: 405.2466\n",
      "MAE_24h: 114.8254\n",
      "RMSE_24h: 187.4579\n",
      "MAE_48h: 107.7613\n",
      "RMSE_48h: 175.3026\n",
      "MAE_72h: 113.1492\n",
      "RMSE_72h: 181.2862\n",
      "MAE_mean: 157.9536\n",
      "RMSE_mean: 237.3233\n",
      "\n",
      "=== Station S3028124 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1377 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1354, 24, 400) Ytr2: (1354, 4) \n",
      "  Xva3: (197, 24, 400) Yva2: (197, 4) \n",
      "  Xte3: (348, 24, 400) Yte2: (348, 4)\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 3s 58ms/step - loss: 1868.1539 - mae: 1868.1416 - val_loss: 1810.9430 - val_mae: 1810.9304 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1863.6130 - mae: 1863.6001 - val_loss: 1804.3452 - val_mae: 1804.3323 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1855.5540 - mae: 1855.5408 - val_loss: 1794.6208 - val_mae: 1794.6075 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1844.5217 - mae: 1844.5083 - val_loss: 1781.6951 - val_mae: 1781.6812 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1829.8301 - mae: 1829.8156 - val_loss: 1765.1602 - val_mae: 1765.1451 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1811.5771 - mae: 1811.5615 - val_loss: 1744.6287 - val_mae: 1744.6122 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 1789.2313 - mae: 1789.2142 - val_loss: 1719.9308 - val_mae: 1719.9125 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1762.6790 - mae: 1762.6595 - val_loss: 1691.0339 - val_mae: 1691.0134 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1731.9315 - mae: 1731.9099 - val_loss: 1657.8367 - val_mae: 1657.8135 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1696.9763 - mae: 1696.9520 - val_loss: 1620.2694 - val_mae: 1620.2430 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1657.6689 - mae: 1657.6415 - val_loss: 1578.3782 - val_mae: 1578.3485 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1615.3324 - mae: 1615.3009 - val_loss: 1534.5488 - val_mae: 1534.5153 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1570.8649 - mae: 1570.8296 - val_loss: 1491.7480 - val_mae: 1491.7103 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1528.3307 - mae: 1528.2910 - val_loss: 1451.8073 - val_mae: 1451.7653 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1488.6433 - mae: 1488.5995 - val_loss: 1413.9332 - val_mae: 1413.8867 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1450.6764 - mae: 1450.6281 - val_loss: 1378.5542 - val_mae: 1378.5033 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1414.8455 - mae: 1414.7926 - val_loss: 1343.4093 - val_mae: 1343.3538 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1377.8102 - mae: 1377.7528 - val_loss: 1309.0742 - val_mae: 1309.0139 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1345.4668 - mae: 1345.4042 - val_loss: 1277.9930 - val_mae: 1277.9279 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1314.5880 - mae: 1314.5205 - val_loss: 1248.5457 - val_mae: 1248.4756 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 1825.9397\n",
      "LV_RMSE_12h: 2104.1306\n",
      "LV_MAE_24h: 293.0316\n",
      "LV_RMSE_24h: 442.7928\n",
      "LV_MAE_48h: 386.4282\n",
      "LV_RMSE_48h: 582.4093\n",
      "LV_MAE_72h: 330.3592\n",
      "LV_RMSE_72h: 503.2318\n",
      "LV_MAE_mean: 708.9396\n",
      "LV_RMSE_mean: 908.1411\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 1173.3749\n",
      "RMSE_12h: 1518.6071\n",
      "MAE_24h: 1181.8621\n",
      "RMSE_24h: 1516.6110\n",
      "MAE_48h: 1198.1963\n",
      "RMSE_48h: 1541.9114\n",
      "MAE_72h: 1204.7026\n",
      "RMSE_72h: 1553.1674\n",
      "MAE_mean: 1189.5339\n",
      "RMSE_mean: 1532.5742\n",
      "\n",
      "=== Station S3028125 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1376 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1353, 24, 400) Ytr2: (1353, 4) \n",
      "  Xva3: (197, 24, 400) Yva2: (197, 4) \n",
      "  Xte3: (348, 24, 400) Yte2: (348, 4)\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 3s 61ms/step - loss: 1.4681 - mae: 1.4554 - val_loss: 1.2651 - val_mae: 1.2524 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1.3595 - mae: 1.3469 - val_loss: 1.1998 - val_mae: 1.1872 - lr: 0.0010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1.3077 - mae: 1.2950 - val_loss: 1.1826 - val_mae: 1.1700 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1.2637 - mae: 1.2511 - val_loss: 1.1514 - val_mae: 1.1389 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1.2209 - mae: 1.2084 - val_loss: 1.1312 - val_mae: 1.1186 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 1.1773 - mae: 1.1647 - val_loss: 1.0957 - val_mae: 1.0831 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 1.1235 - mae: 1.1109 - val_loss: 1.0709 - val_mae: 1.0583 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1.0898 - mae: 1.0771 - val_loss: 1.0447 - val_mae: 1.0321 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 1.0604 - mae: 1.0477 - val_loss: 1.0479 - val_mae: 1.0353 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1.0580 - mae: 1.0454 - val_loss: 1.0302 - val_mae: 1.0176 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 1.0262 - mae: 1.0136 - val_loss: 1.0402 - val_mae: 1.0276 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1.0248 - mae: 1.0122 - val_loss: 1.0017 - val_mae: 0.9891 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.9954 - mae: 0.9828 - val_loss: 1.0161 - val_mae: 1.0035 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.9896 - mae: 0.9770 - val_loss: 1.0054 - val_mae: 0.9928 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.9671 - mae: 0.9546 - val_loss: 0.9878 - val_mae: 0.9752 - lr: 5.0000e-04\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.9517 - mae: 0.9391 - val_loss: 0.9963 - val_mae: 0.9838 - lr: 5.0000e-04\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.9498 - mae: 0.9373 - val_loss: 0.9761 - val_mae: 0.9636 - lr: 5.0000e-04\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.9277 - mae: 0.9152 - val_loss: 0.9753 - val_mae: 0.9628 - lr: 5.0000e-04\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.9271 - mae: 0.9146 - val_loss: 0.9826 - val_mae: 0.9701 - lr: 5.0000e-04\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.9142 - mae: 0.9017 - val_loss: 0.9810 - val_mae: 0.9685 - lr: 5.0000e-04\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 1.9626\n",
      "LV_RMSE_12h: 3.6195\n",
      "LV_MAE_24h: 1.1609\n",
      "LV_RMSE_24h: 2.4283\n",
      "LV_MAE_48h: 1.3649\n",
      "LV_RMSE_48h: 2.7632\n",
      "LV_MAE_72h: 1.3276\n",
      "LV_RMSE_72h: 2.7585\n",
      "LV_MAE_mean: 1.4540\n",
      "LV_RMSE_mean: 2.8923\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 0.8778\n",
      "RMSE_12h: 1.7540\n",
      "MAE_24h: 0.9263\n",
      "RMSE_24h: 1.9545\n",
      "MAE_48h: 1.0229\n",
      "RMSE_48h: 2.1000\n",
      "MAE_72h: 1.0206\n",
      "RMSE_72h: 2.0742\n",
      "MAE_mean: 0.9619\n",
      "RMSE_mean: 1.9707\n",
      "\n",
      "=== Station S3028126 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1376 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1353, 24, 400) Ytr2: (1353, 4) \n",
      "  Xva3: (197, 24, 400) Yva2: (197, 4) \n",
      "  Xte3: (348, 24, 400) Yte2: (348, 4)\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 3s 56ms/step - loss: 73.9764 - mae: 73.9636 - val_loss: 71.7375 - val_mae: 71.7246 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 68.6108 - mae: 68.5979 - val_loss: 64.3758 - val_mae: 64.3628 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 60.9722 - mae: 60.9590 - val_loss: 56.4168 - val_mae: 56.4033 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 53.7636 - mae: 53.7498 - val_loss: 49.3927 - val_mae: 49.3784 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 47.6493 - mae: 47.6346 - val_loss: 43.7217 - val_mae: 43.7065 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 42.7676 - mae: 42.7519 - val_loss: 40.0110 - val_mae: 39.9948 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 39.7126 - mae: 39.6960 - val_loss: 36.7962 - val_mae: 36.7793 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 36.6416 - mae: 36.6244 - val_loss: 33.6289 - val_mae: 33.6115 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 34.0267 - mae: 34.0091 - val_loss: 30.9361 - val_mae: 30.9183 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 31.3487 - mae: 31.3308 - val_loss: 28.7154 - val_mae: 28.6973 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 28.8369 - mae: 28.8185 - val_loss: 26.3107 - val_mae: 26.2922 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 26.7740 - mae: 26.7553 - val_loss: 24.6848 - val_mae: 24.6659 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 25.3152 - mae: 25.2960 - val_loss: 23.3366 - val_mae: 23.3171 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 24.3193 - mae: 24.2996 - val_loss: 22.2627 - val_mae: 22.2426 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 23.2084 - mae: 23.1881 - val_loss: 21.0624 - val_mae: 21.0417 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 22.1050 - mae: 22.0841 - val_loss: 19.6718 - val_mae: 19.6505 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 20.8149 - mae: 20.7933 - val_loss: 18.0837 - val_mae: 18.0616 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 19.5244 - mae: 19.5019 - val_loss: 16.6790 - val_mae: 16.6559 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 18.2739 - mae: 18.2504 - val_loss: 15.2418 - val_mae: 15.2180 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 17.1425 - mae: 17.1183 - val_loss: 14.2487 - val_mae: 14.2240 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 81.5977\n",
      "LV_RMSE_12h: 90.5960\n",
      "LV_MAE_24h: 16.4253\n",
      "LV_RMSE_24h: 22.4625\n",
      "LV_MAE_48h: 17.9397\n",
      "LV_RMSE_48h: 24.2337\n",
      "LV_MAE_72h: 16.4282\n",
      "LV_RMSE_72h: 22.3641\n",
      "LV_MAE_mean: 33.0977\n",
      "LV_RMSE_mean: 39.9141\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 19.9538\n",
      "RMSE_12h: 24.3263\n",
      "MAE_24h: 13.7255\n",
      "RMSE_24h: 19.2163\n",
      "MAE_48h: 12.9482\n",
      "RMSE_48h: 18.3613\n",
      "MAE_72h: 12.8075\n",
      "RMSE_72h: 18.2570\n",
      "MAE_mean: 14.8588\n",
      "RMSE_mean: 20.0403\n",
      "\n",
      "=== Station S3028127 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1376 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1353, 24, 400) Ytr2: (1353, 4) \n",
      "  Xva3: (197, 24, 400) Yva2: (197, 4) \n",
      "  Xte3: (348, 24, 400) Yte2: (348, 4)\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 3s 56ms/step - loss: 172.9787 - mae: 172.9659 - val_loss: 363.9852 - val_mae: 363.9724 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 166.1582 - mae: 166.1453 - val_loss: 354.0553 - val_mae: 354.0422 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 156.5095 - mae: 156.4962 - val_loss: 340.6013 - val_mae: 340.5876 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 146.7146 - mae: 146.7006 - val_loss: 324.9835 - val_mae: 324.9690 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 137.9238 - mae: 137.9089 - val_loss: 309.8498 - val_mae: 309.8342 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 131.4476 - mae: 131.4315 - val_loss: 296.8999 - val_mae: 296.8832 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 128.1221 - mae: 128.1050 - val_loss: 287.4271 - val_mae: 287.4096 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 126.0506 - mae: 126.0328 - val_loss: 282.4295 - val_mae: 282.4115 - lr: 0.0010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 123.8472 - mae: 123.8291 - val_loss: 279.0813 - val_mae: 279.0630 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 118.8904 - mae: 118.8720 - val_loss: 272.3297 - val_mae: 272.3109 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 113.3872 - mae: 113.3678 - val_loss: 260.6161 - val_mae: 260.5960 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 108.4435 - mae: 108.4227 - val_loss: 248.6179 - val_mae: 248.5962 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 102.8917 - mae: 102.8692 - val_loss: 236.8274 - val_mae: 236.8038 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 97.0077 - mae: 96.9832 - val_loss: 222.5169 - val_mae: 222.4911 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 91.4375 - mae: 91.4107 - val_loss: 209.5874 - val_mae: 209.5592 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 86.7590 - mae: 86.7298 - val_loss: 195.7921 - val_mae: 195.7614 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 81.7990 - mae: 81.7671 - val_loss: 182.4306 - val_mae: 182.3972 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 76.7723 - mae: 76.7377 - val_loss: 172.1720 - val_mae: 172.1357 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 73.0900 - mae: 73.0524 - val_loss: 160.7818 - val_mae: 160.7427 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 68.7624 - mae: 68.7219 - val_loss: 151.0899 - val_mae: 151.0479 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 373.8937\n",
      "LV_RMSE_12h: 439.0688\n",
      "LV_MAE_24h: 63.9282\n",
      "LV_RMSE_24h: 102.0346\n",
      "LV_MAE_48h: 82.4799\n",
      "LV_RMSE_48h: 122.3619\n",
      "LV_MAE_72h: 73.8707\n",
      "LV_RMSE_72h: 114.0168\n",
      "LV_MAE_mean: 148.5431\n",
      "LV_RMSE_mean: 194.3705\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 240.5744\n",
      "RMSE_12h: 310.4835\n",
      "MAE_24h: 99.0198\n",
      "RMSE_24h: 152.2837\n",
      "MAE_48h: 99.2732\n",
      "RMSE_48h: 153.5827\n",
      "MAE_72h: 101.1594\n",
      "RMSE_72h: 156.4965\n",
      "MAE_mean: 135.0067\n",
      "RMSE_mean: 193.2116\n",
      "\n",
      "=== Station S3029111 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1377 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1354, 24, 400) Ytr2: (1354, 4) \n",
      "  Xva3: (197, 24, 400) Yva2: (197, 4) \n",
      "  Xte3: (348, 24, 400) Yte2: (348, 4)\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 3s 59ms/step - loss: 148.3843 - mae: 148.3715 - val_loss: 149.8462 - val_mae: 149.8334 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 142.4481 - mae: 142.4353 - val_loss: 142.2502 - val_mae: 142.2373 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 134.5541 - mae: 134.5411 - val_loss: 134.1247 - val_mae: 134.1114 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 126.5810 - mae: 126.5673 - val_loss: 125.6554 - val_mae: 125.6413 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 118.2286 - mae: 118.2140 - val_loss: 117.3555 - val_mae: 117.3404 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 110.8000 - mae: 110.7843 - val_loss: 109.6641 - val_mae: 109.6477 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 104.5028 - mae: 104.4858 - val_loss: 103.0024 - val_mae: 102.9847 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 98.3543 - mae: 98.3360 - val_loss: 97.1394 - val_mae: 97.1204 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 92.6114 - mae: 92.5918 - val_loss: 91.8042 - val_mae: 91.7839 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 86.1196 - mae: 86.0987 - val_loss: 83.9536 - val_mae: 83.9320 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 77.3351 - mae: 77.3128 - val_loss: 74.1954 - val_mae: 74.1722 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 69.5890 - mae: 69.5650 - val_loss: 66.8131 - val_mae: 66.7882 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 63.9817 - mae: 63.9562 - val_loss: 62.1711 - val_mae: 62.1449 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 60.1051 - mae: 60.0784 - val_loss: 59.1158 - val_mae: 59.0887 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 57.6975 - mae: 57.6700 - val_loss: 58.0205 - val_mae: 57.9927 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 56.4905 - mae: 56.4624 - val_loss: 56.2052 - val_mae: 56.1767 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 54.9612 - mae: 54.9325 - val_loss: 54.7481 - val_mae: 54.7189 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 53.6749 - mae: 53.6455 - val_loss: 53.4063 - val_mae: 53.3765 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 52.4899 - mae: 52.4597 - val_loss: 51.6528 - val_mae: 51.6220 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 50.7637 - mae: 50.7325 - val_loss: 50.5145 - val_mae: 50.4827 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 178.5115\n",
      "LV_RMSE_12h: 199.1227\n",
      "LV_MAE_24h: 33.2989\n",
      "LV_RMSE_24h: 48.8105\n",
      "LV_MAE_48h: 42.0948\n",
      "LV_RMSE_48h: 61.4194\n",
      "LV_MAE_72h: 34.6782\n",
      "LV_RMSE_72h: 52.6064\n",
      "LV_MAE_mean: 72.1458\n",
      "LV_RMSE_mean: 90.4898\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 93.5432\n",
      "RMSE_12h: 120.3890\n",
      "MAE_24h: 33.8568\n",
      "RMSE_24h: 48.1094\n",
      "MAE_48h: 32.3521\n",
      "RMSE_48h: 46.7725\n",
      "MAE_72h: 30.4383\n",
      "RMSE_72h: 43.7531\n",
      "MAE_mean: 47.5476\n",
      "RMSE_mean: 64.7560\n",
      "\n",
      "=== Station S3029112 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1377 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1354, 24, 400) Ytr2: (1354, 4) \n",
      "  Xva3: (197, 24, 400) Yva2: (197, 4) \n",
      "  Xte3: (348, 24, 400) Yte2: (348, 4)\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 3s 60ms/step - loss: 255.4270 - mae: 255.4142 - val_loss: 191.5361 - val_mae: 191.5233 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 249.5881 - mae: 249.5751 - val_loss: 182.6558 - val_mae: 182.6427 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 239.3897 - mae: 239.3763 - val_loss: 171.8373 - val_mae: 171.8234 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 228.2407 - mae: 228.2265 - val_loss: 160.9737 - val_mae: 160.9589 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 215.7471 - mae: 215.7317 - val_loss: 150.2513 - val_mae: 150.2351 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 203.6871 - mae: 203.6703 - val_loss: 139.4882 - val_mae: 139.4705 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 191.3417 - mae: 191.3232 - val_loss: 129.0725 - val_mae: 129.0529 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 179.6166 - mae: 179.5961 - val_loss: 120.6228 - val_mae: 120.6012 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 168.9254 - mae: 168.9028 - val_loss: 115.0787 - val_mae: 115.0549 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 160.5760 - mae: 160.5512 - val_loss: 110.9319 - val_mae: 110.9060 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 153.9566 - mae: 153.9299 - val_loss: 105.2815 - val_mae: 105.2538 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 143.4287 - mae: 143.4003 - val_loss: 92.3896 - val_mae: 92.3603 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 130.9998 - mae: 130.9697 - val_loss: 82.5958 - val_mae: 82.5646 - lr: 0.0010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 121.5795 - mae: 121.5474 - val_loss: 75.5145 - val_mae: 75.4814 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 115.1474 - mae: 115.1136 - val_loss: 73.1661 - val_mae: 73.1313 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 110.7459 - mae: 110.7104 - val_loss: 71.1092 - val_mae: 71.0728 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 107.2926 - mae: 107.2555 - val_loss: 67.9446 - val_mae: 67.9066 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 104.1796 - mae: 104.1408 - val_loss: 67.1977 - val_mae: 67.1581 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 102.1221 - mae: 102.0817 - val_loss: 64.3071 - val_mae: 64.2658 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 98.1855 - mae: 98.1433 - val_loss: 64.2735 - val_mae: 64.2301 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 185.4971\n",
      "LV_RMSE_12h: 205.6464\n",
      "LV_MAE_24h: 44.2500\n",
      "LV_RMSE_24h: 65.6742\n",
      "LV_MAE_48h: 54.8937\n",
      "LV_RMSE_48h: 81.1135\n",
      "LV_MAE_72h: 46.2615\n",
      "LV_RMSE_72h: 73.3660\n",
      "LV_MAE_mean: 82.7256\n",
      "LV_RMSE_mean: 106.4500\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 138.1480\n",
      "RMSE_12h: 157.4317\n",
      "MAE_24h: 39.4535\n",
      "RMSE_24h: 58.7001\n",
      "MAE_48h: 38.8880\n",
      "RMSE_48h: 59.2180\n",
      "MAE_72h: 35.1614\n",
      "RMSE_72h: 54.7472\n",
      "MAE_mean: 62.9127\n",
      "RMSE_mean: 82.5243\n",
      "\n",
      "=== Station S3029113 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1377 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1354, 24, 400) Ytr2: (1354, 4) \n",
      "  Xva3: (197, 24, 400) Yva2: (197, 4) \n",
      "  Xte3: (348, 24, 400) Yte2: (348, 4)\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 3s 59ms/step - loss: 452.8799 - mae: 452.8671 - val_loss: 430.2951 - val_mae: 430.2822 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 446.5985 - mae: 446.5855 - val_loss: 421.0993 - val_mae: 421.0861 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 435.4631 - mae: 435.4496 - val_loss: 408.1858 - val_mae: 408.1720 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 421.3456 - mae: 421.3313 - val_loss: 392.5752 - val_mae: 392.5603 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 404.7232 - mae: 404.7078 - val_loss: 375.3077 - val_mae: 375.2916 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 387.9522 - mae: 387.9354 - val_loss: 357.5482 - val_mae: 357.5303 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 370.7513 - mae: 370.7327 - val_loss: 340.1228 - val_mae: 340.1031 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 354.0573 - mae: 354.0367 - val_loss: 322.6089 - val_mae: 322.5870 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 338.2281 - mae: 338.2053 - val_loss: 307.2964 - val_mae: 307.2722 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 323.1375 - mae: 323.1123 - val_loss: 294.3618 - val_mae: 294.3352 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 310.8633 - mae: 310.8355 - val_loss: 282.4938 - val_mae: 282.4647 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 299.8135 - mae: 299.7833 - val_loss: 272.9566 - val_mae: 272.9249 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 289.3472 - mae: 289.3144 - val_loss: 265.7460 - val_mae: 265.7119 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 280.6074 - mae: 280.5723 - val_loss: 255.9042 - val_mae: 255.8678 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 266.7883 - mae: 266.7509 - val_loss: 240.0453 - val_mae: 240.0065 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 250.2774 - mae: 250.2375 - val_loss: 225.2023 - val_mae: 225.1608 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 235.4893 - mae: 235.4467 - val_loss: 212.5564 - val_mae: 212.5122 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 222.0502 - mae: 222.0048 - val_loss: 201.9364 - val_mae: 201.8894 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 212.9934 - mae: 212.9452 - val_loss: 194.2713 - val_mae: 194.2215 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 204.9600 - mae: 204.9090 - val_loss: 188.1398 - val_mae: 188.0874 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 403.4540\n",
      "LV_RMSE_12h: 465.4445\n",
      "LV_MAE_24h: 130.2500\n",
      "LV_RMSE_24h: 185.5340\n",
      "LV_MAE_48h: 171.0115\n",
      "LV_RMSE_48h: 224.4162\n",
      "LV_MAE_72h: 146.5805\n",
      "LV_RMSE_72h: 206.3249\n",
      "LV_MAE_mean: 212.8240\n",
      "LV_RMSE_mean: 270.4299\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 311.6618\n",
      "RMSE_12h: 368.5074\n",
      "MAE_24h: 116.4287\n",
      "RMSE_24h: 166.0293\n",
      "MAE_48h: 119.8586\n",
      "RMSE_48h: 164.8824\n",
      "MAE_72h: 110.8487\n",
      "RMSE_72h: 154.4384\n",
      "MAE_mean: 164.6994\n",
      "RMSE_mean: 213.4644\n",
      "\n",
      "=== Station S3029114 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1377 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1354, 24, 400) Ytr2: (1354, 4) \n",
      "  Xva3: (197, 24, 400) Yva2: (197, 4) \n",
      "  Xte3: (348, 24, 400) Yte2: (348, 4)\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 3s 56ms/step - loss: 690.4498 - mae: 690.4370 - val_loss: 608.5110 - val_mae: 608.4982 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 687.6497 - mae: 687.6367 - val_loss: 604.7186 - val_mae: 604.7055 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 682.4236 - mae: 682.4103 - val_loss: 598.9133 - val_mae: 598.8996 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 675.4513 - mae: 675.4373 - val_loss: 591.3973 - val_mae: 591.3828 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 666.3904 - mae: 666.3754 - val_loss: 581.7510 - val_mae: 581.7352 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 655.5656 - mae: 655.5489 - val_loss: 570.2168 - val_mae: 570.1991 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 643.3483 - mae: 643.3298 - val_loss: 557.2177 - val_mae: 557.1978 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 629.1949 - mae: 629.1738 - val_loss: 542.2235 - val_mae: 542.2009 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 613.3064 - mae: 613.2825 - val_loss: 525.6622 - val_mae: 525.6364 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 595.8574 - mae: 595.8300 - val_loss: 507.7706 - val_mae: 507.7411 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 578.3386 - mae: 578.3072 - val_loss: 488.5811 - val_mae: 488.5474 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 558.2410 - mae: 558.2052 - val_loss: 468.6687 - val_mae: 468.6303 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 537.2998 - mae: 537.2592 - val_loss: 447.7706 - val_mae: 447.7271 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 515.1688 - mae: 515.1230 - val_loss: 425.1183 - val_mae: 425.0692 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 492.0465 - mae: 491.9949 - val_loss: 403.9934 - val_mae: 403.9383 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 470.3315 - mae: 470.2737 - val_loss: 382.2002 - val_mae: 382.1388 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 446.8555 - mae: 446.7912 - val_loss: 358.1915 - val_mae: 358.1234 - lr: 0.0010\n",
      "Epoch 18/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 13ms/step - loss: 423.7820 - mae: 423.7109 - val_loss: 335.0538 - val_mae: 334.9787 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 403.0136 - mae: 402.9354 - val_loss: 312.8352 - val_mae: 312.7529 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 381.7424 - mae: 381.6570 - val_loss: 298.3941 - val_mae: 298.3046 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 856.0517\n",
      "LV_RMSE_12h: 942.2120\n",
      "LV_MAE_24h: 164.1264\n",
      "LV_RMSE_24h: 264.6325\n",
      "LV_MAE_48h: 228.8190\n",
      "LV_RMSE_48h: 346.8874\n",
      "LV_MAE_72h: 180.1178\n",
      "LV_RMSE_72h: 302.1846\n",
      "LV_MAE_mean: 357.2787\n",
      "LV_RMSE_mean: 463.9791\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 437.3480\n",
      "RMSE_12h: 616.1668\n",
      "MAE_24h: 184.5204\n",
      "RMSE_24h: 290.6322\n",
      "MAE_48h: 168.9847\n",
      "RMSE_48h: 268.0889\n",
      "MAE_72h: 158.8592\n",
      "RMSE_72h: 246.0720\n",
      "MAE_mean: 237.4281\n",
      "RMSE_mean: 355.2400\n",
      "\n",
      "=== Station S3030131 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1377 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1354, 24, 400) Ytr2: (1354, 4) \n",
      "  Xva3: (197, 24, 400) Yva2: (197, 4) \n",
      "  Xte3: (348, 24, 400) Yte2: (348, 4)\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 3s 59ms/step - loss: 3534.7471 - mae: 3534.7349 - val_loss: 3527.3328 - val_mae: 3527.3201 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 3529.0200 - mae: 3529.0073 - val_loss: 3519.7141 - val_mae: 3519.7012 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 3519.7268 - mae: 3519.7139 - val_loss: 3508.7087 - val_mae: 3508.6953 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 3507.5564 - mae: 3507.5432 - val_loss: 3494.6179 - val_mae: 3494.6040 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 3491.6799 - mae: 3491.6655 - val_loss: 3476.8616 - val_mae: 3476.8464 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 3472.2068 - mae: 3472.1904 - val_loss: 3455.4133 - val_mae: 3455.3965 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 3449.1067 - mae: 3449.0894 - val_loss: 3430.2507 - val_mae: 3430.2327 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 3421.9524 - mae: 3421.9329 - val_loss: 3401.4797 - val_mae: 3401.4595 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 3392.2651 - mae: 3392.2434 - val_loss: 3369.7615 - val_mae: 3369.7385 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 3357.0806 - mae: 3357.0562 - val_loss: 3335.3386 - val_mae: 3335.3125 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 3320.0439 - mae: 3320.0164 - val_loss: 3297.0667 - val_mae: 3297.0374 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 3279.6499 - mae: 3279.6196 - val_loss: 3255.2278 - val_mae: 3255.1948 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 3237.7578 - mae: 3237.7231 - val_loss: 3211.0496 - val_mae: 3211.0127 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 3191.4929 - mae: 3191.4541 - val_loss: 3164.0667 - val_mae: 3164.0254 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 3141.2246 - mae: 3141.1814 - val_loss: 3115.1099 - val_mae: 3115.0635 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 3091.8669 - mae: 3091.8191 - val_loss: 3063.9568 - val_mae: 3063.9055 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 3039.4937 - mae: 3039.4399 - val_loss: 3010.7144 - val_mae: 3010.6580 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 2981.1755 - mae: 2981.1162 - val_loss: 2955.3186 - val_mae: 2955.2556 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 2926.6248 - mae: 2926.5596 - val_loss: 2898.1970 - val_mae: 2898.1282 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 2867.4775 - mae: 2867.4058 - val_loss: 2841.3828 - val_mae: 2841.3079 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 3141.2932\n",
      "LV_RMSE_12h: 3618.4485\n",
      "LV_MAE_24h: 575.3161\n",
      "LV_RMSE_24h: 822.2247\n",
      "LV_MAE_48h: 750.5115\n",
      "LV_RMSE_48h: 1044.0541\n",
      "LV_MAE_72h: 656.2241\n",
      "LV_RMSE_72h: 855.7907\n",
      "LV_MAE_mean: 1280.8363\n",
      "LV_RMSE_mean: 1585.1295\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 2669.4421\n",
      "RMSE_12h: 3204.9565\n",
      "MAE_24h: 2742.2073\n",
      "RMSE_24h: 3255.5027\n",
      "MAE_48h: 2714.0215\n",
      "RMSE_48h: 3232.6743\n",
      "MAE_72h: 2735.6782\n",
      "RMSE_72h: 3257.1855\n",
      "MAE_mean: 2715.3374\n",
      "RMSE_mean: 3237.5796\n",
      "\n",
      "=== Station S3031011 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1377 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1354, 24, 400) Ytr2: (1354, 4) \n",
      "  Xva3: (197, 24, 400) Yva2: (197, 4) \n",
      "  Xte3: (348, 24, 400) Yte2: (348, 4)\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 3s 60ms/step - loss: 384.6747 - mae: 384.6619 - val_loss: 356.6133 - val_mae: 356.6006 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 378.3289 - mae: 378.3161 - val_loss: 348.1874 - val_mae: 348.1744 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 369.0245 - mae: 369.0114 - val_loss: 338.6087 - val_mae: 338.5953 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 358.8798 - mae: 358.8661 - val_loss: 328.4771 - val_mae: 328.4630 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 347.8031 - mae: 347.7885 - val_loss: 317.9715 - val_mae: 317.9563 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 336.7303 - mae: 336.7144 - val_loss: 307.1874 - val_mae: 307.1709 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 325.9399 - mae: 325.9228 - val_loss: 296.5700 - val_mae: 296.5519 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 315.0788 - mae: 315.0601 - val_loss: 286.8973 - val_mae: 286.8775 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 304.9992 - mae: 304.9786 - val_loss: 278.2481 - val_mae: 278.2265 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 295.5636 - mae: 295.5411 - val_loss: 268.8527 - val_mae: 268.8291 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 284.0441 - mae: 284.0196 - val_loss: 255.1656 - val_mae: 255.1400 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 268.2360 - mae: 268.2093 - val_loss: 238.6755 - val_mae: 238.6474 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 252.6551 - mae: 252.6259 - val_loss: 223.2757 - val_mae: 223.2448 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 236.9139 - mae: 236.8817 - val_loss: 208.1453 - val_mae: 208.1112 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 221.0517 - mae: 221.0161 - val_loss: 193.7222 - val_mae: 193.6847 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 207.6949 - mae: 207.6559 - val_loss: 181.1895 - val_mae: 181.1484 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 196.0602 - mae: 196.0176 - val_loss: 172.2003 - val_mae: 172.1560 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 187.4586 - mae: 187.4130 - val_loss: 166.3338 - val_mae: 166.2868 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 182.7108 - mae: 182.6628 - val_loss: 164.2646 - val_mae: 164.2155 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 180.7228 - mae: 180.6731 - val_loss: 161.4118 - val_mae: 161.3614 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 477.7155\n",
      "LV_RMSE_12h: 543.5647\n",
      "LV_MAE_24h: 102.3621\n",
      "LV_RMSE_24h: 160.6033\n",
      "LV_MAE_48h: 138.3419\n",
      "LV_RMSE_48h: 216.8959\n",
      "LV_MAE_72h: 136.1523\n",
      "LV_RMSE_72h: 226.8355\n",
      "LV_MAE_mean: 213.6430\n",
      "LV_RMSE_mean: 286.9749\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 323.8390\n",
      "RMSE_12h: 407.8469\n",
      "MAE_24h: 117.9539\n",
      "RMSE_24h: 191.1950\n",
      "MAE_48h: 118.4394\n",
      "RMSE_48h: 192.5693\n",
      "MAE_72h: 110.4596\n",
      "RMSE_72h: 179.2753\n",
      "MAE_mean: 167.6730\n",
      "RMSE_mean: 242.7216\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Station S3031015 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1376 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1353, 24, 400) Ytr2: (1353, 4) \n",
      "  Xva3: (197, 24, 400) Yva2: (197, 4) \n",
      "  Xte3: (348, 24, 400) Yte2: (348, 4)\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 3s 58ms/step - loss: 59.6631 - mae: 59.6504 - val_loss: 57.7400 - val_mae: 57.7272 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 55.1357 - mae: 55.1230 - val_loss: 51.7361 - val_mae: 51.7232 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 48.6566 - mae: 48.6435 - val_loss: 44.6371 - val_mae: 44.6239 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 42.0790 - mae: 42.0655 - val_loss: 38.8533 - val_mae: 38.8394 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 37.2750 - mae: 37.2608 - val_loss: 34.8669 - val_mae: 34.8523 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 33.9463 - mae: 33.9314 - val_loss: 32.4597 - val_mae: 32.4445 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 32.4015 - mae: 32.3861 - val_loss: 30.7709 - val_mae: 30.7553 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 30.2585 - mae: 30.2427 - val_loss: 28.3635 - val_mae: 28.3475 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 27.8330 - mae: 27.8169 - val_loss: 25.2551 - val_mae: 25.2387 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 24.7552 - mae: 24.7386 - val_loss: 22.1161 - val_mae: 22.0992 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 22.1111 - mae: 22.0939 - val_loss: 20.3128 - val_mae: 20.2952 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 20.5027 - mae: 20.4848 - val_loss: 18.6143 - val_mae: 18.5961 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 19.3761 - mae: 19.3576 - val_loss: 17.0248 - val_mae: 17.0061 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 0s 20ms/step - loss: 18.0321 - mae: 18.0132 - val_loss: 15.9251 - val_mae: 15.9058 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 16.8624 - mae: 16.8429 - val_loss: 14.0435 - val_mae: 14.0237 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 15.6443 - mae: 15.6242 - val_loss: 12.8537 - val_mae: 12.8331 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 14.3127 - mae: 14.2919 - val_loss: 11.6080 - val_mae: 11.5867 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 13.5115 - mae: 13.4899 - val_loss: 10.9522 - val_mae: 10.9303 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 13.2060 - mae: 13.1838 - val_loss: 10.4082 - val_mae: 10.3858 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 12.8683 - mae: 12.8458 - val_loss: 10.7392 - val_mae: 10.7165 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 60.4971\n",
      "LV_RMSE_12h: 68.5805\n",
      "LV_MAE_24h: 14.9943\n",
      "LV_RMSE_24h: 20.4685\n",
      "LV_MAE_48h: 16.5776\n",
      "LV_RMSE_48h: 21.9841\n",
      "LV_MAE_72h: 15.0661\n",
      "LV_RMSE_72h: 20.2777\n",
      "LV_MAE_mean: 26.7838\n",
      "LV_RMSE_mean: 32.8277\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 12.0168\n",
      "RMSE_12h: 15.9737\n",
      "MAE_24h: 11.8799\n",
      "RMSE_24h: 15.8382\n",
      "MAE_48h: 11.4173\n",
      "RMSE_48h: 15.2378\n",
      "MAE_72h: 11.3073\n",
      "RMSE_72h: 15.1388\n",
      "MAE_mean: 11.6553\n",
      "RMSE_mean: 15.5471\n",
      "\n",
      "=== Station S3031020 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1377 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1354, 24, 400) Ytr2: (1354, 4) \n",
      "  Xva3: (197, 24, 400) Yva2: (197, 4) \n",
      "  Xte3: (348, 24, 400) Yte2: (348, 4)\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 3s 58ms/step - loss: 603.9694 - mae: 603.9565 - val_loss: 575.7883 - val_mae: 575.7755 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 597.5248 - mae: 597.5118 - val_loss: 566.1430 - val_mae: 566.1299 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 585.7630 - mae: 585.7496 - val_loss: 552.3370 - val_mae: 552.3232 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 570.7900 - mae: 570.7757 - val_loss: 535.5689 - val_mae: 535.5540 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 552.6627 - mae: 552.6471 - val_loss: 517.3594 - val_mae: 517.3430 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 534.0750 - mae: 534.0579 - val_loss: 499.2631 - val_mae: 499.2448 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 515.0999 - mae: 515.0807 - val_loss: 480.7495 - val_mae: 480.7291 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 496.3621 - mae: 496.3407 - val_loss: 462.5932 - val_mae: 462.5703 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 478.4205 - mae: 478.3965 - val_loss: 444.9600 - val_mae: 444.9345 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 459.9756 - mae: 459.9488 - val_loss: 428.5582 - val_mae: 428.5298 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 443.5502 - mae: 443.5204 - val_loss: 413.7043 - val_mae: 413.6727 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 428.3573 - mae: 428.3243 - val_loss: 400.6263 - val_mae: 400.5916 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 414.0868 - mae: 414.0507 - val_loss: 384.4245 - val_mae: 384.3866 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 394.3728 - mae: 394.3334 - val_loss: 359.3229 - val_mae: 359.2816 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 368.1469 - mae: 368.1038 - val_loss: 333.9972 - val_mae: 333.9519 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 345.0910 - mae: 345.0438 - val_loss: 312.1926 - val_mae: 312.1429 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 323.0909 - mae: 323.0391 - val_loss: 290.8390 - val_mae: 290.7846 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 301.5897 - mae: 301.5331 - val_loss: 271.8797 - val_mae: 271.8202 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 283.4206 - mae: 283.3588 - val_loss: 254.1484 - val_mae: 254.0837 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 266.4784 - mae: 266.4115 - val_loss: 239.6283 - val_mae: 239.5588 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 695.0575\n",
      "LV_RMSE_12h: 776.8557\n",
      "LV_MAE_24h: 141.0833\n",
      "LV_RMSE_24h: 212.7587\n",
      "LV_MAE_48h: 189.3103\n",
      "LV_RMSE_48h: 281.5634\n",
      "LV_MAE_72h: 184.3247\n",
      "LV_RMSE_72h: 280.4954\n",
      "LV_MAE_mean: 302.4440\n",
      "LV_RMSE_mean: 387.9183\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 494.3369\n",
      "RMSE_12h: 590.7728\n",
      "MAE_24h: 189.1393\n",
      "RMSE_24h: 275.4144\n",
      "MAE_48h: 177.1225\n",
      "RMSE_48h: 262.9383\n",
      "MAE_72h: 173.2695\n",
      "RMSE_72h: 256.9679\n",
      "MAE_mean: 258.4670\n",
      "RMSE_mean: 346.5233\n",
      "\n",
      "=== Station S3031051 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1377 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1354, 24, 400) Ytr2: (1354, 4) \n",
      "  Xva3: (197, 24, 400) Yva2: (197, 4) \n",
      "  Xte3: (348, 24, 400) Yte2: (348, 4)\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 3s 60ms/step - loss: 376.3414 - mae: 376.3287 - val_loss: 349.8542 - val_mae: 349.8415 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 370.8455 - mae: 370.8326 - val_loss: 341.9247 - val_mae: 341.9117 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 361.9237 - mae: 361.9105 - val_loss: 332.4505 - val_mae: 332.4369 - lr: 0.0010\n",
      "Epoch 4/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 12ms/step - loss: 352.0536 - mae: 352.0397 - val_loss: 322.6860 - val_mae: 322.6716 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 341.5771 - mae: 341.5622 - val_loss: 312.5116 - val_mae: 312.4959 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 330.9558 - mae: 330.9396 - val_loss: 301.9155 - val_mae: 301.8983 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 319.6187 - mae: 319.6008 - val_loss: 291.0872 - val_mae: 291.0683 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 307.5473 - mae: 307.5276 - val_loss: 279.0748 - val_mae: 279.0539 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 295.3976 - mae: 295.3757 - val_loss: 267.2240 - val_mae: 267.2008 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 283.2531 - mae: 283.2289 - val_loss: 255.7764 - val_mae: 255.7508 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 271.9168 - mae: 271.8902 - val_loss: 245.5473 - val_mae: 245.5192 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 261.8035 - mae: 261.7745 - val_loss: 237.3273 - val_mae: 237.2969 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 253.4150 - mae: 253.3837 - val_loss: 229.0069 - val_mae: 228.9743 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 245.2955 - mae: 245.2620 - val_loss: 221.9176 - val_mae: 221.8829 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 236.9692 - mae: 236.9336 - val_loss: 212.6876 - val_mae: 212.6507 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 228.7178 - mae: 228.6798 - val_loss: 205.0983 - val_mae: 205.0590 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 219.6338 - mae: 219.5932 - val_loss: 196.7092 - val_mae: 196.6671 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 210.5483 - mae: 210.5049 - val_loss: 188.3318 - val_mae: 188.2866 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 200.8640 - mae: 200.8174 - val_loss: 179.7321 - val_mae: 179.6834 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 191.9473 - mae: 191.8970 - val_loss: 171.1153 - val_mae: 171.0630 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 511.0000\n",
      "LV_RMSE_12h: 622.2396\n",
      "LV_MAE_24h: 91.4971\n",
      "LV_RMSE_24h: 147.2758\n",
      "LV_MAE_48h: 120.1063\n",
      "LV_RMSE_48h: 196.8385\n",
      "LV_MAE_72h: 110.1839\n",
      "LV_RMSE_72h: 187.7058\n",
      "LV_MAE_mean: 208.1968\n",
      "LV_RMSE_mean: 288.5149\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 308.3629\n",
      "RMSE_12h: 434.8000\n",
      "MAE_24h: 118.1335\n",
      "RMSE_24h: 209.6760\n",
      "MAE_48h: 123.9903\n",
      "RMSE_48h: 215.4227\n",
      "MAE_72h: 127.0594\n",
      "RMSE_72h: 217.7579\n",
      "MAE_mean: 169.3865\n",
      "RMSE_mean: 269.4142\n",
      "\n",
      "=== Station S3031052 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1377 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1354, 24, 400) Ytr2: (1354, 4) \n",
      "  Xva3: (197, 24, 400) Yva2: (197, 4) \n",
      "  Xte3: (348, 24, 400) Yte2: (348, 4)\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 3s 58ms/step - loss: 2582.1282 - mae: 2582.1150 - val_loss: 2526.4541 - val_mae: 2526.4414 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 2574.4802 - mae: 2574.4670 - val_loss: 2514.9426 - val_mae: 2514.9294 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 2560.5234 - mae: 2560.5103 - val_loss: 2498.3855 - val_mae: 2498.3716 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 2542.2649 - mae: 2542.2505 - val_loss: 2477.4482 - val_mae: 2477.4331 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 2518.8042 - mae: 2518.7883 - val_loss: 2451.3699 - val_mae: 2451.3533 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 2490.1841 - mae: 2490.1665 - val_loss: 2419.5527 - val_mae: 2419.5339 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 2455.9595 - mae: 2455.9392 - val_loss: 2381.9165 - val_mae: 2381.8950 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 2415.6633 - mae: 2415.6406 - val_loss: 2338.1741 - val_mae: 2338.1497 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 2369.8584 - mae: 2369.8323 - val_loss: 2288.2402 - val_mae: 2288.2117 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 2315.7600 - mae: 2315.7295 - val_loss: 2232.0530 - val_mae: 2232.0200 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 2258.2009 - mae: 2258.1655 - val_loss: 2170.9832 - val_mae: 2170.9453 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 2197.0583 - mae: 2197.0186 - val_loss: 2109.1650 - val_mae: 2109.1216 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 2135.4138 - mae: 2135.3682 - val_loss: 2050.2639 - val_mae: 2050.2151 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 2077.6541 - mae: 2077.6028 - val_loss: 1995.1525 - val_mae: 1995.0977 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 2021.9722 - mae: 2021.9147 - val_loss: 1942.1906 - val_mae: 1942.1298 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1970.5432 - mae: 1970.4799 - val_loss: 1893.1196 - val_mae: 1893.0526 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1920.7029 - mae: 1920.6332 - val_loss: 1847.3450 - val_mae: 1847.2717 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1874.6650 - mae: 1874.5890 - val_loss: 1802.5660 - val_mae: 1802.4863 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1832.2130 - mae: 1832.1307 - val_loss: 1757.9523 - val_mae: 1757.8660 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1792.2104 - mae: 1792.1211 - val_loss: 1714.4913 - val_mae: 1714.3982 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 2482.7729\n",
      "LV_RMSE_12h: 2896.3164\n",
      "LV_MAE_24h: 392.0402\n",
      "LV_RMSE_24h: 583.4808\n",
      "LV_MAE_48h: 536.4052\n",
      "LV_RMSE_48h: 790.0616\n",
      "LV_MAE_72h: 460.9828\n",
      "LV_RMSE_72h: 705.7516\n",
      "LV_MAE_mean: 968.0502\n",
      "LV_RMSE_mean: 1243.9026\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 1575.8503\n",
      "RMSE_12h: 2025.4288\n",
      "MAE_24h: 1624.8583\n",
      "RMSE_24h: 2075.3940\n",
      "MAE_48h: 1664.6024\n",
      "RMSE_48h: 2134.6282\n",
      "MAE_72h: 1613.1418\n",
      "RMSE_72h: 2069.1287\n",
      "MAE_mean: 1619.6133\n",
      "RMSE_mean: 2076.1450\n",
      "\n",
      "=== Station S3031053 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1376 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1353, 24, 400) Ytr2: (1353, 4) \n",
      "  Xva3: (197, 24, 400) Yva2: (197, 4) \n",
      "  Xte3: (348, 24, 400) Yte2: (348, 4)\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 3s 58ms/step - loss: 87.2837 - mae: 87.2708 - val_loss: 86.7232 - val_mae: 86.7102 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 82.5396 - mae: 82.5266 - val_loss: 81.0286 - val_mae: 81.0154 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 76.7742 - mae: 76.7609 - val_loss: 75.0005 - val_mae: 74.9870 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 71.1839 - mae: 71.1700 - val_loss: 69.6080 - val_mae: 69.5937 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 65.9776 - mae: 65.9630 - val_loss: 64.5552 - val_mae: 64.5400 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 60.9634 - mae: 60.9479 - val_loss: 59.9973 - val_mae: 59.9812 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 56.9574 - mae: 56.9409 - val_loss: 56.0550 - val_mae: 56.0379 - lr: 0.0010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 53.1133 - mae: 53.0958 - val_loss: 52.2959 - val_mae: 52.2779 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 49.1862 - mae: 49.1678 - val_loss: 47.3521 - val_mae: 47.3333 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 43.6905 - mae: 43.6715 - val_loss: 42.4852 - val_mae: 42.4658 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 39.4907 - mae: 39.4709 - val_loss: 38.0110 - val_mae: 37.9908 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 35.9080 - mae: 35.8876 - val_loss: 35.6405 - val_mae: 35.6197 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 33.9430 - mae: 33.9220 - val_loss: 33.9915 - val_mae: 33.9701 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 32.8596 - mae: 32.8380 - val_loss: 32.6444 - val_mae: 32.6225 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 31.3610 - mae: 31.3389 - val_loss: 31.1735 - val_mae: 31.1510 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 29.6684 - mae: 29.6456 - val_loss: 29.2841 - val_mae: 29.2608 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 28.3091 - mae: 28.2854 - val_loss: 27.3228 - val_mae: 27.2986 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 26.2598 - mae: 26.2351 - val_loss: 25.0789 - val_mae: 25.0535 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 24.1647 - mae: 24.1388 - val_loss: 23.1658 - val_mae: 23.1393 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 22.7732 - mae: 22.7461 - val_loss: 21.2906 - val_mae: 21.2629 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 113.4799\n",
      "LV_RMSE_12h: 126.2941\n",
      "LV_MAE_24h: 20.1954\n",
      "LV_RMSE_24h: 31.4273\n",
      "LV_MAE_48h: 24.1379\n",
      "LV_RMSE_48h: 36.0083\n",
      "LV_MAE_72h: 24.2011\n",
      "LV_RMSE_72h: 36.7474\n",
      "LV_MAE_mean: 45.5036\n",
      "LV_RMSE_mean: 57.6193\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 23.9973\n",
      "RMSE_12h: 34.4020\n",
      "MAE_24h: 21.1324\n",
      "RMSE_24h: 29.9137\n",
      "MAE_48h: 20.4986\n",
      "RMSE_48h: 29.2936\n",
      "MAE_72h: 20.4057\n",
      "RMSE_72h: 28.9868\n",
      "MAE_mean: 21.5085\n",
      "RMSE_mean: 30.6490\n",
      "\n",
      "=== Station S3031054 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1376 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1353, 24, 400) Ytr2: (1353, 4) \n",
      "  Xva3: (197, 24, 400) Yva2: (197, 4) \n",
      "  Xte3: (348, 24, 400) Yte2: (348, 4)\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 3s 59ms/step - loss: 145.3457 - mae: 145.3330 - val_loss: 149.6161 - val_mae: 149.6034 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 139.8552 - mae: 139.8425 - val_loss: 142.8654 - val_mae: 142.8526 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 132.9136 - mae: 132.9006 - val_loss: 135.8791 - val_mae: 135.8658 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 126.0829 - mae: 126.0693 - val_loss: 128.9003 - val_mae: 128.8864 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 119.4957 - mae: 119.4814 - val_loss: 121.8825 - val_mae: 121.8676 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 113.2554 - mae: 113.2401 - val_loss: 115.6150 - val_mae: 115.5991 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 107.6746 - mae: 107.6582 - val_loss: 109.2244 - val_mae: 109.2073 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 101.7403 - mae: 101.7227 - val_loss: 102.9817 - val_mae: 102.9634 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 95.8873 - mae: 95.8684 - val_loss: 95.1362 - val_mae: 95.1166 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 87.8248 - mae: 87.8046 - val_loss: 87.8603 - val_mae: 87.8393 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 80.8667 - mae: 80.8451 - val_loss: 80.0463 - val_mae: 80.0237 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 73.6459 - mae: 73.6227 - val_loss: 73.7208 - val_mae: 73.6967 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 68.1350 - mae: 68.1104 - val_loss: 67.3988 - val_mae: 67.3734 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 63.0682 - mae: 63.0422 - val_loss: 63.0851 - val_mae: 63.0585 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 59.7441 - mae: 59.7170 - val_loss: 60.4573 - val_mae: 60.4296 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 58.1081 - mae: 58.0800 - val_loss: 58.4454 - val_mae: 58.4168 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 56.0061 - mae: 55.9770 - val_loss: 56.1550 - val_mae: 56.1254 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 54.5615 - mae: 54.5316 - val_loss: 55.9323 - val_mae: 55.9019 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 52.8173 - mae: 52.7865 - val_loss: 52.9861 - val_mae: 52.9547 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 50.8481 - mae: 50.8163 - val_loss: 51.5000 - val_mae: 51.4676 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 187.8994\n",
      "LV_RMSE_12h: 210.0859\n",
      "LV_MAE_24h: 30.4339\n",
      "LV_RMSE_24h: 48.2157\n",
      "LV_MAE_48h: 36.9684\n",
      "LV_RMSE_48h: 56.1643\n",
      "LV_MAE_72h: 35.5029\n",
      "LV_RMSE_72h: 55.2539\n",
      "LV_MAE_mean: 72.7011\n",
      "LV_RMSE_mean: 92.4300\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 88.9411\n",
      "RMSE_12h: 117.1205\n",
      "MAE_24h: 34.3545\n",
      "RMSE_24h: 49.1634\n",
      "MAE_48h: 32.9669\n",
      "RMSE_48h: 47.4007\n",
      "MAE_72h: 33.0169\n",
      "RMSE_72h: 47.5374\n",
      "MAE_mean: 47.3198\n",
      "RMSE_mean: 65.3055\n",
      "\n",
      "=== Station S3031056 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1376 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1353, 24, 400) Ytr2: (1353, 4) \n",
      "  Xva3: (197, 24, 400) Yva2: (197, 4) \n",
      "  Xte3: (348, 24, 400) Yte2: (348, 4)\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 3s 59ms/step - loss: 238.5725 - mae: 238.5596 - val_loss: 241.7845 - val_mae: 241.7715 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 233.2853 - mae: 233.2723 - val_loss: 234.0879 - val_mae: 234.0746 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 224.3171 - mae: 224.3037 - val_loss: 223.7814 - val_mae: 223.7677 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 214.0126 - mae: 213.9985 - val_loss: 213.1315 - val_mae: 213.1170 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 203.7669 - mae: 203.7519 - val_loss: 202.7377 - val_mae: 202.7221 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 193.7852 - mae: 193.7689 - val_loss: 192.9900 - val_mae: 192.9730 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 184.4786 - mae: 184.4610 - val_loss: 184.2712 - val_mae: 184.2527 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 175.7477 - mae: 175.7285 - val_loss: 176.7752 - val_mae: 176.7550 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 169.1648 - mae: 169.1439 - val_loss: 170.8415 - val_mae: 170.8197 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 162.5103 - mae: 162.4878 - val_loss: 163.9953 - val_mae: 163.9719 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 153.7560 - mae: 153.7319 - val_loss: 150.5377 - val_mae: 150.5126 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 141.3509 - mae: 141.3250 - val_loss: 139.0010 - val_mae: 138.9740 - lr: 0.0010\n",
      "Epoch 13/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 13ms/step - loss: 131.3857 - mae: 131.3578 - val_loss: 127.5819 - val_mae: 127.5526 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 119.7194 - mae: 119.6891 - val_loss: 114.9586 - val_mae: 114.9268 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 107.8534 - mae: 107.8204 - val_loss: 103.6825 - val_mae: 103.6479 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 98.6061 - mae: 98.5703 - val_loss: 95.8595 - val_mae: 95.8223 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 92.7683 - mae: 92.7300 - val_loss: 89.3781 - val_mae: 89.3386 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 88.6130 - mae: 88.5728 - val_loss: 85.2553 - val_mae: 85.2143 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 86.4035 - mae: 86.3620 - val_loss: 82.4749 - val_mae: 82.4329 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 84.4573 - mae: 84.4150 - val_loss: 81.1354 - val_mae: 81.0926 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 266.1494\n",
      "LV_RMSE_12h: 295.2133\n",
      "LV_MAE_24h: 46.2557\n",
      "LV_RMSE_24h: 69.7552\n",
      "LV_MAE_48h: 53.9167\n",
      "LV_RMSE_48h: 79.2284\n",
      "LV_MAE_72h: 50.3506\n",
      "LV_RMSE_72h: 74.9091\n",
      "LV_MAE_mean: 104.1681\n",
      "LV_RMSE_mean: 129.7765\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 166.5832\n",
      "RMSE_12h: 207.4875\n",
      "MAE_24h: 52.0007\n",
      "RMSE_24h: 76.9495\n",
      "MAE_48h: 48.1877\n",
      "RMSE_48h: 73.7590\n",
      "MAE_72h: 48.2722\n",
      "RMSE_72h: 74.1245\n",
      "MAE_mean: 78.7609\n",
      "RMSE_mean: 108.0801\n",
      "\n",
      "=== Station S3031081 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1377 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1354, 24, 400) Ytr2: (1354, 4) \n",
      "  Xva3: (197, 24, 400) Yva2: (197, 4) \n",
      "  Xte3: (348, 24, 400) Yte2: (348, 4)\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 3s 58ms/step - loss: 168.7881 - mae: 168.7754 - val_loss: 163.7159 - val_mae: 163.7034 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 164.4560 - mae: 164.4435 - val_loss: 157.8373 - val_mae: 157.8247 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 158.7544 - mae: 158.7416 - val_loss: 151.5430 - val_mae: 151.5301 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 153.1636 - mae: 153.1505 - val_loss: 145.3022 - val_mae: 145.2888 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 147.2054 - mae: 147.1916 - val_loss: 139.2406 - val_mae: 139.2264 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 141.3556 - mae: 141.3410 - val_loss: 133.2000 - val_mae: 133.1847 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 136.2078 - mae: 136.1920 - val_loss: 127.5756 - val_mae: 127.5593 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 130.8956 - mae: 130.8788 - val_loss: 122.5506 - val_mae: 122.5331 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 125.3689 - mae: 125.3509 - val_loss: 117.2948 - val_mae: 117.2760 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 119.8208 - mae: 119.8014 - val_loss: 111.3471 - val_mae: 111.3270 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 112.6923 - mae: 112.6715 - val_loss: 103.4061 - val_mae: 103.3843 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 103.3570 - mae: 103.3345 - val_loss: 93.3277 - val_mae: 93.3040 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 91.9494 - mae: 91.9247 - val_loss: 82.8807 - val_mae: 82.8545 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 81.7734 - mae: 81.7460 - val_loss: 75.0385 - val_mae: 75.0095 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 73.5701 - mae: 73.5400 - val_loss: 69.7503 - val_mae: 69.7186 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 68.6159 - mae: 68.5832 - val_loss: 66.1200 - val_mae: 66.0861 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 65.8544 - mae: 65.8197 - val_loss: 64.4491 - val_mae: 64.4135 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 64.3219 - mae: 64.2857 - val_loss: 63.5245 - val_mae: 63.4875 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 62.1006 - mae: 62.0631 - val_loss: 61.7366 - val_mae: 61.6985 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 59.9100 - mae: 59.8714 - val_loss: 61.6153 - val_mae: 61.5759 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 353.9081\n",
      "LV_RMSE_12h: 391.5812\n",
      "LV_MAE_24h: 60.8851\n",
      "LV_RMSE_24h: 103.6783\n",
      "LV_MAE_48h: 73.4914\n",
      "LV_RMSE_48h: 114.5065\n",
      "LV_MAE_72h: 78.3592\n",
      "LV_RMSE_72h: 121.4532\n",
      "LV_MAE_mean: 141.6609\n",
      "LV_RMSE_mean: 182.8048\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 178.9137\n",
      "RMSE_12h: 259.7618\n",
      "MAE_24h: 79.8568\n",
      "RMSE_24h: 124.3362\n",
      "MAE_48h: 86.1305\n",
      "RMSE_48h: 135.0996\n",
      "MAE_72h: 95.0404\n",
      "RMSE_72h: 146.9619\n",
      "MAE_mean: 109.9853\n",
      "RMSE_mean: 166.5399\n",
      "\n",
      "=== Station S3031082 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1377 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1354, 24, 400) Ytr2: (1354, 4) \n",
      "  Xva3: (197, 24, 400) Yva2: (197, 4) \n",
      "  Xte3: (348, 24, 400) Yte2: (348, 4)\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 3s 56ms/step - loss: 155.7960 - mae: 155.7833 - val_loss: 137.4878 - val_mae: 137.4751 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 150.4843 - mae: 150.4716 - val_loss: 130.4949 - val_mae: 130.4819 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 143.2867 - mae: 143.2735 - val_loss: 123.0507 - val_mae: 123.0372 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 136.0510 - mae: 136.0371 - val_loss: 115.5983 - val_mae: 115.5839 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 128.9502 - mae: 128.9354 - val_loss: 108.0063 - val_mae: 107.9909 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 122.2972 - mae: 122.2812 - val_loss: 101.3248 - val_mae: 101.3081 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 115.9079 - mae: 115.8906 - val_loss: 94.7979 - val_mae: 94.7798 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 109.9502 - mae: 109.9314 - val_loss: 88.3229 - val_mae: 88.3033 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 102.9956 - mae: 102.9754 - val_loss: 81.6451 - val_mae: 81.6240 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 94.8321 - mae: 94.8103 - val_loss: 73.6728 - val_mae: 73.6499 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 84.0651 - mae: 84.0414 - val_loss: 65.1679 - val_mae: 65.1429 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 74.1978 - mae: 74.1717 - val_loss: 62.0575 - val_mae: 62.0301 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 67.7685 - mae: 67.7401 - val_loss: 61.8739 - val_mae: 61.8444 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 64.3427 - mae: 64.3125 - val_loss: 60.4658 - val_mae: 60.4348 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 61.5491 - mae: 61.5176 - val_loss: 57.6633 - val_mae: 57.6312 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 59.7463 - mae: 59.7138 - val_loss: 56.9413 - val_mae: 56.9081 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 57.7544 - mae: 57.7207 - val_loss: 55.9762 - val_mae: 55.9418 - lr: 0.0010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/20\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 56.5691 - mae: 56.5343 - val_loss: 53.0228 - val_mae: 52.9873 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 54.4972 - mae: 54.4612 - val_loss: 51.2221 - val_mae: 51.1856 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 52.3471 - mae: 52.3100 - val_loss: 49.9393 - val_mae: 49.9015 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 263.5690\n",
      "LV_RMSE_12h: 308.9085\n",
      "LV_MAE_24h: 54.3333\n",
      "LV_RMSE_24h: 86.4410\n",
      "LV_MAE_48h: 71.7615\n",
      "LV_RMSE_48h: 108.7494\n",
      "LV_MAE_72h: 71.1121\n",
      "LV_RMSE_72h: 110.9599\n",
      "LV_MAE_mean: 115.1940\n",
      "LV_RMSE_mean: 153.7647\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 121.5575\n",
      "RMSE_12h: 183.7468\n",
      "MAE_24h: 63.8897\n",
      "RMSE_24h: 101.1473\n",
      "MAE_48h: 69.1883\n",
      "RMSE_48h: 111.7305\n",
      "MAE_72h: 75.6775\n",
      "RMSE_72h: 122.2661\n",
      "MAE_mean: 82.5782\n",
      "RMSE_mean: 129.7227\n",
      "\n",
      "=== Station S3032051 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1377 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1354, 24, 400) Ytr2: (1354, 4) \n",
      "  Xva3: (197, 24, 400) Yva2: (197, 4) \n",
      "  Xte3: (348, 24, 400) Yte2: (348, 4)\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 3s 60ms/step - loss: 1718.7188 - mae: 1718.7061 - val_loss: 1659.2928 - val_mae: 1659.2800 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1712.9650 - mae: 1712.9520 - val_loss: 1650.8521 - val_mae: 1650.8391 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1702.6343 - mae: 1702.6211 - val_loss: 1638.4841 - val_mae: 1638.4708 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 1688.8649 - mae: 1688.8510 - val_loss: 1622.4633 - val_mae: 1622.4490 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1670.9192 - mae: 1670.9042 - val_loss: 1602.2125 - val_mae: 1602.1970 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1648.8379 - mae: 1648.8218 - val_loss: 1577.4430 - val_mae: 1577.4258 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 1621.7018 - mae: 1621.6837 - val_loss: 1547.7435 - val_mae: 1547.7241 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1589.7870 - mae: 1589.7665 - val_loss: 1512.6847 - val_mae: 1512.6627 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1552.8422 - mae: 1552.8192 - val_loss: 1472.4209 - val_mae: 1472.3958 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 1509.2850 - mae: 1509.2584 - val_loss: 1426.8044 - val_mae: 1426.7759 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 1461.8904 - mae: 1461.8600 - val_loss: 1375.7994 - val_mae: 1375.7668 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1409.8535 - mae: 1409.8190 - val_loss: 1320.6405 - val_mae: 1320.6034 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 1354.2966 - mae: 1354.2574 - val_loss: 1264.8971 - val_mae: 1264.8550 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 1299.0510 - mae: 1299.0066 - val_loss: 1211.0542 - val_mae: 1211.0070 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1245.8623 - mae: 1245.8127 - val_loss: 1161.7601 - val_mae: 1161.7076 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1199.2957 - mae: 1199.2407 - val_loss: 1117.5127 - val_mae: 1117.4547 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1154.4635 - mae: 1154.4032 - val_loss: 1075.5959 - val_mae: 1075.5325 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1110.8877 - mae: 1110.8219 - val_loss: 1036.6661 - val_mae: 1036.5970 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1074.3541 - mae: 1074.2826 - val_loss: 1000.9293 - val_mae: 1000.8546 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1037.8226 - mae: 1037.7455 - val_loss: 968.0009 - val_mae: 967.9205 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 1389.8334\n",
      "LV_RMSE_12h: 1594.3824\n",
      "LV_MAE_24h: 304.3649\n",
      "LV_RMSE_24h: 412.0078\n",
      "LV_MAE_48h: 346.9684\n",
      "LV_RMSE_48h: 465.3468\n",
      "LV_MAE_72h: 331.4253\n",
      "LV_RMSE_72h: 458.1137\n",
      "LV_MAE_mean: 593.1479\n",
      "LV_RMSE_mean: 732.4627\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 973.4887\n",
      "RMSE_12h: 1184.3401\n",
      "MAE_24h: 977.8719\n",
      "RMSE_24h: 1179.1619\n",
      "MAE_48h: 972.3978\n",
      "RMSE_48h: 1173.9222\n",
      "MAE_72h: 943.7188\n",
      "RMSE_72h: 1133.7990\n",
      "MAE_mean: 966.8693\n",
      "RMSE_mean: 1167.8058\n",
      "\n",
      "=== Station S3032054 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1314 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1291, 24, 400) Ytr2: (1291, 4) \n",
      "  Xva3: (188, 24, 400) Yva2: (188, 4) \n",
      "  Xte3: (330, 24, 400) Yte2: (330, 4)\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 3s 58ms/step - loss: 14.3114 - mae: 14.2984 - val_loss: 12.1668 - val_mae: 12.1539 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 13.3755 - mae: 13.3625 - val_loss: 11.2413 - val_mae: 11.2283 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 12.9653 - mae: 12.9523 - val_loss: 10.8574 - val_mae: 10.8443 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 12.7025 - mae: 12.6894 - val_loss: 10.6007 - val_mae: 10.5876 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 12.4740 - mae: 12.4608 - val_loss: 10.3650 - val_mae: 10.3518 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 12.2602 - mae: 12.2469 - val_loss: 10.3589 - val_mae: 10.3455 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 12.1013 - mae: 12.0878 - val_loss: 10.3466 - val_mae: 10.3330 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 11.9206 - mae: 11.9069 - val_loss: 10.0333 - val_mae: 10.0195 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 11.8065 - mae: 11.7927 - val_loss: 10.0565 - val_mae: 10.0426 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 11.7034 - mae: 11.6894 - val_loss: 10.0911 - val_mae: 10.0769 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 11.4945 - mae: 11.4803 - val_loss: 9.7885 - val_mae: 9.7742 - lr: 5.0000e-04\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 11.4617 - mae: 11.4474 - val_loss: 9.8044 - val_mae: 9.7900 - lr: 5.0000e-04\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 11.3595 - mae: 11.3450 - val_loss: 9.6363 - val_mae: 9.6217 - lr: 5.0000e-04\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 11.2316 - mae: 11.2170 - val_loss: 9.4570 - val_mae: 9.4423 - lr: 5.0000e-04\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 11.1000 - mae: 11.0852 - val_loss: 9.7018 - val_mae: 9.6869 - lr: 5.0000e-04\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 11.0225 - mae: 11.0075 - val_loss: 9.3873 - val_mae: 9.3722 - lr: 5.0000e-04\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 10.9273 - mae: 10.9121 - val_loss: 9.2080 - val_mae: 9.1927 - lr: 5.0000e-04\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 10.9024 - mae: 10.8870 - val_loss: 9.2150 - val_mae: 9.1995 - lr: 5.0000e-04\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 10.7315 - mae: 10.7159 - val_loss: 9.2494 - val_mae: 9.2338 - lr: 5.0000e-04\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 10.6187 - mae: 10.6030 - val_loss: 9.0226 - val_mae: 9.0068 - lr: 2.5000e-04\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 27.5788\n",
      "LV_RMSE_12h: 67.5925\n",
      "LV_MAE_24h: 15.7909\n",
      "LV_RMSE_24h: 51.5317\n",
      "LV_MAE_48h: 20.2394\n",
      "LV_RMSE_48h: 59.3646\n",
      "LV_MAE_72h: 16.8121\n",
      "LV_RMSE_72h: 50.0667\n",
      "LV_MAE_mean: 20.1053\n",
      "LV_RMSE_mean: 57.1389\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 11.2532\n",
      "RMSE_12h: 40.6492\n",
      "MAE_24h: 11.4450\n",
      "RMSE_24h: 39.4050\n",
      "MAE_48h: 11.9029\n",
      "RMSE_48h: 40.1009\n",
      "MAE_72h: 12.0745\n",
      "RMSE_72h: 41.2116\n",
      "MAE_mean: 11.6689\n",
      "RMSE_mean: 40.3417\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Station S3032071 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1376 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1353, 24, 400) Ytr2: (1353, 4) \n",
      "  Xva3: (197, 24, 400) Yva2: (197, 4) \n",
      "  Xte3: (348, 24, 400) Yte2: (348, 4)\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 3s 59ms/step - loss: 302.3063 - mae: 302.2937 - val_loss: 310.0180 - val_mae: 310.0054 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 296.7043 - mae: 296.6917 - val_loss: 302.1207 - val_mae: 302.1079 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 287.6208 - mae: 287.6078 - val_loss: 292.3280 - val_mae: 292.3148 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 277.3469 - mae: 277.3333 - val_loss: 282.1520 - val_mae: 282.1381 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 267.3449 - mae: 267.3305 - val_loss: 272.0186 - val_mae: 272.0035 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 257.1091 - mae: 257.0936 - val_loss: 262.3272 - val_mae: 262.3109 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 247.5760 - mae: 247.5591 - val_loss: 252.5156 - val_mae: 252.4980 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 237.9902 - mae: 237.9719 - val_loss: 243.0413 - val_mae: 243.0220 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 229.0153 - mae: 228.9953 - val_loss: 233.6643 - val_mae: 233.6433 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 219.5176 - mae: 219.4958 - val_loss: 224.5580 - val_mae: 224.5351 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 210.6948 - mae: 210.6710 - val_loss: 214.5978 - val_mae: 214.5728 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 199.5903 - mae: 199.5643 - val_loss: 200.5581 - val_mae: 200.5309 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 184.5945 - mae: 184.5662 - val_loss: 186.5453 - val_mae: 186.5156 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 171.1449 - mae: 171.1140 - val_loss: 172.5475 - val_mae: 172.5151 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 157.2838 - mae: 157.2501 - val_loss: 159.1983 - val_mae: 159.1630 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 143.9990 - mae: 143.9623 - val_loss: 145.3011 - val_mae: 145.2626 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 131.8507 - mae: 131.8108 - val_loss: 132.5922 - val_mae: 132.5504 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 123.0264 - mae: 122.9833 - val_loss: 124.8281 - val_mae: 124.7834 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 116.3390 - mae: 116.2932 - val_loss: 119.0440 - val_mae: 118.9969 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 111.8348 - mae: 111.7870 - val_loss: 116.4965 - val_mae: 116.4477 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 359.9195\n",
      "LV_RMSE_12h: 400.6216\n",
      "LV_MAE_24h: 62.1954\n",
      "LV_RMSE_24h: 95.2885\n",
      "LV_MAE_48h: 82.3333\n",
      "LV_RMSE_48h: 116.8643\n",
      "LV_MAE_72h: 69.4971\n",
      "LV_RMSE_72h: 105.7524\n",
      "LV_MAE_mean: 143.4863\n",
      "LV_RMSE_mean: 179.6317\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 251.4330\n",
      "RMSE_12h: 299.9190\n",
      "MAE_24h: 60.0280\n",
      "RMSE_24h: 88.8342\n",
      "MAE_48h: 57.9369\n",
      "RMSE_48h: 88.4015\n",
      "MAE_72h: 60.2306\n",
      "RMSE_72h: 88.6711\n",
      "MAE_mean: 107.4071\n",
      "RMSE_mean: 141.4564\n",
      "\n",
      "=== Station S3032111 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1377 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1354, 24, 400) Ytr2: (1354, 4) \n",
      "  Xva3: (197, 24, 400) Yva2: (197, 4) \n",
      "  Xte3: (348, 24, 400) Yte2: (348, 4)\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 3s 58ms/step - loss: 1875.9990 - mae: 1875.9863 - val_loss: 1851.8536 - val_mae: 1851.8409 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1869.3870 - mae: 1869.3744 - val_loss: 1842.0706 - val_mae: 1842.0577 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1857.4529 - mae: 1857.4396 - val_loss: 1828.0006 - val_mae: 1827.9872 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 1842.0339 - mae: 1842.0198 - val_loss: 1810.4332 - val_mae: 1810.4186 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1822.2430 - mae: 1822.2277 - val_loss: 1788.7819 - val_mae: 1788.7659 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1798.9391 - mae: 1798.9225 - val_loss: 1764.1663 - val_mae: 1764.1483 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 1771.1073 - mae: 1771.0883 - val_loss: 1736.1636 - val_mae: 1736.1432 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1740.2362 - mae: 1740.2147 - val_loss: 1704.8405 - val_mae: 1704.8174 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1707.2284 - mae: 1707.2043 - val_loss: 1671.3613 - val_mae: 1671.3351 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1670.2942 - mae: 1670.2662 - val_loss: 1636.2437 - val_mae: 1636.2140 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1633.4215 - mae: 1633.3900 - val_loss: 1599.6415 - val_mae: 1599.6075 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1592.8700 - mae: 1592.8344 - val_loss: 1561.3663 - val_mae: 1561.3282 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1553.9564 - mae: 1553.9164 - val_loss: 1521.9835 - val_mae: 1521.9407 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1511.9446 - mae: 1511.8995 - val_loss: 1482.1140 - val_mae: 1482.0662 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1469.2717 - mae: 1469.2216 - val_loss: 1441.7479 - val_mae: 1441.6948 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1429.3661 - mae: 1429.3104 - val_loss: 1400.7299 - val_mae: 1400.6710 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1385.8107 - mae: 1385.7490 - val_loss: 1358.0674 - val_mae: 1358.0023 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1338.1096 - mae: 1338.0419 - val_loss: 1313.6593 - val_mae: 1313.5879 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1297.4709 - mae: 1297.3964 - val_loss: 1267.9194 - val_mae: 1267.8412 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1252.8490 - mae: 1252.7676 - val_loss: 1222.1293 - val_mae: 1222.0441 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 1807.0201\n",
      "LV_RMSE_12h: 2005.7524\n",
      "LV_MAE_24h: 300.9081\n",
      "LV_RMSE_24h: 482.3931\n",
      "LV_MAE_48h: 395.7874\n",
      "LV_RMSE_48h: 606.7276\n",
      "LV_MAE_72h: 327.7672\n",
      "LV_RMSE_72h: 509.5473\n",
      "LV_MAE_mean: 707.8707\n",
      "LV_RMSE_mean: 901.1051\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 1191.3308\n",
      "RMSE_12h: 1383.3229\n",
      "MAE_24h: 1222.5165\n",
      "RMSE_24h: 1425.6991\n",
      "MAE_48h: 1217.1172\n",
      "RMSE_48h: 1421.7606\n",
      "MAE_72h: 1203.1698\n",
      "RMSE_72h: 1401.1210\n",
      "MAE_mean: 1208.5336\n",
      "RMSE_mean: 1407.9760\n",
      "\n",
      "=== Station S3033021 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1376 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1353, 24, 400) Ytr2: (1353, 4) \n",
      "  Xva3: (197, 24, 400) Yva2: (197, 4) \n",
      "  Xte3: (347, 24, 400) Yte2: (347, 4)\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 3s 61ms/step - loss: 1.7604 - mae: 1.7478 - val_loss: 1.7082 - val_mae: 1.6956 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1.6198 - mae: 1.6071 - val_loss: 1.6841 - val_mae: 1.6715 - lr: 0.0010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1.5784 - mae: 1.5659 - val_loss: 1.6387 - val_mae: 1.6262 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1.5352 - mae: 1.5227 - val_loss: 1.6072 - val_mae: 1.5948 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1.4975 - mae: 1.4851 - val_loss: 1.5919 - val_mae: 1.5795 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1.4801 - mae: 1.4677 - val_loss: 1.5960 - val_mae: 1.5837 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1.4441 - mae: 1.4318 - val_loss: 1.5801 - val_mae: 1.5678 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 1.4149 - mae: 1.4026 - val_loss: 1.5900 - val_mae: 1.5777 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1.3970 - mae: 1.3846 - val_loss: 1.5887 - val_mae: 1.5764 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1.3631 - mae: 1.3508 - val_loss: 1.4573 - val_mae: 1.4450 - lr: 5.0000e-04\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1.3362 - mae: 1.3238 - val_loss: 1.4729 - val_mae: 1.4606 - lr: 5.0000e-04\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1.3137 - mae: 1.3014 - val_loss: 1.4544 - val_mae: 1.4420 - lr: 5.0000e-04\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 1.2920 - mae: 1.2796 - val_loss: 1.4332 - val_mae: 1.4209 - lr: 5.0000e-04\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1.2752 - mae: 1.2628 - val_loss: 1.4117 - val_mae: 1.3993 - lr: 5.0000e-04\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1.2665 - mae: 1.2541 - val_loss: 1.4488 - val_mae: 1.4364 - lr: 5.0000e-04\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1.2427 - mae: 1.2302 - val_loss: 1.3818 - val_mae: 1.3693 - lr: 5.0000e-04\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1.2292 - mae: 1.2167 - val_loss: 1.3735 - val_mae: 1.3610 - lr: 5.0000e-04\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1.2158 - mae: 1.2033 - val_loss: 1.3940 - val_mae: 1.3815 - lr: 5.0000e-04\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1.2185 - mae: 1.2060 - val_loss: 1.3971 - val_mae: 1.3846 - lr: 5.0000e-04\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1.1882 - mae: 1.1757 - val_loss: 1.3490 - val_mae: 1.3365 - lr: 2.5000e-04\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 2.5879\n",
      "LV_RMSE_12h: 5.5644\n",
      "LV_MAE_24h: 1.5648\n",
      "LV_RMSE_24h: 3.9982\n",
      "LV_MAE_48h: 1.7579\n",
      "LV_RMSE_48h: 4.5412\n",
      "LV_MAE_72h: 1.7464\n",
      "LV_RMSE_72h: 4.8326\n",
      "LV_MAE_mean: 1.9143\n",
      "LV_RMSE_mean: 4.7341\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 1.1278\n",
      "RMSE_12h: 3.0235\n",
      "MAE_24h: 1.2609\n",
      "RMSE_24h: 3.1690\n",
      "MAE_48h: 1.3444\n",
      "RMSE_48h: 3.3116\n",
      "MAE_72h: 1.4088\n",
      "RMSE_72h: 3.4567\n",
      "MAE_mean: 1.2855\n",
      "RMSE_mean: 3.2402\n",
      "\n",
      "=== Station S3033061 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1377 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1354, 24, 400) Ytr2: (1354, 4) \n",
      "  Xva3: (197, 24, 400) Yva2: (197, 4) \n",
      "  Xte3: (348, 24, 400) Yte2: (348, 4)\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 3s 60ms/step - loss: 1477.1804 - mae: 1477.1675 - val_loss: 1485.0942 - val_mae: 1485.0815 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1472.7301 - mae: 1472.7172 - val_loss: 1478.8829 - val_mae: 1478.8698 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1465.5358 - mae: 1465.5226 - val_loss: 1469.8914 - val_mae: 1469.8778 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1456.1951 - mae: 1456.1809 - val_loss: 1458.6038 - val_mae: 1458.5895 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1444.7030 - mae: 1444.6881 - val_loss: 1445.0968 - val_mae: 1445.0812 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1431.4016 - mae: 1431.3854 - val_loss: 1429.7827 - val_mae: 1429.7654 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1416.0867 - mae: 1416.0687 - val_loss: 1412.5021 - val_mae: 1412.4829 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1398.1438 - mae: 1398.1235 - val_loss: 1392.6543 - val_mae: 1392.6326 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1378.2527 - mae: 1378.2297 - val_loss: 1369.9043 - val_mae: 1369.8798 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1355.5282 - mae: 1355.5023 - val_loss: 1343.5947 - val_mae: 1343.5669 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1329.1034 - mae: 1329.0740 - val_loss: 1312.9149 - val_mae: 1312.8833 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1298.0109 - mae: 1297.9774 - val_loss: 1279.8108 - val_mae: 1279.7748 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1265.2356 - mae: 1265.1975 - val_loss: 1244.3643 - val_mae: 1244.3232 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1230.6510 - mae: 1230.6078 - val_loss: 1205.8363 - val_mae: 1205.7900 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1193.3219 - mae: 1193.2729 - val_loss: 1166.3458 - val_mae: 1166.2936 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1154.0045 - mae: 1153.9496 - val_loss: 1125.1260 - val_mae: 1125.0675 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1113.4301 - mae: 1113.3685 - val_loss: 1082.0488 - val_mae: 1081.9834 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1069.5270 - mae: 1069.4585 - val_loss: 1037.6642 - val_mae: 1037.5916 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1029.3104 - mae: 1029.2343 - val_loss: 991.9567 - val_mae: 991.8762 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 985.8885 - mae: 985.8046 - val_loss: 946.2213 - val_mae: 946.1328 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 1691.1552\n",
      "LV_RMSE_12h: 1849.2942\n",
      "LV_MAE_24h: 279.1925\n",
      "LV_RMSE_24h: 481.2291\n",
      "LV_MAE_48h: 386.6092\n",
      "LV_RMSE_48h: 634.4596\n",
      "LV_MAE_72h: 315.8190\n",
      "LV_RMSE_72h: 547.4445\n",
      "LV_MAE_mean: 668.1940\n",
      "LV_RMSE_mean: 878.1068\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 1177.4082\n",
      "RMSE_12h: 1395.3325\n",
      "MAE_24h: 784.1805\n",
      "RMSE_24h: 1022.1810\n",
      "MAE_48h: 762.2195\n",
      "RMSE_48h: 997.3974\n",
      "MAE_72h: 756.6196\n",
      "RMSE_72h: 985.9917\n",
      "MAE_mean: 870.1069\n",
      "RMSE_mean: 1100.2256\n",
      "\n",
      "=== Station S3033062 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1377 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1354, 24, 400) Ytr2: (1354, 4) \n",
      "  Xva3: (197, 24, 400) Yva2: (197, 4) \n",
      "  Xte3: (348, 24, 400) Yte2: (348, 4)\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 3s 57ms/step - loss: 429.5856 - mae: 429.5728 - val_loss: 423.5726 - val_mae: 423.5597 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 425.7512 - mae: 425.7382 - val_loss: 418.0375 - val_mae: 418.0243 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 419.4470 - mae: 419.4336 - val_loss: 410.5690 - val_mae: 410.5553 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 411.7061 - mae: 411.6919 - val_loss: 401.2063 - val_mae: 401.1916 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 401.7642 - mae: 401.7489 - val_loss: 389.9498 - val_mae: 389.9337 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 389.9760 - mae: 389.9592 - val_loss: 376.8612 - val_mae: 376.8433 - lr: 0.0010\n",
      "Epoch 7/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 12ms/step - loss: 376.3663 - mae: 376.3474 - val_loss: 361.9018 - val_mae: 361.8817 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 361.0492 - mae: 361.0280 - val_loss: 344.5365 - val_mae: 344.5137 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 343.9209 - mae: 343.8967 - val_loss: 325.7430 - val_mae: 325.7171 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 324.6599 - mae: 324.6324 - val_loss: 305.6998 - val_mae: 305.6702 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 306.1201 - mae: 306.0888 - val_loss: 285.4263 - val_mae: 285.3927 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 286.2757 - mae: 286.2402 - val_loss: 264.3263 - val_mae: 264.2884 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 0s 17ms/step - loss: 268.0750 - mae: 268.0352 - val_loss: 245.4375 - val_mae: 245.3951 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 0s 20ms/step - loss: 250.2690 - mae: 250.2245 - val_loss: 226.7108 - val_mae: 226.6637 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 231.4771 - mae: 231.4278 - val_loss: 208.5791 - val_mae: 208.5270 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 215.8224 - mae: 215.7682 - val_loss: 192.8858 - val_mae: 192.8289 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 201.5147 - mae: 201.4557 - val_loss: 179.3132 - val_mae: 179.2516 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 188.5477 - mae: 188.4841 - val_loss: 168.0334 - val_mae: 167.9673 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 181.0853 - mae: 181.0174 - val_loss: 160.7854 - val_mae: 160.7153 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 173.7352 - mae: 173.6637 - val_loss: 154.7896 - val_mae: 154.7163 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 615.4368\n",
      "LV_RMSE_12h: 678.0851\n",
      "LV_MAE_24h: 99.1408\n",
      "LV_RMSE_24h: 151.2529\n",
      "LV_MAE_48h: 122.5920\n",
      "LV_RMSE_48h: 181.9467\n",
      "LV_MAE_72h: 117.1178\n",
      "LV_RMSE_72h: 175.3033\n",
      "LV_MAE_mean: 238.5718\n",
      "LV_RMSE_mean: 296.6470\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 341.8947\n",
      "RMSE_12h: 401.2997\n",
      "MAE_24h: 122.4095\n",
      "RMSE_24h: 175.0038\n",
      "MAE_48h: 113.9809\n",
      "RMSE_48h: 165.4890\n",
      "MAE_72h: 110.6284\n",
      "RMSE_72h: 159.1000\n",
      "MAE_mean: 172.2284\n",
      "RMSE_mean: 225.2231\n",
      "\n",
      "=== Station S3033075 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 856 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (833, 24, 400) Ytr2: (833, 4) \n",
      "  Xva3: (123, 24, 400) Yva2: (123, 4) \n",
      "  Xte3: (199, 24, 400) Yte2: (199, 4)\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 3s 99ms/step - loss: 0.8064 - mae: 0.7936 - val_loss: 0.7268 - val_mae: 0.7140 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.7135 - mae: 0.7007 - val_loss: 0.7435 - val_mae: 0.7309 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.6913 - mae: 0.6786 - val_loss: 0.7283 - val_mae: 0.7157 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.6818 - mae: 0.6693 - val_loss: 0.7206 - val_mae: 0.7081 - lr: 5.0000e-04\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.6641 - mae: 0.6517 - val_loss: 0.7360 - val_mae: 0.7236 - lr: 5.0000e-04\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.6671 - mae: 0.6547 - val_loss: 0.7229 - val_mae: 0.7106 - lr: 5.0000e-04\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.6681 - mae: 0.6558 - val_loss: 0.7216 - val_mae: 0.7092 - lr: 2.5000e-04\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.6638 - mae: 0.6515 - val_loss: 0.7255 - val_mae: 0.7132 - lr: 2.5000e-04\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.6629 - mae: 0.6506 - val_loss: 0.7206 - val_mae: 0.7083 - lr: 1.2500e-04\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.6635 - mae: 0.6512 - val_loss: 0.7207 - val_mae: 0.7084 - lr: 1.2500e-04\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.6589 - mae: 0.6466 - val_loss: 0.7213 - val_mae: 0.7090 - lr: 6.2500e-05\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.6571 - mae: 0.6448 - val_loss: 0.7208 - val_mae: 0.7085 - lr: 6.2500e-05\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.6572 - mae: 0.6449 - val_loss: 0.7210 - val_mae: 0.7088 - lr: 3.1250e-05\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.6557 - mae: 0.6434 - val_loss: 0.7208 - val_mae: 0.7086 - lr: 3.1250e-05\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 1.7839\n",
      "LV_RMSE_12h: 2.6628\n",
      "LV_MAE_24h: 0.9648\n",
      "LV_RMSE_24h: 1.8349\n",
      "LV_MAE_48h: 1.0854\n",
      "LV_RMSE_48h: 1.9975\n",
      "LV_MAE_72h: 0.9749\n",
      "LV_RMSE_72h: 1.8129\n",
      "LV_MAE_mean: 1.2023\n",
      "LV_RMSE_mean: 2.0770\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 0.8157\n",
      "RMSE_12h: 1.5046\n",
      "MAE_24h: 0.7846\n",
      "RMSE_24h: 1.4565\n",
      "MAE_48h: 0.7465\n",
      "RMSE_48h: 1.3953\n",
      "MAE_72h: 0.6821\n",
      "RMSE_72h: 1.3063\n",
      "MAE_mean: 0.7573\n",
      "RMSE_mean: 1.4157\n",
      "\n",
      "=== Station S3033081 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1162 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1139, 24, 400) Ytr2: (1139, 4) \n",
      "  Xva3: (167, 24, 400) Yva2: (167, 4) \n",
      "  Xte3: (286, 24, 400) Yte2: (286, 4)\n",
      "Epoch 1/20\n",
      "9/9 [==============================] - 3s 70ms/step - loss: 5.1797 - mae: 5.1670 - val_loss: 3.1415 - val_mae: 3.1288 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 3.7599 - mae: 3.7471 - val_loss: 2.5125 - val_mae: 2.4997 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 3.2387 - mae: 3.2259 - val_loss: 2.6244 - val_mae: 2.6116 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 3.0965 - mae: 3.0837 - val_loss: 2.4884 - val_mae: 2.4756 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 3.0479 - mae: 3.0352 - val_loss: 2.4232 - val_mae: 2.4105 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 2.9664 - mae: 2.9538 - val_loss: 2.5207 - val_mae: 2.5081 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 2.9165 - mae: 2.9038 - val_loss: 2.5379 - val_mae: 2.5253 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 2.8451 - mae: 2.8325 - val_loss: 2.4999 - val_mae: 2.4873 - lr: 5.0000e-04\n",
      "Epoch 9/20\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 2.7762 - mae: 2.7636 - val_loss: 2.4646 - val_mae: 2.4519 - lr: 5.0000e-04\n",
      "Epoch 10/20\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 2.7431 - mae: 2.7305 - val_loss: 2.4910 - val_mae: 2.4784 - lr: 2.5000e-04\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 7.1608\n",
      "LV_RMSE_12h: 8.8827\n",
      "LV_MAE_24h: 3.2168\n",
      "LV_RMSE_24h: 4.8009\n",
      "LV_MAE_48h: 3.4615\n",
      "LV_RMSE_48h: 5.3526\n",
      "LV_MAE_72h: 3.6643\n",
      "LV_RMSE_72h: 5.5797\n",
      "LV_MAE_mean: 4.3759\n",
      "LV_RMSE_mean: 6.1540\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 2.7240\n",
      "RMSE_12h: 3.9900\n",
      "MAE_24h: 2.6748\n",
      "RMSE_24h: 3.9047\n",
      "MAE_48h: 2.6748\n",
      "RMSE_48h: 3.9886\n",
      "MAE_72h: 2.6545\n",
      "RMSE_72h: 4.0144\n",
      "MAE_mean: 2.6820\n",
      "RMSE_mean: 3.9744\n",
      "\n",
      "=== Station S3034034 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1376 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1353, 24, 400) Ytr2: (1353, 4) \n",
      "  Xva3: (197, 24, 400) Yva2: (197, 4) \n",
      "  Xte3: (347, 24, 400) Yte2: (347, 4)\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 3s 58ms/step - loss: 151.1367 - mae: 151.1240 - val_loss: 140.5673 - val_mae: 140.5546 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 145.0415 - mae: 145.0288 - val_loss: 132.4288 - val_mae: 132.4159 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 135.9458 - mae: 135.9327 - val_loss: 123.4599 - val_mae: 123.4464 - lr: 0.0010\n",
      "Epoch 4/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 13ms/step - loss: 126.7582 - mae: 126.7445 - val_loss: 115.4004 - val_mae: 115.3862 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 118.6837 - mae: 118.6691 - val_loss: 108.3301 - val_mae: 108.3149 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 111.4294 - mae: 111.4137 - val_loss: 102.7932 - val_mae: 102.7769 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 104.9930 - mae: 104.9761 - val_loss: 97.1150 - val_mae: 97.0975 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 98.4229 - mae: 98.4048 - val_loss: 89.9053 - val_mae: 89.8865 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 90.4346 - mae: 90.4153 - val_loss: 80.8133 - val_mae: 80.7932 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 81.4851 - mae: 81.4643 - val_loss: 73.6570 - val_mae: 73.6354 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 74.5825 - mae: 74.5601 - val_loss: 69.3352 - val_mae: 69.3118 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 70.4060 - mae: 70.3820 - val_loss: 66.7191 - val_mae: 66.6944 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 68.2572 - mae: 68.2321 - val_loss: 65.1830 - val_mae: 65.1574 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 66.0993 - mae: 66.0733 - val_loss: 63.1321 - val_mae: 63.1058 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 64.6486 - mae: 64.6221 - val_loss: 60.4988 - val_mae: 60.4719 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 63.0484 - mae: 63.0211 - val_loss: 58.8495 - val_mae: 58.8217 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 61.1827 - mae: 61.1545 - val_loss: 56.7814 - val_mae: 56.7526 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 59.6221 - mae: 59.5927 - val_loss: 54.5007 - val_mae: 54.4707 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 57.7010 - mae: 57.6704 - val_loss: 52.8176 - val_mae: 52.7864 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 54.6795 - mae: 54.6476 - val_loss: 50.8834 - val_mae: 50.8507 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 133.9453\n",
      "LV_RMSE_12h: 147.7441\n",
      "LV_MAE_24h: 33.1499\n",
      "LV_RMSE_24h: 53.9323\n",
      "LV_MAE_48h: 44.8184\n",
      "LV_RMSE_48h: 70.9518\n",
      "LV_MAE_72h: 36.2133\n",
      "LV_RMSE_72h: 61.2429\n",
      "LV_MAE_mean: 62.0317\n",
      "LV_RMSE_mean: 83.4678\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 54.2871\n",
      "RMSE_12h: 69.9544\n",
      "MAE_24h: 46.6837\n",
      "RMSE_24h: 67.8043\n",
      "MAE_48h: 42.7324\n",
      "RMSE_48h: 63.3397\n",
      "MAE_72h: 40.1432\n",
      "RMSE_72h: 57.8449\n",
      "MAE_mean: 45.9616\n",
      "RMSE_mean: 64.7358\n",
      "\n",
      "=== Station S3034035 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1375 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1352, 24, 400) Ytr2: (1352, 4) \n",
      "  Xva3: (197, 24, 400) Yva2: (197, 4) \n",
      "  Xte3: (347, 24, 400) Yte2: (347, 4)\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 3s 58ms/step - loss: 305.1811 - mae: 305.1685 - val_loss: 298.5219 - val_mae: 298.5094 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 298.4347 - mae: 298.4221 - val_loss: 289.0170 - val_mae: 289.0042 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 287.2029 - mae: 287.1899 - val_loss: 275.9612 - val_mae: 275.9479 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 272.8755 - mae: 272.8617 - val_loss: 260.3159 - val_mae: 260.3016 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 256.6753 - mae: 256.6604 - val_loss: 244.1507 - val_mae: 244.1351 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 239.7574 - mae: 239.7411 - val_loss: 227.6158 - val_mae: 227.5987 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 223.1934 - mae: 223.1755 - val_loss: 211.4496 - val_mae: 211.4305 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 207.1173 - mae: 207.0973 - val_loss: 197.2255 - val_mae: 197.2044 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 193.4742 - mae: 193.4522 - val_loss: 185.2871 - val_mae: 185.2638 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 181.5415 - mae: 181.5173 - val_loss: 176.4582 - val_mae: 176.4328 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 173.8583 - mae: 173.8321 - val_loss: 170.4184 - val_mae: 170.3910 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 167.6105 - mae: 167.5824 - val_loss: 164.2739 - val_mae: 164.2448 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 159.9057 - mae: 159.8759 - val_loss: 154.1054 - val_mae: 154.0747 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 150.1552 - mae: 150.1238 - val_loss: 142.9352 - val_mae: 142.9029 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 139.6639 - mae: 139.6307 - val_loss: 131.8217 - val_mae: 131.7875 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 129.2628 - mae: 129.2276 - val_loss: 122.0383 - val_mae: 122.0020 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 121.0509 - mae: 121.0137 - val_loss: 114.2861 - val_mae: 114.2477 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 116.0149 - mae: 115.9758 - val_loss: 109.6481 - val_mae: 109.6082 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 112.1666 - mae: 112.1262 - val_loss: 106.6691 - val_mae: 106.6281 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 110.0022 - mae: 109.9608 - val_loss: 104.0135 - val_mae: 103.9716 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 237.3084\n",
      "LV_RMSE_12h: 268.4743\n",
      "LV_MAE_24h: 60.6916\n",
      "LV_RMSE_24h: 88.5650\n",
      "LV_MAE_48h: 71.7983\n",
      "LV_RMSE_48h: 102.7983\n",
      "LV_MAE_72h: 66.7435\n",
      "LV_RMSE_72h: 95.8459\n",
      "LV_MAE_mean: 109.1355\n",
      "LV_RMSE_mean: 138.9209\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 187.9758\n",
      "RMSE_12h: 219.5911\n",
      "MAE_24h: 60.1081\n",
      "RMSE_24h: 88.4794\n",
      "MAE_48h: 59.3643\n",
      "RMSE_48h: 87.8988\n",
      "MAE_72h: 61.7831\n",
      "RMSE_72h: 89.7420\n",
      "MAE_mean: 92.3078\n",
      "RMSE_mean: 121.4278\n",
      "\n",
      "=== Station S3034036 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1375 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1352, 24, 400) Ytr2: (1352, 4) \n",
      "  Xva3: (197, 24, 400) Yva2: (197, 4) \n",
      "  Xte3: (347, 24, 400) Yte2: (347, 4)\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 3s 59ms/step - loss: 20.7744 - mae: 20.7616 - val_loss: 18.6968 - val_mae: 18.6840 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 16.8570 - mae: 16.8441 - val_loss: 14.8661 - val_mae: 14.8530 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 13.6895 - mae: 13.6762 - val_loss: 12.1582 - val_mae: 12.1448 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 11.3527 - mae: 11.3391 - val_loss: 9.8144 - val_mae: 9.8007 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 9.5109 - mae: 9.4970 - val_loss: 8.0624 - val_mae: 8.0484 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 8.4118 - mae: 8.3978 - val_loss: 7.0614 - val_mae: 7.0473 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 7.6402 - mae: 7.6260 - val_loss: 6.2127 - val_mae: 6.1984 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 6.9945 - mae: 6.9801 - val_loss: 5.5359 - val_mae: 5.5214 - lr: 0.0010\n",
      "Epoch 9/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 17ms/step - loss: 6.4718 - mae: 6.4572 - val_loss: 5.2899 - val_mae: 5.2752 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 6.3398 - mae: 6.3251 - val_loss: 4.8873 - val_mae: 4.8726 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 6.2419 - mae: 6.2271 - val_loss: 5.0097 - val_mae: 4.9950 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 6.1420 - mae: 6.1273 - val_loss: 4.9917 - val_mae: 4.9770 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 6.0014 - mae: 5.9868 - val_loss: 4.7849 - val_mae: 4.7703 - lr: 5.0000e-04\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 5.9589 - mae: 5.9442 - val_loss: 4.8384 - val_mae: 4.8238 - lr: 5.0000e-04\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 5.9906 - mae: 5.9760 - val_loss: 4.7829 - val_mae: 4.7684 - lr: 5.0000e-04\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 5.9255 - mae: 5.9110 - val_loss: 4.8260 - val_mae: 4.8115 - lr: 5.0000e-04\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 5.9324 - mae: 5.9179 - val_loss: 4.7854 - val_mae: 4.7709 - lr: 5.0000e-04\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 5.7628 - mae: 5.7483 - val_loss: 4.8225 - val_mae: 4.8080 - lr: 2.5000e-04\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 5.8456 - mae: 5.8312 - val_loss: 4.8537 - val_mae: 4.8392 - lr: 2.5000e-04\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 5.8911 - mae: 5.8767 - val_loss: 4.7876 - val_mae: 4.7732 - lr: 1.2500e-04\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 26.5245\n",
      "LV_RMSE_12h: 30.2214\n",
      "LV_MAE_24h: 7.4957\n",
      "LV_RMSE_24h: 11.0241\n",
      "LV_MAE_48h: 7.7839\n",
      "LV_RMSE_48h: 11.1131\n",
      "LV_MAE_72h: 7.6455\n",
      "LV_RMSE_72h: 10.9359\n",
      "LV_MAE_mean: 12.3624\n",
      "LV_RMSE_mean: 15.8236\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 5.7075\n",
      "RMSE_12h: 8.2056\n",
      "MAE_24h: 5.6949\n",
      "RMSE_24h: 8.1320\n",
      "MAE_48h: 5.7132\n",
      "RMSE_48h: 8.2238\n",
      "MAE_72h: 5.5470\n",
      "RMSE_72h: 8.0154\n",
      "MAE_mean: 5.6656\n",
      "RMSE_mean: 8.1442\n",
      "\n",
      "=== Station S3034101 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1377 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1354, 24, 400) Ytr2: (1354, 4) \n",
      "  Xva3: (197, 24, 400) Yva2: (197, 4) \n",
      "  Xte3: (348, 24, 400) Yte2: (348, 4)\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 3s 61ms/step - loss: 786.3498 - mae: 786.3370 - val_loss: 768.8774 - val_mae: 768.8647 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 779.9821 - mae: 779.9692 - val_loss: 759.2887 - val_mae: 759.2757 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 768.2264 - mae: 768.2133 - val_loss: 745.1358 - val_mae: 745.1221 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 752.4344 - mae: 752.4202 - val_loss: 726.8037 - val_mae: 726.7890 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 731.6561 - mae: 731.6409 - val_loss: 703.4725 - val_mae: 703.4564 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 0s 19ms/step - loss: 706.5337 - mae: 706.5167 - val_loss: 677.1128 - val_mae: 677.0945 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 678.8927 - mae: 678.8734 - val_loss: 649.5751 - val_mae: 649.5545 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 650.4855 - mae: 650.4637 - val_loss: 622.4153 - val_mae: 622.3920 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 623.0388 - mae: 623.0140 - val_loss: 595.8884 - val_mae: 595.8619 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 596.8484 - mae: 596.8206 - val_loss: 570.1553 - val_mae: 570.1256 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 571.0964 - mae: 571.0651 - val_loss: 545.7168 - val_mae: 545.6836 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 546.8378 - mae: 546.8029 - val_loss: 523.4238 - val_mae: 523.3867 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 524.4130 - mae: 524.3743 - val_loss: 503.8298 - val_mae: 503.7890 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 505.4471 - mae: 505.4046 - val_loss: 487.3774 - val_mae: 487.3328 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 487.8534 - mae: 487.8071 - val_loss: 473.5350 - val_mae: 473.4866 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 475.7848 - mae: 475.7349 - val_loss: 461.3002 - val_mae: 461.2483 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 457.3201 - mae: 457.2666 - val_loss: 437.4486 - val_mae: 437.3931 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 428.3358 - mae: 428.2787 - val_loss: 405.2315 - val_mae: 405.1721 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 0s 17ms/step - loss: 400.4766 - mae: 400.4153 - val_loss: 379.6295 - val_mae: 379.5656 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 374.0769 - mae: 374.0110 - val_loss: 357.5876 - val_mae: 357.5189 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 670.9943\n",
      "LV_RMSE_12h: 746.6007\n",
      "LV_MAE_24h: 197.8908\n",
      "LV_RMSE_24h: 303.4949\n",
      "LV_MAE_48h: 249.3937\n",
      "LV_RMSE_48h: 359.9385\n",
      "LV_MAE_72h: 183.2874\n",
      "LV_RMSE_72h: 280.0140\n",
      "LV_MAE_mean: 325.3915\n",
      "LV_RMSE_mean: 422.5120\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 489.7906\n",
      "RMSE_12h: 574.5008\n",
      "MAE_24h: 214.7379\n",
      "RMSE_24h: 304.9016\n",
      "MAE_48h: 217.2253\n",
      "RMSE_48h: 307.0820\n",
      "MAE_72h: 203.1651\n",
      "RMSE_72h: 278.3567\n",
      "MAE_mean: 281.2297\n",
      "RMSE_mean: 366.2103\n",
      "\n",
      "=== Station S3034102 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1316 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1293, 24, 400) Ytr2: (1293, 4) \n",
      "  Xva3: (189, 24, 400) Yva2: (189, 4) \n",
      "  Xte3: (330, 24, 400) Yte2: (330, 4)\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 3s 57ms/step - loss: 102.9733 - mae: 102.9606 - val_loss: 98.5120 - val_mae: 98.4992 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 97.4494 - mae: 97.4366 - val_loss: 90.7615 - val_mae: 90.7486 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 89.4409 - mae: 89.4278 - val_loss: 82.4242 - val_mae: 82.4108 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 81.4418 - mae: 81.4282 - val_loss: 74.9262 - val_mae: 74.9121 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 74.6112 - mae: 74.5967 - val_loss: 68.0734 - val_mae: 68.0583 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 68.5333 - mae: 68.5179 - val_loss: 62.4765 - val_mae: 62.4605 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 63.4664 - mae: 63.4500 - val_loss: 56.6281 - val_mae: 56.6110 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 58.5388 - mae: 58.5213 - val_loss: 50.6404 - val_mae: 50.6223 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 53.6610 - mae: 53.6426 - val_loss: 45.6815 - val_mae: 45.6625 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 50.1822 - mae: 50.1628 - val_loss: 40.8048 - val_mae: 40.7850 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 46.6956 - mae: 46.6756 - val_loss: 37.4060 - val_mae: 37.3856 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 44.5049 - mae: 44.4844 - val_loss: 35.2889 - val_mae: 35.2681 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 42.6397 - mae: 42.6187 - val_loss: 33.4016 - val_mae: 33.3803 - lr: 0.0010\n",
      "Epoch 14/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 13ms/step - loss: 41.0578 - mae: 41.0363 - val_loss: 32.5838 - val_mae: 32.5620 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 39.8473 - mae: 39.8254 - val_loss: 30.9913 - val_mae: 30.9691 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 38.5859 - mae: 38.5636 - val_loss: 29.8896 - val_mae: 29.8671 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 37.6684 - mae: 37.6457 - val_loss: 29.0719 - val_mae: 29.0488 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 36.7008 - mae: 36.6776 - val_loss: 27.9779 - val_mae: 27.9543 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 35.6693 - mae: 35.6455 - val_loss: 27.0599 - val_mae: 27.0358 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 34.2631 - mae: 34.2387 - val_loss: 25.7614 - val_mae: 25.7366 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 83.3242\n",
      "LV_RMSE_12h: 96.3500\n",
      "LV_MAE_24h: 19.3606\n",
      "LV_RMSE_24h: 30.3403\n",
      "LV_MAE_48h: 23.2000\n",
      "LV_RMSE_48h: 37.2241\n",
      "LV_MAE_72h: 23.2121\n",
      "LV_RMSE_72h: 36.6278\n",
      "LV_MAE_mean: 37.2742\n",
      "LV_RMSE_mean: 50.1356\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 40.3593\n",
      "RMSE_12h: 48.5695\n",
      "MAE_24h: 46.6065\n",
      "RMSE_24h: 57.5177\n",
      "MAE_48h: 45.9339\n",
      "RMSE_48h: 56.2481\n",
      "MAE_72h: 46.3966\n",
      "RMSE_72h: 56.1424\n",
      "MAE_mean: 44.8241\n",
      "RMSE_mean: 54.6194\n",
      "\n",
      "=== Station S3034103 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1316 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1293, 24, 400) Ytr2: (1293, 4) \n",
      "  Xva3: (189, 24, 400) Yva2: (189, 4) \n",
      "  Xte3: (330, 24, 400) Yte2: (330, 4)\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 3s 61ms/step - loss: 112.0365 - mae: 112.0237 - val_loss: 111.6896 - val_mae: 111.6767 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 106.3433 - mae: 106.3304 - val_loss: 104.0385 - val_mae: 104.0255 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 98.5017 - mae: 98.4884 - val_loss: 95.9281 - val_mae: 95.9146 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 90.7058 - mae: 90.6920 - val_loss: 88.3193 - val_mae: 88.3050 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 83.9438 - mae: 83.9292 - val_loss: 81.6751 - val_mae: 81.6599 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 78.1811 - mae: 78.1655 - val_loss: 76.3651 - val_mae: 76.3489 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 73.2109 - mae: 73.1942 - val_loss: 71.9745 - val_mae: 71.9572 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 69.5609 - mae: 69.5433 - val_loss: 67.5349 - val_mae: 67.5168 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 65.7003 - mae: 65.6818 - val_loss: 62.7831 - val_mae: 62.7641 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 61.8243 - mae: 61.8050 - val_loss: 58.3916 - val_mae: 58.3719 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 58.0161 - mae: 57.9961 - val_loss: 54.3739 - val_mae: 54.3535 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 54.8220 - mae: 54.8013 - val_loss: 49.9079 - val_mae: 49.8867 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 51.1861 - mae: 51.1645 - val_loss: 46.2943 - val_mae: 46.2722 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 47.8279 - mae: 47.8054 - val_loss: 44.0097 - val_mae: 43.9865 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 45.5674 - mae: 45.5438 - val_loss: 41.4756 - val_mae: 41.4515 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 43.9210 - mae: 43.8965 - val_loss: 39.9648 - val_mae: 39.9398 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 43.0759 - mae: 43.0506 - val_loss: 38.0296 - val_mae: 38.0037 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 41.0957 - mae: 41.0694 - val_loss: 36.3896 - val_mae: 36.3628 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 39.3093 - mae: 39.2821 - val_loss: 34.7851 - val_mae: 34.7573 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 37.8899 - mae: 37.8617 - val_loss: 31.7057 - val_mae: 31.6769 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 105.8030\n",
      "LV_RMSE_12h: 123.2214\n",
      "LV_MAE_24h: 25.3121\n",
      "LV_RMSE_24h: 38.9739\n",
      "LV_MAE_48h: 31.5636\n",
      "LV_RMSE_48h: 49.5282\n",
      "LV_MAE_72h: 28.4182\n",
      "LV_RMSE_72h: 43.4361\n",
      "LV_MAE_mean: 47.7742\n",
      "LV_RMSE_mean: 63.7899\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 37.9114\n",
      "RMSE_12h: 48.6494\n",
      "MAE_24h: 38.7965\n",
      "RMSE_24h: 52.5657\n",
      "MAE_48h: 40.1758\n",
      "RMSE_48h: 53.5873\n",
      "MAE_72h: 38.8337\n",
      "RMSE_72h: 52.0551\n",
      "MAE_mean: 38.9293\n",
      "RMSE_mean: 51.7144\n",
      "\n",
      "=== Station S3034104 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1072 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1049, 24, 400) Ytr2: (1049, 4) \n",
      "  Xva3: (154, 24, 400) Yva2: (154, 4) \n",
      "  Xte3: (260, 24, 400) Yte2: (260, 4)\n",
      "Epoch 1/20\n",
      "9/9 [==============================] - 3s 73ms/step - loss: 225.8670 - mae: 225.8543 - val_loss: 209.5840 - val_mae: 209.5713 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 221.5419 - mae: 221.5291 - val_loss: 203.2785 - val_mae: 203.2657 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 214.2036 - mae: 214.1908 - val_loss: 195.3639 - val_mae: 195.3508 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 205.8518 - mae: 205.8386 - val_loss: 187.5172 - val_mae: 187.5036 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 197.5536 - mae: 197.5398 - val_loss: 179.9534 - val_mae: 179.9391 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 189.3994 - mae: 189.3848 - val_loss: 172.5095 - val_mae: 172.4944 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 181.4280 - mae: 181.4126 - val_loss: 165.2531 - val_mae: 165.2371 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 174.3254 - mae: 174.3089 - val_loss: 158.5254 - val_mae: 158.5082 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 167.3269 - mae: 167.3092 - val_loss: 152.5988 - val_mae: 152.5804 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 160.6546 - mae: 160.6357 - val_loss: 147.5993 - val_mae: 147.5796 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 155.0233 - mae: 155.0031 - val_loss: 142.8186 - val_mae: 142.7977 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 150.3811 - mae: 150.3597 - val_loss: 138.7023 - val_mae: 138.6801 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 145.4326 - mae: 145.4099 - val_loss: 134.2701 - val_mae: 134.2466 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 141.0451 - mae: 141.0210 - val_loss: 128.7529 - val_mae: 128.7281 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 135.8307 - mae: 135.8054 - val_loss: 120.7329 - val_mae: 120.7069 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 128.3497 - mae: 128.3232 - val_loss: 113.0058 - val_mae: 112.9785 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 121.4906 - mae: 121.4627 - val_loss: 106.7366 - val_mae: 106.7080 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 114.1215 - mae: 114.0923 - val_loss: 99.2009 - val_mae: 99.1710 - lr: 0.0010\n",
      "Epoch 19/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 15ms/step - loss: 108.4586 - mae: 108.4283 - val_loss: 93.7290 - val_mae: 93.6979 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 103.4665 - mae: 103.4348 - val_loss: 89.9109 - val_mae: 89.8787 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 175.7577\n",
      "LV_RMSE_12h: 205.1915\n",
      "LV_MAE_24h: 34.3885\n",
      "LV_RMSE_24h: 54.0758\n",
      "LV_MAE_48h: 45.3692\n",
      "LV_RMSE_48h: 73.6994\n",
      "LV_MAE_72h: 44.0231\n",
      "LV_RMSE_72h: 70.3661\n",
      "LV_MAE_mean: 74.8846\n",
      "LV_RMSE_mean: 100.8332\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 147.1342\n",
      "RMSE_12h: 168.6275\n",
      "MAE_24h: 78.4888\n",
      "RMSE_24h: 96.4935\n",
      "MAE_48h: 78.4550\n",
      "RMSE_48h: 97.0306\n",
      "MAE_72h: 87.8402\n",
      "RMSE_72h: 107.0443\n",
      "MAE_mean: 97.9796\n",
      "RMSE_mean: 117.2990\n",
      "\n",
      "=== Station S3034105 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1377 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1354, 24, 400) Ytr2: (1354, 4) \n",
      "  Xva3: (197, 24, 400) Yva2: (197, 4) \n",
      "  Xte3: (348, 24, 400) Yte2: (348, 4)\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 3s 62ms/step - loss: 706.5077 - mae: 706.4950 - val_loss: 671.3191 - val_mae: 671.3065 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 701.6779 - mae: 701.6652 - val_loss: 665.1029 - val_mae: 665.0902 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 695.1229 - mae: 695.1100 - val_loss: 657.1533 - val_mae: 657.1401 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 687.0840 - mae: 687.0707 - val_loss: 647.6891 - val_mae: 647.6752 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 676.9942 - mae: 676.9798 - val_loss: 636.4012 - val_mae: 636.3861 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 664.9614 - mae: 664.9456 - val_loss: 623.1315 - val_mae: 623.1147 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 651.2783 - mae: 651.2607 - val_loss: 607.6094 - val_mae: 607.5906 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 634.4289 - mae: 634.4090 - val_loss: 590.3414 - val_mae: 590.3201 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 616.0806 - mae: 616.0580 - val_loss: 570.3016 - val_mae: 570.2773 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 595.5428 - mae: 595.5169 - val_loss: 549.0800 - val_mae: 549.0520 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 574.0210 - mae: 573.9915 - val_loss: 525.6891 - val_mae: 525.6572 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 0s 19ms/step - loss: 549.8948 - mae: 549.8611 - val_loss: 502.1846 - val_mae: 502.1483 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 524.3171 - mae: 524.2787 - val_loss: 478.1179 - val_mae: 478.0765 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 499.9080 - mae: 499.8644 - val_loss: 453.8659 - val_mae: 453.8192 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 473.2045 - mae: 473.1554 - val_loss: 430.5473 - val_mae: 430.4950 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 450.0619 - mae: 450.0070 - val_loss: 406.4754 - val_mae: 406.4171 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 424.2025 - mae: 424.1415 - val_loss: 385.2756 - val_mae: 385.2112 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 400.1620 - mae: 400.0948 - val_loss: 364.5144 - val_mae: 364.4436 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 377.7483 - mae: 377.6747 - val_loss: 346.3120 - val_mae: 346.2346 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 356.6774 - mae: 356.5973 - val_loss: 328.7490 - val_mae: 328.6654 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 1109.0660\n",
      "LV_RMSE_12h: 1381.5068\n",
      "LV_MAE_24h: 498.9856\n",
      "LV_RMSE_24h: 993.2917\n",
      "LV_MAE_48h: 646.9857\n",
      "LV_RMSE_48h: 1164.4104\n",
      "LV_MAE_72h: 605.5143\n",
      "LV_RMSE_72h: 1038.6226\n",
      "LV_MAE_mean: 715.1379\n",
      "LV_RMSE_mean: 1144.4579\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 741.9088\n",
      "RMSE_12h: 1084.3469\n",
      "MAE_24h: 359.7029\n",
      "RMSE_24h: 731.6134\n",
      "MAE_48h: 501.2361\n",
      "RMSE_48h: 973.7116\n",
      "MAE_72h: 484.6019\n",
      "RMSE_72h: 956.9291\n",
      "MAE_mean: 521.8624\n",
      "RMSE_mean: 936.6503\n",
      "\n",
      "=== Station S3034106 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1316 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1293, 24, 400) Ytr2: (1293, 4) \n",
      "  Xva3: (189, 24, 400) Yva2: (189, 4) \n",
      "  Xte3: (330, 24, 400) Yte2: (330, 4)\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 3s 61ms/step - loss: 115.2156 - mae: 115.2029 - val_loss: 117.6681 - val_mae: 117.6554 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 110.0889 - mae: 110.0762 - val_loss: 110.7589 - val_mae: 110.7460 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 102.6129 - mae: 102.5999 - val_loss: 102.8801 - val_mae: 102.8668 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 95.1879 - mae: 95.1743 - val_loss: 95.5655 - val_mae: 95.5515 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 87.8458 - mae: 87.8314 - val_loss: 88.2632 - val_mae: 88.2482 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 80.9384 - mae: 80.9229 - val_loss: 81.6328 - val_mae: 81.6167 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 74.7099 - mae: 74.6933 - val_loss: 75.5166 - val_mae: 75.4993 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 69.4476 - mae: 69.4298 - val_loss: 69.1678 - val_mae: 69.1494 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 63.8528 - mae: 63.8339 - val_loss: 62.0447 - val_mae: 62.0253 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 58.4452 - mae: 58.4253 - val_loss: 55.7866 - val_mae: 55.7662 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 54.4595 - mae: 54.4388 - val_loss: 51.6250 - val_mae: 51.6038 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 52.1044 - mae: 52.0829 - val_loss: 49.0851 - val_mae: 49.0632 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 50.3056 - mae: 50.2836 - val_loss: 47.9962 - val_mae: 47.9740 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 49.3317 - mae: 49.3094 - val_loss: 46.8512 - val_mae: 46.8286 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 48.7038 - mae: 48.6809 - val_loss: 46.2643 - val_mae: 46.2412 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 47.0023 - mae: 46.9789 - val_loss: 44.2912 - val_mae: 44.2673 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 45.8733 - mae: 45.8491 - val_loss: 43.8690 - val_mae: 43.8444 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 44.1744 - mae: 44.1495 - val_loss: 41.4635 - val_mae: 41.4382 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 42.7435 - mae: 42.7178 - val_loss: 39.8043 - val_mae: 39.7781 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 41.3664 - mae: 41.3398 - val_loss: 37.9413 - val_mae: 37.9141 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 104.9394\n",
      "LV_RMSE_12h: 119.1969\n",
      "LV_MAE_24h: 23.6394\n",
      "LV_RMSE_24h: 43.2970\n",
      "LV_MAE_48h: 31.6455\n",
      "LV_RMSE_48h: 57.8241\n",
      "LV_MAE_72h: 28.5182\n",
      "LV_RMSE_72h: 53.1693\n",
      "LV_MAE_mean: 47.1856\n",
      "LV_RMSE_mean: 68.3718\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 42.6924\n",
      "RMSE_12h: 56.4056\n",
      "MAE_24h: 35.7163\n",
      "RMSE_24h: 48.5008\n",
      "MAE_48h: 35.6408\n",
      "RMSE_48h: 49.5970\n",
      "MAE_72h: 36.1284\n",
      "RMSE_72h: 50.4667\n",
      "MAE_mean: 37.5445\n",
      "RMSE_mean: 51.2425\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Station S3034107 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1316 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1293, 24, 400) Ytr2: (1293, 4) \n",
      "  Xva3: (189, 24, 400) Yva2: (189, 4) \n",
      "  Xte3: (330, 24, 400) Yte2: (330, 4)\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 3s 62ms/step - loss: 109.4466 - mae: 109.4337 - val_loss: 106.8805 - val_mae: 106.8676 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 103.9117 - mae: 103.8987 - val_loss: 99.6415 - val_mae: 99.6283 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 96.2278 - mae: 96.2144 - val_loss: 92.1302 - val_mae: 92.1165 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 88.7940 - mae: 88.7800 - val_loss: 85.1995 - val_mae: 85.1851 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 82.3129 - mae: 82.2980 - val_loss: 79.1305 - val_mae: 79.1151 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 76.9049 - mae: 76.8891 - val_loss: 74.3125 - val_mae: 74.2961 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 72.4236 - mae: 72.4068 - val_loss: 69.5583 - val_mae: 69.5409 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 68.3149 - mae: 68.2971 - val_loss: 63.8771 - val_mae: 63.8588 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 63.3044 - mae: 63.2857 - val_loss: 57.9372 - val_mae: 57.9180 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 57.7672 - mae: 57.7475 - val_loss: 51.7960 - val_mae: 51.7757 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 53.1471 - mae: 53.1264 - val_loss: 46.3105 - val_mae: 46.2893 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 49.5878 - mae: 49.5663 - val_loss: 43.3776 - val_mae: 43.3555 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 46.8940 - mae: 46.8717 - val_loss: 41.6572 - val_mae: 41.6346 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 45.6371 - mae: 45.6144 - val_loss: 40.4196 - val_mae: 40.3967 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 44.6161 - mae: 44.5930 - val_loss: 38.9431 - val_mae: 38.9197 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 43.4440 - mae: 43.4205 - val_loss: 37.6287 - val_mae: 37.6047 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 42.3669 - mae: 42.3428 - val_loss: 36.5786 - val_mae: 36.5540 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 40.9092 - mae: 40.8843 - val_loss: 34.6386 - val_mae: 34.6132 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 39.0923 - mae: 39.0665 - val_loss: 32.9402 - val_mae: 32.9139 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 37.6036 - mae: 37.5768 - val_loss: 33.0602 - val_mae: 33.0329 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 97.9879\n",
      "LV_RMSE_12h: 109.7934\n",
      "LV_MAE_24h: 24.6939\n",
      "LV_RMSE_24h: 39.9725\n",
      "LV_MAE_48h: 29.3848\n",
      "LV_RMSE_48h: 49.8143\n",
      "LV_MAE_72h: 27.2212\n",
      "LV_RMSE_72h: 45.0386\n",
      "LV_MAE_mean: 44.8220\n",
      "LV_RMSE_mean: 61.1547\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 33.1761\n",
      "RMSE_12h: 41.4539\n",
      "MAE_24h: 38.2611\n",
      "RMSE_24h: 50.8107\n",
      "MAE_48h: 39.4429\n",
      "RMSE_48h: 52.3803\n",
      "MAE_72h: 37.7701\n",
      "RMSE_72h: 50.9651\n",
      "MAE_mean: 37.1625\n",
      "RMSE_mean: 48.9025\n",
      "\n",
      "=== Station S3036011 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1377 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1354, 24, 400) Ytr2: (1354, 4) \n",
      "  Xva3: (197, 24, 400) Yva2: (197, 4) \n",
      "  Xte3: (348, 24, 400) Yte2: (348, 4)\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 3s 62ms/step - loss: 691.5640 - mae: 691.5513 - val_loss: 701.4110 - val_mae: 701.3981 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 685.8779 - mae: 685.8650 - val_loss: 693.0145 - val_mae: 693.0013 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 676.0743 - mae: 676.0611 - val_loss: 681.1412 - val_mae: 681.1276 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 664.0298 - mae: 664.0158 - val_loss: 667.6824 - val_mae: 667.6680 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 650.1620 - mae: 650.1470 - val_loss: 653.0162 - val_mae: 653.0005 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 634.7347 - mae: 634.7184 - val_loss: 636.9086 - val_mae: 636.8912 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 618.5103 - mae: 618.4921 - val_loss: 620.7059 - val_mae: 620.6867 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 601.5349 - mae: 601.5148 - val_loss: 603.6453 - val_mae: 603.6239 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 584.8066 - mae: 584.7842 - val_loss: 586.2972 - val_mae: 586.2734 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 566.3245 - mae: 566.2995 - val_loss: 567.3017 - val_mae: 567.2751 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 547.3776 - mae: 547.3498 - val_loss: 547.0043 - val_mae: 546.9747 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 525.1768 - mae: 525.1458 - val_loss: 522.8433 - val_mae: 522.8103 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 500.3056 - mae: 500.2710 - val_loss: 497.3096 - val_mae: 497.2727 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 475.9615 - mae: 475.9229 - val_loss: 474.3008 - val_mae: 474.2598 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 453.3663 - mae: 453.3235 - val_loss: 453.1630 - val_mae: 453.1177 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 432.7391 - mae: 432.6919 - val_loss: 431.9312 - val_mae: 431.8816 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 412.7400 - mae: 412.6884 - val_loss: 413.1519 - val_mae: 413.0977 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 392.5397 - mae: 392.4836 - val_loss: 396.2267 - val_mae: 396.1681 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 375.2560 - mae: 375.1956 - val_loss: 378.5420 - val_mae: 378.4791 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 360.4671 - mae: 360.4023 - val_loss: 365.7097 - val_mae: 365.6426 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 940.8477\n",
      "LV_RMSE_12h: 1083.1458\n",
      "LV_MAE_24h: 147.8994\n",
      "LV_RMSE_24h: 208.0078\n",
      "LV_MAE_48h: 181.4397\n",
      "LV_RMSE_48h: 258.4146\n",
      "LV_MAE_72h: 182.6293\n",
      "LV_RMSE_72h: 249.9912\n",
      "LV_MAE_mean: 363.2040\n",
      "LV_RMSE_mean: 449.8898\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 609.9250\n",
      "RMSE_12h: 768.0693\n",
      "MAE_24h: 311.4656\n",
      "RMSE_24h: 441.7799\n",
      "MAE_48h: 324.6651\n",
      "RMSE_48h: 460.5145\n",
      "MAE_72h: 324.5819\n",
      "RMSE_72h: 459.2073\n",
      "MAE_mean: 392.6594\n",
      "RMSE_mean: 532.3928\n",
      "\n",
      "=== Station S3036021 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1377 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1354, 24, 400) Ytr2: (1354, 4) \n",
      "  Xva3: (197, 24, 400) Yva2: (197, 4) \n",
      "  Xte3: (348, 24, 400) Yte2: (348, 4)\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 3s 58ms/step - loss: 652.3206 - mae: 652.3079 - val_loss: 643.9883 - val_mae: 643.9757 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 646.9918 - mae: 646.9792 - val_loss: 636.5751 - val_mae: 636.5623 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 638.4895 - mae: 638.4766 - val_loss: 626.6219 - val_mae: 626.6089 - lr: 0.0010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 627.6885 - mae: 627.6751 - val_loss: 614.4700 - val_mae: 614.4562 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 614.1519 - mae: 614.1376 - val_loss: 600.5302 - val_mae: 600.5153 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 598.9984 - mae: 598.9830 - val_loss: 585.0468 - val_mae: 585.0306 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 582.6969 - mae: 582.6799 - val_loss: 568.5663 - val_mae: 568.5483 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 565.0794 - mae: 565.0607 - val_loss: 551.6304 - val_mae: 551.6104 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 546.8301 - mae: 546.8092 - val_loss: 534.4854 - val_mae: 534.4631 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 528.3903 - mae: 528.3668 - val_loss: 516.9567 - val_mae: 516.9319 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 510.9641 - mae: 510.9380 - val_loss: 499.6646 - val_mae: 499.6371 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 492.3148 - mae: 492.2858 - val_loss: 482.1945 - val_mae: 482.1639 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 474.0762 - mae: 474.0442 - val_loss: 463.6121 - val_mae: 463.5783 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 454.8421 - mae: 454.8069 - val_loss: 444.0205 - val_mae: 443.9833 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 433.1004 - mae: 433.0616 - val_loss: 420.8055 - val_mae: 420.7646 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 411.4970 - mae: 411.4545 - val_loss: 398.3401 - val_mae: 398.2954 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 388.9049 - mae: 388.8585 - val_loss: 378.0071 - val_mae: 377.9585 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 368.4581 - mae: 368.4077 - val_loss: 358.8459 - val_mae: 358.7932 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 349.4652 - mae: 349.4107 - val_loss: 339.8352 - val_mae: 339.7783 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 328.7882 - mae: 328.7295 - val_loss: 319.5352 - val_mae: 319.4740 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 753.6293\n",
      "LV_RMSE_12h: 851.9594\n",
      "LV_MAE_24h: 139.2701\n",
      "LV_RMSE_24h: 200.0162\n",
      "LV_MAE_48h: 168.9828\n",
      "LV_RMSE_48h: 242.8804\n",
      "LV_MAE_72h: 156.5029\n",
      "LV_RMSE_72h: 226.1972\n",
      "LV_MAE_mean: 304.5963\n",
      "LV_RMSE_mean: 380.2633\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 521.9943\n",
      "RMSE_12h: 629.9387\n",
      "MAE_24h: 262.9059\n",
      "RMSE_24h: 347.7834\n",
      "MAE_48h: 264.5039\n",
      "RMSE_48h: 357.7581\n",
      "MAE_72h: 290.0638\n",
      "RMSE_72h: 393.0896\n",
      "MAE_mean: 334.8669\n",
      "RMSE_mean: 432.1425\n",
      "\n",
      "=== Station S3036041 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1377 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1354, 24, 400) Ytr2: (1354, 4) \n",
      "  Xva3: (197, 24, 400) Yva2: (197, 4) \n",
      "  Xte3: (348, 24, 400) Yte2: (348, 4)\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 3s 61ms/step - loss: 607.1300 - mae: 607.1174 - val_loss: 597.1976 - val_mae: 597.1849 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 600.5413 - mae: 600.5285 - val_loss: 587.2957 - val_mae: 587.2827 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 588.9161 - mae: 588.9028 - val_loss: 574.3220 - val_mae: 574.3084 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 574.8527 - mae: 574.8387 - val_loss: 559.4933 - val_mae: 559.4787 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 558.7958 - mae: 558.7806 - val_loss: 543.3798 - val_mae: 543.3638 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 541.7316 - mae: 541.7149 - val_loss: 525.9822 - val_mae: 525.9645 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 522.9138 - mae: 522.8951 - val_loss: 507.8807 - val_mae: 507.8609 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 502.6238 - mae: 502.6030 - val_loss: 489.9388 - val_mae: 489.9166 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 0s 18ms/step - loss: 484.4152 - mae: 484.3918 - val_loss: 471.9683 - val_mae: 471.9434 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 465.5180 - mae: 465.4919 - val_loss: 454.7474 - val_mae: 454.7197 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 448.1743 - mae: 448.1452 - val_loss: 437.1501 - val_mae: 437.1192 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 430.6729 - mae: 430.6407 - val_loss: 420.7071 - val_mae: 420.6729 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 413.3932 - mae: 413.3575 - val_loss: 403.2511 - val_mae: 403.2135 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 393.7783 - mae: 393.7391 - val_loss: 381.1192 - val_mae: 381.0780 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 370.6383 - mae: 370.5954 - val_loss: 357.2599 - val_mae: 357.2149 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 346.8444 - mae: 346.7977 - val_loss: 334.5489 - val_mae: 334.4999 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 324.5979 - mae: 324.5471 - val_loss: 316.2513 - val_mae: 316.1982 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 305.1399 - mae: 305.0849 - val_loss: 297.8904 - val_mae: 297.8330 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 288.4330 - mae: 288.3736 - val_loss: 283.3598 - val_mae: 283.2979 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 274.3718 - mae: 274.3082 - val_loss: 270.4027 - val_mae: 270.3368 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 698.8908\n",
      "LV_RMSE_12h: 792.4810\n",
      "LV_MAE_24h: 130.0575\n",
      "LV_RMSE_24h: 186.4159\n",
      "LV_MAE_48h: 158.9770\n",
      "LV_RMSE_48h: 227.4471\n",
      "LV_MAE_72h: 152.7155\n",
      "LV_RMSE_72h: 216.0488\n",
      "LV_MAE_mean: 285.1602\n",
      "LV_RMSE_mean: 355.5982\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 505.9917\n",
      "RMSE_12h: 601.1723\n",
      "MAE_24h: 223.0276\n",
      "RMSE_24h: 295.0565\n",
      "MAE_48h: 218.6994\n",
      "RMSE_48h: 293.1239\n",
      "MAE_72h: 229.3658\n",
      "RMSE_72h: 304.1817\n",
      "MAE_mean: 294.2711\n",
      "RMSE_mean: 373.3836\n",
      "\n",
      "=== Station S3036042 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1377 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1354, 24, 400) Ytr2: (1354, 4) \n",
      "  Xva3: (197, 24, 400) Yva2: (197, 4) \n",
      "  Xte3: (348, 24, 400) Yte2: (348, 4)\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 3s 59ms/step - loss: 2630.4502 - mae: 2630.4373 - val_loss: 2637.5686 - val_mae: 2637.5559 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 2624.0208 - mae: 2624.0083 - val_loss: 2628.4641 - val_mae: 2628.4514 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 2613.0681 - mae: 2613.0557 - val_loss: 2615.4341 - val_mae: 2615.4207 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 2598.3040 - mae: 2598.2900 - val_loss: 2598.3032 - val_mae: 2598.2888 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 2579.0789 - mae: 2579.0640 - val_loss: 2576.4700 - val_mae: 2576.4541 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 2555.0610 - mae: 2555.0444 - val_loss: 2549.5151 - val_mae: 2549.4976 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 2525.6255 - mae: 2525.6067 - val_loss: 2517.1641 - val_mae: 2517.1440 - lr: 0.0010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 2490.8525 - mae: 2490.8313 - val_loss: 2479.2380 - val_mae: 2479.2151 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 2450.9094 - mae: 2450.8853 - val_loss: 2435.6465 - val_mae: 2435.6199 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 2404.7249 - mae: 2404.6968 - val_loss: 2386.3191 - val_mae: 2386.2888 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 2352.1294 - mae: 2352.0969 - val_loss: 2331.0828 - val_mae: 2331.0479 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 2295.1763 - mae: 2295.1392 - val_loss: 2270.1836 - val_mae: 2270.1436 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 2234.1262 - mae: 2234.0840 - val_loss: 2205.4829 - val_mae: 2205.4373 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 2171.4026 - mae: 2171.3542 - val_loss: 2143.2126 - val_mae: 2143.1611 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 2111.5081 - mae: 2111.4539 - val_loss: 2083.6770 - val_mae: 2083.6194 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 2054.2117 - mae: 2054.1516 - val_loss: 2028.1647 - val_mae: 2028.1007 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 1997.1532 - mae: 1997.0865 - val_loss: 1972.9426 - val_mae: 1972.8723 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1938.0142 - mae: 1937.9413 - val_loss: 1916.5023 - val_mae: 1916.4253 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1887.9830 - mae: 1887.9025 - val_loss: 1862.2343 - val_mae: 1862.1500 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1836.7267 - mae: 1836.6394 - val_loss: 1813.8682 - val_mae: 1813.7770 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 2259.3047\n",
      "LV_RMSE_12h: 2478.3452\n",
      "LV_MAE_24h: 427.3563\n",
      "LV_RMSE_24h: 693.4286\n",
      "LV_MAE_48h: 591.7787\n",
      "LV_RMSE_48h: 912.6355\n",
      "LV_MAE_72h: 470.6236\n",
      "LV_RMSE_72h: 752.0567\n",
      "LV_MAE_mean: 937.2659\n",
      "LV_RMSE_mean: 1209.1166\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 1617.8853\n",
      "RMSE_12h: 1990.2924\n",
      "MAE_24h: 1667.6312\n",
      "RMSE_24h: 2035.5455\n",
      "MAE_48h: 1668.9285\n",
      "RMSE_48h: 2040.9901\n",
      "MAE_72h: 1641.8243\n",
      "RMSE_72h: 2004.4586\n",
      "MAE_mean: 1649.0674\n",
      "RMSE_mean: 2017.8217\n",
      "\n",
      "=== Station S3036043 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1266 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1243, 24, 400) Ytr2: (1243, 4) \n",
      "  Xva3: (181, 24, 400) Yva2: (181, 4) \n",
      "  Xte3: (316, 24, 400) Yte2: (316, 4)\n",
      "Epoch 1/20\n",
      "10/10 [==============================] - 3s 63ms/step - loss: 8.9612 - mae: 8.9486 - val_loss: 8.6408 - val_mae: 8.6283 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 7.9428 - mae: 7.9302 - val_loss: 8.1533 - val_mae: 8.1408 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 7.6853 - mae: 7.6728 - val_loss: 8.0440 - val_mae: 8.0316 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 7.5494 - mae: 7.5370 - val_loss: 7.8950 - val_mae: 7.8827 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 7.4897 - mae: 7.4773 - val_loss: 7.7717 - val_mae: 7.7594 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 7.3622 - mae: 7.3499 - val_loss: 7.6885 - val_mae: 7.6763 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 7.2636 - mae: 7.2514 - val_loss: 7.6090 - val_mae: 7.5968 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 7.1673 - mae: 7.1551 - val_loss: 7.5696 - val_mae: 7.5573 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 7.0377 - mae: 7.0255 - val_loss: 7.4026 - val_mae: 7.3902 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 6.9153 - mae: 6.9030 - val_loss: 7.1981 - val_mae: 7.1857 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 6.8096 - mae: 6.7971 - val_loss: 7.2377 - val_mae: 7.2250 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 6.5981 - mae: 6.5854 - val_loss: 7.0048 - val_mae: 6.9919 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 6.4728 - mae: 6.4599 - val_loss: 6.8228 - val_mae: 6.8097 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 6.2496 - mae: 6.2364 - val_loss: 6.5811 - val_mae: 6.5677 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 6.1047 - mae: 6.0912 - val_loss: 6.4782 - val_mae: 6.4644 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 5.9374 - mae: 5.9235 - val_loss: 6.5353 - val_mae: 6.5212 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 5.8482 - mae: 5.8340 - val_loss: 6.2160 - val_mae: 6.2015 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 5.7241 - mae: 5.7094 - val_loss: 6.0340 - val_mae: 6.0192 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 5.6183 - mae: 5.6033 - val_loss: 5.9755 - val_mae: 5.9602 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 5.4677 - mae: 5.4523 - val_loss: 5.9523 - val_mae: 5.9367 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 9.9241\n",
      "LV_RMSE_12h: 23.3022\n",
      "LV_MAE_24h: 4.8070\n",
      "LV_RMSE_24h: 9.3099\n",
      "LV_MAE_48h: 5.5475\n",
      "LV_RMSE_48h: 11.7010\n",
      "LV_MAE_72h: 5.2848\n",
      "LV_RMSE_72h: 13.0061\n",
      "LV_MAE_mean: 6.3908\n",
      "LV_RMSE_mean: 14.3298\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 4.2384\n",
      "RMSE_12h: 10.3631\n",
      "MAE_24h: 4.4782\n",
      "RMSE_24h: 11.0260\n",
      "MAE_48h: 4.1054\n",
      "RMSE_48h: 8.7383\n",
      "MAE_72h: 3.5358\n",
      "RMSE_72h: 7.4312\n",
      "MAE_mean: 4.0895\n",
      "RMSE_mean: 9.3897\n",
      "\n",
      "=== Station S3036044 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1247 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1224, 24, 400) Ytr2: (1224, 4) \n",
      "  Xva3: (179, 24, 400) Yva2: (179, 4) \n",
      "  Xte3: (310, 24, 400) Yte2: (310, 4)\n",
      "Epoch 1/20\n",
      "10/10 [==============================] - 3s 63ms/step - loss: 63.5700 - mae: 63.5573 - val_loss: 61.7321 - val_mae: 61.7194 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 58.9852 - mae: 58.9724 - val_loss: 55.7664 - val_mae: 55.7534 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 53.7048 - mae: 53.6917 - val_loss: 51.1099 - val_mae: 51.0966 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 50.2728 - mae: 50.2593 - val_loss: 48.6891 - val_mae: 48.6753 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 48.5564 - mae: 48.5424 - val_loss: 47.6866 - val_mae: 47.6725 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 47.8882 - mae: 47.8740 - val_loss: 46.8704 - val_mae: 46.8561 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 46.9093 - mae: 46.8951 - val_loss: 45.2207 - val_mae: 45.2064 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 45.7127 - mae: 45.6984 - val_loss: 43.1399 - val_mae: 43.1255 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 43.9077 - mae: 43.8932 - val_loss: 40.7332 - val_mae: 40.7185 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 41.9288 - mae: 41.9139 - val_loss: 38.4284 - val_mae: 38.4133 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 40.0085 - mae: 39.9931 - val_loss: 36.4148 - val_mae: 36.3990 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 38.7216 - mae: 38.7055 - val_loss: 35.1928 - val_mae: 35.1763 - lr: 0.0010\n",
      "Epoch 13/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 12ms/step - loss: 37.4871 - mae: 37.4704 - val_loss: 33.7731 - val_mae: 33.7560 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 36.2681 - mae: 36.2508 - val_loss: 32.7328 - val_mae: 32.7152 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 35.1432 - mae: 35.1253 - val_loss: 31.5731 - val_mae: 31.5548 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 34.0048 - mae: 33.9863 - val_loss: 30.7365 - val_mae: 30.7176 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 33.0503 - mae: 33.0311 - val_loss: 29.7938 - val_mae: 29.7742 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 32.4485 - mae: 32.4287 - val_loss: 29.0890 - val_mae: 29.0688 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 31.8432 - mae: 31.8227 - val_loss: 28.8851 - val_mae: 28.8643 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 31.4206 - mae: 31.3996 - val_loss: 28.7576 - val_mae: 28.7363 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 69.1387\n",
      "LV_RMSE_12h: 90.4699\n",
      "LV_MAE_24h: 24.7548\n",
      "LV_RMSE_24h: 45.5184\n",
      "LV_MAE_48h: 31.1065\n",
      "LV_RMSE_48h: 52.8765\n",
      "LV_MAE_72h: 26.2935\n",
      "LV_RMSE_72h: 51.2680\n",
      "LV_MAE_mean: 37.8234\n",
      "LV_RMSE_mean: 60.0332\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 21.9106\n",
      "RMSE_12h: 43.2989\n",
      "MAE_24h: 26.5094\n",
      "RMSE_24h: 46.7867\n",
      "MAE_48h: 22.7108\n",
      "RMSE_48h: 38.4554\n",
      "MAE_72h: 20.0758\n",
      "RMSE_72h: 35.7811\n",
      "MAE_mean: 22.8016\n",
      "RMSE_mean: 41.0805\n",
      "\n",
      "=== Station S3036061 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1376 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1353, 24, 400) Ytr2: (1353, 4) \n",
      "  Xva3: (197, 24, 400) Yva2: (197, 4) \n",
      "  Xte3: (348, 24, 400) Yte2: (348, 4)\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 3s 57ms/step - loss: 36.6357 - mae: 36.6230 - val_loss: 36.8000 - val_mae: 36.7873 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 32.8336 - mae: 32.8209 - val_loss: 32.2043 - val_mae: 32.1914 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 28.6628 - mae: 28.6498 - val_loss: 27.5450 - val_mae: 27.5317 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 24.8117 - mae: 24.7983 - val_loss: 23.2336 - val_mae: 23.2198 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 21.4909 - mae: 21.4769 - val_loss: 20.7179 - val_mae: 20.7035 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 19.9508 - mae: 19.9362 - val_loss: 19.9384 - val_mae: 19.9237 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 18.8710 - mae: 18.8562 - val_loss: 19.0586 - val_mae: 19.0436 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 17.9822 - mae: 17.9671 - val_loss: 17.9679 - val_mae: 17.9527 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 17.2362 - mae: 17.2209 - val_loss: 17.3228 - val_mae: 17.3072 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 16.9618 - mae: 16.9461 - val_loss: 16.9710 - val_mae: 16.9553 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 16.5527 - mae: 16.5369 - val_loss: 16.8078 - val_mae: 16.7920 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 16.3885 - mae: 16.3726 - val_loss: 16.5584 - val_mae: 16.5425 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 16.0078 - mae: 15.9918 - val_loss: 16.4577 - val_mae: 16.4417 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 15.8309 - mae: 15.8147 - val_loss: 16.2747 - val_mae: 16.2584 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 15.5114 - mae: 15.4950 - val_loss: 15.7978 - val_mae: 15.7814 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 15.2201 - mae: 15.2035 - val_loss: 15.6774 - val_mae: 15.6607 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 14.8323 - mae: 14.8155 - val_loss: 15.4708 - val_mae: 15.4537 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 14.5552 - mae: 14.5380 - val_loss: 15.1792 - val_mae: 15.1619 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 14.3054 - mae: 14.2879 - val_loss: 14.7313 - val_mae: 14.7137 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 13.8869 - mae: 13.8691 - val_loss: 14.6132 - val_mae: 14.5953 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 38.2644\n",
      "LV_RMSE_12h: 47.0368\n",
      "LV_MAE_24h: 12.4799\n",
      "LV_RMSE_24h: 20.9595\n",
      "LV_MAE_48h: 16.5431\n",
      "LV_RMSE_48h: 27.8198\n",
      "LV_MAE_72h: 14.6322\n",
      "LV_RMSE_72h: 26.9105\n",
      "LV_MAE_mean: 20.4799\n",
      "LV_RMSE_mean: 30.6816\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 11.8336\n",
      "RMSE_12h: 20.1494\n",
      "MAE_24h: 14.6383\n",
      "RMSE_24h: 23.7238\n",
      "MAE_48h: 13.4152\n",
      "RMSE_48h: 21.7204\n",
      "MAE_72h: 12.8466\n",
      "RMSE_72h: 20.2245\n",
      "MAE_mean: 13.1834\n",
      "RMSE_mean: 21.4545\n",
      "\n",
      "=== Station S3036071 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1377 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1354, 24, 400) Ytr2: (1354, 4) \n",
      "  Xva3: (197, 24, 400) Yva2: (197, 4) \n",
      "  Xte3: (348, 24, 400) Yte2: (348, 4)\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 3s 58ms/step - loss: 376.3435 - mae: 376.3306 - val_loss: 372.9964 - val_mae: 372.9835 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 370.0473 - mae: 370.0343 - val_loss: 364.5975 - val_mae: 364.5843 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 360.7736 - mae: 360.7601 - val_loss: 354.3943 - val_mae: 354.3804 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 350.4014 - mae: 350.3871 - val_loss: 343.4553 - val_mae: 343.4405 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 339.0256 - mae: 339.0103 - val_loss: 331.5169 - val_mae: 331.5008 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 326.9380 - mae: 326.9213 - val_loss: 318.7336 - val_mae: 318.7159 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 313.7263 - mae: 313.7077 - val_loss: 305.1840 - val_mae: 305.1642 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 300.5618 - mae: 300.5411 - val_loss: 290.9457 - val_mae: 290.9236 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 286.5745 - mae: 286.5513 - val_loss: 277.2051 - val_mae: 277.1804 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 273.0969 - mae: 273.0710 - val_loss: 263.5829 - val_mae: 263.5555 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 259.9570 - mae: 259.9284 - val_loss: 248.5526 - val_mae: 248.5223 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 246.2285 - mae: 246.1970 - val_loss: 233.9005 - val_mae: 233.8673 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 231.7756 - mae: 231.7412 - val_loss: 218.8173 - val_mae: 218.7812 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 218.6798 - mae: 218.6423 - val_loss: 207.0849 - val_mae: 207.0457 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 207.2074 - mae: 207.1671 - val_loss: 195.9733 - val_mae: 195.9314 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 197.6727 - mae: 197.6297 - val_loss: 186.7854 - val_mae: 186.7410 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 187.9489 - mae: 187.9035 - val_loss: 178.9930 - val_mae: 178.9463 - lr: 0.0010\n",
      "Epoch 18/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 12ms/step - loss: 180.4166 - mae: 180.3688 - val_loss: 170.4597 - val_mae: 170.4106 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 170.7304 - mae: 170.6801 - val_loss: 162.1286 - val_mae: 162.0768 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 162.9791 - mae: 162.9262 - val_loss: 155.0423 - val_mae: 154.9880 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 501.0690\n",
      "LV_RMSE_12h: 577.5590\n",
      "LV_MAE_24h: 77.4828\n",
      "LV_RMSE_24h: 104.2874\n",
      "LV_MAE_48h: 91.9253\n",
      "LV_RMSE_48h: 128.9312\n",
      "LV_MAE_72h: 88.0862\n",
      "LV_RMSE_72h: 122.3302\n",
      "LV_MAE_mean: 189.6408\n",
      "LV_RMSE_mean: 233.2769\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 348.2670\n",
      "RMSE_12h: 429.5178\n",
      "MAE_24h: 106.9111\n",
      "RMSE_24h: 149.5348\n",
      "MAE_48h: 110.8109\n",
      "RMSE_48h: 152.7857\n",
      "MAE_72h: 111.1904\n",
      "RMSE_72h: 153.0210\n",
      "MAE_mean: 169.2948\n",
      "RMSE_mean: 221.2148\n",
      "\n",
      "=== Station S3036072 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1377 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1354, 24, 400) Ytr2: (1354, 4) \n",
      "  Xva3: (197, 24, 400) Yva2: (197, 4) \n",
      "  Xte3: (348, 24, 400) Yte2: (348, 4)\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 3s 61ms/step - loss: 1630.1981 - mae: 1630.1855 - val_loss: 1635.1218 - val_mae: 1635.1093 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1625.0237 - mae: 1625.0109 - val_loss: 1627.7173 - val_mae: 1627.7046 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1616.0591 - mae: 1616.0461 - val_loss: 1617.0095 - val_mae: 1616.9963 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1604.0442 - mae: 1604.0309 - val_loss: 1602.9343 - val_mae: 1602.9207 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1588.0548 - mae: 1588.0406 - val_loss: 1584.9838 - val_mae: 1584.9691 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1568.5853 - mae: 1568.5698 - val_loss: 1563.0452 - val_mae: 1563.0289 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1545.0421 - mae: 1545.0249 - val_loss: 1537.0524 - val_mae: 1537.0341 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1517.7051 - mae: 1517.6859 - val_loss: 1508.3153 - val_mae: 1508.2947 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1489.1392 - mae: 1489.1176 - val_loss: 1478.6265 - val_mae: 1478.6033 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 1459.6526 - mae: 1459.6283 - val_loss: 1450.0211 - val_mae: 1449.9952 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 1431.9691 - mae: 1431.9419 - val_loss: 1421.2379 - val_mae: 1421.2091 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1403.6821 - mae: 1403.6520 - val_loss: 1392.5276 - val_mae: 1392.4956 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1376.0370 - mae: 1376.0035 - val_loss: 1363.4146 - val_mae: 1363.3789 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1348.6768 - mae: 1348.6398 - val_loss: 1334.4276 - val_mae: 1334.3884 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1319.7324 - mae: 1319.6915 - val_loss: 1307.2903 - val_mae: 1307.2472 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1295.8081 - mae: 1295.7634 - val_loss: 1280.9309 - val_mae: 1280.8839 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1268.6675 - mae: 1268.6185 - val_loss: 1254.1371 - val_mae: 1254.0858 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1243.3956 - mae: 1243.3423 - val_loss: 1226.8038 - val_mae: 1226.7483 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1216.8239 - mae: 1216.7664 - val_loss: 1195.5535 - val_mae: 1195.4933 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 1182.9277 - mae: 1182.8656 - val_loss: 1153.9929 - val_mae: 1153.9279 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 1762.0862\n",
      "LV_RMSE_12h: 1952.2935\n",
      "LV_MAE_24h: 282.9138\n",
      "LV_RMSE_24h: 425.1699\n",
      "LV_MAE_48h: 360.9224\n",
      "LV_RMSE_48h: 558.0316\n",
      "LV_MAE_72h: 309.8851\n",
      "LV_RMSE_72h: 474.7104\n",
      "LV_MAE_mean: 678.9518\n",
      "LV_RMSE_mean: 852.5513\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 1134.0160\n",
      "RMSE_12h: 1425.3312\n",
      "MAE_24h: 1042.7365\n",
      "RMSE_24h: 1338.8567\n",
      "MAE_48h: 1029.9954\n",
      "RMSE_48h: 1323.1317\n",
      "MAE_72h: 1032.9037\n",
      "RMSE_72h: 1324.2532\n",
      "MAE_mean: 1059.9128\n",
      "RMSE_mean: 1352.8933\n",
      "\n",
      "=== Station S3036073 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1376 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1353, 24, 400) Ytr2: (1353, 4) \n",
      "  Xva3: (197, 24, 400) Yva2: (197, 4) \n",
      "  Xte3: (347, 24, 400) Yte2: (347, 4)\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 3s 59ms/step - loss: 493.1977 - mae: 493.1848 - val_loss: 516.2881 - val_mae: 516.2752 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 486.9721 - mae: 486.9592 - val_loss: 507.4179 - val_mae: 507.4048 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 476.3094 - mae: 476.2960 - val_loss: 494.9273 - val_mae: 494.9136 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 463.1422 - mae: 463.1281 - val_loss: 480.9942 - val_mae: 480.9796 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 449.3808 - mae: 449.3657 - val_loss: 467.3104 - val_mae: 467.2946 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 435.7807 - mae: 435.7643 - val_loss: 453.9449 - val_mae: 453.9277 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 421.9996 - mae: 421.9816 - val_loss: 439.9837 - val_mae: 439.9648 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 408.1243 - mae: 408.1044 - val_loss: 425.7828 - val_mae: 425.7619 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 394.8818 - mae: 394.8600 - val_loss: 411.8143 - val_mae: 411.7912 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 379.7246 - mae: 379.7005 - val_loss: 398.5324 - val_mae: 398.5069 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 367.0381 - mae: 367.0114 - val_loss: 386.4095 - val_mae: 386.3814 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 354.8378 - mae: 354.8087 - val_loss: 373.3575 - val_mae: 373.3268 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 341.9694 - mae: 341.9377 - val_loss: 356.2209 - val_mae: 356.1877 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 324.4723 - mae: 324.4379 - val_loss: 336.5697 - val_mae: 336.5338 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 304.9421 - mae: 304.9049 - val_loss: 314.7706 - val_mae: 314.7315 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 284.8264 - mae: 284.7859 - val_loss: 295.2221 - val_mae: 295.1797 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 266.4206 - mae: 266.3764 - val_loss: 277.2610 - val_mae: 277.2147 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 250.5419 - mae: 250.4939 - val_loss: 262.3205 - val_mae: 262.2703 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 236.7435 - mae: 236.6917 - val_loss: 247.9809 - val_mae: 247.9269 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 225.5352 - mae: 225.4797 - val_loss: 236.6491 - val_mae: 236.5916 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 590.8127\n",
      "LV_RMSE_12h: 697.6457\n",
      "LV_MAE_24h: 110.8963\n",
      "LV_RMSE_24h: 176.9640\n",
      "LV_MAE_48h: 151.2190\n",
      "LV_RMSE_48h: 242.3530\n",
      "LV_MAE_72h: 134.0663\n",
      "LV_RMSE_72h: 222.6248\n",
      "LV_MAE_mean: 246.7486\n",
      "LV_RMSE_mean: 334.8969\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 414.0326\n",
      "RMSE_12h: 529.5079\n",
      "MAE_24h: 138.7819\n",
      "RMSE_24h: 247.4662\n",
      "MAE_48h: 138.9088\n",
      "RMSE_48h: 244.6495\n",
      "MAE_72h: 141.1295\n",
      "RMSE_72h: 247.9007\n",
      "MAE_mean: 208.2132\n",
      "RMSE_mean: 317.3811\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Station S3036074 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1376 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1353, 24, 400) Ytr2: (1353, 4) \n",
      "  Xva3: (197, 24, 400) Yva2: (197, 4) \n",
      "  Xte3: (347, 24, 400) Yte2: (347, 4)\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 3s 59ms/step - loss: 32.5765 - mae: 32.5637 - val_loss: 29.9036 - val_mae: 29.8909 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 30.3501 - mae: 30.3374 - val_loss: 27.5296 - val_mae: 27.5168 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 27.8377 - mae: 27.8249 - val_loss: 25.4754 - val_mae: 25.4625 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 26.0254 - mae: 26.0123 - val_loss: 24.8495 - val_mae: 24.8362 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 25.4077 - mae: 25.3943 - val_loss: 24.6891 - val_mae: 24.6757 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 25.2543 - mae: 25.2409 - val_loss: 24.6585 - val_mae: 24.6451 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 25.1026 - mae: 25.0893 - val_loss: 24.5036 - val_mae: 24.4903 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 24.9756 - mae: 24.9623 - val_loss: 24.2860 - val_mae: 24.2728 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 24.8253 - mae: 24.8122 - val_loss: 24.1626 - val_mae: 24.1495 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 24.7073 - mae: 24.6942 - val_loss: 24.0212 - val_mae: 24.0081 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 24.5314 - mae: 24.5182 - val_loss: 23.9978 - val_mae: 23.9846 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 24.4037 - mae: 24.3904 - val_loss: 23.7289 - val_mae: 23.7156 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 24.1371 - mae: 24.1238 - val_loss: 23.5786 - val_mae: 23.5651 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 23.9477 - mae: 23.9342 - val_loss: 23.4903 - val_mae: 23.4767 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 23.8400 - mae: 23.8263 - val_loss: 23.4332 - val_mae: 23.4194 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 23.5076 - mae: 23.4937 - val_loss: 23.0421 - val_mae: 23.0280 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 23.2663 - mae: 23.2521 - val_loss: 22.9342 - val_mae: 22.9197 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 22.9879 - mae: 22.9733 - val_loss: 22.5920 - val_mae: 22.5771 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 22.7532 - mae: 22.7381 - val_loss: 21.9935 - val_mae: 21.9781 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 22.1673 - mae: 22.1516 - val_loss: 21.7626 - val_mae: 21.7466 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 44.1960\n",
      "LV_RMSE_12h: 80.7945\n",
      "LV_MAE_24h: 16.7291\n",
      "LV_RMSE_24h: 40.6988\n",
      "LV_MAE_48h: 22.8501\n",
      "LV_RMSE_48h: 54.0940\n",
      "LV_MAE_72h: 21.3631\n",
      "LV_RMSE_72h: 53.2928\n",
      "LV_MAE_mean: 26.2846\n",
      "LV_RMSE_mean: 57.2200\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 18.1703\n",
      "RMSE_12h: 43.5087\n",
      "MAE_24h: 19.5873\n",
      "RMSE_24h: 46.5436\n",
      "MAE_48h: 19.8411\n",
      "RMSE_48h: 47.2199\n",
      "MAE_72h: 18.3174\n",
      "RMSE_72h: 45.2226\n",
      "MAE_mean: 18.9790\n",
      "RMSE_mean: 45.6237\n",
      "\n",
      "=== Station S3036081 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1377 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1354, 24, 400) Ytr2: (1354, 4) \n",
      "  Xva3: (197, 24, 400) Yva2: (197, 4) \n",
      "  Xte3: (348, 24, 400) Yte2: (348, 4)\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 3s 59ms/step - loss: 1566.2335 - mae: 1566.2208 - val_loss: 1571.2975 - val_mae: 1571.2845 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1561.9075 - mae: 1561.8945 - val_loss: 1565.1156 - val_mae: 1565.1028 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1555.2013 - mae: 1555.1884 - val_loss: 1556.6367 - val_mae: 1556.6234 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1546.6165 - mae: 1546.6028 - val_loss: 1546.2766 - val_mae: 1546.2627 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1535.6965 - mae: 1535.6820 - val_loss: 1533.7463 - val_mae: 1533.7313 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1523.1390 - mae: 1523.1232 - val_loss: 1519.4141 - val_mae: 1519.3976 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1509.0442 - mae: 1509.0267 - val_loss: 1503.7198 - val_mae: 1503.7017 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1492.9125 - mae: 1492.8933 - val_loss: 1486.0812 - val_mae: 1486.0609 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1475.0680 - mae: 1475.0464 - val_loss: 1465.8810 - val_mae: 1465.8582 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1453.6116 - mae: 1453.5873 - val_loss: 1442.7037 - val_mae: 1442.6780 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1429.7434 - mae: 1429.7161 - val_loss: 1415.5023 - val_mae: 1415.4731 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1401.2073 - mae: 1401.1763 - val_loss: 1385.5515 - val_mae: 1385.5184 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1371.5442 - mae: 1371.5093 - val_loss: 1352.4724 - val_mae: 1352.4348 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1338.8650 - mae: 1338.8254 - val_loss: 1317.9073 - val_mae: 1317.8650 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1303.3315 - mae: 1303.2867 - val_loss: 1279.9381 - val_mae: 1279.8903 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1266.5601 - mae: 1266.5096 - val_loss: 1241.1116 - val_mae: 1241.0577 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1228.4819 - mae: 1228.4253 - val_loss: 1199.8872 - val_mae: 1199.8271 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1183.1971 - mae: 1183.1340 - val_loss: 1158.5323 - val_mae: 1158.4652 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1142.7152 - mae: 1142.6449 - val_loss: 1113.2065 - val_mae: 1113.1320 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1098.0778 - mae: 1097.9996 - val_loss: 1066.0942 - val_mae: 1066.0121 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 1888.8160\n",
      "LV_RMSE_12h: 2095.7500\n",
      "LV_MAE_24h: 291.7270\n",
      "LV_RMSE_24h: 447.6775\n",
      "LV_MAE_48h: 376.0833\n",
      "LV_RMSE_48h: 587.2809\n",
      "LV_MAE_72h: 321.2069\n",
      "LV_RMSE_72h: 495.1613\n",
      "LV_MAE_mean: 719.4583\n",
      "LV_RMSE_mean: 906.4675\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 1253.5382\n",
      "RMSE_12h: 1540.6732\n",
      "MAE_24h: 882.3515\n",
      "RMSE_24h: 1187.8286\n",
      "MAE_48h: 900.1505\n",
      "RMSE_48h: 1209.5270\n",
      "MAE_72h: 899.6139\n",
      "RMSE_72h: 1201.9976\n",
      "MAE_mean: 983.9135\n",
      "RMSE_mean: 1285.0066\n",
      "\n",
      "=== Station S3036082 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1377 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1354, 24, 400) Ytr2: (1354, 4) \n",
      "  Xva3: (197, 24, 400) Yva2: (197, 4) \n",
      "  Xte3: (348, 24, 400) Yte2: (348, 4)\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 3s 58ms/step - loss: 371.1745 - mae: 371.1617 - val_loss: 370.1151 - val_mae: 370.1023 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 368.2895 - mae: 368.2766 - val_loss: 366.0742 - val_mae: 366.0612 - lr: 0.0010\n",
      "Epoch 3/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 12ms/step - loss: 363.4898 - mae: 363.4767 - val_loss: 360.1035 - val_mae: 360.0900 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 356.7670 - mae: 356.7532 - val_loss: 352.0634 - val_mae: 352.0490 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 347.6645 - mae: 347.6496 - val_loss: 341.4985 - val_mae: 341.4829 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 335.9230 - mae: 335.9067 - val_loss: 328.4026 - val_mae: 328.3853 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 322.0386 - mae: 322.0203 - val_loss: 312.9948 - val_mae: 312.9753 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 305.0896 - mae: 305.0689 - val_loss: 294.8197 - val_mae: 294.7975 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 286.5457 - mae: 286.5221 - val_loss: 275.1503 - val_mae: 275.1249 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 267.1439 - mae: 267.1170 - val_loss: 255.0795 - val_mae: 255.0506 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 248.4968 - mae: 248.4663 - val_loss: 235.6977 - val_mae: 235.6650 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 229.8978 - mae: 229.8634 - val_loss: 216.3740 - val_mae: 216.3373 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 213.0613 - mae: 213.0228 - val_loss: 199.8765 - val_mae: 199.8357 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 198.3815 - mae: 198.3389 - val_loss: 186.4492 - val_mae: 186.4041 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 185.5462 - mae: 185.4994 - val_loss: 175.4469 - val_mae: 175.3979 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 175.6659 - mae: 175.6153 - val_loss: 165.2038 - val_mae: 165.1510 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 166.2256 - mae: 166.1713 - val_loss: 157.1675 - val_mae: 157.1112 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 158.9238 - mae: 158.8660 - val_loss: 151.6817 - val_mae: 151.6221 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 152.3575 - mae: 152.2964 - val_loss: 143.4702 - val_mae: 143.4073 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 145.5008 - mae: 145.4366 - val_loss: 139.2465 - val_mae: 139.1805 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 532.0057\n",
      "LV_RMSE_12h: 610.3087\n",
      "LV_MAE_24h: 81.0057\n",
      "LV_RMSE_24h: 112.2754\n",
      "LV_MAE_48h: 96.3333\n",
      "LV_RMSE_48h: 139.0347\n",
      "LV_MAE_72h: 92.6523\n",
      "LV_RMSE_72h: 131.1514\n",
      "LV_MAE_mean: 200.4993\n",
      "LV_RMSE_mean: 248.1926\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 302.2388\n",
      "RMSE_12h: 377.7133\n",
      "MAE_24h: 100.4364\n",
      "RMSE_24h: 145.4967\n",
      "MAE_48h: 100.4659\n",
      "RMSE_48h: 143.3361\n",
      "MAE_72h: 101.0946\n",
      "RMSE_72h: 144.2848\n",
      "MAE_mean: 151.0589\n",
      "RMSE_mean: 202.7077\n",
      "\n",
      "=== Station S3036091 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1377 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1354, 24, 400) Ytr2: (1354, 4) \n",
      "  Xva3: (197, 24, 400) Yva2: (197, 4) \n",
      "  Xte3: (348, 24, 400) Yte2: (348, 4)\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 3s 58ms/step - loss: 1622.7460 - mae: 1622.7328 - val_loss: 1598.4592 - val_mae: 1598.4462 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1616.5752 - mae: 1616.5620 - val_loss: 1589.9958 - val_mae: 1589.9825 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1606.6682 - mae: 1606.6549 - val_loss: 1578.7687 - val_mae: 1578.7551 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1594.7781 - mae: 1594.7642 - val_loss: 1565.5613 - val_mae: 1565.5466 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1580.1333 - mae: 1580.1182 - val_loss: 1549.8477 - val_mae: 1549.8319 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 1563.1714 - mae: 1563.1548 - val_loss: 1531.8982 - val_mae: 1531.8807 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 1543.6152 - mae: 1543.5969 - val_loss: 1511.3458 - val_mae: 1511.3262 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1520.9801 - mae: 1520.9594 - val_loss: 1488.7002 - val_mae: 1488.6783 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1496.6495 - mae: 1496.6263 - val_loss: 1465.0293 - val_mae: 1465.0046 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 1473.5536 - mae: 1473.5275 - val_loss: 1441.0332 - val_mae: 1441.0052 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1450.1991 - mae: 1450.1697 - val_loss: 1416.6367 - val_mae: 1416.6053 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1426.6980 - mae: 1426.6650 - val_loss: 1390.7578 - val_mae: 1390.7227 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 1401.5721 - mae: 1401.5356 - val_loss: 1362.7069 - val_mae: 1362.6681 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1374.3555 - mae: 1374.3146 - val_loss: 1331.5746 - val_mae: 1331.5314 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1342.1675 - mae: 1342.1223 - val_loss: 1296.5044 - val_mae: 1296.4565 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1307.0364 - mae: 1306.9862 - val_loss: 1257.5293 - val_mae: 1257.4762 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 1263.8405 - mae: 1263.7848 - val_loss: 1216.5757 - val_mae: 1216.5167 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 1222.4238 - mae: 1222.3623 - val_loss: 1175.2909 - val_mae: 1175.2255 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1183.2484 - mae: 1183.1801 - val_loss: 1132.5942 - val_mae: 1132.5217 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 1140.7810 - mae: 1140.7051 - val_loss: 1086.5566 - val_mae: 1086.4764 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 1844.2787\n",
      "LV_RMSE_12h: 2019.2383\n",
      "LV_MAE_24h: 353.0115\n",
      "LV_RMSE_24h: 594.5275\n",
      "LV_MAE_48h: 473.4138\n",
      "LV_RMSE_48h: 735.4027\n",
      "LV_MAE_72h: 366.9569\n",
      "LV_RMSE_72h: 588.1277\n",
      "LV_MAE_mean: 759.4153\n",
      "LV_RMSE_mean: 984.3240\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 1281.3562\n",
      "RMSE_12h: 1534.7092\n",
      "MAE_24h: 988.7021\n",
      "RMSE_24h: 1262.8296\n",
      "MAE_48h: 954.3290\n",
      "RMSE_48h: 1227.0417\n",
      "MAE_72h: 925.5709\n",
      "RMSE_72h: 1189.8317\n",
      "MAE_mean: 1037.4896\n",
      "RMSE_mean: 1303.6030\n",
      "\n",
      "=== Station S3036092 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1377 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1354, 24, 400) Ytr2: (1354, 4) \n",
      "  Xva3: (197, 24, 400) Yva2: (197, 4) \n",
      "  Xte3: (348, 24, 400) Yte2: (348, 4)\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 3s 59ms/step - loss: 423.3609 - mae: 423.3482 - val_loss: 416.2443 - val_mae: 416.2315 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 419.4359 - mae: 419.4230 - val_loss: 410.7813 - val_mae: 410.7682 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 413.1607 - mae: 413.1473 - val_loss: 403.3257 - val_mae: 403.3120 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 405.2174 - mae: 405.2032 - val_loss: 393.7185 - val_mae: 393.7037 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 394.8199 - mae: 394.8044 - val_loss: 381.7968 - val_mae: 381.7805 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 382.1251 - mae: 382.1079 - val_loss: 367.6541 - val_mae: 367.6357 - lr: 0.0010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 367.0055 - mae: 366.9860 - val_loss: 350.7754 - val_mae: 350.7544 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 349.1749 - mae: 349.1526 - val_loss: 331.3286 - val_mae: 331.3045 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 329.8138 - mae: 329.7882 - val_loss: 309.6652 - val_mae: 309.6375 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 308.2644 - mae: 308.2349 - val_loss: 286.5542 - val_mae: 286.5223 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 286.4114 - mae: 286.3774 - val_loss: 263.8052 - val_mae: 263.7686 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 264.4803 - mae: 264.4415 - val_loss: 240.1988 - val_mae: 240.1571 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 243.5363 - mae: 243.4924 - val_loss: 218.6261 - val_mae: 218.5792 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 223.3741 - mae: 223.3249 - val_loss: 200.2846 - val_mae: 200.2323 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 205.6350 - mae: 205.5804 - val_loss: 184.5231 - val_mae: 184.4655 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 191.9309 - mae: 191.8711 - val_loss: 171.5165 - val_mae: 171.4539 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 182.2798 - mae: 182.2154 - val_loss: 162.0540 - val_mae: 161.9872 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 174.4326 - mae: 174.3643 - val_loss: 155.2753 - val_mae: 155.2051 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 170.0510 - mae: 169.9795 - val_loss: 152.7724 - val_mae: 152.6993 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 165.6393 - mae: 165.5650 - val_loss: 147.0687 - val_mae: 146.9929 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 618.0230\n",
      "LV_RMSE_12h: 678.2288\n",
      "LV_MAE_24h: 102.7644\n",
      "LV_RMSE_24h: 156.4700\n",
      "LV_MAE_48h: 125.7672\n",
      "LV_RMSE_48h: 185.8989\n",
      "LV_MAE_72h: 118.3247\n",
      "LV_RMSE_72h: 179.0256\n",
      "LV_MAE_mean: 241.2198\n",
      "LV_RMSE_mean: 299.9058\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 330.2531\n",
      "RMSE_12h: 399.8335\n",
      "MAE_24h: 119.1743\n",
      "RMSE_24h: 171.7384\n",
      "MAE_48h: 107.3731\n",
      "RMSE_48h: 158.2136\n",
      "MAE_72h: 106.4208\n",
      "RMSE_72h: 154.5965\n",
      "MAE_mean: 165.8053\n",
      "RMSE_mean: 221.0955\n",
      "\n",
      "=== Station S3038021 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1375 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1352, 24, 400) Ytr2: (1352, 4) \n",
      "  Xva3: (197, 24, 400) Yva2: (197, 4) \n",
      "  Xte3: (347, 24, 400) Yte2: (347, 4)\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 3s 61ms/step - loss: 172.5146 - mae: 172.5018 - val_loss: 170.8207 - val_mae: 170.8079 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 167.0329 - mae: 167.0200 - val_loss: 162.6968 - val_mae: 162.6838 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 158.0183 - mae: 158.0051 - val_loss: 153.1961 - val_mae: 153.1826 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 148.8474 - mae: 148.8336 - val_loss: 144.2921 - val_mae: 144.2779 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 139.1486 - mae: 139.1339 - val_loss: 135.2164 - val_mae: 135.2011 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 129.3443 - mae: 129.3285 - val_loss: 126.0865 - val_mae: 126.0699 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 119.5806 - mae: 119.5633 - val_loss: 116.4616 - val_mae: 116.4435 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 110.1875 - mae: 110.1687 - val_loss: 106.7259 - val_mae: 106.7061 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 100.0112 - mae: 99.9907 - val_loss: 95.8730 - val_mae: 95.8515 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 90.2589 - mae: 90.2366 - val_loss: 87.0121 - val_mae: 86.9888 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 81.6879 - mae: 81.6638 - val_loss: 79.3940 - val_mae: 79.3690 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 74.0598 - mae: 74.0340 - val_loss: 72.3084 - val_mae: 72.2817 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 68.1898 - mae: 68.1623 - val_loss: 67.9486 - val_mae: 67.9202 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 64.4483 - mae: 64.4193 - val_loss: 63.5716 - val_mae: 63.5418 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 61.1843 - mae: 61.1540 - val_loss: 61.1489 - val_mae: 61.1180 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 60.0822 - mae: 60.0509 - val_loss: 59.5211 - val_mae: 59.4893 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 58.4524 - mae: 58.4203 - val_loss: 57.8321 - val_mae: 57.7994 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 57.2412 - mae: 57.2082 - val_loss: 55.3684 - val_mae: 55.3349 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 55.3923 - mae: 55.3586 - val_loss: 56.0439 - val_mae: 56.0096 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 53.7954 - mae: 53.7608 - val_loss: 53.4095 - val_mae: 53.3744 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 227.4236\n",
      "LV_RMSE_12h: 259.3536\n",
      "LV_MAE_24h: 37.3487\n",
      "LV_RMSE_24h: 58.2646\n",
      "LV_MAE_48h: 44.1988\n",
      "LV_RMSE_48h: 66.4666\n",
      "LV_MAE_72h: 40.4294\n",
      "LV_RMSE_72h: 60.9347\n",
      "LV_MAE_mean: 87.3501\n",
      "LV_RMSE_mean: 111.2549\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 124.1526\n",
      "RMSE_12h: 158.9281\n",
      "MAE_24h: 36.9298\n",
      "RMSE_24h: 52.0389\n",
      "MAE_48h: 37.4886\n",
      "RMSE_48h: 52.3524\n",
      "MAE_72h: 38.2245\n",
      "RMSE_72h: 52.8336\n",
      "MAE_mean: 59.1989\n",
      "RMSE_mean: 79.0382\n",
      "\n",
      "=== Station S3038031 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1375 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1352, 24, 400) Ytr2: (1352, 4) \n",
      "  Xva3: (197, 24, 400) Yva2: (197, 4) \n",
      "  Xte3: (347, 24, 400) Yte2: (347, 4)\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 3s 61ms/step - loss: 82.0107 - mae: 81.9979 - val_loss: 78.4996 - val_mae: 78.4869 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 78.2056 - mae: 78.1929 - val_loss: 73.6914 - val_mae: 73.6787 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 72.9117 - mae: 72.8989 - val_loss: 68.5650 - val_mae: 68.5520 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 67.5716 - mae: 67.5584 - val_loss: 63.6718 - val_mae: 63.6583 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 62.9867 - mae: 62.9730 - val_loss: 59.3954 - val_mae: 59.3813 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 58.7090 - mae: 58.6946 - val_loss: 55.6961 - val_mae: 55.6812 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 55.0082 - mae: 54.9930 - val_loss: 52.4342 - val_mae: 52.4186 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 51.4730 - mae: 51.4571 - val_loss: 48.3960 - val_mae: 48.3797 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 46.6872 - mae: 46.6705 - val_loss: 43.3692 - val_mae: 43.3519 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 41.3630 - mae: 41.3454 - val_loss: 37.9334 - val_mae: 37.9152 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 36.2419 - mae: 36.2232 - val_loss: 32.5701 - val_mae: 32.5507 - lr: 0.0010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 32.1487 - mae: 32.1289 - val_loss: 28.8653 - val_mae: 28.8449 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 29.3921 - mae: 29.3714 - val_loss: 26.9188 - val_mae: 26.8977 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 28.0675 - mae: 28.0461 - val_loss: 25.5021 - val_mae: 25.4805 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 26.8803 - mae: 26.8583 - val_loss: 24.1098 - val_mae: 24.0875 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 25.4361 - mae: 25.4135 - val_loss: 22.5219 - val_mae: 22.4989 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 23.8475 - mae: 23.8241 - val_loss: 20.8892 - val_mae: 20.8653 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 21.9280 - mae: 21.9037 - val_loss: 19.1215 - val_mae: 19.0965 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 20.6501 - mae: 20.6246 - val_loss: 17.0080 - val_mae: 16.9819 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 18.9988 - mae: 18.9722 - val_loss: 15.1104 - val_mae: 15.0831 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 116.1210\n",
      "LV_RMSE_12h: 126.3674\n",
      "LV_MAE_24h: 20.3545\n",
      "LV_RMSE_24h: 31.1744\n",
      "LV_MAE_48h: 22.5793\n",
      "LV_RMSE_48h: 34.8611\n",
      "LV_MAE_72h: 20.4409\n",
      "LV_RMSE_72h: 31.4431\n",
      "LV_MAE_mean: 44.8739\n",
      "LV_RMSE_mean: 55.9615\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 22.5746\n",
      "RMSE_12h: 30.8798\n",
      "MAE_24h: 17.8331\n",
      "RMSE_24h: 26.7751\n",
      "MAE_48h: 17.8443\n",
      "RMSE_48h: 26.7129\n",
      "MAE_72h: 18.1147\n",
      "RMSE_72h: 26.9809\n",
      "MAE_mean: 19.0917\n",
      "RMSE_mean: 27.8372\n",
      "\n",
      "=== Station S3038081 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1377 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1354, 24, 400) Ytr2: (1354, 4) \n",
      "  Xva3: (197, 24, 400) Yva2: (197, 4) \n",
      "  Xte3: (348, 24, 400) Yte2: (348, 4)\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 3s 60ms/step - loss: 1599.6339 - mae: 1599.6210 - val_loss: 1584.9648 - val_mae: 1584.9518 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1592.9081 - mae: 1592.8949 - val_loss: 1574.6344 - val_mae: 1574.6211 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 1580.2528 - mae: 1580.2393 - val_loss: 1559.5038 - val_mae: 1559.4897 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1563.4862 - mae: 1563.4718 - val_loss: 1540.2123 - val_mae: 1540.1971 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1541.6653 - mae: 1541.6497 - val_loss: 1515.7976 - val_mae: 1515.7808 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 1514.8555 - mae: 1514.8379 - val_loss: 1486.1425 - val_mae: 1486.1235 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1483.2499 - mae: 1483.2297 - val_loss: 1451.6448 - val_mae: 1451.6234 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1446.7167 - mae: 1446.6941 - val_loss: 1414.5552 - val_mae: 1414.5308 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1409.4092 - mae: 1409.3832 - val_loss: 1378.1138 - val_mae: 1378.0858 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 1372.1381 - mae: 1372.1085 - val_loss: 1343.7676 - val_mae: 1343.7361 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1336.6180 - mae: 1336.5850 - val_loss: 1311.4480 - val_mae: 1311.4125 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 1304.5710 - mae: 1304.5336 - val_loss: 1280.0828 - val_mae: 1280.0431 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1271.8121 - mae: 1271.7705 - val_loss: 1249.8948 - val_mae: 1249.8507 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1239.8574 - mae: 1239.8114 - val_loss: 1220.3960 - val_mae: 1220.3473 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1209.8486 - mae: 1209.7979 - val_loss: 1190.7390 - val_mae: 1190.6855 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1181.7103 - mae: 1181.6547 - val_loss: 1162.1691 - val_mae: 1162.1107 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1153.3026 - mae: 1153.2419 - val_loss: 1134.3235 - val_mae: 1134.2600 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1124.2369 - mae: 1124.1714 - val_loss: 1107.8049 - val_mae: 1107.7361 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1098.0931 - mae: 1098.0222 - val_loss: 1080.7151 - val_mae: 1080.6409 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1071.3711 - mae: 1071.2944 - val_loss: 1047.3046 - val_mae: 1047.2246 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 1921.2271\n",
      "LV_RMSE_12h: 2185.2903\n",
      "LV_MAE_24h: 309.4310\n",
      "LV_RMSE_24h: 439.4146\n",
      "LV_MAE_48h: 377.3793\n",
      "LV_RMSE_48h: 527.7210\n",
      "LV_MAE_72h: 352.9454\n",
      "LV_RMSE_72h: 483.7874\n",
      "LV_MAE_mean: 740.2457\n",
      "LV_RMSE_mean: 909.0533\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 1129.7983\n",
      "RMSE_12h: 1399.3149\n",
      "MAE_24h: 1116.7366\n",
      "RMSE_24h: 1406.9745\n",
      "MAE_48h: 1105.7078\n",
      "RMSE_48h: 1382.2469\n",
      "MAE_72h: 1139.2019\n",
      "RMSE_72h: 1435.5062\n",
      "MAE_mean: 1122.8611\n",
      "RMSE_mean: 1406.0107\n",
      "\n",
      "=== Station S3038083 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1376 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1353, 24, 400) Ytr2: (1353, 4) \n",
      "  Xva3: (197, 24, 400) Yva2: (197, 4) \n",
      "  Xte3: (348, 24, 400) Yte2: (348, 4)\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 3s 59ms/step - loss: 157.6012 - mae: 157.5884 - val_loss: 157.6158 - val_mae: 157.6030 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 152.7673 - mae: 152.7544 - val_loss: 151.2228 - val_mae: 151.2098 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 145.7934 - mae: 145.7803 - val_loss: 143.9671 - val_mae: 143.9537 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 138.3207 - mae: 138.3071 - val_loss: 136.0918 - val_mae: 136.0777 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 130.8822 - mae: 130.8677 - val_loss: 128.4290 - val_mae: 128.4140 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 123.3527 - mae: 123.3372 - val_loss: 121.6517 - val_mae: 121.6356 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 117.0767 - mae: 117.0600 - val_loss: 115.3081 - val_mae: 115.2908 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 111.0119 - mae: 110.9940 - val_loss: 109.9142 - val_mae: 109.8956 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 106.7159 - mae: 106.6966 - val_loss: 105.5127 - val_mae: 105.4928 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 102.6033 - mae: 102.5828 - val_loss: 101.5439 - val_mae: 101.5229 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 98.8003 - mae: 98.7788 - val_loss: 96.1315 - val_mae: 96.1094 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 92.1299 - mae: 92.1073 - val_loss: 88.9182 - val_mae: 88.8950 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 85.1124 - mae: 85.0887 - val_loss: 81.2586 - val_mae: 81.2342 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 76.9987 - mae: 76.9736 - val_loss: 73.4712 - val_mae: 73.4454 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 69.2338 - mae: 69.2073 - val_loss: 66.8352 - val_mae: 66.8079 - lr: 0.0010\n",
      "Epoch 16/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 12ms/step - loss: 63.3556 - mae: 63.3277 - val_loss: 60.5122 - val_mae: 60.4835 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 59.0788 - mae: 59.0496 - val_loss: 55.5751 - val_mae: 55.5451 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 55.8869 - mae: 55.8562 - val_loss: 52.3660 - val_mae: 52.3346 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 53.2429 - mae: 53.2109 - val_loss: 49.6652 - val_mae: 49.6324 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 50.9218 - mae: 50.8885 - val_loss: 48.2213 - val_mae: 48.1872 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 202.1868\n",
      "LV_RMSE_12h: 227.6582\n",
      "LV_MAE_24h: 32.5517\n",
      "LV_RMSE_24h: 47.3720\n",
      "LV_MAE_48h: 40.4138\n",
      "LV_RMSE_48h: 56.9345\n",
      "LV_MAE_72h: 36.7098\n",
      "LV_RMSE_72h: 52.4912\n",
      "LV_MAE_mean: 77.9655\n",
      "LV_RMSE_mean: 96.1140\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 110.9430\n",
      "RMSE_12h: 138.0202\n",
      "MAE_24h: 33.0841\n",
      "RMSE_24h: 46.7842\n",
      "MAE_48h: 33.8078\n",
      "RMSE_48h: 47.5367\n",
      "MAE_72h: 34.0155\n",
      "RMSE_72h: 47.4574\n",
      "MAE_mean: 52.9626\n",
      "RMSE_mean: 69.9496\n",
      "\n",
      "=== Station S3038084 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1376 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1353, 24, 400) Ytr2: (1353, 4) \n",
      "  Xva3: (197, 24, 400) Yva2: (197, 4) \n",
      "  Xte3: (348, 24, 400) Yte2: (348, 4)\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 3s 57ms/step - loss: 58.3582 - mae: 58.3454 - val_loss: 56.3978 - val_mae: 56.3850 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 53.2308 - mae: 53.2180 - val_loss: 50.9254 - val_mae: 50.9124 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 47.8141 - mae: 47.8010 - val_loss: 46.1332 - val_mae: 46.1198 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 43.3028 - mae: 43.2892 - val_loss: 41.5175 - val_mae: 41.5036 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 38.9764 - mae: 38.9622 - val_loss: 37.2895 - val_mae: 37.2748 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 35.2198 - mae: 35.2049 - val_loss: 34.2567 - val_mae: 34.2414 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 32.1704 - mae: 32.1548 - val_loss: 30.8964 - val_mae: 30.8805 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 28.9334 - mae: 28.9172 - val_loss: 27.1234 - val_mae: 27.1069 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 25.6769 - mae: 25.6601 - val_loss: 24.0799 - val_mae: 24.0627 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 23.0903 - mae: 23.0729 - val_loss: 22.0815 - val_mae: 22.0639 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 21.6042 - mae: 21.5863 - val_loss: 20.6740 - val_mae: 20.6559 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 20.4624 - mae: 20.4441 - val_loss: 19.2863 - val_mae: 19.2677 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 19.0196 - mae: 19.0008 - val_loss: 17.8150 - val_mae: 17.7959 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 17.9422 - mae: 17.9229 - val_loss: 16.4788 - val_mae: 16.4591 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 16.7009 - mae: 16.6809 - val_loss: 14.9378 - val_mae: 14.9174 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 15.5950 - mae: 15.5743 - val_loss: 13.7802 - val_mae: 13.7592 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 14.6724 - mae: 14.6511 - val_loss: 12.9891 - val_mae: 12.9676 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 14.5008 - mae: 14.4791 - val_loss: 12.8595 - val_mae: 12.8376 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 14.2542 - mae: 14.2322 - val_loss: 12.4370 - val_mae: 12.4148 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 13.9748 - mae: 13.9526 - val_loss: 12.3021 - val_mae: 12.2799 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 79.8448\n",
      "LV_RMSE_12h: 88.2652\n",
      "LV_MAE_24h: 15.2902\n",
      "LV_RMSE_24h: 21.7830\n",
      "LV_MAE_48h: 17.9023\n",
      "LV_RMSE_48h: 25.7722\n",
      "LV_MAE_72h: 17.0603\n",
      "LV_RMSE_72h: 24.6887\n",
      "LV_MAE_mean: 32.5244\n",
      "LV_RMSE_mean: 40.1273\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 13.8403\n",
      "RMSE_12h: 19.8993\n",
      "MAE_24h: 13.7303\n",
      "RMSE_24h: 19.7398\n",
      "MAE_48h: 13.4527\n",
      "RMSE_48h: 19.2175\n",
      "MAE_72h: 13.3247\n",
      "RMSE_72h: 18.9339\n",
      "MAE_mean: 13.5870\n",
      "RMSE_mean: 19.4476\n",
      "\n",
      "=== Station S3038085 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1132 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1109, 24, 400) Ytr2: (1109, 4) \n",
      "  Xva3: (162, 24, 400) Yva2: (162, 4) \n",
      "  Xte3: (278, 24, 400) Yte2: (278, 4)\n",
      "Epoch 1/20\n",
      "9/9 [==============================] - 3s 71ms/step - loss: 54.7418 - mae: 54.7293 - val_loss: 49.4145 - val_mae: 49.4020 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 51.2386 - mae: 51.2259 - val_loss: 45.2767 - val_mae: 45.2639 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 47.2223 - mae: 47.2094 - val_loss: 41.3042 - val_mae: 41.2912 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 43.6555 - mae: 43.6422 - val_loss: 37.8623 - val_mae: 37.8488 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 40.4991 - mae: 40.4853 - val_loss: 35.0053 - val_mae: 34.9912 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 37.3883 - mae: 37.3740 - val_loss: 31.9220 - val_mae: 31.9074 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 33.9034 - mae: 33.8886 - val_loss: 28.3621 - val_mae: 28.3469 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 30.1239 - mae: 30.1084 - val_loss: 24.5721 - val_mae: 24.5562 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 26.3501 - mae: 26.3338 - val_loss: 21.7354 - val_mae: 21.7187 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 23.4200 - mae: 23.4030 - val_loss: 19.7848 - val_mae: 19.7673 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 21.4442 - mae: 21.4265 - val_loss: 18.6373 - val_mae: 18.6193 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 20.5146 - mae: 20.4964 - val_loss: 17.8904 - val_mae: 17.8720 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 19.7785 - mae: 19.7599 - val_loss: 17.1411 - val_mae: 17.1223 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "9/9 [==============================] - 0s 18ms/step - loss: 18.8541 - mae: 18.8352 - val_loss: 15.9145 - val_mae: 15.8954 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 17.8343 - mae: 17.8149 - val_loss: 15.1236 - val_mae: 15.1041 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 17.1867 - mae: 17.1670 - val_loss: 13.8290 - val_mae: 13.8090 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 16.3266 - mae: 16.3064 - val_loss: 12.9491 - val_mae: 12.9286 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 15.2089 - mae: 15.1881 - val_loss: 12.4075 - val_mae: 12.3864 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 14.5705 - mae: 14.5492 - val_loss: 11.6390 - val_mae: 11.6174 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 14.2512 - mae: 14.2294 - val_loss: 11.4369 - val_mae: 11.4148 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 76.0036\n",
      "LV_RMSE_12h: 84.1625\n",
      "LV_MAE_24h: 12.9676\n",
      "LV_RMSE_24h: 19.1444\n",
      "LV_MAE_48h: 16.3849\n",
      "LV_RMSE_48h: 25.3527\n",
      "LV_MAE_72h: 14.5036\n",
      "LV_RMSE_72h: 23.6541\n",
      "LV_MAE_mean: 29.9649\n",
      "LV_RMSE_mean: 38.0784\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 14.8005\n",
      "RMSE_12h: 21.5970\n",
      "MAE_24h: 14.2227\n",
      "RMSE_24h: 20.4168\n",
      "MAE_48h: 14.6750\n",
      "RMSE_48h: 22.8886\n",
      "MAE_72h: 14.3476\n",
      "RMSE_72h: 22.4704\n",
      "MAE_mean: 14.5114\n",
      "RMSE_mean: 21.8432\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Station S3038091 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1377 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1354, 24, 400) Ytr2: (1354, 4) \n",
      "  Xva3: (197, 24, 400) Yva2: (197, 4) \n",
      "  Xte3: (348, 24, 400) Yte2: (348, 4)\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 3s 60ms/step - loss: 1613.1847 - mae: 1613.1722 - val_loss: 1573.0270 - val_mae: 1573.0143 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1607.0490 - mae: 1607.0364 - val_loss: 1564.2321 - val_mae: 1564.2192 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1596.3976 - mae: 1596.3844 - val_loss: 1551.1801 - val_mae: 1551.1669 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1581.8724 - mae: 1581.8589 - val_loss: 1534.2621 - val_mae: 1534.2478 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1562.9651 - mae: 1562.9503 - val_loss: 1512.7745 - val_mae: 1512.7589 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1539.4449 - mae: 1539.4286 - val_loss: 1486.3184 - val_mae: 1486.3008 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1511.2407 - mae: 1511.2222 - val_loss: 1454.8903 - val_mae: 1454.8704 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1477.7009 - mae: 1477.6798 - val_loss: 1419.0889 - val_mae: 1419.0660 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 1442.1772 - mae: 1442.1532 - val_loss: 1382.6859 - val_mae: 1382.6600 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1406.5315 - mae: 1406.5043 - val_loss: 1349.2202 - val_mae: 1349.1907 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1372.4093 - mae: 1372.3784 - val_loss: 1318.0271 - val_mae: 1317.9940 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1341.0304 - mae: 1340.9956 - val_loss: 1288.6097 - val_mae: 1288.5728 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1311.0017 - mae: 1310.9631 - val_loss: 1260.7999 - val_mae: 1260.7589 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1282.3275 - mae: 1282.2847 - val_loss: 1233.2931 - val_mae: 1233.2480 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1255.4407 - mae: 1255.3938 - val_loss: 1207.3307 - val_mae: 1207.2812 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 0s 17ms/step - loss: 1231.8589 - mae: 1231.8075 - val_loss: 1183.0536 - val_mae: 1182.9996 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1206.2343 - mae: 1206.1783 - val_loss: 1159.8812 - val_mae: 1159.8226 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1183.4517 - mae: 1183.3915 - val_loss: 1137.0149 - val_mae: 1136.9520 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 1159.1687 - mae: 1159.1036 - val_loss: 1108.6284 - val_mae: 1108.5608 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1130.4503 - mae: 1130.3806 - val_loss: 1077.0753 - val_mae: 1077.0028 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 2032.5144\n",
      "LV_RMSE_12h: 2237.3857\n",
      "LV_MAE_24h: 353.7701\n",
      "LV_RMSE_24h: 507.7851\n",
      "LV_MAE_48h: 385.2902\n",
      "LV_RMSE_48h: 548.6862\n",
      "LV_MAE_72h: 347.7385\n",
      "LV_RMSE_72h: 491.3590\n",
      "LV_MAE_mean: 779.8283\n",
      "LV_RMSE_mean: 946.3041\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 1211.3175\n",
      "RMSE_12h: 1534.3386\n",
      "MAE_24h: 1112.0743\n",
      "RMSE_24h: 1434.6215\n",
      "MAE_48h: 1112.4530\n",
      "RMSE_48h: 1447.6956\n",
      "MAE_72h: 1114.4723\n",
      "RMSE_72h: 1454.4709\n",
      "MAE_mean: 1137.5792\n",
      "RMSE_mean: 1467.7815\n",
      "\n",
      "=== Station S3038092 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1376 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1353, 24, 400) Ytr2: (1353, 4) \n",
      "  Xva3: (197, 24, 400) Yva2: (197, 4) \n",
      "  Xte3: (348, 24, 400) Yte2: (348, 4)\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 3s 58ms/step - loss: 64.1429 - mae: 64.1301 - val_loss: 70.6485 - val_mae: 70.6356 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 60.1220 - mae: 60.1092 - val_loss: 65.5646 - val_mae: 65.5516 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 55.0448 - mae: 55.0316 - val_loss: 60.1985 - val_mae: 60.1850 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 50.5616 - mae: 50.5479 - val_loss: 56.0246 - val_mae: 56.0106 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 46.9161 - mae: 46.9017 - val_loss: 52.7775 - val_mae: 52.7627 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 43.7837 - mae: 43.7687 - val_loss: 49.6176 - val_mae: 49.6022 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 40.3199 - mae: 40.3041 - val_loss: 45.2836 - val_mae: 45.2674 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 35.9131 - mae: 35.8966 - val_loss: 40.5383 - val_mae: 40.5213 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 31.8815 - mae: 31.8642 - val_loss: 36.2709 - val_mae: 36.2532 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 28.5058 - mae: 28.4878 - val_loss: 33.1333 - val_mae: 33.1150 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 26.3862 - mae: 26.3676 - val_loss: 30.9836 - val_mae: 30.9647 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 24.9875 - mae: 24.9684 - val_loss: 29.2288 - val_mae: 29.2095 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 23.7315 - mae: 23.7119 - val_loss: 28.0163 - val_mae: 27.9963 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 22.2863 - mae: 22.2660 - val_loss: 26.8904 - val_mae: 26.8697 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 20.8610 - mae: 20.8400 - val_loss: 25.1642 - val_mae: 25.1427 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 19.3565 - mae: 19.3346 - val_loss: 23.0470 - val_mae: 23.0245 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 18.2118 - mae: 18.1888 - val_loss: 21.6506 - val_mae: 21.6271 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 17.5735 - mae: 17.5497 - val_loss: 20.5679 - val_mae: 20.5436 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 17.1209 - mae: 17.0965 - val_loss: 20.4360 - val_mae: 20.4114 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 16.7765 - mae: 16.7519 - val_loss: 20.2362 - val_mae: 20.2114 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 84.6063\n",
      "LV_RMSE_12h: 93.5575\n",
      "LV_MAE_24h: 19.0575\n",
      "LV_RMSE_24h: 27.5136\n",
      "LV_MAE_48h: 22.8851\n",
      "LV_RMSE_48h: 33.8722\n",
      "LV_MAE_72h: 19.9713\n",
      "LV_RMSE_72h: 31.6151\n",
      "LV_MAE_mean: 36.6300\n",
      "LV_RMSE_mean: 46.6396\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 18.0910\n",
      "RMSE_12h: 26.5461\n",
      "MAE_24h: 18.4136\n",
      "RMSE_24h: 27.3817\n",
      "MAE_48h: 17.6313\n",
      "RMSE_48h: 25.7980\n",
      "MAE_72h: 17.4608\n",
      "RMSE_72h: 25.2500\n",
      "MAE_mean: 17.8992\n",
      "RMSE_mean: 26.2440\n",
      "\n",
      "=== Station S3038094 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1377 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1354, 24, 400) Ytr2: (1354, 4) \n",
      "  Xva3: (197, 24, 400) Yva2: (197, 4) \n",
      "  Xte3: (348, 24, 400) Yte2: (348, 4)\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 3s 58ms/step - loss: 1105.4207 - mae: 1105.4078 - val_loss: 1139.4807 - val_mae: 1139.4679 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 1099.1637 - mae: 1099.1506 - val_loss: 1130.7494 - val_mae: 1130.7363 - lr: 0.0010\n",
      "Epoch 3/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 13ms/step - loss: 1088.4624 - mae: 1088.4491 - val_loss: 1117.9950 - val_mae: 1117.9813 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1074.3224 - mae: 1074.3083 - val_loss: 1101.5312 - val_mae: 1101.5166 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1055.8799 - mae: 1055.8649 - val_loss: 1080.6289 - val_mae: 1080.6130 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 1032.6951 - mae: 1032.6785 - val_loss: 1054.6810 - val_mae: 1054.6635 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1004.4773 - mae: 1004.4587 - val_loss: 1023.7111 - val_mae: 1023.6913 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 971.0195 - mae: 970.9987 - val_loss: 987.4839 - val_mae: 987.4614 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 933.1819 - mae: 933.1580 - val_loss: 945.6734 - val_mae: 945.6477 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 888.2253 - mae: 888.1981 - val_loss: 898.5089 - val_mae: 898.4794 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 841.0141 - mae: 840.9829 - val_loss: 846.5956 - val_mae: 846.5621 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 790.2557 - mae: 790.2202 - val_loss: 790.4409 - val_mae: 790.4028 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 737.5082 - mae: 737.4679 - val_loss: 731.6123 - val_mae: 731.5692 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 685.2696 - mae: 685.2243 - val_loss: 676.2448 - val_mae: 676.1965 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 638.0287 - mae: 637.9782 - val_loss: 631.9415 - val_mae: 631.8881 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 599.8959 - mae: 599.8405 - val_loss: 598.4413 - val_mae: 598.3831 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 572.7263 - mae: 572.6660 - val_loss: 571.4293 - val_mae: 571.3665 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 546.3836 - mae: 546.3190 - val_loss: 549.4970 - val_mae: 549.4300 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 528.9371 - mae: 528.8682 - val_loss: 529.9031 - val_mae: 529.8319 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 513.9436 - mae: 513.8708 - val_loss: 513.6036 - val_mae: 513.5288 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 894.6580\n",
      "LV_RMSE_12h: 997.2106\n",
      "LV_MAE_24h: 164.5431\n",
      "LV_RMSE_24h: 229.5393\n",
      "LV_MAE_48h: 221.5718\n",
      "LV_RMSE_48h: 295.8591\n",
      "LV_MAE_72h: 188.4138\n",
      "LV_RMSE_72h: 258.2531\n",
      "LV_MAE_mean: 367.2967\n",
      "LV_RMSE_mean: 445.2155\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 541.7622\n",
      "RMSE_12h: 665.6432\n",
      "MAE_24h: 524.0604\n",
      "RMSE_24h: 635.2694\n",
      "MAE_48h: 523.1934\n",
      "RMSE_48h: 635.4249\n",
      "MAE_72h: 550.9830\n",
      "RMSE_72h: 680.6491\n",
      "MAE_mean: 534.9998\n",
      "RMSE_mean: 654.2466\n",
      "\n",
      "=== Station S3038096 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1132 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1109, 24, 400) Ytr2: (1109, 4) \n",
      "  Xva3: (162, 24, 400) Yva2: (162, 4) \n",
      "  Xte3: (278, 24, 400) Yte2: (278, 4)\n",
      "Epoch 1/20\n",
      "9/9 [==============================] - 3s 70ms/step - loss: 113.0258 - mae: 113.0132 - val_loss: 107.8372 - val_mae: 107.8246 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 110.3024 - mae: 110.2899 - val_loss: 104.1263 - val_mae: 104.1137 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 105.9910 - mae: 105.9783 - val_loss: 99.3380 - val_mae: 99.3251 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 101.5310 - mae: 101.5180 - val_loss: 94.9852 - val_mae: 94.9720 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 97.5434 - mae: 97.5300 - val_loss: 90.9892 - val_mae: 90.9755 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 93.7891 - mae: 93.7752 - val_loss: 87.1764 - val_mae: 87.1622 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 90.1206 - mae: 90.1060 - val_loss: 83.5503 - val_mae: 83.5353 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 86.9367 - mae: 86.9215 - val_loss: 79.9317 - val_mae: 79.9160 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 83.5207 - mae: 83.5046 - val_loss: 76.1472 - val_mae: 76.1307 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 79.6531 - mae: 79.6363 - val_loss: 72.0870 - val_mae: 72.0696 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 75.2999 - mae: 75.2822 - val_loss: 67.4032 - val_mae: 67.3850 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 70.2767 - mae: 70.2581 - val_loss: 61.7725 - val_mae: 61.7532 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 64.6257 - mae: 64.6059 - val_loss: 56.3021 - val_mae: 56.2816 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 58.3616 - mae: 58.3405 - val_loss: 50.0783 - val_mae: 50.0564 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 52.7430 - mae: 52.7206 - val_loss: 46.1760 - val_mae: 46.1527 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 49.2447 - mae: 49.2210 - val_loss: 43.2526 - val_mae: 43.2282 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 47.0137 - mae: 46.9889 - val_loss: 41.1776 - val_mae: 41.1523 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 44.9927 - mae: 44.9670 - val_loss: 39.4023 - val_mae: 39.3761 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 43.3996 - mae: 43.3731 - val_loss: 37.8719 - val_mae: 37.8448 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 42.2000 - mae: 42.1726 - val_loss: 36.4485 - val_mae: 36.4206 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 143.9101\n",
      "LV_RMSE_12h: 162.1686\n",
      "LV_MAE_24h: 27.8130\n",
      "LV_RMSE_24h: 41.8054\n",
      "LV_MAE_48h: 37.7338\n",
      "LV_RMSE_48h: 55.8245\n",
      "LV_MAE_72h: 30.7518\n",
      "LV_RMSE_72h: 49.4782\n",
      "LV_MAE_mean: 60.0522\n",
      "LV_RMSE_mean: 77.3192\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 71.4628\n",
      "RMSE_12h: 96.1744\n",
      "MAE_24h: 34.4309\n",
      "RMSE_24h: 49.0782\n",
      "MAE_48h: 33.9273\n",
      "RMSE_48h: 50.4028\n",
      "MAE_72h: 32.6906\n",
      "RMSE_72h: 48.6597\n",
      "MAE_mean: 43.1279\n",
      "RMSE_mean: 61.0788\n",
      "\n",
      "=== Station S3038097 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1376 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1353, 24, 400) Ytr2: (1353, 4) \n",
      "  Xva3: (197, 24, 400) Yva2: (197, 4) \n",
      "  Xte3: (348, 24, 400) Yte2: (348, 4)\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 3s 58ms/step - loss: 135.7493 - mae: 135.7366 - val_loss: 134.4449 - val_mae: 134.4321 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 129.8016 - mae: 129.7888 - val_loss: 127.1921 - val_mae: 127.1791 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 122.7062 - mae: 122.6931 - val_loss: 120.2531 - val_mae: 120.2397 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 115.6764 - mae: 115.6627 - val_loss: 113.1632 - val_mae: 113.1491 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 108.9464 - mae: 108.9318 - val_loss: 106.1082 - val_mae: 106.0930 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 102.7405 - mae: 102.7248 - val_loss: 100.0085 - val_mae: 99.9921 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 97.4504 - mae: 97.4335 - val_loss: 95.6041 - val_mae: 95.5865 - lr: 0.0010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 93.0082 - mae: 92.9902 - val_loss: 91.7483 - val_mae: 91.7296 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 89.1880 - mae: 89.1688 - val_loss: 86.9450 - val_mae: 86.9253 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 83.6040 - mae: 83.5839 - val_loss: 80.3461 - val_mae: 80.3254 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 76.2468 - mae: 76.2255 - val_loss: 72.6472 - val_mae: 72.6251 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 69.1008 - mae: 69.0782 - val_loss: 65.8130 - val_mae: 65.7896 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 63.4838 - mae: 63.4598 - val_loss: 60.1152 - val_mae: 60.0906 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 59.9092 - mae: 59.8841 - val_loss: 57.1526 - val_mae: 57.1271 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 56.7888 - mae: 56.7629 - val_loss: 54.4071 - val_mae: 54.3807 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 55.5108 - mae: 55.4841 - val_loss: 53.4434 - val_mae: 53.4163 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 53.5855 - mae: 53.5581 - val_loss: 51.6336 - val_mae: 51.6057 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 52.6256 - mae: 52.5972 - val_loss: 50.3175 - val_mae: 50.2886 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 50.7248 - mae: 50.6955 - val_loss: 48.4724 - val_mae: 48.4426 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 48.8111 - mae: 48.7807 - val_loss: 46.1517 - val_mae: 46.1207 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 172.5862\n",
      "LV_RMSE_12h: 193.8524\n",
      "LV_MAE_24h: 34.4397\n",
      "LV_RMSE_24h: 50.8365\n",
      "LV_MAE_48h: 45.5115\n",
      "LV_RMSE_48h: 66.9505\n",
      "LV_MAE_72h: 40.3822\n",
      "LV_RMSE_72h: 61.2948\n",
      "LV_MAE_mean: 73.2299\n",
      "LV_RMSE_mean: 93.2336\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 80.1139\n",
      "RMSE_12h: 109.4742\n",
      "MAE_24h: 34.6278\n",
      "RMSE_24h: 52.5987\n",
      "MAE_48h: 32.7792\n",
      "RMSE_48h: 49.4116\n",
      "MAE_72h: 34.1887\n",
      "RMSE_72h: 50.7251\n",
      "MAE_mean: 45.4274\n",
      "RMSE_mean: 65.5524\n",
      "\n",
      "=== Station S3038098 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1376 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1353, 24, 400) Ytr2: (1353, 4) \n",
      "  Xva3: (197, 24, 400) Yva2: (197, 4) \n",
      "  Xte3: (348, 24, 400) Yte2: (348, 4)\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 3s 59ms/step - loss: 161.6469 - mae: 161.6340 - val_loss: 156.4663 - val_mae: 156.4534 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 155.5256 - mae: 155.5126 - val_loss: 149.1951 - val_mae: 149.1820 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 148.4078 - mae: 148.3945 - val_loss: 141.8812 - val_mae: 141.8677 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 141.4836 - mae: 141.4698 - val_loss: 135.4342 - val_mae: 135.4200 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 135.2172 - mae: 135.2026 - val_loss: 128.8526 - val_mae: 128.8374 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 129.2761 - mae: 129.2605 - val_loss: 122.9317 - val_mae: 122.9155 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 123.7274 - mae: 123.7107 - val_loss: 117.1556 - val_mae: 117.1382 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 117.9570 - mae: 117.9391 - val_loss: 110.8437 - val_mae: 110.8251 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 111.4771 - mae: 111.4579 - val_loss: 104.5546 - val_mae: 104.5347 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 103.6551 - mae: 103.6346 - val_loss: 96.2061 - val_mae: 96.1847 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 94.6149 - mae: 94.5929 - val_loss: 87.0487 - val_mae: 87.0256 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 85.4927 - mae: 85.4688 - val_loss: 77.5778 - val_mae: 77.5528 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 77.2628 - mae: 77.2369 - val_loss: 71.1894 - val_mae: 71.1623 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 71.0747 - mae: 71.0468 - val_loss: 66.7669 - val_mae: 66.7381 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 66.9675 - mae: 66.9381 - val_loss: 63.2846 - val_mae: 63.2546 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 65.2531 - mae: 65.2227 - val_loss: 61.6699 - val_mae: 61.6390 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 63.0852 - mae: 63.0538 - val_loss: 59.8523 - val_mae: 59.8204 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 61.9151 - mae: 61.8828 - val_loss: 57.5791 - val_mae: 57.5463 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 59.8268 - mae: 59.7935 - val_loss: 56.3179 - val_mae: 56.2841 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 57.9895 - mae: 57.9552 - val_loss: 53.8042 - val_mae: 53.7692 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 204.8535\n",
      "LV_RMSE_12h: 229.2051\n",
      "LV_MAE_24h: 36.3621\n",
      "LV_RMSE_24h: 56.9449\n",
      "LV_MAE_48h: 50.0460\n",
      "LV_RMSE_48h: 77.3497\n",
      "LV_MAE_72h: 44.4799\n",
      "LV_RMSE_72h: 72.9575\n",
      "LV_MAE_mean: 83.9353\n",
      "LV_RMSE_mean: 109.1143\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 102.6344\n",
      "RMSE_12h: 138.1751\n",
      "MAE_24h: 43.2791\n",
      "RMSE_24h: 64.6341\n",
      "MAE_48h: 41.6880\n",
      "RMSE_48h: 64.2726\n",
      "MAE_72h: 42.6999\n",
      "RMSE_72h: 64.7831\n",
      "MAE_mean: 57.5753\n",
      "RMSE_mean: 82.9662\n",
      "\n",
      "=== Station S3038099 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1132 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1109, 24, 400) Ytr2: (1109, 4) \n",
      "  Xva3: (162, 24, 400) Yva2: (162, 4) \n",
      "  Xte3: (278, 24, 400) Yte2: (278, 4)\n",
      "Epoch 1/20\n",
      "9/9 [==============================] - 3s 66ms/step - loss: 60.6206 - mae: 60.6078 - val_loss: 58.0508 - val_mae: 58.0380 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 56.6830 - mae: 56.6700 - val_loss: 53.4656 - val_mae: 53.4525 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 51.7431 - mae: 51.7300 - val_loss: 48.6694 - val_mae: 48.6561 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 47.3209 - mae: 47.3074 - val_loss: 44.4066 - val_mae: 44.3927 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 43.2131 - mae: 43.1990 - val_loss: 40.4972 - val_mae: 40.4828 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 39.8480 - mae: 39.8334 - val_loss: 36.9556 - val_mae: 36.9405 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 36.7987 - mae: 36.7834 - val_loss: 33.7892 - val_mae: 33.7736 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 33.8003 - mae: 33.7844 - val_loss: 31.2936 - val_mae: 31.2774 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 31.3385 - mae: 31.3221 - val_loss: 29.3650 - val_mae: 29.3484 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 29.0978 - mae: 29.0810 - val_loss: 27.1965 - val_mae: 27.1794 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 26.6442 - mae: 26.6270 - val_loss: 25.5849 - val_mae: 25.5675 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 24.9635 - mae: 24.9459 - val_loss: 23.9669 - val_mae: 23.9492 - lr: 0.0010\n",
      "Epoch 13/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 14ms/step - loss: 23.6288 - mae: 23.6109 - val_loss: 23.2524 - val_mae: 23.2343 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 22.9020 - mae: 22.8838 - val_loss: 22.1869 - val_mae: 22.1684 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 21.8664 - mae: 21.8478 - val_loss: 21.2310 - val_mae: 21.2122 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 21.0083 - mae: 20.9893 - val_loss: 20.5321 - val_mae: 20.5129 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 20.3301 - mae: 20.3107 - val_loss: 19.5539 - val_mae: 19.5342 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 19.4102 - mae: 19.3903 - val_loss: 18.6061 - val_mae: 18.5859 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 18.3075 - mae: 18.2871 - val_loss: 17.4152 - val_mae: 17.3946 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 17.7465 - mae: 17.7257 - val_loss: 16.5358 - val_mae: 16.5146 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 72.2194\n",
      "LV_RMSE_12h: 83.6844\n",
      "LV_MAE_24h: 14.8345\n",
      "LV_RMSE_24h: 21.0193\n",
      "LV_MAE_48h: 18.3813\n",
      "LV_RMSE_48h: 26.0781\n",
      "LV_MAE_72h: 15.6367\n",
      "LV_RMSE_72h: 22.9266\n",
      "LV_MAE_mean: 30.2680\n",
      "LV_RMSE_mean: 38.4271\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 21.3687\n",
      "RMSE_12h: 30.3598\n",
      "MAE_24h: 17.1118\n",
      "RMSE_24h: 23.5060\n",
      "MAE_48h: 16.5934\n",
      "RMSE_48h: 23.0111\n",
      "MAE_72h: 15.5083\n",
      "RMSE_72h: 21.7014\n",
      "MAE_mean: 17.6456\n",
      "RMSE_mean: 24.6446\n",
      "\n",
      "=== Station S3038101 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1377 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1354, 24, 400) Ytr2: (1354, 4) \n",
      "  Xva3: (197, 24, 400) Yva2: (197, 4) \n",
      "  Xte3: (348, 24, 400) Yte2: (348, 4)\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 3s 57ms/step - loss: 1939.8843 - mae: 1939.8715 - val_loss: 1904.8103 - val_mae: 1904.7975 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1934.5886 - mae: 1934.5757 - val_loss: 1897.4581 - val_mae: 1897.4449 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1925.8093 - mae: 1925.7960 - val_loss: 1887.1084 - val_mae: 1887.0948 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1914.2524 - mae: 1914.2385 - val_loss: 1873.4756 - val_mae: 1873.4612 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1898.6445 - mae: 1898.6296 - val_loss: 1855.9620 - val_mae: 1855.9464 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 1879.4104 - mae: 1879.3942 - val_loss: 1834.5027 - val_mae: 1834.4856 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1856.3177 - mae: 1856.2997 - val_loss: 1808.7069 - val_mae: 1808.6879 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1828.3445 - mae: 1828.3246 - val_loss: 1778.3137 - val_mae: 1778.2924 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1795.9482 - mae: 1795.9255 - val_loss: 1743.1965 - val_mae: 1743.1722 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1758.4135 - mae: 1758.3879 - val_loss: 1703.5234 - val_mae: 1703.4962 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1717.4304 - mae: 1717.4012 - val_loss: 1659.1709 - val_mae: 1659.1398 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1670.3436 - mae: 1670.3108 - val_loss: 1610.1294 - val_mae: 1610.0942 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1620.7302 - mae: 1620.6931 - val_loss: 1556.4072 - val_mae: 1556.3674 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1564.4856 - mae: 1564.4437 - val_loss: 1498.0264 - val_mae: 1497.9816 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1501.6460 - mae: 1501.5991 - val_loss: 1434.7456 - val_mae: 1434.6954 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 1439.3035 - mae: 1439.2507 - val_loss: 1366.7200 - val_mae: 1366.6641 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1368.2229 - mae: 1368.1642 - val_loss: 1294.0049 - val_mae: 1293.9425 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1290.9535 - mae: 1290.8881 - val_loss: 1216.4431 - val_mae: 1216.3739 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1217.1235 - mae: 1217.0513 - val_loss: 1134.7556 - val_mae: 1134.6792 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1136.7235 - mae: 1136.6438 - val_loss: 1058.7162 - val_mae: 1058.6324 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 1459.8477\n",
      "LV_RMSE_12h: 1645.0990\n",
      "LV_MAE_24h: 271.1897\n",
      "LV_RMSE_24h: 437.7107\n",
      "LV_MAE_48h: 328.0431\n",
      "LV_RMSE_48h: 500.8593\n",
      "LV_MAE_72h: 299.8448\n",
      "LV_RMSE_72h: 477.1335\n",
      "LV_MAE_mean: 589.7313\n",
      "LV_RMSE_mean: 765.2007\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 1105.2485\n",
      "RMSE_12h: 1400.8778\n",
      "MAE_24h: 1095.1283\n",
      "RMSE_24h: 1386.2566\n",
      "MAE_48h: 1146.7665\n",
      "RMSE_48h: 1442.1235\n",
      "MAE_72h: 1136.5177\n",
      "RMSE_72h: 1436.6750\n",
      "MAE_mean: 1120.9153\n",
      "RMSE_mean: 1416.4832\n",
      "\n",
      "=== Station S3038104 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1377 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1354, 24, 400) Ytr2: (1354, 4) \n",
      "  Xva3: (197, 24, 400) Yva2: (197, 4) \n",
      "  Xte3: (348, 24, 400) Yte2: (348, 4)\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 3s 61ms/step - loss: 1428.1538 - mae: 1428.1411 - val_loss: 1378.4385 - val_mae: 1378.4258 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1421.9062 - mae: 1421.8933 - val_loss: 1369.6000 - val_mae: 1369.5869 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1411.1931 - mae: 1411.1801 - val_loss: 1356.8556 - val_mae: 1356.8422 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1397.0032 - mae: 1396.9891 - val_loss: 1340.2650 - val_mae: 1340.2506 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1378.3306 - mae: 1378.3156 - val_loss: 1319.4199 - val_mae: 1319.4043 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1355.4478 - mae: 1355.4314 - val_loss: 1293.7925 - val_mae: 1293.7753 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1327.7776 - mae: 1327.7593 - val_loss: 1263.1145 - val_mae: 1263.0950 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1294.8325 - mae: 1294.8118 - val_loss: 1227.3420 - val_mae: 1227.3197 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1257.2758 - mae: 1257.2523 - val_loss: 1186.3735 - val_mae: 1186.3480 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1213.4373 - mae: 1213.4103 - val_loss: 1140.0654 - val_mae: 1140.0365 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1165.7623 - mae: 1165.7316 - val_loss: 1088.4297 - val_mae: 1088.3966 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 1110.9484 - mae: 1110.9131 - val_loss: 1031.3414 - val_mae: 1031.3037 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1052.2798 - mae: 1052.2396 - val_loss: 968.7641 - val_mae: 968.7213 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 986.9230 - mae: 986.8777 - val_loss: 900.8699 - val_mae: 900.8212 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 918.1382 - mae: 918.0870 - val_loss: 833.4208 - val_mae: 833.3663 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 861.9803 - mae: 861.9233 - val_loss: 786.0834 - val_mae: 786.0231 - lr: 0.0010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/20\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 820.0205 - mae: 819.9578 - val_loss: 756.3085 - val_mae: 756.2429 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 790.8240 - mae: 790.7567 - val_loss: 734.2690 - val_mae: 734.1991 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 771.3237 - mae: 771.2518 - val_loss: 715.3766 - val_mae: 715.3025 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 753.5526 - mae: 753.4767 - val_loss: 698.3558 - val_mae: 698.2778 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 1250.9512\n",
      "LV_RMSE_12h: 1358.4524\n",
      "LV_MAE_24h: 231.2759\n",
      "LV_RMSE_24h: 378.0104\n",
      "LV_MAE_48h: 268.2242\n",
      "LV_RMSE_48h: 417.3820\n",
      "LV_MAE_72h: 229.6408\n",
      "LV_RMSE_72h: 383.9316\n",
      "LV_MAE_mean: 495.0230\n",
      "LV_RMSE_mean: 634.4441\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 718.0811\n",
      "RMSE_12h: 889.0756\n",
      "MAE_24h: 747.0422\n",
      "RMSE_24h: 938.5941\n",
      "MAE_48h: 746.3140\n",
      "RMSE_48h: 942.2034\n",
      "MAE_72h: 737.9291\n",
      "RMSE_72h: 930.9342\n",
      "MAE_mean: 737.3416\n",
      "RMSE_mean: 925.2018\n",
      "\n",
      "=== Station S3038111 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1377 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1354, 24, 400) Ytr2: (1354, 4) \n",
      "  Xva3: (197, 24, 400) Yva2: (197, 4) \n",
      "  Xte3: (348, 24, 400) Yte2: (348, 4)\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 3s 58ms/step - loss: 1569.8536 - mae: 1569.8411 - val_loss: 1533.0886 - val_mae: 1533.0758 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1564.4272 - mae: 1564.4142 - val_loss: 1525.6345 - val_mae: 1525.6215 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1556.0691 - mae: 1556.0559 - val_loss: 1516.2510 - val_mae: 1516.2373 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 1546.4835 - mae: 1546.4695 - val_loss: 1505.5044 - val_mae: 1505.4901 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1535.2151 - mae: 1535.2003 - val_loss: 1493.5194 - val_mae: 1493.5038 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1522.9169 - mae: 1522.9010 - val_loss: 1480.2322 - val_mae: 1480.2151 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1508.8605 - mae: 1508.8427 - val_loss: 1464.7646 - val_mae: 1464.7457 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1492.2904 - mae: 1492.2703 - val_loss: 1445.8081 - val_mae: 1445.7870 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1472.7899 - mae: 1472.7678 - val_loss: 1423.8865 - val_mae: 1423.8627 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1449.9431 - mae: 1449.9183 - val_loss: 1399.4719 - val_mae: 1399.4451 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1425.0148 - mae: 1424.9865 - val_loss: 1372.8322 - val_mae: 1372.8018 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1398.3083 - mae: 1398.2762 - val_loss: 1344.6986 - val_mae: 1344.6641 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1370.2516 - mae: 1370.2151 - val_loss: 1314.8090 - val_mae: 1314.7698 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1340.7748 - mae: 1340.7336 - val_loss: 1284.2622 - val_mae: 1284.2183 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1309.0432 - mae: 1308.9969 - val_loss: 1252.9614 - val_mae: 1252.9120 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1277.4158 - mae: 1277.3639 - val_loss: 1220.6904 - val_mae: 1220.6351 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1242.3871 - mae: 1242.3293 - val_loss: 1184.3729 - val_mae: 1184.3113 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1204.6930 - mae: 1204.6285 - val_loss: 1149.0428 - val_mae: 1148.9742 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1169.8131 - mae: 1169.7412 - val_loss: 1111.3243 - val_mae: 1111.2485 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1131.5708 - mae: 1131.4915 - val_loss: 1073.7363 - val_mae: 1073.6527 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 2254.4656\n",
      "LV_RMSE_12h: 2465.7944\n",
      "LV_MAE_24h: 382.7931\n",
      "LV_RMSE_24h: 570.8718\n",
      "LV_MAE_48h: 422.2270\n",
      "LV_RMSE_48h: 628.4991\n",
      "LV_MAE_72h: 371.2011\n",
      "LV_RMSE_72h: 547.1195\n",
      "LV_MAE_mean: 857.6718\n",
      "LV_RMSE_mean: 1053.0712\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 1443.5294\n",
      "RMSE_12h: 1800.3829\n",
      "MAE_24h: 1028.5476\n",
      "RMSE_24h: 1371.7784\n",
      "MAE_48h: 1059.2715\n",
      "RMSE_48h: 1432.0942\n",
      "MAE_72h: 1017.8946\n",
      "RMSE_72h: 1384.1534\n",
      "MAE_mean: 1137.3108\n",
      "RMSE_mean: 1497.1023\n",
      "\n",
      "=== Station S3039021 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1082 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1059, 24, 400) Ytr2: (1059, 4) \n",
      "  Xva3: (155, 24, 400) Yva2: (155, 4) \n",
      "  Xte3: (264, 24, 400) Yte2: (264, 4)\n",
      "Epoch 1/20\n",
      "9/9 [==============================] - 3s 72ms/step - loss: 592.9998 - mae: 592.9871 - val_loss: 515.6207 - val_mae: 515.6080 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 588.5808 - mae: 588.5680 - val_loss: 509.3351 - val_mae: 509.3223 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 581.0384 - mae: 581.0256 - val_loss: 500.1093 - val_mae: 500.0963 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 570.9611 - mae: 570.9478 - val_loss: 488.6436 - val_mae: 488.6300 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 559.0681 - mae: 559.0542 - val_loss: 475.8317 - val_mae: 475.8174 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 546.1058 - mae: 546.0910 - val_loss: 463.0384 - val_mae: 463.0230 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 533.2263 - mae: 533.2104 - val_loss: 450.0690 - val_mae: 450.0524 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 520.1573 - mae: 520.1401 - val_loss: 437.0063 - val_mae: 436.9883 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 507.6642 - mae: 507.6456 - val_loss: 423.9309 - val_mae: 423.9113 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 494.6094 - mae: 494.5890 - val_loss: 410.9661 - val_mae: 410.9447 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 482.0942 - mae: 482.0720 - val_loss: 397.8435 - val_mae: 397.8201 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 469.2216 - mae: 469.1974 - val_loss: 384.9310 - val_mae: 384.9055 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 456.7029 - mae: 456.6764 - val_loss: 371.5757 - val_mae: 371.5478 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 442.6780 - mae: 442.6492 - val_loss: 358.2786 - val_mae: 358.2483 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 427.9069 - mae: 427.8756 - val_loss: 342.2110 - val_mae: 342.1782 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 409.7498 - mae: 409.7159 - val_loss: 323.3464 - val_mae: 323.3107 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 389.5386 - mae: 389.5017 - val_loss: 305.2889 - val_mae: 305.2501 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 369.0302 - mae: 368.9899 - val_loss: 291.2541 - val_mae: 291.2119 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 350.3197 - mae: 350.2759 - val_loss: 278.3314 - val_mae: 278.2854 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 330.0183 - mae: 329.9708 - val_loss: 262.5498 - val_mae: 262.5000 - lr: 0.0010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 715.3257\n",
      "LV_RMSE_12h: 775.8709\n",
      "LV_MAE_24h: 89.8561\n",
      "LV_RMSE_24h: 147.4222\n",
      "LV_MAE_48h: 113.9015\n",
      "LV_RMSE_48h: 177.9715\n",
      "LV_MAE_72h: 123.1174\n",
      "LV_RMSE_72h: 190.4464\n",
      "LV_MAE_mean: 260.5502\n",
      "LV_RMSE_mean: 322.9278\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 501.8537\n",
      "RMSE_12h: 587.9335\n",
      "MAE_24h: 264.6255\n",
      "RMSE_24h: 351.3783\n",
      "MAE_48h: 273.2762\n",
      "RMSE_48h: 361.6913\n",
      "MAE_72h: 250.4022\n",
      "RMSE_72h: 328.9878\n",
      "MAE_mean: 322.5394\n",
      "RMSE_mean: 407.4977\n",
      "\n",
      "=== Station S3039031 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1131 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1108, 24, 400) Ytr2: (1108, 4) \n",
      "  Xva3: (162, 24, 400) Yva2: (162, 4) \n",
      "  Xte3: (278, 24, 400) Yte2: (278, 4)\n",
      "Epoch 1/20\n",
      "9/9 [==============================] - 3s 72ms/step - loss: 540.8625 - mae: 540.8497 - val_loss: 499.4666 - val_mae: 499.4538 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 535.7653 - mae: 535.7524 - val_loss: 492.3766 - val_mae: 492.3637 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 527.5219 - mae: 527.5089 - val_loss: 482.8130 - val_mae: 482.7998 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 517.9787 - mae: 517.9653 - val_loss: 472.2991 - val_mae: 472.2853 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 507.9308 - mae: 507.9167 - val_loss: 461.4817 - val_mae: 461.4672 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 498.1667 - mae: 498.1518 - val_loss: 451.1596 - val_mae: 451.1441 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 488.5794 - mae: 488.5634 - val_loss: 441.0142 - val_mae: 440.9976 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 479.2719 - mae: 479.2547 - val_loss: 431.0051 - val_mae: 430.9872 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 470.2792 - mae: 470.2607 - val_loss: 421.4246 - val_mae: 421.4052 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 461.2657 - mae: 461.2457 - val_loss: 412.6823 - val_mae: 412.6614 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 452.7304 - mae: 452.7087 - val_loss: 404.0134 - val_mae: 403.9907 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 443.7430 - mae: 443.7195 - val_loss: 395.3528 - val_mae: 395.3283 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 434.7019 - mae: 434.6766 - val_loss: 386.4324 - val_mae: 386.4061 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 425.5995 - mae: 425.5722 - val_loss: 374.4711 - val_mae: 374.4428 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 412.1247 - mae: 412.0954 - val_loss: 362.6632 - val_mae: 362.6327 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 398.4650 - mae: 398.4334 - val_loss: 350.1241 - val_mae: 350.0911 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 382.2862 - mae: 382.2520 - val_loss: 339.2734 - val_mae: 339.2376 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 367.7858 - mae: 367.7487 - val_loss: 327.7407 - val_mae: 327.7018 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 351.3609 - mae: 351.3206 - val_loss: 315.1787 - val_mae: 315.1364 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 333.5344 - mae: 333.4906 - val_loss: 304.3137 - val_mae: 304.2677 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 843.6871\n",
      "LV_RMSE_12h: 895.0858\n",
      "LV_MAE_24h: 71.2662\n",
      "LV_RMSE_24h: 118.0349\n",
      "LV_MAE_48h: 95.8489\n",
      "LV_RMSE_48h: 153.0913\n",
      "LV_MAE_72h: 102.4065\n",
      "LV_RMSE_72h: 163.7846\n",
      "LV_MAE_mean: 278.3022\n",
      "LV_RMSE_mean: 332.4991\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 538.7377\n",
      "RMSE_12h: 665.6935\n",
      "MAE_24h: 253.0070\n",
      "RMSE_24h: 360.6440\n",
      "MAE_48h: 261.0723\n",
      "RMSE_48h: 376.2716\n",
      "MAE_72h: 274.6132\n",
      "RMSE_72h: 395.2381\n",
      "MAE_mean: 331.8575\n",
      "RMSE_mean: 449.4618\n",
      "\n",
      "=== Station S3042051 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1377 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1354, 24, 400) Ytr2: (1354, 4) \n",
      "  Xva3: (197, 24, 400) Yva2: (197, 4) \n",
      "  Xte3: (348, 24, 400) Yte2: (348, 4)\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 3s 60ms/step - loss: 441.3006 - mae: 441.2879 - val_loss: 408.9062 - val_mae: 408.8936 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 435.6309 - mae: 435.6181 - val_loss: 400.5826 - val_mae: 400.5697 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 425.4400 - mae: 425.4269 - val_loss: 388.5250 - val_mae: 388.5116 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 412.6781 - mae: 412.6643 - val_loss: 374.8305 - val_mae: 374.8163 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 397.9886 - mae: 397.9739 - val_loss: 360.7164 - val_mae: 360.7010 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 383.7938 - mae: 383.7779 - val_loss: 346.8313 - val_mae: 346.8146 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 369.6217 - mae: 369.6042 - val_loss: 332.9355 - val_mae: 332.9171 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 355.1550 - mae: 355.1357 - val_loss: 318.9212 - val_mae: 318.9009 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 341.0280 - mae: 341.0068 - val_loss: 306.0550 - val_mae: 306.0326 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 327.7407 - mae: 327.7173 - val_loss: 294.8140 - val_mae: 294.7894 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 315.7461 - mae: 315.7205 - val_loss: 283.9009 - val_mae: 283.8740 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 304.0323 - mae: 304.0044 - val_loss: 273.6097 - val_mae: 273.5805 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 293.2091 - mae: 293.1788 - val_loss: 262.9032 - val_mae: 262.8714 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 281.1779 - mae: 281.1450 - val_loss: 250.4337 - val_mae: 250.3995 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 267.5753 - mae: 267.5399 - val_loss: 236.6293 - val_mae: 236.5924 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 254.2801 - mae: 254.2420 - val_loss: 222.4663 - val_mae: 222.4266 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 238.8339 - mae: 238.7929 - val_loss: 205.5831 - val_mae: 205.5405 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 223.5289 - mae: 223.4849 - val_loss: 191.1830 - val_mae: 191.1372 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 208.5422 - mae: 208.4949 - val_loss: 178.3984 - val_mae: 178.3493 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 197.7461 - mae: 197.6958 - val_loss: 171.4174 - val_mae: 171.3656 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 525.7529\n",
      "LV_RMSE_12h: 595.4470\n",
      "LV_MAE_24h: 108.1207\n",
      "LV_RMSE_24h: 155.5010\n",
      "LV_MAE_48h: 146.8563\n",
      "LV_RMSE_48h: 205.7179\n",
      "LV_MAE_72h: 148.7442\n",
      "LV_RMSE_72h: 215.7128\n",
      "LV_MAE_mean: 232.3685\n",
      "LV_RMSE_mean: 293.0947\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 372.4983\n",
      "RMSE_12h: 447.5963\n",
      "MAE_24h: 143.6046\n",
      "RMSE_24h: 208.4816\n",
      "MAE_48h: 145.0358\n",
      "RMSE_48h: 212.1893\n",
      "MAE_72h: 146.6455\n",
      "RMSE_72h: 211.4212\n",
      "MAE_mean: 201.9460\n",
      "RMSE_mean: 269.9221\n",
      "\n",
      "=== Station S3042061 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1377 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1354, 24, 400) Ytr2: (1354, 4) \n",
      "  Xva3: (197, 24, 400) Yva2: (197, 4) \n",
      "  Xte3: (348, 24, 400) Yte2: (348, 4)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "11/11 [==============================] - 3s 59ms/step - loss: 823.1073 - mae: 823.0945 - val_loss: 796.5190 - val_mae: 796.5061 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 815.1183 - mae: 815.1052 - val_loss: 785.2455 - val_mae: 785.2324 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 801.3058 - mae: 801.2925 - val_loss: 769.0688 - val_mae: 769.0551 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 783.9083 - mae: 783.8941 - val_loss: 749.1812 - val_mae: 749.1663 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 761.6973 - mae: 761.6817 - val_loss: 724.7711 - val_mae: 724.7546 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 735.9993 - mae: 735.9821 - val_loss: 698.1043 - val_mae: 698.0858 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 709.7258 - mae: 709.7065 - val_loss: 671.5201 - val_mae: 671.4994 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 683.3087 - mae: 683.2869 - val_loss: 645.4716 - val_mae: 645.4482 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 656.5372 - mae: 656.5126 - val_loss: 620.0614 - val_mae: 620.0352 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 631.6765 - mae: 631.6490 - val_loss: 596.2918 - val_mae: 596.2625 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 608.2886 - mae: 608.2578 - val_loss: 574.7076 - val_mae: 574.6749 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 586.6301 - mae: 586.5959 - val_loss: 553.7923 - val_mae: 553.7562 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 564.8890 - mae: 564.8514 - val_loss: 532.2307 - val_mae: 532.1912 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 542.9978 - mae: 542.9564 - val_loss: 507.8488 - val_mae: 507.8055 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 515.6501 - mae: 515.6050 - val_loss: 477.4696 - val_mae: 477.4222 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 487.0155 - mae: 486.9663 - val_loss: 448.3061 - val_mae: 448.2544 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 458.0458 - mae: 457.9921 - val_loss: 422.8837 - val_mae: 422.8275 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 433.1416 - mae: 433.0834 - val_loss: 399.6452 - val_mae: 399.5844 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 411.9433 - mae: 411.8804 - val_loss: 378.7075 - val_mae: 378.6420 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 392.0225 - mae: 391.9549 - val_loss: 360.5447 - val_mae: 360.4744 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 855.8132\n",
      "LV_RMSE_12h: 975.8228\n",
      "LV_MAE_24h: 149.8276\n",
      "LV_RMSE_24h: 228.0860\n",
      "LV_MAE_48h: 197.8592\n",
      "LV_RMSE_48h: 300.8870\n",
      "LV_MAE_72h: 170.3305\n",
      "LV_RMSE_72h: 260.3409\n",
      "LV_MAE_mean: 343.4576\n",
      "LV_RMSE_mean: 441.2841\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 599.3727\n",
      "RMSE_12h: 748.0824\n",
      "MAE_24h: 267.5929\n",
      "RMSE_24h: 402.7515\n",
      "MAE_48h: 260.6027\n",
      "RMSE_48h: 396.6840\n",
      "MAE_72h: 265.0074\n",
      "RMSE_72h: 402.2808\n",
      "MAE_mean: 348.1439\n",
      "RMSE_mean: 487.4496\n",
      "\n",
      "=== Station S3043011 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1377 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1354, 24, 400) Ytr2: (1354, 4) \n",
      "  Xva3: (197, 24, 400) Yva2: (197, 4) \n",
      "  Xte3: (348, 24, 400) Yte2: (348, 4)\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 3s 57ms/step - loss: 722.9636 - mae: 722.9509 - val_loss: 408.8514 - val_mae: 408.8386 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 716.7416 - mae: 716.7287 - val_loss: 399.8240 - val_mae: 399.8109 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 706.0204 - mae: 706.0071 - val_loss: 387.6662 - val_mae: 387.6525 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 693.0060 - mae: 692.9919 - val_loss: 374.2094 - val_mae: 374.1947 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 677.6901 - mae: 677.6749 - val_loss: 360.1938 - val_mae: 360.1778 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 661.3463 - mae: 661.3297 - val_loss: 345.8414 - val_mae: 345.8237 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 643.6793 - mae: 643.6608 - val_loss: 330.9695 - val_mae: 330.9498 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 624.2775 - mae: 624.2568 - val_loss: 316.7764 - val_mae: 316.7543 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 603.5007 - mae: 603.4774 - val_loss: 304.0009 - val_mae: 303.9761 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 583.4178 - mae: 583.3918 - val_loss: 291.9205 - val_mae: 291.8927 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 564.2002 - mae: 564.1711 - val_loss: 280.9206 - val_mae: 280.8897 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 546.3877 - mae: 546.3553 - val_loss: 268.8259 - val_mae: 268.7917 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 527.2327 - mae: 527.1970 - val_loss: 251.6814 - val_mae: 251.6439 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 505.1465 - mae: 505.1075 - val_loss: 234.1052 - val_mae: 234.0640 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 483.0912 - mae: 483.0484 - val_loss: 217.6487 - val_mae: 217.6036 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 462.0107 - mae: 461.9637 - val_loss: 205.6829 - val_mae: 205.6336 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 443.2166 - mae: 443.1656 - val_loss: 197.2699 - val_mae: 197.2166 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 427.2292 - mae: 427.1741 - val_loss: 189.9486 - val_mae: 189.8915 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 414.7086 - mae: 414.6498 - val_loss: 189.1899 - val_mae: 189.1292 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 403.9136 - mae: 403.8516 - val_loss: 186.2983 - val_mae: 186.2344 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 555.9368\n",
      "LV_RMSE_12h: 629.6741\n",
      "LV_MAE_24h: 112.3017\n",
      "LV_RMSE_24h: 161.4881\n",
      "LV_MAE_48h: 151.9167\n",
      "LV_RMSE_48h: 213.7334\n",
      "LV_MAE_72h: 155.6006\n",
      "LV_RMSE_72h: 225.4107\n",
      "LV_MAE_mean: 243.9389\n",
      "LV_RMSE_mean: 307.5766\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 422.9670\n",
      "RMSE_12h: 491.8535\n",
      "MAE_24h: 140.4302\n",
      "RMSE_24h: 203.8772\n",
      "MAE_48h: 142.4705\n",
      "RMSE_48h: 203.9114\n",
      "MAE_72h: 141.4305\n",
      "RMSE_72h: 203.5910\n",
      "MAE_mean: 211.8245\n",
      "RMSE_mean: 275.8083\n",
      "\n",
      "=== Station S3043061 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1377 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1354, 24, 400) Ytr2: (1354, 4) \n",
      "  Xva3: (197, 24, 400) Yva2: (197, 4) \n",
      "  Xte3: (348, 24, 400) Yte2: (348, 4)\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 3s 57ms/step - loss: 2688.9338 - mae: 2688.9211 - val_loss: 2644.3616 - val_mae: 2644.3489 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 2682.3638 - mae: 2682.3506 - val_loss: 2635.2847 - val_mae: 2635.2720 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 2671.7686 - mae: 2671.7551 - val_loss: 2623.0337 - val_mae: 2623.0198 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 2658.3054 - mae: 2658.2915 - val_loss: 2607.4309 - val_mae: 2607.4165 - lr: 0.0010\n",
      "Epoch 5/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 13ms/step - loss: 2640.9006 - mae: 2640.8860 - val_loss: 2588.0520 - val_mae: 2588.0364 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 2619.7351 - mae: 2619.7190 - val_loss: 2564.5342 - val_mae: 2564.5171 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 2593.8318 - mae: 2593.8135 - val_loss: 2536.3870 - val_mae: 2536.3679 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 2563.6685 - mae: 2563.6482 - val_loss: 2503.5305 - val_mae: 2503.5088 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 2529.2305 - mae: 2529.2078 - val_loss: 2466.1218 - val_mae: 2466.0977 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 2489.1697 - mae: 2489.1440 - val_loss: 2423.9812 - val_mae: 2423.9536 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 2445.1824 - mae: 2445.1531 - val_loss: 2377.0491 - val_mae: 2377.0178 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 2395.9622 - mae: 2395.9292 - val_loss: 2325.2314 - val_mae: 2325.1960 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 2342.6885 - mae: 2342.6514 - val_loss: 2268.8250 - val_mae: 2268.7849 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 2284.5596 - mae: 2284.5173 - val_loss: 2208.3335 - val_mae: 2208.2886 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 2222.2571 - mae: 2222.2100 - val_loss: 2145.4402 - val_mae: 2145.3899 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 2160.5447 - mae: 2160.4917 - val_loss: 2082.7771 - val_mae: 2082.7209 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 2100.2542 - mae: 2100.1958 - val_loss: 2023.1407 - val_mae: 2023.0787 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 2040.1758 - mae: 2040.1110 - val_loss: 1964.8611 - val_mae: 1964.7930 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 0s 18ms/step - loss: 1982.9016 - mae: 1982.8308 - val_loss: 1906.6394 - val_mae: 1906.5648 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1924.5735 - mae: 1924.4961 - val_loss: 1848.0073 - val_mae: 1847.9263 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 1922.5891\n",
      "LV_RMSE_12h: 2188.2410\n",
      "LV_MAE_24h: 353.1581\n",
      "LV_RMSE_24h: 499.4881\n",
      "LV_MAE_48h: 458.4023\n",
      "LV_RMSE_48h: 636.0926\n",
      "LV_MAE_72h: 419.9655\n",
      "LV_RMSE_72h: 542.5576\n",
      "LV_MAE_mean: 788.5287\n",
      "LV_RMSE_mean: 966.5948\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 1735.2798\n",
      "RMSE_12h: 2054.3557\n",
      "MAE_24h: 1798.8944\n",
      "RMSE_24h: 2108.4897\n",
      "MAE_48h: 1768.8838\n",
      "RMSE_48h: 2079.9688\n",
      "MAE_72h: 1729.7690\n",
      "RMSE_72h: 2039.7723\n",
      "MAE_mean: 1758.2068\n",
      "RMSE_mean: 2070.6467\n",
      "\n",
      "=== Station S3043064 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1376 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1353, 24, 400) Ytr2: (1353, 4) \n",
      "  Xva3: (197, 24, 400) Yva2: (197, 4) \n",
      "  Xte3: (348, 24, 400) Yte2: (348, 4)\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 3s 56ms/step - loss: 2.3622 - mae: 2.3495 - val_loss: 3.5873 - val_mae: 3.5747 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 2.1305 - mae: 2.1179 - val_loss: 3.4035 - val_mae: 3.3909 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 2.0280 - mae: 2.0154 - val_loss: 3.2893 - val_mae: 3.2768 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1.9354 - mae: 1.9228 - val_loss: 3.1418 - val_mae: 3.1292 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1.8787 - mae: 1.8662 - val_loss: 3.0651 - val_mae: 3.0525 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1.8223 - mae: 1.8098 - val_loss: 3.1293 - val_mae: 3.1167 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1.8001 - mae: 1.7876 - val_loss: 3.0014 - val_mae: 2.9888 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1.7659 - mae: 1.7533 - val_loss: 2.8945 - val_mae: 2.8819 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1.7412 - mae: 1.7286 - val_loss: 2.9925 - val_mae: 2.9799 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1.7185 - mae: 1.7060 - val_loss: 2.8247 - val_mae: 2.8121 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1.6940 - mae: 1.6814 - val_loss: 2.8909 - val_mae: 2.8783 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1.6742 - mae: 1.6617 - val_loss: 2.7009 - val_mae: 2.6883 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1.6389 - mae: 1.6263 - val_loss: 2.6567 - val_mae: 2.6441 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1.6181 - mae: 1.6056 - val_loss: 2.7772 - val_mae: 2.7646 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1.5924 - mae: 1.5798 - val_loss: 2.6961 - val_mae: 2.6835 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1.5661 - mae: 1.5535 - val_loss: 2.5689 - val_mae: 2.5563 - lr: 5.0000e-04\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1.5563 - mae: 1.5437 - val_loss: 2.6496 - val_mae: 2.6370 - lr: 5.0000e-04\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 1.5345 - mae: 1.5219 - val_loss: 2.5642 - val_mae: 2.5516 - lr: 5.0000e-04\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1.5263 - mae: 1.5136 - val_loss: 2.5462 - val_mae: 2.5336 - lr: 5.0000e-04\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1.5144 - mae: 1.5018 - val_loss: 2.5139 - val_mae: 2.5013 - lr: 5.0000e-04\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 4.5920\n",
      "LV_RMSE_12h: 7.2868\n",
      "LV_MAE_24h: 2.6609\n",
      "LV_RMSE_24h: 4.4709\n",
      "LV_MAE_48h: 2.9540\n",
      "LV_RMSE_48h: 5.2193\n",
      "LV_MAE_72h: 3.1810\n",
      "LV_RMSE_72h: 5.6286\n",
      "LV_MAE_mean: 3.3470\n",
      "LV_RMSE_mean: 5.6514\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 2.0637\n",
      "RMSE_12h: 3.5727\n",
      "MAE_24h: 2.2230\n",
      "RMSE_24h: 3.7777\n",
      "MAE_48h: 2.2957\n",
      "RMSE_48h: 3.8305\n",
      "MAE_72h: 2.2408\n",
      "RMSE_72h: 3.7898\n",
      "MAE_mean: 2.2058\n",
      "RMSE_mean: 3.7427\n",
      "\n",
      "=== Station S3043065 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1376 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1353, 24, 400) Ytr2: (1353, 4) \n",
      "  Xva3: (197, 24, 400) Yva2: (197, 4) \n",
      "  Xte3: (348, 24, 400) Yte2: (348, 4)\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 3s 58ms/step - loss: 62.8461 - mae: 62.8334 - val_loss: 58.3714 - val_mae: 58.3587 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 56.0591 - mae: 56.0463 - val_loss: 49.4166 - val_mae: 49.4037 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 46.9772 - mae: 46.9640 - val_loss: 40.6271 - val_mae: 40.6137 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 38.9615 - mae: 38.9478 - val_loss: 34.5496 - val_mae: 34.5355 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 34.2415 - mae: 34.2271 - val_loss: 31.8491 - val_mae: 31.8343 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 31.9332 - mae: 31.9182 - val_loss: 29.1768 - val_mae: 29.1616 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 29.3425 - mae: 29.3272 - val_loss: 26.6128 - val_mae: 26.5973 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 27.0497 - mae: 27.0342 - val_loss: 24.8235 - val_mae: 24.8078 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 25.4358 - mae: 25.4200 - val_loss: 23.5324 - val_mae: 23.5165 - lr: 0.0010\n",
      "Epoch 10/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 14ms/step - loss: 24.3129 - mae: 24.2968 - val_loss: 22.2776 - val_mae: 22.2614 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 22.7479 - mae: 22.7315 - val_loss: 21.4318 - val_mae: 21.4151 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 21.9272 - mae: 21.9103 - val_loss: 20.1671 - val_mae: 20.1499 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 20.7774 - mae: 20.7599 - val_loss: 18.9065 - val_mae: 18.8887 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 19.8782 - mae: 19.8600 - val_loss: 17.9397 - val_mae: 17.9212 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 19.2186 - mae: 19.1998 - val_loss: 17.4285 - val_mae: 17.4094 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 18.5845 - mae: 18.5652 - val_loss: 16.7810 - val_mae: 16.7615 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 18.3656 - mae: 18.3459 - val_loss: 16.4774 - val_mae: 16.4575 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 17.9796 - mae: 17.9596 - val_loss: 15.9569 - val_mae: 15.9367 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 17.5181 - mae: 17.4978 - val_loss: 15.7011 - val_mae: 15.6806 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 16.7714 - mae: 16.7508 - val_loss: 15.5714 - val_mae: 15.5506 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 55.6523\n",
      "LV_RMSE_12h: 64.2234\n",
      "LV_MAE_24h: 14.1897\n",
      "LV_RMSE_24h: 21.9784\n",
      "LV_MAE_48h: 17.0402\n",
      "LV_RMSE_48h: 25.2616\n",
      "LV_MAE_72h: 16.0201\n",
      "LV_RMSE_72h: 24.3962\n",
      "LV_MAE_mean: 25.7256\n",
      "LV_RMSE_mean: 33.9649\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 13.9644\n",
      "RMSE_12h: 20.8504\n",
      "MAE_24h: 13.5026\n",
      "RMSE_24h: 20.2449\n",
      "MAE_48h: 13.3555\n",
      "RMSE_48h: 19.4161\n",
      "MAE_72h: 12.8357\n",
      "RMSE_72h: 18.4843\n",
      "MAE_mean: 13.4146\n",
      "RMSE_mean: 19.7489\n",
      "\n",
      "=== Station S3043091 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1377 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1354, 24, 400) Ytr2: (1354, 4) \n",
      "  Xva3: (197, 24, 400) Yva2: (197, 4) \n",
      "  Xte3: (348, 24, 400) Yte2: (348, 4)\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 3s 57ms/step - loss: 2674.5398 - mae: 2674.5269 - val_loss: 2624.5486 - val_mae: 2624.5359 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 2668.0293 - mae: 2668.0164 - val_loss: 2615.4414 - val_mae: 2615.4280 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 2657.0322 - mae: 2657.0188 - val_loss: 2602.3191 - val_mae: 2602.3054 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 2642.2244 - mae: 2642.2102 - val_loss: 2585.1440 - val_mae: 2585.1294 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 2623.1304 - mae: 2623.1150 - val_loss: 2563.3940 - val_mae: 2563.3779 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 2598.9070 - mae: 2598.8899 - val_loss: 2536.7295 - val_mae: 2536.7112 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 2569.8743 - mae: 2569.8550 - val_loss: 2504.8198 - val_mae: 2504.7993 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 2535.8740 - mae: 2535.8525 - val_loss: 2467.5610 - val_mae: 2467.5374 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 2496.6685 - mae: 2496.6436 - val_loss: 2424.8398 - val_mae: 2424.8127 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 2450.8191 - mae: 2450.7905 - val_loss: 2376.5188 - val_mae: 2376.4880 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 2400.2402 - mae: 2400.2073 - val_loss: 2322.5520 - val_mae: 2322.5171 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 2344.0837 - mae: 2344.0466 - val_loss: 2263.0427 - val_mae: 2263.0024 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 2282.4863 - mae: 2282.4434 - val_loss: 2199.2332 - val_mae: 2199.1877 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 2218.1294 - mae: 2218.0813 - val_loss: 2133.1863 - val_mae: 2133.1345 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 2151.3623 - mae: 2151.3079 - val_loss: 2068.2461 - val_mae: 2068.1885 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 2088.6221 - mae: 2088.5613 - val_loss: 2005.9016 - val_mae: 2005.8373 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 2025.9110 - mae: 2025.8436 - val_loss: 1944.1505 - val_mae: 1944.0793 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1961.3311 - mae: 1961.2566 - val_loss: 1881.5966 - val_mae: 1881.5184 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1901.5339 - mae: 1901.4525 - val_loss: 1818.2472 - val_mae: 1818.1615 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1838.5695 - mae: 1838.4806 - val_loss: 1755.2496 - val_mae: 1755.1566 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 1932.5029\n",
      "LV_RMSE_12h: 2198.8877\n",
      "LV_MAE_24h: 342.2644\n",
      "LV_RMSE_24h: 484.4850\n",
      "LV_MAE_48h: 445.3276\n",
      "LV_RMSE_48h: 624.9648\n",
      "LV_MAE_72h: 411.8822\n",
      "LV_RMSE_72h: 531.3707\n",
      "LV_MAE_mean: 782.9943\n",
      "LV_RMSE_mean: 959.9270\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 1662.6792\n",
      "RMSE_12h: 1972.0951\n",
      "MAE_24h: 1686.1261\n",
      "RMSE_24h: 1984.9562\n",
      "MAE_48h: 1642.4965\n",
      "RMSE_48h: 1940.5258\n",
      "MAE_72h: 1709.9906\n",
      "RMSE_72h: 2016.2878\n",
      "MAE_mean: 1675.3231\n",
      "RMSE_mean: 1978.4663\n",
      "\n",
      "=== Station S3043092 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1376 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1353, 24, 400) Ytr2: (1353, 4) \n",
      "  Xva3: (197, 24, 400) Yva2: (197, 4) \n",
      "  Xte3: (348, 24, 400) Yte2: (348, 4)\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 3s 56ms/step - loss: 13.4336 - mae: 13.4207 - val_loss: 17.0125 - val_mae: 16.9997 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 11.9326 - mae: 11.9197 - val_loss: 14.8998 - val_mae: 14.8867 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 11.2125 - mae: 11.1993 - val_loss: 13.3705 - val_mae: 13.3573 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 10.4366 - mae: 10.4233 - val_loss: 12.2185 - val_mae: 12.2051 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 9.5511 - mae: 9.5375 - val_loss: 11.2234 - val_mae: 11.2095 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 8.9994 - mae: 8.9853 - val_loss: 10.3735 - val_mae: 10.3591 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.5087 - mae: 8.4942 - val_loss: 10.0414 - val_mae: 10.0267 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 8.2214 - mae: 8.2065 - val_loss: 9.3455 - val_mae: 9.3304 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0098 - mae: 7.9945 - val_loss: 9.1071 - val_mae: 9.0916 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 7.7331 - mae: 7.7174 - val_loss: 8.7859 - val_mae: 8.7700 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 7.4349 - mae: 7.4188 - val_loss: 8.5447 - val_mae: 8.5285 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 7.2980 - mae: 7.2817 - val_loss: 8.3098 - val_mae: 8.2933 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 7.1691 - mae: 7.1524 - val_loss: 8.3207 - val_mae: 8.3039 - lr: 0.0010\n",
      "Epoch 14/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 12ms/step - loss: 7.1220 - mae: 7.1051 - val_loss: 8.1121 - val_mae: 8.0950 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 6.9918 - mae: 6.9746 - val_loss: 7.9282 - val_mae: 7.9109 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 6.9365 - mae: 6.9191 - val_loss: 7.7732 - val_mae: 7.7557 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 6.6730 - mae: 6.6554 - val_loss: 7.5007 - val_mae: 7.4830 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 6.6050 - mae: 6.5871 - val_loss: 7.5291 - val_mae: 7.5111 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 6.6629 - mae: 6.6449 - val_loss: 7.5462 - val_mae: 7.5281 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 6.5093 - mae: 6.4911 - val_loss: 7.3390 - val_mae: 7.3209 - lr: 5.0000e-04\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 27.5287\n",
      "LV_RMSE_12h: 37.2379\n",
      "LV_MAE_24h: 9.3793\n",
      "LV_RMSE_24h: 16.8835\n",
      "LV_MAE_48h: 12.1580\n",
      "LV_RMSE_48h: 20.9192\n",
      "LV_MAE_72h: 10.4655\n",
      "LV_RMSE_72h: 18.5545\n",
      "LV_MAE_mean: 14.8829\n",
      "LV_RMSE_mean: 23.3988\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 7.0452\n",
      "RMSE_12h: 12.5026\n",
      "MAE_24h: 9.0487\n",
      "RMSE_24h: 16.4030\n",
      "MAE_48h: 8.3388\n",
      "RMSE_48h: 15.4630\n",
      "MAE_72h: 8.3333\n",
      "RMSE_72h: 15.0340\n",
      "MAE_mean: 8.1915\n",
      "RMSE_mean: 14.8506\n",
      "\n",
      "=== Station S3043093 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1376 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1353, 24, 400) Ytr2: (1353, 4) \n",
      "  Xva3: (197, 24, 400) Yva2: (197, 4) \n",
      "  Xte3: (348, 24, 400) Yte2: (348, 4)\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 3s 56ms/step - loss: 152.0644 - mae: 152.0516 - val_loss: 144.9386 - val_mae: 144.9257 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 145.6367 - mae: 145.6237 - val_loss: 135.8689 - val_mae: 135.8557 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 134.2818 - mae: 134.2684 - val_loss: 123.0979 - val_mae: 123.0840 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 120.3582 - mae: 120.3439 - val_loss: 109.5651 - val_mae: 109.5502 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 105.8695 - mae: 105.8540 - val_loss: 96.1415 - val_mae: 96.1252 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 92.8093 - mae: 92.7923 - val_loss: 85.0884 - val_mae: 85.0705 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 82.8904 - mae: 82.8718 - val_loss: 77.4522 - val_mae: 77.4327 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 76.4357 - mae: 76.4155 - val_loss: 72.9370 - val_mae: 72.9161 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 73.8713 - mae: 73.8499 - val_loss: 69.7953 - val_mae: 69.7733 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 69.4617 - mae: 69.4395 - val_loss: 63.0901 - val_mae: 63.0676 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 63.3541 - mae: 63.3313 - val_loss: 57.7990 - val_mae: 57.7758 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 58.9315 - mae: 58.9080 - val_loss: 53.7059 - val_mae: 53.6820 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 55.8770 - mae: 55.8529 - val_loss: 50.8504 - val_mae: 50.8260 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 53.7382 - mae: 53.7135 - val_loss: 49.2216 - val_mae: 49.1966 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 52.3877 - mae: 52.3625 - val_loss: 47.2631 - val_mae: 47.2377 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 0s 17ms/step - loss: 50.8095 - mae: 50.7839 - val_loss: 45.6690 - val_mae: 45.6431 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 49.6000 - mae: 49.5739 - val_loss: 44.6464 - val_mae: 44.6201 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 48.4138 - mae: 48.3872 - val_loss: 43.4672 - val_mae: 43.4403 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 47.1463 - mae: 47.1192 - val_loss: 42.1995 - val_mae: 42.1719 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 46.3049 - mae: 46.2771 - val_loss: 40.9117 - val_mae: 40.8834 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 120.4454\n",
      "LV_RMSE_12h: 137.2999\n",
      "LV_MAE_24h: 31.3822\n",
      "LV_RMSE_24h: 45.1617\n",
      "LV_MAE_48h: 38.6236\n",
      "LV_RMSE_48h: 53.5558\n",
      "LV_MAE_72h: 35.1810\n",
      "LV_RMSE_72h: 49.3916\n",
      "LV_MAE_mean: 56.4080\n",
      "LV_RMSE_mean: 71.3522\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 78.9216\n",
      "RMSE_12h: 92.6443\n",
      "MAE_24h: 29.4507\n",
      "RMSE_24h: 41.3126\n",
      "MAE_48h: 30.3638\n",
      "RMSE_48h: 42.8434\n",
      "MAE_72h: 30.4062\n",
      "RMSE_72h: 43.2116\n",
      "MAE_mean: 42.2856\n",
      "RMSE_mean: 55.0030\n",
      "\n",
      "=== Station S3044011 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1375 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1352, 24, 400) Ytr2: (1352, 4) \n",
      "  Xva3: (197, 24, 400) Yva2: (197, 4) \n",
      "  Xte3: (347, 24, 400) Yte2: (347, 4)\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 3s 57ms/step - loss: 155.8294 - mae: 155.8166 - val_loss: 161.6829 - val_mae: 161.6702 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 149.9119 - mae: 149.8991 - val_loss: 153.6315 - val_mae: 153.6185 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 141.0884 - mae: 141.0753 - val_loss: 144.0883 - val_mae: 144.0749 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 131.9494 - mae: 131.9358 - val_loss: 135.1612 - val_mae: 135.1471 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 123.4049 - mae: 123.3904 - val_loss: 126.9372 - val_mae: 126.9221 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 115.5524 - mae: 115.5368 - val_loss: 120.4917 - val_mae: 120.4755 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 109.7127 - mae: 109.6960 - val_loss: 115.5764 - val_mae: 115.5591 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 105.4109 - mae: 105.3930 - val_loss: 112.4895 - val_mae: 112.4711 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 102.5939 - mae: 102.5751 - val_loss: 108.4626 - val_mae: 108.4434 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 97.6751 - mae: 97.6556 - val_loss: 102.3737 - val_mae: 102.3537 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 91.4568 - mae: 91.4364 - val_loss: 95.9329 - val_mae: 95.9120 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 85.5197 - mae: 85.4983 - val_loss: 89.1325 - val_mae: 89.1105 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 80.4384 - mae: 80.4158 - val_loss: 83.0125 - val_mae: 82.9890 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 75.4376 - mae: 75.4134 - val_loss: 77.2917 - val_mae: 77.2667 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 70.5910 - mae: 70.5653 - val_loss: 72.3340 - val_mae: 72.3073 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 67.0325 - mae: 67.0051 - val_loss: 68.3044 - val_mae: 68.2760 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 63.9078 - mae: 63.8787 - val_loss: 65.0426 - val_mae: 65.0126 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 61.2416 - mae: 61.2108 - val_loss: 62.1674 - val_mae: 62.1356 - lr: 0.0010\n",
      "Epoch 19/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 13ms/step - loss: 57.9411 - mae: 57.9085 - val_loss: 58.6447 - val_mae: 58.6111 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 55.6484 - mae: 55.6141 - val_loss: 56.4078 - val_mae: 56.3725 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 193.8011\n",
      "LV_RMSE_12h: 233.1727\n",
      "LV_MAE_24h: 48.3890\n",
      "LV_RMSE_24h: 75.1909\n",
      "LV_MAE_48h: 63.0490\n",
      "LV_RMSE_48h: 95.0355\n",
      "LV_MAE_72h: 53.5130\n",
      "LV_RMSE_72h: 81.8560\n",
      "LV_MAE_mean: 89.6880\n",
      "LV_RMSE_mean: 121.3138\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 89.4449\n",
      "RMSE_12h: 128.4897\n",
      "MAE_24h: 42.7486\n",
      "RMSE_24h: 67.8903\n",
      "MAE_48h: 42.8417\n",
      "RMSE_48h: 67.8932\n",
      "MAE_72h: 41.7544\n",
      "RMSE_72h: 65.5273\n",
      "MAE_mean: 54.1974\n",
      "RMSE_mean: 82.4501\n",
      "\n",
      "=== Station S3044012 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1377 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1354, 24, 400) Ytr2: (1354, 4) \n",
      "  Xva3: (197, 24, 400) Yva2: (197, 4) \n",
      "  Xte3: (348, 24, 400) Yte2: (348, 4)\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 3s 58ms/step - loss: 4061.1497 - mae: 4061.1367 - val_loss: 4081.0837 - val_mae: 4081.0710 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 4054.7542 - mae: 4054.7407 - val_loss: 4072.2959 - val_mae: 4072.2830 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 4044.3250 - mae: 4044.3118 - val_loss: 4059.9956 - val_mae: 4059.9817 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 4030.6636 - mae: 4030.6497 - val_loss: 4044.1167 - val_mae: 4044.1025 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 4012.7507 - mae: 4012.7356 - val_loss: 4024.3274 - val_mae: 4024.3115 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 3991.2456 - mae: 3991.2285 - val_loss: 4000.0647 - val_mae: 4000.0476 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 3964.7781 - mae: 3964.7595 - val_loss: 3970.9905 - val_mae: 3970.9712 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 3933.4358 - mae: 3933.4155 - val_loss: 3937.0044 - val_mae: 3936.9829 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 3897.5769 - mae: 3897.5540 - val_loss: 3898.0850 - val_mae: 3898.0603 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 3855.7603 - mae: 3855.7341 - val_loss: 3854.1243 - val_mae: 3854.0964 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 3810.6462 - mae: 3810.6160 - val_loss: 3805.0857 - val_mae: 3805.0537 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 3759.2305 - mae: 3759.1958 - val_loss: 3750.9524 - val_mae: 3750.9155 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 3703.1702 - mae: 3703.1313 - val_loss: 3691.6121 - val_mae: 3691.5703 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 3641.7361 - mae: 3641.6924 - val_loss: 3627.1543 - val_mae: 3627.1077 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 3571.2976 - mae: 3571.2480 - val_loss: 3557.0669 - val_mae: 3557.0142 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 3502.2319 - mae: 3502.1760 - val_loss: 3482.3916 - val_mae: 3482.3325 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 3429.3535 - mae: 3429.2913 - val_loss: 3407.9927 - val_mae: 3407.9268 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 3355.0088 - mae: 3354.9402 - val_loss: 3338.0393 - val_mae: 3337.9663 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 3289.5708 - mae: 3289.4949 - val_loss: 3272.2683 - val_mae: 3272.1887 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 3225.9172 - mae: 3225.8337 - val_loss: 3209.6682 - val_mae: 3209.5813 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 3593.5115\n",
      "LV_RMSE_12h: 3904.0984\n",
      "LV_MAE_24h: 343.6552\n",
      "LV_RMSE_24h: 724.9359\n",
      "LV_MAE_48h: 545.2730\n",
      "LV_RMSE_48h: 1024.6849\n",
      "LV_MAE_72h: 584.3276\n",
      "LV_RMSE_72h: 1059.0431\n",
      "LV_MAE_mean: 1266.6919\n",
      "LV_RMSE_mean: 1678.1906\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 3155.2937\n",
      "RMSE_12h: 3756.4075\n",
      "MAE_24h: 3239.2693\n",
      "RMSE_24h: 3814.7080\n",
      "MAE_48h: 3204.6106\n",
      "RMSE_48h: 3779.8269\n",
      "MAE_72h: 3168.0684\n",
      "RMSE_72h: 3738.0442\n",
      "MAE_mean: 3191.8105\n",
      "RMSE_mean: 3772.2466\n",
      "\n",
      "=== Station S3044013 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1375 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1352, 24, 400) Ytr2: (1352, 4) \n",
      "  Xva3: (197, 24, 400) Yva2: (197, 4) \n",
      "  Xte3: (347, 24, 400) Yte2: (347, 4)\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 3s 60ms/step - loss: 422.5567 - mae: 422.5439 - val_loss: 425.9553 - val_mae: 425.9425 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 416.7643 - mae: 416.7514 - val_loss: 417.4266 - val_mae: 417.4137 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 406.1771 - mae: 406.1639 - val_loss: 404.5567 - val_mae: 404.5432 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 391.8301 - mae: 391.8163 - val_loss: 388.2340 - val_mae: 388.2196 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 374.2606 - mae: 374.2457 - val_loss: 368.9367 - val_mae: 368.9211 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 355.0665 - mae: 355.0501 - val_loss: 349.1977 - val_mae: 349.1805 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 335.7439 - mae: 335.7258 - val_loss: 329.9883 - val_mae: 329.9691 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 317.9620 - mae: 317.9420 - val_loss: 311.8812 - val_mae: 311.8600 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 301.2148 - mae: 301.1927 - val_loss: 295.3644 - val_mae: 295.3410 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 285.0764 - mae: 285.0520 - val_loss: 281.0610 - val_mae: 281.0352 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 271.9667 - mae: 271.9398 - val_loss: 269.1351 - val_mae: 269.1068 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 260.5580 - mae: 260.5287 - val_loss: 260.2890 - val_mae: 260.2584 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 253.0750 - mae: 253.0435 - val_loss: 254.1574 - val_mae: 254.1247 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 246.3517 - mae: 246.3182 - val_loss: 247.9164 - val_mae: 247.8819 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 237.7960 - mae: 237.7607 - val_loss: 235.1918 - val_mae: 235.1555 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 225.6026 - mae: 225.5655 - val_loss: 221.2510 - val_mae: 221.2128 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 211.4577 - mae: 211.4185 - val_loss: 206.0041 - val_mae: 205.9635 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 198.2025 - mae: 198.1608 - val_loss: 193.2912 - val_mae: 193.2480 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 185.2112 - mae: 185.1667 - val_loss: 180.9183 - val_mae: 180.8721 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 174.5422 - mae: 174.4948 - val_loss: 170.4886 - val_mae: 170.4395 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 409.1124\n",
      "LV_RMSE_12h: 450.2291\n",
      "LV_MAE_24h: 93.6599\n",
      "LV_RMSE_24h: 155.1604\n",
      "LV_MAE_48h: 121.5331\n",
      "LV_RMSE_48h: 192.5880\n",
      "LV_MAE_72h: 105.5101\n",
      "LV_RMSE_72h: 166.4580\n",
      "LV_MAE_mean: 182.4539\n",
      "LV_RMSE_mean: 241.1088\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 316.0108\n",
      "RMSE_12h: 359.9047\n",
      "MAE_24h: 106.8847\n",
      "RMSE_24h: 151.4363\n",
      "MAE_48h: 105.3146\n",
      "RMSE_48h: 147.8039\n",
      "MAE_72h: 104.8217\n",
      "RMSE_72h: 145.8059\n",
      "MAE_mean: 158.2579\n",
      "RMSE_mean: 201.2377\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Station S3044021 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1377 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1354, 24, 400) Ytr2: (1354, 4) \n",
      "  Xva3: (197, 24, 400) Yva2: (197, 4) \n",
      "  Xte3: (348, 24, 400) Yte2: (348, 4)\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 3s 55ms/step - loss: 1253.8397 - mae: 1253.8270 - val_loss: 1130.0900 - val_mae: 1130.0771 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1247.9471 - mae: 1247.9342 - val_loss: 1121.3855 - val_mae: 1121.3723 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 0s 17ms/step - loss: 1237.3450 - mae: 1237.3317 - val_loss: 1108.7563 - val_mae: 1108.7426 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 1223.2496 - mae: 1223.2355 - val_loss: 1092.3192 - val_mae: 1092.3044 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 1204.6179 - mae: 1204.6027 - val_loss: 1071.1923 - val_mae: 1071.1760 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1181.0892 - mae: 1181.0724 - val_loss: 1045.0359 - val_mae: 1045.0178 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 1153.0988 - mae: 1153.0797 - val_loss: 1013.7429 - val_mae: 1013.7225 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1119.2904 - mae: 1119.2688 - val_loss: 977.0933 - val_mae: 977.0700 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1080.8557 - mae: 1080.8312 - val_loss: 935.0038 - val_mae: 934.9773 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1035.6672 - mae: 1035.6390 - val_loss: 887.3530 - val_mae: 887.3226 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 985.2902 - mae: 985.2579 - val_loss: 833.8662 - val_mae: 833.8315 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 929.3002 - mae: 929.2637 - val_loss: 774.1980 - val_mae: 774.1584 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 867.4867 - mae: 867.4448 - val_loss: 708.9282 - val_mae: 708.8832 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 800.6605 - mae: 800.6130 - val_loss: 637.9871 - val_mae: 637.9362 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 726.1320 - mae: 726.0783 - val_loss: 561.5905 - val_mae: 561.5331 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 653.3506 - mae: 653.2902 - val_loss: 491.3459 - val_mae: 491.2818 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 592.1954 - mae: 592.1285 - val_loss: 442.3825 - val_mae: 442.3121 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 548.9980 - mae: 548.9250 - val_loss: 410.3876 - val_mae: 410.3115 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 523.4036 - mae: 523.3254 - val_loss: 388.7410 - val_mae: 388.6602 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 504.4733 - mae: 504.3906 - val_loss: 372.8841 - val_mae: 372.7991 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 570.3707\n",
      "LV_RMSE_12h: 667.9535\n",
      "LV_MAE_24h: 174.0546\n",
      "LV_RMSE_24h: 327.3121\n",
      "LV_MAE_48h: 228.3075\n",
      "LV_RMSE_48h: 374.0117\n",
      "LV_MAE_72h: 194.9626\n",
      "LV_RMSE_72h: 361.2083\n",
      "LV_MAE_mean: 291.9239\n",
      "LV_RMSE_mean: 432.6214\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 312.1587\n",
      "RMSE_12h: 422.9374\n",
      "MAE_24h: 314.3428\n",
      "RMSE_24h: 427.5446\n",
      "MAE_48h: 336.7476\n",
      "RMSE_48h: 461.8198\n",
      "MAE_72h: 303.2440\n",
      "RMSE_72h: 409.9117\n",
      "MAE_mean: 316.6233\n",
      "RMSE_mean: 430.5534\n",
      "\n",
      "=== Station S3044022 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1375 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1352, 24, 400) Ytr2: (1352, 4) \n",
      "  Xva3: (197, 24, 400) Yva2: (197, 4) \n",
      "  Xte3: (347, 24, 400) Yte2: (347, 4)\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 3s 52ms/step - loss: 213.9294 - mae: 213.9165 - val_loss: 215.3002 - val_mae: 215.2872 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 207.7245 - mae: 207.7114 - val_loss: 206.6188 - val_mae: 206.6056 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 197.3490 - mae: 197.3356 - val_loss: 194.9644 - val_mae: 194.9506 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 185.5607 - mae: 185.5465 - val_loss: 183.5957 - val_mae: 183.5811 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 174.3469 - mae: 174.3318 - val_loss: 173.2040 - val_mae: 173.1882 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 163.8386 - mae: 163.8223 - val_loss: 163.6918 - val_mae: 163.6747 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 154.9665 - mae: 154.9488 - val_loss: 155.7630 - val_mae: 155.7445 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 148.0494 - mae: 148.0303 - val_loss: 149.3167 - val_mae: 149.2967 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 143.7247 - mae: 143.7041 - val_loss: 144.0884 - val_mae: 144.0671 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 139.6357 - mae: 139.6139 - val_loss: 139.9219 - val_mae: 139.8994 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 135.7592 - mae: 135.7362 - val_loss: 134.1649 - val_mae: 134.1413 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 128.3568 - mae: 128.3326 - val_loss: 124.9527 - val_mae: 124.9278 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 117.5696 - mae: 117.5440 - val_loss: 113.6775 - val_mae: 113.6509 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 108.8804 - mae: 108.8531 - val_loss: 103.7927 - val_mae: 103.7644 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 100.5486 - mae: 100.5194 - val_loss: 96.3719 - val_mae: 96.3417 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 94.3163 - mae: 94.2852 - val_loss: 89.0521 - val_mae: 89.0200 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 88.8306 - mae: 88.7976 - val_loss: 83.8653 - val_mae: 83.8312 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 85.3542 - mae: 85.3193 - val_loss: 80.7948 - val_mae: 80.7591 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 82.1698 - mae: 82.1334 - val_loss: 76.3677 - val_mae: 76.3306 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 80.8498 - mae: 80.8122 - val_loss: 75.0100 - val_mae: 74.9717 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 238.8069\n",
      "LV_RMSE_12h: 268.9369\n",
      "LV_MAE_24h: 55.8329\n",
      "LV_RMSE_24h: 91.2133\n",
      "LV_MAE_48h: 76.0605\n",
      "LV_RMSE_48h: 116.6247\n",
      "LV_MAE_72h: 65.9539\n",
      "LV_RMSE_72h: 102.9481\n",
      "LV_MAE_mean: 109.1635\n",
      "LV_RMSE_mean: 144.9308\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 158.7148\n",
      "RMSE_12h: 196.0087\n",
      "MAE_24h: 53.6961\n",
      "RMSE_24h: 87.4696\n",
      "MAE_48h: 52.8281\n",
      "RMSE_48h: 86.9877\n",
      "MAE_72h: 53.3690\n",
      "RMSE_72h: 87.1561\n",
      "MAE_mean: 79.6520\n",
      "RMSE_mean: 114.4055\n",
      "\n",
      "=== Station S3044023 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1375 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1352, 24, 400) Ytr2: (1352, 4) \n",
      "  Xva3: (197, 24, 400) Yva2: (197, 4) \n",
      "  Xte3: (347, 24, 400) Yte2: (347, 4)\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 3s 56ms/step - loss: 403.2289 - mae: 403.2163 - val_loss: 402.4234 - val_mae: 402.4109 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 398.7088 - mae: 398.6961 - val_loss: 395.6850 - val_mae: 395.6723 - lr: 0.0010\n",
      "Epoch 3/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 16ms/step - loss: 390.2418 - mae: 390.2290 - val_loss: 385.2352 - val_mae: 385.2221 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 378.5420 - mae: 378.5285 - val_loss: 371.5994 - val_mae: 371.5855 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 363.8191 - mae: 363.8047 - val_loss: 355.8227 - val_mae: 355.8076 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 347.6523 - mae: 347.6367 - val_loss: 340.0113 - val_mae: 339.9949 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 331.2350 - mae: 331.2178 - val_loss: 325.1143 - val_mae: 325.0963 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 316.0867 - mae: 316.0678 - val_loss: 311.0902 - val_mae: 311.0703 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 303.0074 - mae: 302.9865 - val_loss: 297.2003 - val_mae: 297.1783 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 289.3942 - mae: 289.3713 - val_loss: 284.5188 - val_mae: 284.4947 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 277.9586 - mae: 277.9335 - val_loss: 272.9575 - val_mae: 272.9311 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 266.8120 - mae: 266.7846 - val_loss: 262.2646 - val_mae: 262.2360 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 257.0632 - mae: 257.0336 - val_loss: 251.9104 - val_mae: 251.8795 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 244.0839 - mae: 244.0519 - val_loss: 235.2659 - val_mae: 235.2326 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 228.1242 - mae: 228.0898 - val_loss: 219.4657 - val_mae: 219.4298 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 214.1621 - mae: 214.1249 - val_loss: 205.5479 - val_mae: 205.5091 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 201.9157 - mae: 201.8755 - val_loss: 193.6372 - val_mae: 193.5954 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 191.1585 - mae: 191.1153 - val_loss: 182.5753 - val_mae: 182.5304 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 182.5058 - mae: 182.4597 - val_loss: 173.6808 - val_mae: 173.6329 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 173.5845 - mae: 173.5354 - val_loss: 165.1127 - val_mae: 165.0619 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 452.0144\n",
      "LV_RMSE_12h: 531.0071\n",
      "LV_MAE_24h: 91.0519\n",
      "LV_RMSE_24h: 146.5904\n",
      "LV_MAE_48h: 118.0058\n",
      "LV_RMSE_48h: 178.0027\n",
      "LV_MAE_72h: 105.9510\n",
      "LV_RMSE_72h: 154.4874\n",
      "LV_MAE_mean: 191.7558\n",
      "LV_RMSE_mean: 252.5219\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 318.4940\n",
      "RMSE_12h: 391.4997\n",
      "MAE_24h: 119.4080\n",
      "RMSE_24h: 177.8482\n",
      "MAE_48h: 124.2507\n",
      "RMSE_48h: 185.5432\n",
      "MAE_72h: 120.4877\n",
      "RMSE_72h: 178.2083\n",
      "MAE_mean: 170.6601\n",
      "RMSE_mean: 233.2748\n",
      "\n",
      "=== Station S3044051 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1377 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1354, 24, 400) Ytr2: (1354, 4) \n",
      "  Xva3: (197, 24, 400) Yva2: (197, 4) \n",
      "  Xte3: (348, 24, 400) Yte2: (348, 4)\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 3s 54ms/step - loss: 4061.4128 - mae: 4061.4004 - val_loss: 4081.5364 - val_mae: 4081.5237 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 4055.1477 - mae: 4055.1353 - val_loss: 4072.5845 - val_mae: 4072.5718 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 4044.4070 - mae: 4044.3936 - val_loss: 4059.8975 - val_mae: 4059.8838 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 4030.5295 - mae: 4030.5151 - val_loss: 4043.6123 - val_mae: 4043.5981 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 4012.0425 - mae: 4012.0281 - val_loss: 4023.0654 - val_mae: 4023.0496 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 3989.4102 - mae: 3989.3940 - val_loss: 3997.8582 - val_mae: 3997.8408 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 3962.2297 - mae: 3962.2117 - val_loss: 3967.6782 - val_mae: 3967.6592 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 3929.5244 - mae: 3929.5042 - val_loss: 3932.2761 - val_mae: 3932.2539 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 3892.1765 - mae: 3892.1536 - val_loss: 3891.6797 - val_mae: 3891.6543 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 3848.2065 - mae: 3848.1799 - val_loss: 3845.7659 - val_mae: 3845.7373 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 3801.5771 - mae: 3801.5466 - val_loss: 3794.5483 - val_mae: 3794.5156 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 3746.6846 - mae: 3746.6499 - val_loss: 3737.9209 - val_mae: 3737.8838 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 3689.3208 - mae: 3689.2808 - val_loss: 3675.9368 - val_mae: 3675.8948 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 3625.2610 - mae: 3625.2168 - val_loss: 3608.6914 - val_mae: 3608.6433 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 3551.5122 - mae: 3551.4617 - val_loss: 3535.7888 - val_mae: 3535.7349 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 3480.5435 - mae: 3480.4871 - val_loss: 3458.7297 - val_mae: 3458.6692 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 3407.0396 - mae: 3406.9761 - val_loss: 3384.9182 - val_mae: 3384.8508 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 3330.7761 - mae: 3330.7061 - val_loss: 3315.8928 - val_mae: 3315.8186 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 3268.4568 - mae: 3268.3792 - val_loss: 3251.0266 - val_mae: 3250.9451 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 3204.1982 - mae: 3204.1140 - val_loss: 3188.2312 - val_mae: 3188.1428 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 3593.5115\n",
      "LV_RMSE_12h: 3904.0984\n",
      "LV_MAE_24h: 343.6552\n",
      "LV_RMSE_24h: 724.9359\n",
      "LV_MAE_48h: 545.2730\n",
      "LV_RMSE_48h: 1024.6849\n",
      "LV_MAE_72h: 584.3276\n",
      "LV_RMSE_72h: 1059.0431\n",
      "LV_MAE_mean: 1266.6919\n",
      "LV_RMSE_mean: 1678.1906\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 3118.6868\n",
      "RMSE_12h: 3715.6626\n",
      "MAE_24h: 3204.3347\n",
      "RMSE_24h: 3776.3782\n",
      "MAE_48h: 3167.6418\n",
      "RMSE_48h: 3738.7664\n",
      "MAE_72h: 3191.3313\n",
      "RMSE_72h: 3764.0840\n",
      "MAE_mean: 3170.4985\n",
      "RMSE_mean: 3748.7229\n",
      "\n",
      "=== Station S3044052 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1377 rows, 1631 features...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[44], line 327\u001b[0m\n\u001b[1;32m    323\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo station results produced. Check inputs and schema.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    325\u001b[0m \u001b[38;5;66;03m# ---------------- run ----------------\u001b[39;00m\n\u001b[1;32m    326\u001b[0m \u001b[38;5;66;03m# Expect: df in memory with DateTimeIndex and columns [STATION_COL, FLOW_COL, ...non-flow features...]\u001b[39;00m\n\u001b[0;32m--> 327\u001b[0m \u001b[43mrun_all_stations_fast\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[44], line 313\u001b[0m, in \u001b[0;36mrun_all_stations_fast\u001b[0;34m(df)\u001b[0m\n\u001b[1;32m    311\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m stations:\n\u001b[1;32m    312\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 313\u001b[0m         row \u001b[38;5;241m=\u001b[39m \u001b[43mrun_one_station_fast\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflow_wide\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    314\u001b[0m         summary_rows\u001b[38;5;241m.\u001b[39mappend(row)\n\u001b[1;32m    315\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "Cell \u001b[0;32mIn[44], line 224\u001b[0m, in \u001b[0;36mrun_one_station_fast\u001b[0;34m(df, flow_wide, target)\u001b[0m\n\u001b[1;32m    221\u001b[0m mi_kick \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m(\u001b[38;5;241m3000\u001b[39m, subsz)\n\u001b[1;32m    222\u001b[0m mi_idx \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mchoice(np\u001b[38;5;241m.\u001b[39marange(subsz), size\u001b[38;5;241m=\u001b[39mmi_kick, replace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    223\u001b[0m mi_vals \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mSeries(\n\u001b[0;32m--> 224\u001b[0m     \u001b[43mmutual_info_regression\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_tr_sub\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43mmi_idx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my12_sub\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43mmi_idx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdiscrete_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mauto\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m42\u001b[39;49m\u001b[43m)\u001b[49m,\n\u001b[1;32m    225\u001b[0m     index\u001b[38;5;241m=\u001b[39mX_tr_sub\u001b[38;5;241m.\u001b[39mcolumns\n\u001b[1;32m    226\u001b[0m )\n\u001b[1;32m    227\u001b[0m \u001b[38;5;66;03m# rank by combined score\u001b[39;00m\n\u001b[1;32m    228\u001b[0m comb \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.8\u001b[39m \u001b[38;5;241m*\u001b[39m gb_imp\u001b[38;5;241m.\u001b[39mrank(ascending\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maverage\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m0.2\u001b[39m \u001b[38;5;241m*\u001b[39m mi_vals\u001b[38;5;241m.\u001b[39mrank(ascending\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maverage\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m/software/python/anaconda3-2023-python3.10/lib/python3.10/site-packages/sklearn/feature_selection/_mutual_info.py:388\u001b[0m, in \u001b[0;36mmutual_info_regression\u001b[0;34m(X, y, discrete_features, n_neighbors, copy, random_state)\u001b[0m\n\u001b[1;32m    312\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmutual_info_regression\u001b[39m(\n\u001b[1;32m    313\u001b[0m     X, y, \u001b[38;5;241m*\u001b[39m, discrete_features\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m\"\u001b[39m, n_neighbors\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    314\u001b[0m ):\n\u001b[1;32m    315\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Estimate mutual information for a continuous target variable.\u001b[39;00m\n\u001b[1;32m    316\u001b[0m \n\u001b[1;32m    317\u001b[0m \u001b[38;5;124;03m    Mutual information (MI) [1]_ between two random variables is a non-negative\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    386\u001b[0m \u001b[38;5;124;03m           of a Random Vector\", Probl. Peredachi Inf., 23:2 (1987), 9-16\u001b[39;00m\n\u001b[1;32m    387\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 388\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_estimate_mi\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdiscrete_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_neighbors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/software/python/anaconda3-2023-python3.10/lib/python3.10/site-packages/sklearn/feature_selection/_mutual_info.py:304\u001b[0m, in \u001b[0;36m_estimate_mi\u001b[0;34m(X, y, discrete_features, discrete_target, n_neighbors, copy, random_state)\u001b[0m\n\u001b[1;32m    297\u001b[0m     y \u001b[38;5;241m=\u001b[39m scale(y, with_mean\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    298\u001b[0m     y \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    299\u001b[0m         \u001b[38;5;241m1e-10\u001b[39m\n\u001b[1;32m    300\u001b[0m         \u001b[38;5;241m*\u001b[39m np\u001b[38;5;241m.\u001b[39mmaximum(\u001b[38;5;241m1\u001b[39m, np\u001b[38;5;241m.\u001b[39mmean(np\u001b[38;5;241m.\u001b[39mabs(y)))\n\u001b[1;32m    301\u001b[0m         \u001b[38;5;241m*\u001b[39m rng\u001b[38;5;241m.\u001b[39mstandard_normal(size\u001b[38;5;241m=\u001b[39mn_samples)\n\u001b[1;32m    302\u001b[0m     )\n\u001b[0;32m--> 304\u001b[0m mi \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    305\u001b[0m     _compute_mi(x, y, discrete_feature, discrete_target, n_neighbors)\n\u001b[1;32m    306\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m x, discrete_feature \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(_iterate_columns(X), discrete_mask)\n\u001b[1;32m    307\u001b[0m ]\n\u001b[1;32m    309\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray(mi)\n",
      "File \u001b[0;32m/software/python/anaconda3-2023-python3.10/lib/python3.10/site-packages/sklearn/feature_selection/_mutual_info.py:305\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    297\u001b[0m     y \u001b[38;5;241m=\u001b[39m scale(y, with_mean\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    298\u001b[0m     y \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    299\u001b[0m         \u001b[38;5;241m1e-10\u001b[39m\n\u001b[1;32m    300\u001b[0m         \u001b[38;5;241m*\u001b[39m np\u001b[38;5;241m.\u001b[39mmaximum(\u001b[38;5;241m1\u001b[39m, np\u001b[38;5;241m.\u001b[39mmean(np\u001b[38;5;241m.\u001b[39mabs(y)))\n\u001b[1;32m    301\u001b[0m         \u001b[38;5;241m*\u001b[39m rng\u001b[38;5;241m.\u001b[39mstandard_normal(size\u001b[38;5;241m=\u001b[39mn_samples)\n\u001b[1;32m    302\u001b[0m     )\n\u001b[1;32m    304\u001b[0m mi \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m--> 305\u001b[0m     \u001b[43m_compute_mi\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdiscrete_feature\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdiscrete_target\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_neighbors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    306\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m x, discrete_feature \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(_iterate_columns(X), discrete_mask)\n\u001b[1;32m    307\u001b[0m ]\n\u001b[1;32m    309\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray(mi)\n",
      "File \u001b[0;32m/software/python/anaconda3-2023-python3.10/lib/python3.10/site-packages/sklearn/feature_selection/_mutual_info.py:165\u001b[0m, in \u001b[0;36m_compute_mi\u001b[0;34m(x, y, x_discrete, y_discrete, n_neighbors)\u001b[0m\n\u001b[1;32m    163\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _compute_mi_cd(x, y, n_neighbors)\n\u001b[1;32m    164\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 165\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_compute_mi_cc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_neighbors\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/software/python/anaconda3-2023-python3.10/lib/python3.10/site-packages/sklearn/feature_selection/_mutual_info.py:66\u001b[0m, in \u001b[0;36m_compute_mi_cc\u001b[0;34m(x, y, n_neighbors)\u001b[0m\n\u001b[1;32m     63\u001b[0m nx \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(nx) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1.0\u001b[39m\n\u001b[1;32m     65\u001b[0m kd \u001b[38;5;241m=\u001b[39m KDTree(y, metric\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchebyshev\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 66\u001b[0m ny \u001b[38;5;241m=\u001b[39m \u001b[43mkd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquery_radius\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mradius\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcount_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_distance\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     67\u001b[0m ny \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(ny) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1.0\u001b[39m\n\u001b[1;32m     69\u001b[0m mi \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     70\u001b[0m     digamma(n_samples)\n\u001b[1;32m     71\u001b[0m     \u001b[38;5;241m+\u001b[39m digamma(n_neighbors)\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;241m-\u001b[39m np\u001b[38;5;241m.\u001b[39mmean(digamma(nx \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m))\n\u001b[1;32m     73\u001b[0m     \u001b[38;5;241m-\u001b[39m np\u001b[38;5;241m.\u001b[39mmean(digamma(ny \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m))\n\u001b[1;32m     74\u001b[0m )\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# ========================= PER-STATION (FAST v2): Neighbor selection → Slim lags → Top-K → Scale → Window → Conv1D+LSTM =========================\n",
    "# What changed vs your original:\n",
    "#   1) Neighbor selection: choose top-N stations most correlated with the target on TRAIN window only (no self).\n",
    "#   2) Slim lags: use 1..48 plus weekly anchors [72, 96, 120, 144, 168] instead of 1..168 for every station.\n",
    "#   3) Lightweight importance: GradientBoosting on a SMALL random subsample of train rows, fewer trees, shallow depth, stochastic subsample.\n",
    "#   4) Everything float32, no massive all-station × all-lag table.\n",
    "#   5) Safe fallbacks and clear prints so you can see progress per station.\n",
    "\n",
    "import os, gc, warnings, logging, math\n",
    "import numpy as np, pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.feature_selection import mutual_info_regression\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "# ---------------- CONFIG ----------------\n",
    "FLOW_COL        = \"Total Flow\"       # flow column\n",
    "STATION_COL     = \"StationName\"      # station id column\n",
    "LOOKBACK        = 24\n",
    "HORIZONS        = [12, 24, 48, 72]\n",
    "ORDERED_COLS    = [f\"y_{h}h\" for h in HORIZONS]\n",
    "\n",
    "# Speed-related knobs\n",
    "NEIGHBORS       = 30                 # number of correlated neighbor stations to keep\n",
    "LAG_SET         = list(range(1, 49)) + [72, 96, 120, 144, 168]   # compact, high-signal lags\n",
    "TOP_K           = 400                # final feature count after importance ranking\n",
    "GB_TREES        = 300                # fewer trees\n",
    "GB_MAX_DEPTH    = 3                  # shallower trees\n",
    "GB_SUBSAMPLE    = 0.5                # stochastic gradient boosting\n",
    "IMP_SUBSAMP     = 10000              # rows for importance fit (random sample from train)\n",
    "\n",
    "EPOCHS          = 20\n",
    "BATCH_SIZE      = 128\n",
    "LR              = 1e-3\n",
    "PATIENCE        = 5\n",
    "\n",
    "PLOT_DIAGNOSTICS = False             # set True if you want per-horizon plots\n",
    "\n",
    "# TensorFlow hygiene\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
    "os.environ.setdefault(\"TF_FORCE_GPU_ALLOW_GROWTH\", \"true\")\n",
    "tf.get_logger().setLevel(logging.ERROR)\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# ---------------- helpers ----------------\n",
    "def time_split_index(idx, train_ratio=0.7, val_ratio=0.1):\n",
    "    n = len(idx); n_tr = int(n*train_ratio); n_va = int(n*val_ratio)\n",
    "    return idx[:n_tr], idx[n_tr:n_tr+n_va], idx[n_tr+n_va:]\n",
    "\n",
    "def make_windows(X2d, lookback):\n",
    "    T, F = X2d.shape\n",
    "    N = T - lookback + 1\n",
    "    out = np.empty((N, lookback, F), dtype=np.float32)\n",
    "    # simple sliding window\n",
    "    for i in range(N):\n",
    "        out[i] = X2d[i:i+lookback]\n",
    "    return out\n",
    "\n",
    "def align_windows_with_targets(X_df, Y_df, lookback):\n",
    "    X_df = X_df.sort_index(); Y_df = Y_df.sort_index()\n",
    "    common = X_df.index.intersection(Y_df.index)\n",
    "    X2 = X_df.loc[common].to_numpy(dtype=np.float32)\n",
    "    Y2 = Y_df.loc[common].to_numpy(dtype=np.float32)\n",
    "    X3 = make_windows(X2, lookback)\n",
    "    Y_al = Y2[lookback-1:]\n",
    "    idx_al = common[lookback-1:]\n",
    "    return X3, Y_al, idx_al\n",
    "\n",
    "def build_model(n_features, n_outputs):\n",
    "    inp = keras.Input(shape=(LOOKBACK, n_features))\n",
    "    x = keras.layers.Conv1D(32, 3, padding=\"causal\", activation=\"relu\")(inp)\n",
    "    x = keras.layers.LSTM(128)(x)\n",
    "    x = keras.layers.Dense(128, activation='relu', kernel_regularizer=keras.regularizers.l2(1e-4))(x)\n",
    "    x = keras.layers.Dropout(0.3)(x)\n",
    "    out = keras.layers.Dense(n_outputs)(x)\n",
    "    m = keras.Model(inp, out)\n",
    "    m.compile(optimizer=keras.optimizers.Adam(LR), loss='mae', metrics=['mae'])\n",
    "    return m\n",
    "\n",
    "def metrics_by_horizon(y_true, y_pred, horizons):\n",
    "    res, maes, rmses = {}, [], []\n",
    "    for j, h in enumerate(horizons):\n",
    "        mae  = mean_absolute_error(y_true[:, j], y_pred[:, j])\n",
    "        rmse = mean_squared_error(y_true[:, j], y_pred[:, j], squared=False)\n",
    "        res[f\"MAE_{h}h\"] = float(mae); res[f\"RMSE_{h}h\"] = float(rmse)\n",
    "        maes.append(mae); rmses.append(rmse)\n",
    "    res[\"MAE_mean\"]  = float(np.mean(maes)); res[\"RMSE_mean\"] = float(np.mean(rmses))\n",
    "    return res\n",
    "\n",
    "def lv_baseline_metrics(y_true_df, ref_series, horizons):\n",
    "    y_true = y_true_df.to_numpy()\n",
    "    ref_vals = ref_series.loc[y_true_df.index].values.astype(np.float32).reshape(-1, 1)\n",
    "    preds_lv = np.repeat(ref_vals, repeats=len(horizons), axis=1)\n",
    "    res, maes, rmses = {}, [], []\n",
    "    for j, h in enumerate(horizons):\n",
    "        mae  = mean_absolute_error(y_true[:, j], preds_lv[:, j])\n",
    "        rmse = mean_squared_error(y_true[:, j], preds_lv[:, j], squared=False)\n",
    "        res[f\"LV_MAE_{h}h\"] = float(mae); res[f\"LV_RMSE_{h}h\"] = float(rmse)\n",
    "        maes.append(mae); rmses.append(rmse)\n",
    "    res[\"LV_MAE_mean\"]  = float(np.mean(maes)); res[\"LV_RMSE_mean\"] = float(np.mean(rmses))\n",
    "    return res\n",
    "\n",
    "def clean_numeric(df_in):\n",
    "    X = df_in.copy()\n",
    "    bcols = X.select_dtypes(include=['bool']).columns\n",
    "    if len(bcols): X[bcols] = X[bcols].astype(np.int8)\n",
    "    # drop non-numerics\n",
    "    for c in X.columns:\n",
    "        if X[c].dtype == object:\n",
    "            X[c] = pd.to_numeric(X[c], errors='coerce')\n",
    "    X = X.replace([np.inf, -np.inf], np.nan).fillna(0.0)\n",
    "    # cast to float32 for speed/memory\n",
    "    for c in X.columns:\n",
    "        if np.issubdtype(X[c].dtype, np.number):\n",
    "            X[c] = X[c].astype(np.float32)\n",
    "    return X\n",
    "\n",
    "# ---------------- fast neighbor + slim lag builders ----------------\n",
    "def compute_flow_wide(df):\n",
    "    fw = df.pivot_table(index=df.index, columns=STATION_COL, values=FLOW_COL, aggfunc='mean')\n",
    "    fw = fw.reindex(sorted(fw.columns), axis=1).astype(np.float32)\n",
    "    return fw\n",
    "\n",
    "def select_neighbors(flow_wide, target, train_index, k=NEIGHBORS):\n",
    "    \"\"\"\n",
    "    Pick top-k stations by absolute Pearson correlation with the target on the TRAIN slice.\n",
    "    Excludes the target itself.\n",
    "    \"\"\"\n",
    "    target_series = flow_wide[target].loc[train_index]\n",
    "    corrs = flow_wide.loc[train_index].corrwith(target_series).abs().sort_values(ascending=False)\n",
    "    neighbors = [s for s in corrs.index if s != target][:k]\n",
    "    return neighbors\n",
    "\n",
    "def build_slim_crosslags(flow_wide, neighbors, lags):\n",
    "    \"\"\"\n",
    "    Build lag features only for the selected neighbor stations and selected lags.\n",
    "    \"\"\"\n",
    "    pieces = []\n",
    "    for s in neighbors:\n",
    "        s_col = flow_wide[s]\n",
    "        for L in lags:\n",
    "            pieces.append(s_col.shift(L).rename(f\"{s}_lag_{L}\"))\n",
    "    X_cross = pd.concat(pieces, axis=1)\n",
    "    return X_cross\n",
    "\n",
    "# ---------------- data builders ----------------\n",
    "def build_XY_for_target_fast(df, flow_wide, target, train_idx):\n",
    "    \"\"\"\n",
    "    1) pick neighbors from flow_wide using train slice\n",
    "    2) build slim cross-lag matrix for those neighbors\n",
    "    3) add target station's non-flow features\n",
    "    4) build multi-horizon Y for the target\n",
    "    \"\"\"\n",
    "    neighbors = select_neighbors(flow_wide, target, train_idx, k=NEIGHBORS)\n",
    "    X_cross = build_slim_crosslags(flow_wide, neighbors, LAG_SET)\n",
    "\n",
    "    # non-flow features only for target rows\n",
    "    drop_cols = [c for c in ['Station', STATION_COL, FLOW_COL] if c in df.columns]\n",
    "    drop_cols += [c for c in df.columns if c.startswith('TotalFlow_lag_')]\n",
    "    X_target_feats = df[df[STATION_COL] == target].drop(columns=drop_cols, errors='ignore')\n",
    "\n",
    "    # combine and sync\n",
    "    X = pd.concat([X_cross, X_target_feats], axis=1).sort_index()\n",
    "    # multi-horizon Y\n",
    "    Y = pd.concat({h: df.loc[df[STATION_COL] == target, FLOW_COL].shift(-h) for h in HORIZONS}, axis=1)\n",
    "    Y.columns = ORDERED_COLS\n",
    "\n",
    "    # burn-in for max lag, mask NaNs\n",
    "    burn_in = max(LAG_SET)\n",
    "    common_idx = X.index.intersection(Y.index)\n",
    "    X = X.loc[common_idx].iloc[burn_in:]\n",
    "    Y = Y.loc[common_idx].iloc[burn_in:]\n",
    "    mask = ~Y.isna().any(axis=1)\n",
    "    X = X.loc[mask]\n",
    "    Y = Y.loc[mask]\n",
    "    return clean_numeric(X), Y, neighbors\n",
    "\n",
    "# ---------------- per-station runner ----------------\n",
    "def run_one_station_fast(df, flow_wide, target):\n",
    "    print(f\"\\n=== Station {target} ===\")\n",
    "    station_dir = f\"per_station/{target}\"\n",
    "    os.makedirs(station_dir, exist_ok=True)\n",
    "\n",
    "    # Global time split from the full target timeline\n",
    "    target_mask = (df[STATION_COL] == target)\n",
    "    target_idx = df.loc[target_mask].index.sort_values().unique()\n",
    "    tr_idx, va_idx, te_idx = time_split_index(target_idx, train_ratio=0.7, val_ratio=0.1)\n",
    "\n",
    "    # Build X, Y with neighbors decided on train slice\n",
    "    X_all, Y_all, neighbors = build_XY_for_target_fast(df, flow_wide, target, train_idx=tr_idx)\n",
    "    print(f\"[neighbors] picked {len(neighbors)} neighbors\")\n",
    "\n",
    "    # Align X to the same indices used for splitting\n",
    "    # Use only rows where target exists (already ensured) and in each split range\n",
    "    X_tr, X_va, X_te = X_all.loc[tr_idx.intersection(X_all.index)], X_all.loc[va_idx.intersection(X_all.index)], X_all.loc[te_idx.intersection(X_all.index)]\n",
    "    Y_tr, Y_va, Y_te = Y_all.loc[X_tr.index], Y_all.loc[X_va.index], Y_all.loc[X_te.index]\n",
    "\n",
    "    # ---------------- Importance on a subsample (y_12h proxy) ----------------\n",
    "    n_rows = len(X_tr)\n",
    "    if n_rows == 0:\n",
    "        raise ValueError(\"No training rows after alignment. Check the data index and feature build.\")\n",
    "    subsz = min(IMP_SUBSAMP, n_rows)\n",
    "    sub_idx = np.random.choice(np.arange(n_rows), size=subsz, replace=False)\n",
    "    X_tr_sub = X_tr.iloc[sub_idx]\n",
    "    y12_sub  = Y_tr['y_12h'].iloc[sub_idx]\n",
    "\n",
    "    print(f\"[GB] computing importances on {subsz} rows, {X_tr.shape[1]} features...\")\n",
    "    gbr = GradientBoostingRegressor(\n",
    "        n_estimators=GB_TREES, learning_rate=0.05,\n",
    "        max_depth=GB_MAX_DEPTH, subsample=GB_SUBSAMPLE, random_state=42\n",
    "    )\n",
    "    gbr.fit(X_tr_sub, y12_sub)\n",
    "    gb_imp = pd.Series(gbr.feature_importances_, index=X_tr.columns)\n",
    "\n",
    "    # optional tie-breaker with mutual information on a tiny slice\n",
    "    # (guards against tree bias when many near-zero importances)\n",
    "    mi_kick = min(3000, subsz)\n",
    "    mi_idx = np.random.choice(np.arange(subsz), size=mi_kick, replace=False)\n",
    "    mi_vals = pd.Series(\n",
    "        mutual_info_regression(X_tr_sub.iloc[mi_idx], y12_sub.iloc[mi_idx], discrete_features='auto', random_state=42),\n",
    "        index=X_tr_sub.columns\n",
    "    )\n",
    "    # rank by combined score\n",
    "    comb = 0.8 * gb_imp.rank(ascending=False, method='average') + 0.2 * mi_vals.rank(ascending=False, method='average')\n",
    "    comb = comb.sort_values()\n",
    "    keep_cols = list(comb.index[:min(TOP_K, comb.shape[0])])\n",
    "    print(f\"[select] kept top-{len(keep_cols)} features\")\n",
    "\n",
    "    # ---------------- Scale, window, and align ----------------\n",
    "    scaler = StandardScaler()\n",
    "    Xtr2 = scaler.fit_transform(X_tr[keep_cols]).astype(np.float32)\n",
    "    Xva2 = scaler.transform(X_va[keep_cols]).astype(np.float32)\n",
    "    Xte2 = scaler.transform(X_te[keep_cols]).astype(np.float32)\n",
    "\n",
    "    Xtr3, Ytr2, tr_al_idx = align_windows_with_targets(pd.DataFrame(Xtr2, index=X_tr.index, columns=keep_cols), Y_tr, LOOKBACK)\n",
    "    Xva3, Yva2, va_al_idx = align_windows_with_targets(pd.DataFrame(Xva2, index=X_va.index, columns=keep_cols), Y_va, LOOKBACK)\n",
    "    Xte3, Yte2, te_al_idx = align_windows_with_targets(pd.DataFrame(Xte2, index=X_te.index, columns=keep_cols), Y_te, LOOKBACK)\n",
    "\n",
    "    print(\"Shapes:\",\n",
    "          \"\\n  Xtr3:\", Xtr3.shape, \"Ytr2:\", Ytr2.shape,\n",
    "          \"\\n  Xva3:\", Xva3.shape, \"Yva2:\", Yva2.shape,\n",
    "          \"\\n  Xte3:\", Xte3.shape, \"Yte2:\", Yte2.shape)\n",
    "\n",
    "    # ---------------- Train ----------------\n",
    "    tf.keras.backend.clear_session()\n",
    "    model = build_model(n_features=Xtr3.shape[-1], n_outputs=len(HORIZONS))\n",
    "    cbs = [\n",
    "        keras.callbacks.EarlyStopping(monitor='val_loss', patience=PATIENCE, restore_best_weights=True),\n",
    "        keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, min_lr=1e-5),\n",
    "    ]\n",
    "    _ = model.fit(\n",
    "        Xtr3, Ytr2,\n",
    "        validation_data=(Xva3, Yva2),\n",
    "        epochs=EPOCHS, batch_size=BATCH_SIZE, verbose=1, callbacks=cbs\n",
    "    )\n",
    "\n",
    "    # ---------------- Evaluate ----------------\n",
    "    Yhat_te = model.predict(Xte3, verbose=0)\n",
    "    results = metrics_by_horizon(Yte2, Yhat_te, HORIZONS)\n",
    "\n",
    "    # ---------------- Save artifacts ----------------\n",
    "    Yte_df  = pd.DataFrame(Yte2, index=te_al_idx, columns=ORDERED_COLS)\n",
    "    Yhat_df = pd.DataFrame(Yhat_te, index=te_al_idx, columns=ORDERED_COLS)\n",
    "\n",
    "    target_series = df.loc[df[STATION_COL] == target, FLOW_COL].sort_index()\n",
    "    baseline_res = lv_baseline_metrics(Yte_df, target_series, HORIZONS)\n",
    "\n",
    "    print(\"\\nBaseline (LV) metrics:\")\n",
    "    for k, v in baseline_res.items():\n",
    "        print(f\"{k}: {v:.4f}\")\n",
    "\n",
    "    print(\"\\nConv1D+LSTM Test metrics:\")\n",
    "    for k, v in results.items():\n",
    "        print(f\"{k}: {v:.4f}\")\n",
    "\n",
    "    station_dir = f\"per_station/{target}\"\n",
    "    final_metrics = {**{k: float(v) for k, v in results.items()},\n",
    "                     **{k: float(v) for k, v in baseline_res.items()},\n",
    "                     \"neighbors_used\": len(neighbors),\n",
    "                     \"features_used\": len(keep_cols)}\n",
    "    pd.DataFrame(list(final_metrics.items()), columns=[\"metric\", \"value\"]).to_csv(f\"{station_dir}/metrics.csv\", index=False)\n",
    "\n",
    "    pd.concat([Yte_df.add_prefix(\"ytrue_\"), Yhat_df.add_prefix(\"ypred_\")], axis=1).to_csv(f\"{station_dir}/preds_test.csv\")\n",
    "\n",
    "    pd.DataFrame({\"feature\": keep_cols}).to_csv(f\"{station_dir}/kept_features.csv\", index=False)\n",
    "    model.save(f\"{station_dir}/model.h5\")\n",
    "\n",
    "    gc.collect()\n",
    "\n",
    "    row = {\"station\": target}\n",
    "    row.update(final_metrics)\n",
    "    return row\n",
    "\n",
    "# ---------------- main ----------------\n",
    "def run_all_stations_fast(df):\n",
    "    if not isinstance(df.index, pd.DatetimeIndex):\n",
    "        raise ValueError(\"df must have a DateTimeIndex\")\n",
    "\n",
    "    os.makedirs(\"per_station\", exist_ok=True)\n",
    "\n",
    "    # Precompute wide flow once\n",
    "    print(\"[prep] computing flow_wide...\")\n",
    "    flow_wide = compute_flow_wide(df)\n",
    "\n",
    "    stations = sorted(df[STATION_COL].dropna().unique())\n",
    "    summary_rows = []\n",
    "    for s in stations:\n",
    "        try:\n",
    "            row = run_one_station_fast(df, flow_wide, s)\n",
    "            summary_rows.append(row)\n",
    "        except Exception as e:\n",
    "            print(f\"[{s}] ERROR: {e}\")\n",
    "\n",
    "    if summary_rows:\n",
    "        summary_df = pd.DataFrame(summary_rows).sort_values(by=\"MAE_mean\")\n",
    "        summary_df.to_csv(\"summary_all_stations.csv\", index=False)\n",
    "        print(\"\\nSaved combined summary: summary_all_stations.csv\")\n",
    "    else:\n",
    "        print(\"No station results produced. Check inputs and schema.\")\n",
    "\n",
    "# ---------------- run ----------------\n",
    "# Expect: df in memory with DateTimeIndex and columns [STATION_COL, FLOW_COL, ...non-flow features...]\n",
    "run_all_stations_fast(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1122bd66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "288 stations already trained:\n",
      "['S3001021', 'S3001022', 'S3001101', 'S3001102', 'S3001111', 'S3001121', 'S3003011', 'S3003041', 'S3003044', 'S3003054', 'S3004071', 'S3004072', 'S3005031', 'S3005041', 'S3005052', 'S3007011', 'S3007031', 'S3007033', 'S3007041', 'S3007043']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "done_stations = [\n",
    "    d for d in os.listdir(\"per_station\")\n",
    "    if os.path.exists(f\"per_station/{d}/model.h5\")\n",
    "]\n",
    "print(f\"{len(done_stations)} stations already trained:\")\n",
    "print(done_stations[:20])  # show first 20\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "5afa474f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Re-checking done stations before resume...\n",
      "288 stations already trained.\n",
      "\n",
      "Starting resume + sample run...\n",
      "[resume] already-trained stations: 288\n",
      "[summary] wrote summary_all_stations.csv with 288 rows\n",
      "[prep] computing flow_wide...\n",
      "[stations] total: 1806 | remaining to train: 1518\n",
      "[sampling] selected 120 new stations to train (method='stratified', n=120)\n",
      "\n",
      "=== Station S3047071 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1377 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1354, 24, 400) Ytr2: (1354, 4) \n",
      "  Xva3: (197, 24, 400) Yva2: (197, 4) \n",
      "  Xte3: (348, 24, 400) Yte2: (348, 4)\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 3s 56ms/step - loss: 518.5997 - mae: 518.5870 - val_loss: 462.4972 - val_mae: 462.4845 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 513.2268 - mae: 513.2140 - val_loss: 454.3690 - val_mae: 454.3560 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 503.3490 - mae: 503.3358 - val_loss: 442.6695 - val_mae: 442.6561 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 490.1666 - mae: 490.1528 - val_loss: 427.2504 - val_mae: 427.2362 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 472.7705 - mae: 472.7558 - val_loss: 408.0772 - val_mae: 408.0617 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 452.0111 - mae: 451.9950 - val_loss: 386.2834 - val_mae: 386.2663 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 429.0140 - mae: 428.9962 - val_loss: 363.9885 - val_mae: 363.9695 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 405.9541 - mae: 405.9341 - val_loss: 343.9267 - val_mae: 343.9055 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 385.1068 - mae: 385.0846 - val_loss: 326.1118 - val_mae: 326.0882 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 366.4994 - mae: 366.4748 - val_loss: 310.7568 - val_mae: 310.7308 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 350.0176 - mae: 349.9905 - val_loss: 297.4924 - val_mae: 297.4639 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 337.0209 - mae: 336.9913 - val_loss: 285.0181 - val_mae: 284.9871 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 323.0620 - mae: 323.0299 - val_loss: 272.7409 - val_mae: 272.7073 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 310.0805 - mae: 310.0459 - val_loss: 261.5497 - val_mae: 261.5136 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 296.3102 - mae: 296.2731 - val_loss: 250.8477 - val_mae: 250.8091 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 283.4235 - mae: 283.3838 - val_loss: 240.5602 - val_mae: 240.5190 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 270.7296 - mae: 270.6872 - val_loss: 229.8383 - val_mae: 229.7943 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 256.6048 - mae: 256.5596 - val_loss: 220.7044 - val_mae: 220.6577 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 245.6800 - mae: 245.6321 - val_loss: 211.5168 - val_mae: 211.4673 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 234.1187 - mae: 234.0679 - val_loss: 202.8570 - val_mae: 202.8046 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 737.0057\n",
      "LV_RMSE_12h: 878.4907\n",
      "LV_MAE_24h: 185.3247\n",
      "LV_RMSE_24h: 269.9752\n",
      "LV_MAE_48h: 202.4368\n",
      "LV_RMSE_48h: 299.0265\n",
      "LV_MAE_72h: 219.9397\n",
      "LV_RMSE_72h: 318.6063\n",
      "LV_MAE_mean: 336.1767\n",
      "LV_RMSE_mean: 441.5247\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 489.3458\n",
      "RMSE_12h: 636.2355\n",
      "MAE_24h: 273.2366\n",
      "RMSE_24h: 424.4361\n",
      "MAE_48h: 311.0403\n",
      "RMSE_48h: 479.4119\n",
      "MAE_72h: 311.7563\n",
      "RMSE_72h: 469.0147\n",
      "MAE_mean: 346.3448\n",
      "RMSE_mean: 502.2745\n",
      "\n",
      "=== Station S3047095 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1376 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1353, 24, 400) Ytr2: (1353, 4) \n",
      "  Xva3: (197, 24, 400) Yva2: (197, 4) \n",
      "  Xte3: (347, 24, 400) Yte2: (347, 4)\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 3s 64ms/step - loss: 13.3367 - mae: 13.3239 - val_loss: 12.0259 - val_mae: 12.0131 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 9.8262 - mae: 9.8134 - val_loss: 9.0580 - val_mae: 9.0451 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 7.9033 - mae: 7.8903 - val_loss: 7.8588 - val_mae: 7.8458 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 6.9496 - mae: 6.9365 - val_loss: 7.1853 - val_mae: 7.1722 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 6.4398 - mae: 6.4267 - val_loss: 6.7377 - val_mae: 6.7245 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 6.0834 - mae: 6.0702 - val_loss: 6.5201 - val_mae: 6.5068 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 5.9008 - mae: 5.8876 - val_loss: 6.4946 - val_mae: 6.4814 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 5.7947 - mae: 5.7815 - val_loss: 6.3295 - val_mae: 6.3162 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 5.6859 - mae: 5.6726 - val_loss: 6.3972 - val_mae: 6.3840 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 5.6684 - mae: 5.6552 - val_loss: 6.3793 - val_mae: 6.3662 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 5.5673 - mae: 5.5542 - val_loss: 6.4572 - val_mae: 6.4441 - lr: 5.0000e-04\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 5.4886 - mae: 5.4755 - val_loss: 6.3855 - val_mae: 6.3723 - lr: 5.0000e-04\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 5.4993 - mae: 5.4862 - val_loss: 6.4246 - val_mae: 6.4115 - lr: 2.5000e-04\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 19.6513\n",
      "LV_RMSE_12h: 23.0265\n",
      "LV_MAE_24h: 6.9568\n",
      "LV_RMSE_24h: 10.0869\n",
      "LV_MAE_48h: 7.0749\n",
      "LV_RMSE_48h: 10.4132\n",
      "LV_MAE_72h: 7.3631\n",
      "LV_RMSE_72h: 10.8087\n",
      "LV_MAE_mean: 10.2615\n",
      "LV_RMSE_mean: 13.5838\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 5.6050\n",
      "RMSE_12h: 8.3300\n",
      "MAE_24h: 5.5197\n",
      "RMSE_24h: 8.2215\n",
      "MAE_48h: 4.8904\n",
      "RMSE_48h: 7.0340\n",
      "MAE_72h: 4.7494\n",
      "RMSE_72h: 6.8705\n",
      "MAE_mean: 5.1911\n",
      "RMSE_mean: 7.6140\n",
      "\n",
      "=== Station S3047097 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1376 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1353, 24, 400) Ytr2: (1353, 4) \n",
      "  Xva3: (197, 24, 400) Yva2: (197, 4) \n",
      "  Xte3: (347, 24, 400) Yte2: (347, 4)\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 3s 58ms/step - loss: 22.9328 - mae: 22.9200 - val_loss: 24.3786 - val_mae: 24.3659 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 18.5520 - mae: 18.5391 - val_loss: 19.5311 - val_mae: 19.5181 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 15.0781 - mae: 15.0649 - val_loss: 16.7532 - val_mae: 16.7399 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 12.9986 - mae: 12.9851 - val_loss: 15.3593 - val_mae: 15.3456 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 11.0274 - mae: 11.0136 - val_loss: 15.0683 - val_mae: 15.0544 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 9.7645 - mae: 9.7506 - val_loss: 15.3786 - val_mae: 15.3646 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.7357 - mae: 8.7215 - val_loss: 13.1242 - val_mae: 13.1099 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 8.0061 - mae: 7.9917 - val_loss: 13.1395 - val_mae: 13.1250 - lr: 0.0010\n",
      "Epoch 9/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 12ms/step - loss: 7.4673 - mae: 7.4527 - val_loss: 13.2006 - val_mae: 13.1859 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 7.2393 - mae: 7.2246 - val_loss: 11.3658 - val_mae: 11.3511 - lr: 5.0000e-04\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 7.1858 - mae: 7.1711 - val_loss: 12.6158 - val_mae: 12.6010 - lr: 5.0000e-04\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 7.0477 - mae: 7.0329 - val_loss: 11.1034 - val_mae: 11.0887 - lr: 5.0000e-04\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 7.0903 - mae: 7.0755 - val_loss: 11.9999 - val_mae: 11.9852 - lr: 5.0000e-04\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 7.0899 - mae: 7.0752 - val_loss: 11.2201 - val_mae: 11.2054 - lr: 5.0000e-04\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 6.9966 - mae: 6.9819 - val_loss: 11.5674 - val_mae: 11.5527 - lr: 2.5000e-04\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 6.9073 - mae: 6.8927 - val_loss: 11.4091 - val_mae: 11.3945 - lr: 2.5000e-04\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 6.9094 - mae: 6.8947 - val_loss: 11.3860 - val_mae: 11.3714 - lr: 1.2500e-04\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 29.7118\n",
      "LV_RMSE_12h: 33.7276\n",
      "LV_MAE_24h: 9.0663\n",
      "LV_RMSE_24h: 12.8700\n",
      "LV_MAE_48h: 9.8386\n",
      "LV_RMSE_48h: 13.4745\n",
      "LV_MAE_72h: 9.2622\n",
      "LV_RMSE_72h: 12.8125\n",
      "LV_MAE_mean: 14.4697\n",
      "LV_RMSE_mean: 18.2212\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 7.7495\n",
      "RMSE_12h: 10.8109\n",
      "MAE_24h: 7.4379\n",
      "RMSE_24h: 10.1813\n",
      "MAE_48h: 6.9812\n",
      "RMSE_48h: 9.5058\n",
      "MAE_72h: 6.7639\n",
      "RMSE_72h: 9.3648\n",
      "MAE_mean: 7.2331\n",
      "RMSE_mean: 9.9657\n",
      "\n",
      "=== Station S3047101 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1377 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1354, 24, 400) Ytr2: (1354, 4) \n",
      "  Xva3: (197, 24, 400) Yva2: (197, 4) \n",
      "  Xte3: (348, 24, 400) Yte2: (348, 4)\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 3s 65ms/step - loss: 790.7614 - mae: 790.7486 - val_loss: 719.5635 - val_mae: 719.5507 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 784.8217 - mae: 784.8089 - val_loss: 711.0125 - val_mae: 710.9995 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 774.3718 - mae: 774.3586 - val_loss: 698.6234 - val_mae: 698.6099 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 760.7401 - mae: 760.7264 - val_loss: 682.9543 - val_mae: 682.9401 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 743.2090 - mae: 743.1941 - val_loss: 663.0852 - val_mae: 663.0697 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 721.0280 - mae: 721.0120 - val_loss: 638.8111 - val_mae: 638.7939 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 694.9337 - mae: 694.9157 - val_loss: 609.9031 - val_mae: 609.8839 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 664.4260 - mae: 664.4058 - val_loss: 576.2163 - val_mae: 576.1946 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 628.7066 - mae: 628.6837 - val_loss: 537.6506 - val_mae: 537.6260 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 587.1321 - mae: 587.1060 - val_loss: 494.0781 - val_mae: 494.0500 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 542.2053 - mae: 542.1757 - val_loss: 445.4615 - val_mae: 445.4296 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 490.1292 - mae: 490.0954 - val_loss: 391.6421 - val_mae: 391.6058 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 435.4379 - mae: 435.3995 - val_loss: 332.7880 - val_mae: 332.7468 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 374.2482 - mae: 374.2047 - val_loss: 270.7729 - val_mae: 270.7264 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 312.4398 - mae: 312.3910 - val_loss: 218.2159 - val_mae: 218.1639 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 269.7902 - mae: 269.7360 - val_loss: 188.2252 - val_mae: 188.1682 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 239.2376 - mae: 239.1787 - val_loss: 170.7722 - val_mae: 170.7110 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 221.8108 - mae: 221.7480 - val_loss: 161.5052 - val_mae: 161.4406 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 210.9343 - mae: 210.8684 - val_loss: 157.7685 - val_mae: 157.7012 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 207.0197 - mae: 206.9514 - val_loss: 157.5505 - val_mae: 157.4812 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 446.7040\n",
      "LV_RMSE_12h: 534.8367\n",
      "LV_MAE_24h: 153.1293\n",
      "LV_RMSE_24h: 269.6747\n",
      "LV_MAE_48h: 161.8276\n",
      "LV_RMSE_48h: 272.9866\n",
      "LV_MAE_72h: 173.6695\n",
      "LV_RMSE_72h: 281.7409\n",
      "LV_MAE_mean: 233.8326\n",
      "LV_RMSE_mean: 339.8097\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 247.4739\n",
      "RMSE_12h: 322.4528\n",
      "MAE_24h: 251.9286\n",
      "RMSE_24h: 333.0637\n",
      "MAE_48h: 263.8474\n",
      "RMSE_48h: 345.4854\n",
      "MAE_72h: 269.7673\n",
      "RMSE_72h: 351.4301\n",
      "MAE_mean: 258.2543\n",
      "RMSE_mean: 338.1080\n",
      "\n",
      "=== Station S3049082 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1377 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1354, 24, 400) Ytr2: (1354, 4) \n",
      "  Xva3: (197, 24, 400) Yva2: (197, 4) \n",
      "  Xte3: (348, 24, 400) Yte2: (348, 4)\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 3s 63ms/step - loss: 177.8401 - mae: 177.8273 - val_loss: 155.8859 - val_mae: 155.8730 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 172.7174 - mae: 172.7044 - val_loss: 148.6691 - val_mae: 148.6559 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 165.5529 - mae: 165.5395 - val_loss: 140.5038 - val_mae: 140.4899 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 158.0356 - mae: 158.0213 - val_loss: 131.8886 - val_mae: 131.8738 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 149.9706 - mae: 149.9553 - val_loss: 122.8213 - val_mae: 122.8052 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 141.9151 - mae: 141.8984 - val_loss: 113.3850 - val_mae: 113.3674 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 133.5838 - mae: 133.5654 - val_loss: 104.9694 - val_mae: 104.9501 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 125.3080 - mae: 125.2879 - val_loss: 97.5482 - val_mae: 97.5270 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 117.0094 - mae: 116.9875 - val_loss: 89.8956 - val_mae: 89.8726 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 107.7224 - mae: 107.6985 - val_loss: 81.8477 - val_mae: 81.8227 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 97.4753 - mae: 97.4492 - val_loss: 75.0669 - val_mae: 75.0395 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 87.1583 - mae: 87.1297 - val_loss: 68.8696 - val_mae: 68.8396 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 77.3766 - mae: 77.3455 - val_loss: 65.3642 - val_mae: 65.3316 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 70.1223 - mae: 70.0887 - val_loss: 64.3356 - val_mae: 64.3008 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 66.2605 - mae: 66.2249 - val_loss: 62.3002 - val_mae: 62.2639 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 64.3590 - mae: 64.3222 - val_loss: 59.2505 - val_mae: 59.2131 - lr: 0.0010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 63.4114 - mae: 63.3735 - val_loss: 57.5134 - val_mae: 57.4751 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 61.8698 - mae: 61.8310 - val_loss: 55.1308 - val_mae: 55.0914 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 59.4087 - mae: 59.3688 - val_loss: 53.6667 - val_mae: 53.6263 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 58.0426 - mae: 58.0016 - val_loss: 52.1995 - val_mae: 52.1580 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 296.5172\n",
      "LV_RMSE_12h: 348.7851\n",
      "LV_MAE_24h: 48.2098\n",
      "LV_RMSE_24h: 72.8674\n",
      "LV_MAE_48h: 63.9339\n",
      "LV_RMSE_48h: 94.6697\n",
      "LV_MAE_72h: 62.0517\n",
      "LV_RMSE_72h: 94.9744\n",
      "LV_MAE_mean: 117.6782\n",
      "LV_RMSE_mean: 152.8241\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 138.5318\n",
      "RMSE_12h: 209.4492\n",
      "MAE_24h: 69.0868\n",
      "RMSE_24h: 106.2696\n",
      "MAE_48h: 73.1933\n",
      "RMSE_48h: 117.6697\n",
      "MAE_72h: 82.2876\n",
      "RMSE_72h: 131.4049\n",
      "MAE_mean: 90.7749\n",
      "RMSE_mean: 141.1983\n",
      "\n",
      "=== Station S3050031 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1377 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1354, 24, 400) Ytr2: (1354, 4) \n",
      "  Xva3: (197, 24, 400) Yva2: (197, 4) \n",
      "  Xte3: (348, 24, 400) Yte2: (348, 4)\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 3s 63ms/step - loss: 1133.5619 - mae: 1133.5492 - val_loss: 1072.0911 - val_mae: 1072.0784 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1126.2064 - mae: 1126.1936 - val_loss: 1061.7291 - val_mae: 1061.7161 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1113.8376 - mae: 1113.8242 - val_loss: 1047.3595 - val_mae: 1047.3457 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1098.1820 - mae: 1098.1680 - val_loss: 1029.4204 - val_mae: 1029.4056 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1077.9537 - mae: 1077.9385 - val_loss: 1006.9978 - val_mae: 1006.9816 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1053.2819 - mae: 1053.2649 - val_loss: 979.4977 - val_mae: 979.4797 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1023.7954 - mae: 1023.7764 - val_loss: 946.8138 - val_mae: 946.7933 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 989.4637 - mae: 989.4420 - val_loss: 911.5243 - val_mae: 911.5009 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 954.2142 - mae: 954.1895 - val_loss: 876.7293 - val_mae: 876.7028 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 919.3366 - mae: 919.3085 - val_loss: 843.8514 - val_mae: 843.8214 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 887.2162 - mae: 887.1846 - val_loss: 812.1875 - val_mae: 812.1539 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 856.0820 - mae: 856.0467 - val_loss: 781.0268 - val_mae: 780.9893 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 824.4002 - mae: 824.3608 - val_loss: 750.9142 - val_mae: 750.8724 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 795.1012 - mae: 795.0577 - val_loss: 723.2971 - val_mae: 723.2511 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 765.5978 - mae: 765.5500 - val_loss: 697.7303 - val_mae: 697.6800 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 741.4919 - mae: 741.4395 - val_loss: 673.2531 - val_mae: 673.1984 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 715.7933 - mae: 715.7365 - val_loss: 649.4751 - val_mae: 649.4158 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 690.7744 - mae: 690.7130 - val_loss: 624.8930 - val_mae: 624.8291 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 667.3426 - mae: 667.2766 - val_loss: 602.4524 - val_mae: 602.3837 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 643.2465 - mae: 643.1756 - val_loss: 576.2448 - val_mae: 576.1711 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 1016.0000\n",
      "LV_RMSE_12h: 1210.2297\n",
      "LV_MAE_24h: 180.5833\n",
      "LV_RMSE_24h: 272.2482\n",
      "LV_MAE_48h: 247.7816\n",
      "LV_RMSE_48h: 369.0523\n",
      "LV_MAE_72h: 204.4195\n",
      "LV_RMSE_72h: 317.2680\n",
      "LV_MAE_mean: 412.1961\n",
      "LV_RMSE_mean: 542.1996\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 586.0128\n",
      "RMSE_12h: 739.4781\n",
      "MAE_24h: 510.5791\n",
      "RMSE_24h: 667.5284\n",
      "MAE_48h: 518.3870\n",
      "RMSE_48h: 683.1648\n",
      "MAE_72h: 521.4260\n",
      "RMSE_72h: 687.9111\n",
      "MAE_mean: 534.1012\n",
      "RMSE_mean: 694.5206\n",
      "\n",
      "=== Station S3050084 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1110 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1087, 24, 400) Ytr2: (1087, 4) \n",
      "  Xva3: (159, 24, 400) Yva2: (159, 4) \n",
      "  Xte3: (272, 24, 400) Yte2: (272, 4)\n",
      "Epoch 1/20\n",
      "9/9 [==============================] - 3s 72ms/step - loss: 2.5326 - mae: 2.5198 - val_loss: 2.1893 - val_mae: 2.1764 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 1.8680 - mae: 1.8551 - val_loss: 1.8864 - val_mae: 1.8735 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 1.8010 - mae: 1.7881 - val_loss: 1.9057 - val_mae: 1.8929 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 1.7487 - mae: 1.7359 - val_loss: 1.8291 - val_mae: 1.8164 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 1.7504 - mae: 1.7376 - val_loss: 1.8459 - val_mae: 1.8332 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 1.7154 - mae: 1.7027 - val_loss: 1.8361 - val_mae: 1.8235 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 1.6921 - mae: 1.6795 - val_loss: 1.8182 - val_mae: 1.8056 - lr: 5.0000e-04\n",
      "Epoch 8/20\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 1.6646 - mae: 1.6521 - val_loss: 1.8262 - val_mae: 1.8137 - lr: 5.0000e-04\n",
      "Epoch 9/20\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 1.6705 - mae: 1.6580 - val_loss: 1.8454 - val_mae: 1.8329 - lr: 5.0000e-04\n",
      "Epoch 10/20\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 1.6596 - mae: 1.6471 - val_loss: 1.8075 - val_mae: 1.7950 - lr: 2.5000e-04\n",
      "Epoch 11/20\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 1.6528 - mae: 1.6403 - val_loss: 1.7945 - val_mae: 1.7820 - lr: 2.5000e-04\n",
      "Epoch 12/20\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 1.6535 - mae: 1.6410 - val_loss: 1.8083 - val_mae: 1.7959 - lr: 2.5000e-04\n",
      "Epoch 13/20\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 1.6681 - mae: 1.6556 - val_loss: 1.8305 - val_mae: 1.8181 - lr: 2.5000e-04\n",
      "Epoch 14/20\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 1.6536 - mae: 1.6411 - val_loss: 1.8309 - val_mae: 1.8185 - lr: 1.2500e-04\n",
      "Epoch 15/20\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 1.6411 - mae: 1.6287 - val_loss: 1.8050 - val_mae: 1.7926 - lr: 1.2500e-04\n",
      "Epoch 16/20\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 1.6461 - mae: 1.6337 - val_loss: 1.7970 - val_mae: 1.7846 - lr: 6.2500e-05\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 3.7941\n",
      "LV_RMSE_12h: 4.9170\n",
      "LV_MAE_24h: 2.0221\n",
      "LV_RMSE_24h: 2.9717\n",
      "LV_MAE_48h: 2.0993\n",
      "LV_RMSE_48h: 3.0852\n",
      "LV_MAE_72h: 2.0404\n",
      "LV_RMSE_72h: 3.0456\n",
      "LV_MAE_mean: 2.4890\n",
      "LV_RMSE_mean: 3.5049\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 1.5897\n",
      "RMSE_12h: 2.2108\n",
      "MAE_24h: 1.5240\n",
      "RMSE_24h: 2.1399\n",
      "MAE_48h: 1.5201\n",
      "RMSE_48h: 2.1159\n",
      "MAE_72h: 1.4869\n",
      "RMSE_72h: 2.0364\n",
      "MAE_mean: 1.5302\n",
      "RMSE_mean: 2.1257\n",
      "\n",
      "=== Station S3050091 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1377 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1354, 24, 400) Ytr2: (1354, 4) \n",
      "  Xva3: (197, 24, 400) Yva2: (197, 4) \n",
      "  Xte3: (348, 24, 400) Yte2: (348, 4)\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 3s 52ms/step - loss: 1085.6029 - mae: 1085.5901 - val_loss: 1021.2529 - val_mae: 1021.2402 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1079.9983 - mae: 1079.9855 - val_loss: 1013.2005 - val_mae: 1013.1874 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1070.1638 - mae: 1070.1505 - val_loss: 1001.3724 - val_mae: 1001.3588 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1056.7849 - mae: 1056.7710 - val_loss: 985.6168 - val_mae: 985.6022 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1038.9006 - mae: 1038.8854 - val_loss: 965.6197 - val_mae: 965.6038 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1016.9100 - mae: 1016.8935 - val_loss: 941.0755 - val_mae: 941.0579 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 990.2986 - mae: 990.2800 - val_loss: 912.1851 - val_mae: 912.1652 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 959.9906 - mae: 959.9696 - val_loss: 881.3464 - val_mae: 881.3239 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 928.4016 - mae: 928.3779 - val_loss: 850.6424 - val_mae: 850.6169 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 896.8649 - mae: 896.8379 - val_loss: 821.5340 - val_mae: 821.5054 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 866.5558 - mae: 866.5256 - val_loss: 792.8412 - val_mae: 792.8090 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 836.4857 - mae: 836.4520 - val_loss: 764.8381 - val_mae: 764.8024 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 807.1268 - mae: 807.0893 - val_loss: 738.1794 - val_mae: 738.1396 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 780.8159 - mae: 780.7745 - val_loss: 713.0507 - val_mae: 713.0070 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 754.9878 - mae: 754.9423 - val_loss: 689.7035 - val_mae: 689.6557 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 731.1564 - mae: 731.1069 - val_loss: 667.7830 - val_mae: 667.7310 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 706.2052 - mae: 706.1514 - val_loss: 647.9860 - val_mae: 647.9296 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 681.8798 - mae: 681.8216 - val_loss: 625.3641 - val_mae: 625.3033 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 656.6473 - mae: 656.5846 - val_loss: 597.0947 - val_mae: 597.0294 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 625.7080 - mae: 625.6406 - val_loss: 567.2377 - val_mae: 567.1674 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 984.3075\n",
      "LV_RMSE_12h: 1067.7483\n",
      "LV_MAE_24h: 193.5661\n",
      "LV_RMSE_24h: 331.0267\n",
      "LV_MAE_48h: 269.3448\n",
      "LV_RMSE_48h: 438.2603\n",
      "LV_MAE_72h: 217.9195\n",
      "LV_RMSE_72h: 374.1706\n",
      "LV_MAE_mean: 416.2845\n",
      "LV_RMSE_mean: 552.8015\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 645.7161\n",
      "RMSE_12h: 765.3342\n",
      "MAE_24h: 460.8361\n",
      "RMSE_24h: 592.5071\n",
      "MAE_48h: 467.5999\n",
      "RMSE_48h: 602.7084\n",
      "MAE_72h: 467.0558\n",
      "RMSE_72h: 600.2813\n",
      "MAE_mean: 510.3020\n",
      "RMSE_mean: 640.2078\n",
      "\n",
      "=== Station S3055021 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1377 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1354, 24, 400) Ytr2: (1354, 4) \n",
      "  Xva3: (197, 24, 400) Yva2: (197, 4) \n",
      "  Xte3: (348, 24, 400) Yte2: (348, 4)\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 3s 52ms/step - loss: 1480.3807 - mae: 1480.3677 - val_loss: 1456.2151 - val_mae: 1456.2021 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1474.4088 - mae: 1474.3956 - val_loss: 1447.7859 - val_mae: 1447.7726 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1464.0880 - mae: 1464.0745 - val_loss: 1435.2913 - val_mae: 1435.2773 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1450.1608 - mae: 1450.1465 - val_loss: 1419.0028 - val_mae: 1418.9879 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1431.7335 - mae: 1431.7180 - val_loss: 1398.1954 - val_mae: 1398.1791 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1408.4403 - mae: 1408.4236 - val_loss: 1372.2552 - val_mae: 1372.2373 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1380.9817 - mae: 1380.9626 - val_loss: 1342.2405 - val_mae: 1342.2202 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1350.1292 - mae: 1350.1078 - val_loss: 1310.8529 - val_mae: 1310.8298 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1319.2737 - mae: 1319.2493 - val_loss: 1280.5444 - val_mae: 1280.5182 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1288.5076 - mae: 1288.4801 - val_loss: 1250.3550 - val_mae: 1250.3257 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1259.0259 - mae: 1258.9950 - val_loss: 1219.8314 - val_mae: 1219.7986 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 1230.0029 - mae: 1229.9685 - val_loss: 1189.1350 - val_mae: 1189.0984 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1198.9568 - mae: 1198.9183 - val_loss: 1159.4534 - val_mae: 1159.4127 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 1171.2450 - mae: 1171.2025 - val_loss: 1131.3711 - val_mae: 1131.3263 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1142.2419 - mae: 1142.1952 - val_loss: 1103.1973 - val_mae: 1103.1481 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 1117.6324 - mae: 1117.5813 - val_loss: 1075.4397 - val_mae: 1075.3857 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1091.0446 - mae: 1090.9886 - val_loss: 1048.1442 - val_mae: 1048.0857 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1062.7981 - mae: 1062.7374 - val_loss: 1020.8541 - val_mae: 1020.7905 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1039.8291 - mae: 1039.7634 - val_loss: 993.8494 - val_mae: 993.7805 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1015.5560 - mae: 1015.4847 - val_loss: 966.3748 - val_mae: 966.3006 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 1534.7471\n",
      "LV_RMSE_12h: 1704.9850\n",
      "LV_MAE_24h: 241.0402\n",
      "LV_RMSE_24h: 364.9447\n",
      "LV_MAE_48h: 314.7701\n",
      "LV_RMSE_48h: 482.7565\n",
      "LV_MAE_72h: 261.2242\n",
      "LV_RMSE_72h: 406.1642\n",
      "LV_MAE_mean: 587.9454\n",
      "LV_RMSE_mean: 739.7126\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 906.1730\n",
      "RMSE_12h: 1098.4631\n",
      "MAE_24h: 879.9947\n",
      "RMSE_24h: 1058.8665\n",
      "MAE_48h: 896.1973\n",
      "RMSE_48h: 1082.9271\n",
      "MAE_72h: 906.2453\n",
      "RMSE_72h: 1099.0182\n",
      "MAE_mean: 897.1526\n",
      "RMSE_mean: 1084.8187\n",
      "\n",
      "=== Station S3064081 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1377 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1354, 24, 400) Ytr2: (1354, 4) \n",
      "  Xva3: (197, 24, 400) Yva2: (197, 4) \n",
      "  Xte3: (348, 24, 400) Yte2: (348, 4)\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 3s 49ms/step - loss: 155.0366 - mae: 155.0239 - val_loss: 135.3164 - val_mae: 135.3036 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 149.0843 - mae: 149.0714 - val_loss: 127.1159 - val_mae: 127.1029 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 140.3370 - mae: 140.3237 - val_loss: 118.3015 - val_mae: 118.2879 - lr: 0.0010\n",
      "Epoch 4/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 13ms/step - loss: 132.0122 - mae: 131.9983 - val_loss: 110.0285 - val_mae: 110.0141 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 124.0333 - mae: 124.0185 - val_loss: 102.8428 - val_mae: 102.8274 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 117.3955 - mae: 117.3796 - val_loss: 97.0265 - val_mae: 97.0099 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 112.1682 - mae: 112.1511 - val_loss: 92.7621 - val_mae: 92.7443 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 107.4321 - mae: 107.4139 - val_loss: 89.1044 - val_mae: 89.0856 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 103.6451 - mae: 103.6259 - val_loss: 86.5419 - val_mae: 86.5221 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 99.3272 - mae: 99.3071 - val_loss: 82.2057 - val_mae: 82.1852 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 94.1828 - mae: 94.1620 - val_loss: 77.2676 - val_mae: 77.2462 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 89.3622 - mae: 89.3405 - val_loss: 72.3730 - val_mae: 72.3507 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 84.4016 - mae: 84.3789 - val_loss: 68.7691 - val_mae: 68.7458 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 80.3668 - mae: 80.3430 - val_loss: 66.1061 - val_mae: 66.0816 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 77.0782 - mae: 77.0531 - val_loss: 64.2563 - val_mae: 64.2305 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 74.5018 - mae: 74.4754 - val_loss: 62.6324 - val_mae: 62.6053 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 71.8141 - mae: 71.7864 - val_loss: 60.8762 - val_mae: 60.8478 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 69.2935 - mae: 69.2645 - val_loss: 59.1462 - val_mae: 59.1163 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 67.5055 - mae: 67.4750 - val_loss: 57.4947 - val_mae: 57.4633 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 64.9814 - mae: 64.9493 - val_loss: 55.7723 - val_mae: 55.7393 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 312.5086\n",
      "LV_RMSE_12h: 374.7452\n",
      "LV_MAE_24h: 74.5316\n",
      "LV_RMSE_24h: 119.0724\n",
      "LV_MAE_48h: 83.6063\n",
      "LV_RMSE_48h: 129.0596\n",
      "LV_MAE_72h: 94.0718\n",
      "LV_RMSE_72h: 143.3830\n",
      "LV_MAE_mean: 141.1796\n",
      "LV_RMSE_mean: 191.5650\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 168.8442\n",
      "RMSE_12h: 252.2743\n",
      "MAE_24h: 104.7016\n",
      "RMSE_24h: 174.8641\n",
      "MAE_48h: 112.7850\n",
      "RMSE_48h: 188.9435\n",
      "MAE_72h: 120.7424\n",
      "RMSE_72h: 199.6917\n",
      "MAE_mean: 126.7683\n",
      "RMSE_mean: 203.9434\n",
      "\n",
      "=== Station S3070082 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1377 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1354, 24, 400) Ytr2: (1354, 4) \n",
      "  Xva3: (197, 24, 400) Yva2: (197, 4) \n",
      "  Xte3: (348, 24, 400) Yte2: (348, 4)\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 3s 54ms/step - loss: 717.7676 - mae: 717.7549 - val_loss: 697.3318 - val_mae: 697.3191 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 712.0266 - mae: 712.0137 - val_loss: 689.1363 - val_mae: 689.1234 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 702.1910 - mae: 702.1780 - val_loss: 677.7170 - val_mae: 677.7037 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 0s 20ms/step - loss: 689.7720 - mae: 689.7584 - val_loss: 664.3615 - val_mae: 664.3473 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 675.4386 - mae: 675.4240 - val_loss: 649.8503 - val_mae: 649.8350 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 660.1242 - mae: 660.1083 - val_loss: 634.0259 - val_mae: 634.0091 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 644.0890 - mae: 644.0715 - val_loss: 618.1476 - val_mae: 618.1290 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 626.8160 - mae: 626.7965 - val_loss: 601.4919 - val_mae: 601.4714 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 610.6334 - mae: 610.6118 - val_loss: 584.1146 - val_mae: 584.0918 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 591.8535 - mae: 591.8295 - val_loss: 565.9522 - val_mae: 565.9267 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 573.7162 - mae: 573.6895 - val_loss: 546.9518 - val_mae: 546.9235 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 553.4703 - mae: 553.4405 - val_loss: 525.3353 - val_mae: 525.3036 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 529.5906 - mae: 529.5574 - val_loss: 499.1790 - val_mae: 499.1440 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 502.5341 - mae: 502.4974 - val_loss: 470.3773 - val_mae: 470.3383 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 475.9553 - mae: 475.9145 - val_loss: 445.2078 - val_mae: 445.1646 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 451.0442 - mae: 450.9991 - val_loss: 421.5287 - val_mae: 421.4809 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 427.7081 - mae: 427.6584 - val_loss: 397.2149 - val_mae: 397.1626 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 406.0894 - mae: 406.0350 - val_loss: 376.4457 - val_mae: 376.3888 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 389.8571 - mae: 389.7983 - val_loss: 357.8665 - val_mae: 357.8052 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 373.3407 - mae: 373.2775 - val_loss: 345.4447 - val_mae: 345.3792 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 868.7672\n",
      "LV_RMSE_12h: 978.8887\n",
      "LV_MAE_24h: 127.3534\n",
      "LV_RMSE_24h: 176.6173\n",
      "LV_MAE_48h: 154.5833\n",
      "LV_RMSE_48h: 204.2070\n",
      "LV_MAE_72h: 138.9425\n",
      "LV_RMSE_72h: 188.6913\n",
      "LV_MAE_mean: 322.4116\n",
      "LV_RMSE_mean: 387.1011\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 574.9183\n",
      "RMSE_12h: 703.0563\n",
      "MAE_24h: 281.6650\n",
      "RMSE_24h: 386.2698\n",
      "MAE_48h: 277.5706\n",
      "RMSE_48h: 377.5242\n",
      "MAE_72h: 289.9286\n",
      "RMSE_72h: 393.1998\n",
      "MAE_mean: 356.0206\n",
      "RMSE_mean: 465.0125\n",
      "\n",
      "=== Station S3075063 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1376 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1353, 24, 400) Ytr2: (1353, 4) \n",
      "  Xva3: (197, 24, 400) Yva2: (197, 4) \n",
      "  Xte3: (348, 24, 400) Yte2: (348, 4)\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 3s 52ms/step - loss: 457.3000 - mae: 457.2873 - val_loss: 473.7426 - val_mae: 473.7299 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 449.9424 - mae: 449.9296 - val_loss: 463.6123 - val_mae: 463.5993 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 438.1213 - mae: 438.1082 - val_loss: 449.9400 - val_mae: 449.9264 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 423.9859 - mae: 423.9719 - val_loss: 434.4123 - val_mae: 434.3978 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 409.0767 - mae: 409.0616 - val_loss: 418.3678 - val_mae: 418.3521 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 394.2579 - mae: 394.2415 - val_loss: 402.6462 - val_mae: 402.6289 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 379.5861 - mae: 379.5680 - val_loss: 386.8482 - val_mae: 386.8292 - lr: 0.0010\n",
      "Epoch 8/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 13ms/step - loss: 364.1335 - mae: 364.1135 - val_loss: 370.6588 - val_mae: 370.6377 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 349.2757 - mae: 349.2536 - val_loss: 355.2844 - val_mae: 355.2609 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 334.3714 - mae: 334.3469 - val_loss: 341.2358 - val_mae: 341.2099 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 321.6561 - mae: 321.6290 - val_loss: 328.0162 - val_mae: 327.9877 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 307.3605 - mae: 307.3309 - val_loss: 312.4594 - val_mae: 312.4283 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 292.2953 - mae: 292.2630 - val_loss: 295.8611 - val_mae: 295.8272 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 274.6485 - mae: 274.6133 - val_loss: 276.6672 - val_mae: 276.6302 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 257.5586 - mae: 257.5202 - val_loss: 257.8561 - val_mae: 257.8158 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 240.4394 - mae: 240.3976 - val_loss: 238.3384 - val_mae: 238.2946 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 223.3092 - mae: 223.2637 - val_loss: 219.3595 - val_mae: 219.3118 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 208.0521 - mae: 208.0027 - val_loss: 202.6390 - val_mae: 202.5875 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 192.7828 - mae: 192.7295 - val_loss: 186.8288 - val_mae: 186.7735 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 180.2315 - mae: 180.1746 - val_loss: 173.3349 - val_mae: 173.2761 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 571.5345\n",
      "LV_RMSE_12h: 631.7992\n",
      "LV_MAE_24h: 107.4195\n",
      "LV_RMSE_24h: 175.7044\n",
      "LV_MAE_48h: 123.0948\n",
      "LV_RMSE_48h: 192.3974\n",
      "LV_MAE_72h: 122.4655\n",
      "LV_RMSE_72h: 189.1577\n",
      "LV_MAE_mean: 231.1286\n",
      "LV_RMSE_mean: 297.2647\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 421.6372\n",
      "RMSE_12h: 488.4302\n",
      "MAE_24h: 128.3080\n",
      "RMSE_24h: 166.6008\n",
      "MAE_48h: 128.8488\n",
      "RMSE_48h: 167.5310\n",
      "MAE_72h: 134.1092\n",
      "RMSE_72h: 171.8868\n",
      "MAE_mean: 203.2258\n",
      "RMSE_mean: 248.6122\n",
      "\n",
      "=== Station S308511 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1375 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1352, 24, 400) Ytr2: (1352, 4) \n",
      "  Xva3: (197, 24, 400) Yva2: (197, 4) \n",
      "  Xte3: (347, 24, 400) Yte2: (347, 4)\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 3s 50ms/step - loss: 303.7370 - mae: 303.7242 - val_loss: 314.1915 - val_mae: 314.1786 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 298.0617 - mae: 298.0488 - val_loss: 306.3229 - val_mae: 306.3098 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 289.0280 - mae: 289.0148 - val_loss: 295.5446 - val_mae: 295.5310 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 277.9929 - mae: 277.9791 - val_loss: 282.3927 - val_mae: 282.3783 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 265.4338 - mae: 265.4191 - val_loss: 267.1788 - val_mae: 267.1634 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 251.4599 - mae: 251.4438 - val_loss: 249.7433 - val_mae: 249.7264 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 236.1102 - mae: 236.0925 - val_loss: 230.4329 - val_mae: 230.4141 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 220.0399 - mae: 220.0203 - val_loss: 209.8968 - val_mae: 209.8760 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 203.5349 - mae: 203.5131 - val_loss: 188.1186 - val_mae: 188.0955 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 188.6539 - mae: 188.6297 - val_loss: 169.7452 - val_mae: 169.7196 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 179.7483 - mae: 179.7218 - val_loss: 159.4198 - val_mae: 159.3922 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 174.7749 - mae: 174.7466 - val_loss: 153.2868 - val_mae: 153.2577 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 171.0147 - mae: 170.9851 - val_loss: 148.4198 - val_mae: 148.3895 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 165.1069 - mae: 165.0762 - val_loss: 142.0744 - val_mae: 142.0430 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 159.9309 - mae: 159.8989 - val_loss: 135.6816 - val_mae: 135.6488 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 154.8133 - mae: 154.7797 - val_loss: 130.0487 - val_mae: 130.0141 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 149.6976 - mae: 149.6622 - val_loss: 125.7698 - val_mae: 125.7334 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 145.8222 - mae: 145.7851 - val_loss: 122.2290 - val_mae: 122.1908 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 141.3841 - mae: 141.3451 - val_loss: 120.9109 - val_mae: 120.8709 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 137.5706 - mae: 137.5299 - val_loss: 119.1972 - val_mae: 119.1555 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 356.3602\n",
      "LV_RMSE_12h: 419.3869\n",
      "LV_MAE_24h: 125.9020\n",
      "LV_RMSE_24h: 174.6681\n",
      "LV_MAE_48h: 97.8703\n",
      "LV_RMSE_48h: 142.2607\n",
      "LV_MAE_72h: 110.9424\n",
      "LV_RMSE_72h: 159.6373\n",
      "LV_MAE_mean: 172.7687\n",
      "LV_RMSE_mean: 223.9883\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 238.1496\n",
      "RMSE_12h: 292.7512\n",
      "MAE_24h: 128.3948\n",
      "RMSE_24h: 164.7419\n",
      "MAE_48h: 131.4204\n",
      "RMSE_48h: 168.9742\n",
      "MAE_72h: 130.3855\n",
      "RMSE_72h: 166.7415\n",
      "MAE_mean: 157.0876\n",
      "RMSE_mean: 198.3022\n",
      "\n",
      "=== Station S3086052 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1377 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1354, 24, 400) Ytr2: (1354, 4) \n",
      "  Xva3: (197, 24, 400) Yva2: (197, 4) \n",
      "  Xte3: (348, 24, 400) Yte2: (348, 4)\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 3s 54ms/step - loss: 996.5894 - mae: 996.5764 - val_loss: 961.5733 - val_mae: 961.5604 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 990.7999 - mae: 990.7869 - val_loss: 953.0871 - val_mae: 953.0739 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 980.1349 - mae: 980.1214 - val_loss: 939.9899 - val_mae: 939.9761 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 965.4503 - mae: 965.4362 - val_loss: 922.8352 - val_mae: 922.8204 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 946.5026 - mae: 946.4872 - val_loss: 902.5850 - val_mae: 902.5688 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 926.6444 - mae: 926.6274 - val_loss: 881.5051 - val_mae: 881.4871 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 906.5425 - mae: 906.5236 - val_loss: 860.7884 - val_mae: 860.7683 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 886.2016 - mae: 886.1805 - val_loss: 840.1557 - val_mae: 840.1332 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 865.6954 - mae: 865.6718 - val_loss: 819.0946 - val_mae: 819.0695 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 845.6878 - mae: 845.6613 - val_loss: 798.7527 - val_mae: 798.7246 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 826.2776 - mae: 826.2482 - val_loss: 778.2127 - val_mae: 778.1814 - lr: 0.0010\n",
      "Epoch 12/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 16ms/step - loss: 805.0991 - mae: 805.0663 - val_loss: 756.6039 - val_mae: 756.5690 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 783.2457 - mae: 783.2092 - val_loss: 732.7381 - val_mae: 732.6994 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 759.8074 - mae: 759.7669 - val_loss: 707.4846 - val_mae: 707.4418 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 734.2457 - mae: 734.2010 - val_loss: 680.3027 - val_mae: 680.2556 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 708.7041 - mae: 708.6550 - val_loss: 652.5933 - val_mae: 652.5415 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 679.9507 - mae: 679.8969 - val_loss: 623.0488 - val_mae: 622.9920 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 650.4581 - mae: 650.3990 - val_loss: 590.8683 - val_mae: 590.8062 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 618.8853 - mae: 618.8207 - val_loss: 562.1341 - val_mae: 562.0663 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 592.2778 - mae: 592.2074 - val_loss: 533.5721 - val_mae: 533.4982 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 1281.7644\n",
      "LV_RMSE_12h: 1436.9442\n",
      "LV_MAE_24h: 197.2759\n",
      "LV_RMSE_24h: 277.0489\n",
      "LV_MAE_48h: 248.3965\n",
      "LV_RMSE_48h: 350.6807\n",
      "LV_MAE_72h: 198.0546\n",
      "LV_RMSE_72h: 272.5699\n",
      "LV_MAE_mean: 481.3728\n",
      "LV_RMSE_mean: 584.3109\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 831.0970\n",
      "RMSE_12h: 1052.9746\n",
      "MAE_24h: 492.8247\n",
      "RMSE_24h: 698.5208\n",
      "MAE_48h: 500.2955\n",
      "RMSE_48h: 710.0347\n",
      "MAE_72h: 472.7461\n",
      "RMSE_72h: 672.8688\n",
      "MAE_mean: 574.2408\n",
      "RMSE_mean: 783.5997\n",
      "\n",
      "=== Station S3087032 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1377 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1354, 24, 400) Ytr2: (1354, 4) \n",
      "  Xva3: (197, 24, 400) Yva2: (197, 4) \n",
      "  Xte3: (348, 24, 400) Yte2: (348, 4)\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 3s 52ms/step - loss: 261.5077 - mae: 261.4948 - val_loss: 230.3613 - val_mae: 230.3485 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 256.5838 - mae: 256.5710 - val_loss: 223.4909 - val_mae: 223.4779 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 248.9428 - mae: 248.9297 - val_loss: 215.4133 - val_mae: 215.4000 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 241.0875 - mae: 241.0739 - val_loss: 207.4189 - val_mae: 207.4049 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 233.4395 - mae: 233.4251 - val_loss: 199.2449 - val_mae: 199.2300 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 226.2002 - mae: 226.1848 - val_loss: 191.5896 - val_mae: 191.5736 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 219.1823 - mae: 219.1657 - val_loss: 184.5637 - val_mae: 184.5464 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 212.6237 - mae: 212.6057 - val_loss: 177.7256 - val_mae: 177.7068 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 206.1366 - mae: 206.1172 - val_loss: 170.7106 - val_mae: 170.6904 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 199.8964 - mae: 199.8755 - val_loss: 163.8758 - val_mae: 163.8541 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 192.7682 - mae: 192.7458 - val_loss: 156.2502 - val_mae: 156.2269 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 184.9380 - mae: 184.9140 - val_loss: 148.9104 - val_mae: 148.8854 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 175.9171 - mae: 175.8912 - val_loss: 139.5230 - val_mae: 139.4960 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 164.0970 - mae: 164.0690 - val_loss: 128.2581 - val_mae: 128.2287 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 149.8759 - mae: 149.8451 - val_loss: 115.7902 - val_mae: 115.7577 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 136.1811 - mae: 136.1471 - val_loss: 104.5029 - val_mae: 104.4668 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 122.5632 - mae: 122.5255 - val_loss: 92.8413 - val_mae: 92.8013 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 111.9120 - mae: 111.8704 - val_loss: 88.3485 - val_mae: 88.3049 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 103.9775 - mae: 103.9324 - val_loss: 86.6886 - val_mae: 86.6416 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 99.5407 - mae: 99.4926 - val_loss: 85.4121 - val_mae: 85.3626 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 449.3017\n",
      "LV_RMSE_12h: 501.5069\n",
      "LV_MAE_24h: 78.2213\n",
      "LV_RMSE_24h: 148.4013\n",
      "LV_MAE_48h: 82.2299\n",
      "LV_RMSE_48h: 150.0032\n",
      "LV_MAE_72h: 84.0920\n",
      "LV_RMSE_72h: 146.0512\n",
      "LV_MAE_mean: 173.4612\n",
      "LV_RMSE_mean: 236.4907\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 240.8695\n",
      "RMSE_12h: 336.1184\n",
      "MAE_24h: 91.7415\n",
      "RMSE_24h: 152.5488\n",
      "MAE_48h: 103.6800\n",
      "RMSE_48h: 172.7403\n",
      "MAE_72h: 107.6555\n",
      "RMSE_72h: 177.0131\n",
      "MAE_mean: 135.9866\n",
      "RMSE_mean: 209.6051\n",
      "\n",
      "=== Station S3088033 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1360 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1337, 24, 400) Ytr2: (1337, 4) \n",
      "  Xva3: (195, 24, 400) Yva2: (195, 4) \n",
      "  Xte3: (342, 24, 400) Yte2: (342, 4)\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 3s 76ms/step - loss: 62.0750 - mae: 62.0622 - val_loss: 61.6572 - val_mae: 61.6444 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 57.4637 - mae: 57.4510 - val_loss: 56.3987 - val_mae: 56.3858 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 52.2632 - mae: 52.2501 - val_loss: 51.3628 - val_mae: 51.3495 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 47.5050 - mae: 47.4915 - val_loss: 46.2934 - val_mae: 46.2796 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 42.4308 - mae: 42.4167 - val_loss: 41.4100 - val_mae: 41.3954 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 37.4524 - mae: 37.4374 - val_loss: 36.4675 - val_mae: 36.4520 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 0s 17ms/step - loss: 32.8249 - mae: 32.8089 - val_loss: 31.2019 - val_mae: 31.1854 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 27.9297 - mae: 27.9127 - val_loss: 26.7416 - val_mae: 26.7241 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 24.6784 - mae: 24.6604 - val_loss: 23.9026 - val_mae: 23.8841 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 22.7065 - mae: 22.6878 - val_loss: 22.1994 - val_mae: 22.1803 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 21.3960 - mae: 21.3766 - val_loss: 20.6993 - val_mae: 20.6797 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 0s 17ms/step - loss: 20.0714 - mae: 20.0515 - val_loss: 19.3362 - val_mae: 19.3160 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 19.1892 - mae: 19.1687 - val_loss: 18.3313 - val_mae: 18.3104 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 18.2594 - mae: 18.2383 - val_loss: 16.8279 - val_mae: 16.8064 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 17.0035 - mae: 16.9817 - val_loss: 15.8053 - val_mae: 15.7832 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 15.9368 - mae: 15.9145 - val_loss: 14.6273 - val_mae: 14.6046 - lr: 0.0010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/20\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 15.3498 - mae: 15.3268 - val_loss: 14.0339 - val_mae: 14.0106 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 15.1633 - mae: 15.1399 - val_loss: 13.5281 - val_mae: 13.5044 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 14.6947 - mae: 14.6709 - val_loss: 13.4094 - val_mae: 13.3854 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 14.1948 - mae: 14.1707 - val_loss: 12.7229 - val_mae: 12.6986 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 85.0556\n",
      "LV_RMSE_12h: 95.5235\n",
      "LV_MAE_24h: 15.8918\n",
      "LV_RMSE_24h: 23.7638\n",
      "LV_MAE_48h: 17.6842\n",
      "LV_RMSE_48h: 26.6009\n",
      "LV_MAE_72h: 17.2251\n",
      "LV_RMSE_72h: 24.4775\n",
      "LV_MAE_mean: 33.9642\n",
      "LV_RMSE_mean: 42.5914\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 15.4914\n",
      "RMSE_12h: 22.2354\n",
      "MAE_24h: 14.5140\n",
      "RMSE_24h: 21.2764\n",
      "MAE_48h: 14.4210\n",
      "RMSE_48h: 21.2726\n",
      "MAE_72h: 13.8830\n",
      "RMSE_72h: 20.3873\n",
      "MAE_mean: 14.5774\n",
      "RMSE_mean: 21.2929\n",
      "\n",
      "=== Station S3088034 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1360 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1337, 24, 400) Ytr2: (1337, 4) \n",
      "  Xva3: (195, 24, 400) Yva2: (195, 4) \n",
      "  Xte3: (342, 24, 400) Yte2: (342, 4)\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 3s 52ms/step - loss: 58.0420 - mae: 58.0293 - val_loss: 58.0432 - val_mae: 58.0304 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 54.0044 - mae: 53.9916 - val_loss: 53.1420 - val_mae: 53.1291 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 49.2360 - mae: 49.2229 - val_loss: 48.3528 - val_mae: 48.3394 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 45.2265 - mae: 45.2129 - val_loss: 44.4274 - val_mae: 44.4134 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 42.3525 - mae: 42.3382 - val_loss: 41.2389 - val_mae: 41.2243 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 38.8903 - mae: 38.8754 - val_loss: 37.4574 - val_mae: 37.4422 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 34.9258 - mae: 34.9103 - val_loss: 32.3421 - val_mae: 32.3260 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 29.2898 - mae: 29.2733 - val_loss: 26.2820 - val_mae: 26.2649 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 0s 17ms/step - loss: 24.4300 - mae: 24.4123 - val_loss: 22.0282 - val_mae: 22.0099 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 21.6851 - mae: 21.6664 - val_loss: 20.2299 - val_mae: 20.2109 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 20.0490 - mae: 20.0298 - val_loss: 18.9946 - val_mae: 18.9751 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 18.4472 - mae: 18.4275 - val_loss: 17.5588 - val_mae: 17.5388 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 17.2112 - mae: 17.1909 - val_loss: 16.7318 - val_mae: 16.7111 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 16.3922 - mae: 16.3712 - val_loss: 14.5870 - val_mae: 14.5657 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 15.1309 - mae: 15.1093 - val_loss: 13.3897 - val_mae: 13.3677 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 14.3634 - mae: 14.3413 - val_loss: 12.7769 - val_mae: 12.7546 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 14.2339 - mae: 14.2114 - val_loss: 12.5194 - val_mae: 12.4968 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 14.1745 - mae: 14.1518 - val_loss: 12.2904 - val_mae: 12.2677 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 13.8938 - mae: 13.8711 - val_loss: 12.2608 - val_mae: 12.2382 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 13.7221 - mae: 13.6995 - val_loss: 12.1334 - val_mae: 12.1108 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 81.2193\n",
      "LV_RMSE_12h: 89.2234\n",
      "LV_MAE_24h: 16.8567\n",
      "LV_RMSE_24h: 24.7324\n",
      "LV_MAE_48h: 19.6667\n",
      "LV_RMSE_48h: 29.6427\n",
      "LV_MAE_72h: 15.9474\n",
      "LV_RMSE_72h: 23.5954\n",
      "LV_MAE_mean: 33.4225\n",
      "LV_RMSE_mean: 41.7985\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 14.4867\n",
      "RMSE_12h: 21.0916\n",
      "MAE_24h: 13.9527\n",
      "RMSE_24h: 21.3244\n",
      "MAE_48h: 13.9472\n",
      "RMSE_48h: 21.2005\n",
      "MAE_72h: 13.4416\n",
      "RMSE_72h: 20.4423\n",
      "MAE_mean: 13.9571\n",
      "RMSE_mean: 21.0147\n",
      "\n",
      "=== Station S3088041 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1377 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1354, 24, 400) Ytr2: (1354, 4) \n",
      "  Xva3: (197, 24, 400) Yva2: (197, 4) \n",
      "  Xte3: (348, 24, 400) Yte2: (348, 4)\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 3s 50ms/step - loss: 1218.6271 - mae: 1218.6144 - val_loss: 1299.0641 - val_mae: 1299.0514 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 1213.4460 - mae: 1213.4332 - val_loss: 1291.9012 - val_mae: 1291.8883 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1205.0134 - mae: 1205.0004 - val_loss: 1282.4540 - val_mae: 1282.4406 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1194.7465 - mae: 1194.7327 - val_loss: 1271.1088 - val_mae: 1271.0945 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1182.9879 - mae: 1182.9730 - val_loss: 1258.0370 - val_mae: 1258.0214 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1169.8448 - mae: 1169.8287 - val_loss: 1243.3392 - val_mae: 1243.3220 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1154.9358 - mae: 1154.9177 - val_loss: 1227.1445 - val_mae: 1227.1254 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 1138.4526 - mae: 1138.4323 - val_loss: 1209.2561 - val_mae: 1209.2344 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 1120.7765 - mae: 1120.7538 - val_loss: 1189.5409 - val_mae: 1189.5165 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 1100.8403 - mae: 1100.8148 - val_loss: 1167.7123 - val_mae: 1167.6847 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 1078.7188 - mae: 1078.6898 - val_loss: 1142.9369 - val_mae: 1142.9058 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1051.2487 - mae: 1051.2157 - val_loss: 1113.9030 - val_mae: 1113.8677 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 1020.2073 - mae: 1020.1702 - val_loss: 1080.9346 - val_mae: 1080.8947 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 987.8538 - mae: 987.8116 - val_loss: 1046.4222 - val_mae: 1046.3772 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 952.2024 - mae: 952.1548 - val_loss: 1010.3950 - val_mae: 1010.3441 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 916.0484 - mae: 915.9949 - val_loss: 973.8893 - val_mae: 973.8322 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 879.4420 - mae: 879.3820 - val_loss: 936.1404 - val_mae: 936.0765 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 843.1839 - mae: 843.1169 - val_loss: 898.8372 - val_mae: 898.7662 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 806.9336 - mae: 806.8593 - val_loss: 861.3472 - val_mae: 861.2688 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 772.1537 - mae: 772.0720 - val_loss: 826.3708 - val_mae: 826.2849 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 1738.4397\n",
      "LV_RMSE_12h: 1891.4558\n",
      "LV_MAE_24h: 337.8333\n",
      "LV_RMSE_24h: 488.7556\n",
      "LV_MAE_48h: 408.4684\n",
      "LV_RMSE_48h: 610.1073\n",
      "LV_MAE_72h: 348.0460\n",
      "LV_RMSE_72h: 494.6658\n",
      "LV_MAE_mean: 708.1968\n",
      "LV_RMSE_mean: 871.2462\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 1171.6102\n",
      "RMSE_12h: 1427.0105\n",
      "MAE_24h: 719.3049\n",
      "RMSE_24h: 959.0101\n",
      "MAE_48h: 687.5538\n",
      "RMSE_48h: 923.8970\n",
      "MAE_72h: 664.3105\n",
      "RMSE_72h: 887.9188\n",
      "MAE_mean: 810.6949\n",
      "RMSE_mean: 1049.4591\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Station S3088042 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1377 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1354, 24, 400) Ytr2: (1354, 4) \n",
      "  Xva3: (197, 24, 400) Yva2: (197, 4) \n",
      "  Xte3: (348, 24, 400) Yte2: (348, 4)\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 3s 53ms/step - loss: 269.6028 - mae: 269.5902 - val_loss: 274.3462 - val_mae: 274.3335 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 266.4317 - mae: 266.4190 - val_loss: 270.1419 - val_mae: 270.1291 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 261.5692 - mae: 261.5561 - val_loss: 264.3558 - val_mae: 264.3424 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 255.3627 - mae: 255.3489 - val_loss: 256.9402 - val_mae: 256.9259 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 247.4032 - mae: 247.3884 - val_loss: 247.6454 - val_mae: 247.6298 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 237.9223 - mae: 237.9059 - val_loss: 236.9794 - val_mae: 236.9619 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 227.0073 - mae: 226.9889 - val_loss: 224.5905 - val_mae: 224.5708 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 214.2104 - mae: 214.1894 - val_loss: 210.4372 - val_mae: 210.4146 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 200.2933 - mae: 200.2694 - val_loss: 195.3850 - val_mae: 195.3591 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 184.8593 - mae: 184.8318 - val_loss: 178.8902 - val_mae: 178.8607 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 169.9059 - mae: 169.8746 - val_loss: 162.8747 - val_mae: 162.8410 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 155.1576 - mae: 155.1221 - val_loss: 146.7683 - val_mae: 146.7303 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 141.5718 - mae: 141.5319 - val_loss: 132.7413 - val_mae: 132.6989 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 129.6746 - mae: 129.6302 - val_loss: 122.0712 - val_mae: 122.0244 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 118.7208 - mae: 118.6721 - val_loss: 110.0676 - val_mae: 110.0165 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 109.7133 - mae: 109.6604 - val_loss: 100.7184 - val_mae: 100.6632 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 102.5861 - mae: 102.5294 - val_loss: 93.7876 - val_mae: 93.7288 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 97.2219 - mae: 97.1616 - val_loss: 88.8812 - val_mae: 88.8190 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 92.3506 - mae: 92.2870 - val_loss: 83.6610 - val_mae: 83.5957 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 88.5901 - mae: 88.5235 - val_loss: 79.5252 - val_mae: 79.4570 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 485.5258\n",
      "LV_RMSE_12h: 544.5922\n",
      "LV_MAE_24h: 85.4770\n",
      "LV_RMSE_24h: 128.6190\n",
      "LV_MAE_48h: 106.3534\n",
      "LV_RMSE_48h: 158.3851\n",
      "LV_MAE_72h: 109.6178\n",
      "LV_RMSE_72h: 161.3468\n",
      "LV_MAE_mean: 196.7435\n",
      "LV_RMSE_mean: 248.2358\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 147.9161\n",
      "RMSE_12h: 216.0674\n",
      "MAE_24h: 97.2557\n",
      "RMSE_24h: 146.7696\n",
      "MAE_48h: 90.8339\n",
      "RMSE_48h: 139.8715\n",
      "MAE_72h: 91.4948\n",
      "RMSE_72h: 142.1854\n",
      "MAE_mean: 106.8751\n",
      "RMSE_mean: 161.2235\n",
      "\n",
      "=== Station S3088091 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1377 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1354, 24, 400) Ytr2: (1354, 4) \n",
      "  Xva3: (197, 24, 400) Yva2: (197, 4) \n",
      "  Xte3: (348, 24, 400) Yte2: (348, 4)\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 3s 53ms/step - loss: 1013.2147 - mae: 1013.2020 - val_loss: 956.5717 - val_mae: 956.5590 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1006.0927 - mae: 1006.0800 - val_loss: 946.4144 - val_mae: 946.4013 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 994.0234 - mae: 994.0099 - val_loss: 932.4891 - val_mae: 932.4754 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 978.8790 - mae: 978.8649 - val_loss: 915.0598 - val_mae: 915.0450 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 959.5760 - mae: 959.5607 - val_loss: 894.5043 - val_mae: 894.4883 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 938.8118 - mae: 938.7949 - val_loss: 873.3799 - val_mae: 873.3621 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 917.8058 - mae: 917.7872 - val_loss: 852.4341 - val_mae: 852.4144 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 896.5764 - mae: 896.5555 - val_loss: 831.5496 - val_mae: 831.5273 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 875.8278 - mae: 875.8044 - val_loss: 811.1829 - val_mae: 811.1581 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 854.9614 - mae: 854.9355 - val_loss: 791.2252 - val_mae: 791.1975 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 835.3394 - mae: 835.3104 - val_loss: 770.5010 - val_mae: 770.4702 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 813.7195 - mae: 813.6874 - val_loss: 748.7854 - val_mae: 748.7513 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 792.8495 - mae: 792.8139 - val_loss: 726.8133 - val_mae: 726.7756 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 771.3901 - mae: 771.3508 - val_loss: 704.6586 - val_mae: 704.6171 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 748.4734 - mae: 748.4302 - val_loss: 681.5636 - val_mae: 681.5182 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 727.2687 - mae: 727.2214 - val_loss: 656.4349 - val_mae: 656.3853 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 701.0479 - mae: 700.9963 - val_loss: 629.9380 - val_mae: 629.8840 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 676.2475 - mae: 676.1915 - val_loss: 607.0980 - val_mae: 607.0394 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 654.1686 - mae: 654.1079 - val_loss: 581.5349 - val_mae: 581.4716 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 630.7026 - mae: 630.6371 - val_loss: 557.6629 - val_mae: 557.5947 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 1199.2644\n",
      "LV_RMSE_12h: 1348.6964\n",
      "LV_MAE_24h: 169.2270\n",
      "LV_RMSE_24h: 237.4046\n",
      "LV_MAE_48h: 206.0546\n",
      "LV_RMSE_48h: 289.9217\n",
      "LV_MAE_72h: 189.6552\n",
      "LV_RMSE_72h: 263.3344\n",
      "LV_MAE_mean: 441.0503\n",
      "LV_RMSE_mean: 534.8393\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 744.9213\n",
      "RMSE_12h: 918.9344\n",
      "MAE_24h: 506.7572\n",
      "RMSE_24h: 650.9459\n",
      "MAE_48h: 536.4338\n",
      "RMSE_48h: 694.1462\n",
      "MAE_72h: 531.3394\n",
      "RMSE_72h: 689.1006\n",
      "MAE_mean: 579.8629\n",
      "RMSE_mean: 738.2818\n",
      "\n",
      "=== Station S3090041 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1377 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1354, 24, 400) Ytr2: (1354, 4) \n",
      "  Xva3: (197, 24, 400) Yva2: (197, 4) \n",
      "  Xte3: (348, 24, 400) Yte2: (348, 4)\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 3s 59ms/step - loss: 612.5673 - mae: 612.5546 - val_loss: 582.4113 - val_mae: 582.3984 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 606.2803 - mae: 606.2673 - val_loss: 573.7816 - val_mae: 573.7685 - lr: 0.0010\n",
      "Epoch 3/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 13ms/step - loss: 595.9956 - mae: 595.9824 - val_loss: 563.0878 - val_mae: 563.0742 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 584.4937 - mae: 584.4798 - val_loss: 551.3629 - val_mae: 551.3484 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 571.1307 - mae: 571.1157 - val_loss: 538.5025 - val_mae: 538.4868 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 556.8808 - mae: 556.8644 - val_loss: 524.6191 - val_mae: 524.6019 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 542.0369 - mae: 542.0188 - val_loss: 509.7296 - val_mae: 509.7105 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 526.2491 - mae: 526.2289 - val_loss: 494.0276 - val_mae: 494.0062 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 510.2340 - mae: 510.2116 - val_loss: 478.8861 - val_mae: 478.8623 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 493.7963 - mae: 493.7714 - val_loss: 462.9493 - val_mae: 462.9228 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 477.9304 - mae: 477.9027 - val_loss: 445.1710 - val_mae: 445.1417 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 457.8468 - mae: 457.8161 - val_loss: 424.2200 - val_mae: 424.1875 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 435.2480 - mae: 435.2140 - val_loss: 400.0995 - val_mae: 400.0635 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 412.3439 - mae: 412.3062 - val_loss: 377.5860 - val_mae: 377.5461 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 388.7589 - mae: 388.7172 - val_loss: 356.4989 - val_mae: 356.4548 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 370.5553 - mae: 370.5094 - val_loss: 336.1265 - val_mae: 336.0780 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 349.4010 - mae: 349.3505 - val_loss: 316.1415 - val_mae: 316.0883 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 328.4599 - mae: 328.4046 - val_loss: 295.7278 - val_mae: 295.6697 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 310.4509 - mae: 310.3905 - val_loss: 277.2713 - val_mae: 277.2080 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 293.2040 - mae: 293.1384 - val_loss: 262.5838 - val_mae: 262.5155 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 722.5948\n",
      "LV_RMSE_12h: 790.5120\n",
      "LV_MAE_24h: 129.8506\n",
      "LV_RMSE_24h: 208.0092\n",
      "LV_MAE_48h: 165.3333\n",
      "LV_RMSE_48h: 263.2717\n",
      "LV_MAE_72h: 143.7471\n",
      "LV_RMSE_72h: 227.3634\n",
      "LV_MAE_mean: 290.3815\n",
      "LV_RMSE_mean: 372.2891\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 509.1594\n",
      "RMSE_12h: 610.2574\n",
      "MAE_24h: 160.2358\n",
      "RMSE_24h: 233.7700\n",
      "MAE_48h: 167.8054\n",
      "RMSE_48h: 242.0951\n",
      "MAE_72h: 164.7901\n",
      "RMSE_72h: 237.9540\n",
      "MAE_mean: 250.4977\n",
      "RMSE_mean: 331.0191\n",
      "\n",
      "=== Station S3090044 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1377 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1354, 24, 400) Ytr2: (1354, 4) \n",
      "  Xva3: (197, 24, 400) Yva2: (197, 4) \n",
      "  Xte3: (348, 24, 400) Yte2: (348, 4)\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 3s 65ms/step - loss: 3078.8000 - mae: 3078.7876 - val_loss: 3205.4988 - val_mae: 3205.4861 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 3072.9490 - mae: 3072.9360 - val_loss: 3197.2136 - val_mae: 3197.2004 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 3063.0962 - mae: 3063.0830 - val_loss: 3185.5427 - val_mae: 3185.5295 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 3049.9856 - mae: 3049.9717 - val_loss: 3170.5000 - val_mae: 3170.4858 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 3032.7817 - mae: 3032.7671 - val_loss: 3151.3230 - val_mae: 3151.3074 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 3011.9778 - mae: 3011.9617 - val_loss: 3127.8530 - val_mae: 3127.8357 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 2986.5417 - mae: 2986.5234 - val_loss: 3099.8445 - val_mae: 3099.8254 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 2956.5977 - mae: 2956.5776 - val_loss: 3067.1140 - val_mae: 3067.0920 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 2921.6121 - mae: 2921.5889 - val_loss: 3029.6050 - val_mae: 3029.5803 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 2882.7761 - mae: 2882.7502 - val_loss: 2987.4500 - val_mae: 2987.4219 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 2838.9338 - mae: 2838.9038 - val_loss: 2940.5242 - val_mae: 2940.4922 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 2790.7646 - mae: 2790.7305 - val_loss: 2888.7656 - val_mae: 2888.7295 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 2739.1062 - mae: 2739.0684 - val_loss: 2832.1758 - val_mae: 2832.1345 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 2683.2219 - mae: 2683.1785 - val_loss: 2770.8940 - val_mae: 2770.8477 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 2621.8054 - mae: 2621.7568 - val_loss: 2708.9043 - val_mae: 2708.8528 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 2565.7671 - mae: 2565.7129 - val_loss: 2650.7156 - val_mae: 2650.6582 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 2514.1475 - mae: 2514.0874 - val_loss: 2595.8909 - val_mae: 2595.8279 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 2462.1541 - mae: 2462.0891 - val_loss: 2544.7593 - val_mae: 2544.6904 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 2420.0127 - mae: 2419.9414 - val_loss: 2496.8884 - val_mae: 2496.8137 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 2377.2993 - mae: 2377.2217 - val_loss: 2450.2412 - val_mae: 2450.1606 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 3050.9023\n",
      "LV_RMSE_12h: 3367.2395\n",
      "LV_MAE_24h: 570.3649\n",
      "LV_RMSE_24h: 887.3472\n",
      "LV_MAE_48h: 755.2845\n",
      "LV_RMSE_48h: 1124.7632\n",
      "LV_MAE_72h: 581.8937\n",
      "LV_RMSE_72h: 859.7397\n",
      "LV_MAE_mean: 1239.6113\n",
      "LV_RMSE_mean: 1559.7725\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 2243.0046\n",
      "RMSE_12h: 2790.0581\n",
      "MAE_24h: 2324.1016\n",
      "RMSE_24h: 2860.8987\n",
      "MAE_48h: 2287.2432\n",
      "RMSE_48h: 2820.0066\n",
      "MAE_72h: 2290.7012\n",
      "RMSE_72h: 2818.2305\n",
      "MAE_mean: 2286.2627\n",
      "RMSE_mean: 2822.2986\n",
      "\n",
      "=== Station S3091012 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1377 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1354, 24, 400) Ytr2: (1354, 4) \n",
      "  Xva3: (197, 24, 400) Yva2: (197, 4) \n",
      "  Xte3: (348, 24, 400) Yte2: (348, 4)\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 3s 65ms/step - loss: 2814.2485 - mae: 2814.2358 - val_loss: 2853.5378 - val_mae: 2853.5251 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 2807.3247 - mae: 2807.3118 - val_loss: 2843.5405 - val_mae: 2843.5273 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 2795.2588 - mae: 2795.2456 - val_loss: 2829.5083 - val_mae: 2829.4946 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 2779.9075 - mae: 2779.8936 - val_loss: 2811.7793 - val_mae: 2811.7646 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 2759.7056 - mae: 2759.6899 - val_loss: 2789.1274 - val_mae: 2789.1116 - lr: 0.0010\n",
      "Epoch 6/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 13ms/step - loss: 2734.7461 - mae: 2734.7290 - val_loss: 2761.1719 - val_mae: 2761.1543 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 2704.7754 - mae: 2704.7563 - val_loss: 2728.1787 - val_mae: 2728.1587 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 2669.3694 - mae: 2669.3479 - val_loss: 2689.7583 - val_mae: 2689.7351 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 2628.8184 - mae: 2628.7939 - val_loss: 2645.8245 - val_mae: 2645.7981 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 2582.2441 - mae: 2582.2161 - val_loss: 2596.9014 - val_mae: 2596.8711 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 2532.7446 - mae: 2532.7126 - val_loss: 2545.6821 - val_mae: 2545.6479 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 2481.9351 - mae: 2481.8987 - val_loss: 2495.1047 - val_mae: 2495.0657 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 2432.3394 - mae: 2432.2981 - val_loss: 2446.6387 - val_mae: 2446.5947 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 2385.1077 - mae: 2385.0615 - val_loss: 2399.1064 - val_mae: 2399.0574 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 2337.3179 - mae: 2337.2666 - val_loss: 2351.6365 - val_mae: 2351.5818 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 2292.6963 - mae: 2292.6394 - val_loss: 2304.4626 - val_mae: 2304.4028 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 2248.1453 - mae: 2248.0830 - val_loss: 2257.9441 - val_mae: 2257.8784 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 2199.9744 - mae: 2199.9060 - val_loss: 2212.4829 - val_mae: 2212.4111 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 2158.8687 - mae: 2158.7944 - val_loss: 2168.5154 - val_mae: 2168.4375 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 2118.1885 - mae: 2118.1077 - val_loss: 2126.8298 - val_mae: 2126.7458 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 2718.6926\n",
      "LV_RMSE_12h: 3050.5996\n",
      "LV_MAE_24h: 510.6667\n",
      "LV_RMSE_24h: 796.8087\n",
      "LV_MAE_48h: 704.7040\n",
      "LV_RMSE_48h: 1055.5044\n",
      "LV_MAE_72h: 565.2615\n",
      "LV_RMSE_72h: 863.4594\n",
      "LV_MAE_mean: 1124.8313\n",
      "LV_RMSE_mean: 1441.5930\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 1895.0294\n",
      "RMSE_12h: 2360.4575\n",
      "MAE_24h: 1932.5005\n",
      "RMSE_24h: 2393.5603\n",
      "MAE_48h: 1902.4340\n",
      "RMSE_48h: 2352.9402\n",
      "MAE_72h: 1894.0262\n",
      "RMSE_72h: 2337.6899\n",
      "MAE_mean: 1905.9976\n",
      "RMSE_mean: 2361.1621\n",
      "\n",
      "=== Station S3091023 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1377 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1354, 24, 400) Ytr2: (1354, 4) \n",
      "  Xva3: (197, 24, 400) Yva2: (197, 4) \n",
      "  Xte3: (348, 24, 400) Yte2: (348, 4)\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 3s 62ms/step - loss: 594.7948 - mae: 594.7820 - val_loss: 605.4843 - val_mae: 605.4714 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 587.8956 - mae: 587.8829 - val_loss: 595.9457 - val_mae: 595.9327 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 576.8715 - mae: 576.8582 - val_loss: 584.2122 - val_mae: 584.1986 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 564.3698 - mae: 564.3558 - val_loss: 571.2375 - val_mae: 571.2230 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 550.1277 - mae: 550.1126 - val_loss: 556.6483 - val_mae: 556.6324 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 534.9092 - mae: 534.8928 - val_loss: 541.2787 - val_mae: 541.2613 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 518.9763 - mae: 518.9581 - val_loss: 525.0705 - val_mae: 525.0511 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 502.6613 - mae: 502.6410 - val_loss: 508.4116 - val_mae: 508.3899 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 485.8059 - mae: 485.7832 - val_loss: 491.3166 - val_mae: 491.2924 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 467.6312 - mae: 467.6057 - val_loss: 473.4367 - val_mae: 473.4096 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 449.4986 - mae: 449.4701 - val_loss: 452.9874 - val_mae: 452.9572 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 428.2384 - mae: 428.2066 - val_loss: 429.2105 - val_mae: 429.1767 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 402.5872 - mae: 402.5518 - val_loss: 401.6337 - val_mae: 401.5960 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 373.1556 - mae: 373.1160 - val_loss: 370.2019 - val_mae: 370.1598 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 344.6901 - mae: 344.6459 - val_loss: 343.7987 - val_mae: 343.7518 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 320.4712 - mae: 320.4222 - val_loss: 317.6692 - val_mae: 317.6175 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 298.4718 - mae: 298.4181 - val_loss: 296.1158 - val_mae: 296.0592 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 280.2339 - mae: 280.1753 - val_loss: 279.3016 - val_mae: 279.2404 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 264.0823 - mae: 264.0191 - val_loss: 265.5143 - val_mae: 265.4486 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 252.3377 - mae: 252.2701 - val_loss: 255.0724 - val_mae: 255.0026 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 710.1379\n",
      "LV_RMSE_12h: 817.6683\n",
      "LV_MAE_24h: 129.2874\n",
      "LV_RMSE_24h: 176.2051\n",
      "LV_MAE_48h: 155.6523\n",
      "LV_RMSE_48h: 222.9043\n",
      "LV_MAE_72h: 133.5287\n",
      "LV_RMSE_72h: 185.8191\n",
      "LV_MAE_mean: 282.1516\n",
      "LV_RMSE_mean: 350.6492\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 515.2540\n",
      "RMSE_12h: 626.2392\n",
      "MAE_24h: 176.1024\n",
      "RMSE_24h: 248.6096\n",
      "MAE_48h: 187.2224\n",
      "RMSE_48h: 261.0102\n",
      "MAE_72h: 180.4584\n",
      "RMSE_72h: 250.6060\n",
      "MAE_mean: 264.7593\n",
      "RMSE_mean: 346.6163\n",
      "\n",
      "=== Station S3091033 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1377 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1354, 24, 400) Ytr2: (1354, 4) \n",
      "  Xva3: (197, 24, 400) Yva2: (197, 4) \n",
      "  Xte3: (348, 24, 400) Yte2: (348, 4)\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 3s 67ms/step - loss: 500.5221 - mae: 500.5093 - val_loss: 474.0586 - val_mae: 474.0458 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 495.1411 - mae: 495.1281 - val_loss: 466.4702 - val_mae: 466.4572 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 485.9839 - mae: 485.9706 - val_loss: 456.2851 - val_mae: 456.2716 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 475.3853 - mae: 475.3714 - val_loss: 445.1954 - val_mae: 445.1810 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 463.4487 - mae: 463.4337 - val_loss: 433.3320 - val_mae: 433.3164 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 451.1100 - mae: 451.0938 - val_loss: 420.2035 - val_mae: 420.1863 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 437.4742 - mae: 437.4562 - val_loss: 405.7106 - val_mae: 405.6916 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 423.1588 - mae: 423.1389 - val_loss: 391.0472 - val_mae: 391.0261 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 409.3261 - mae: 409.3040 - val_loss: 377.3298 - val_mae: 377.3063 - lr: 0.0010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 395.3890 - mae: 395.3644 - val_loss: 363.7229 - val_mae: 363.6968 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 382.5585 - mae: 382.5313 - val_loss: 349.1727 - val_mae: 349.1440 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 366.4571 - mae: 366.4271 - val_loss: 332.5772 - val_mae: 332.5456 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 350.2267 - mae: 350.1938 - val_loss: 313.6620 - val_mae: 313.6274 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 332.1219 - mae: 332.0857 - val_loss: 295.9334 - val_mae: 295.8953 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 315.3193 - mae: 315.2796 - val_loss: 278.5172 - val_mae: 278.4753 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 297.9095 - mae: 297.8658 - val_loss: 260.9293 - val_mae: 260.8833 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 279.5819 - mae: 279.5341 - val_loss: 244.0906 - val_mae: 244.0404 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 262.3362 - mae: 262.2841 - val_loss: 229.6469 - val_mae: 229.5925 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 248.6711 - mae: 248.6147 - val_loss: 215.9547 - val_mae: 215.8959 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 236.9968 - mae: 236.9363 - val_loss: 206.3243 - val_mae: 206.2616 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 607.1954\n",
      "LV_RMSE_12h: 671.4269\n",
      "LV_MAE_24h: 100.9511\n",
      "LV_RMSE_24h: 151.7053\n",
      "LV_MAE_48h: 124.6178\n",
      "LV_RMSE_48h: 186.9352\n",
      "LV_MAE_72h: 113.4195\n",
      "LV_RMSE_72h: 179.2225\n",
      "LV_MAE_mean: 236.5460\n",
      "LV_RMSE_mean: 297.3225\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 418.2968\n",
      "RMSE_12h: 494.4504\n",
      "MAE_24h: 146.4657\n",
      "RMSE_24h: 197.3039\n",
      "MAE_48h: 151.5757\n",
      "RMSE_48h: 201.2443\n",
      "MAE_72h: 159.2492\n",
      "RMSE_72h: 208.6881\n",
      "MAE_mean: 218.8968\n",
      "RMSE_mean: 275.4217\n",
      "\n",
      "=== Station S3091061 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1377 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1354, 24, 400) Ytr2: (1354, 4) \n",
      "  Xva3: (197, 24, 400) Yva2: (197, 4) \n",
      "  Xte3: (348, 24, 400) Yte2: (348, 4)\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 3s 66ms/step - loss: 447.0132 - mae: 447.0006 - val_loss: 429.9760 - val_mae: 429.9633 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 439.8433 - mae: 439.8304 - val_loss: 420.5164 - val_mae: 420.5034 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 429.1209 - mae: 429.1076 - val_loss: 409.1433 - val_mae: 409.1296 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 417.4449 - mae: 417.4308 - val_loss: 397.2740 - val_mae: 397.2592 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 404.7113 - mae: 404.6960 - val_loss: 383.9512 - val_mae: 383.9350 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 391.0105 - mae: 390.9935 - val_loss: 368.8545 - val_mae: 368.8365 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 376.2485 - mae: 376.2296 - val_loss: 353.3495 - val_mae: 353.3293 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 361.4326 - mae: 361.4114 - val_loss: 338.6821 - val_mae: 338.6596 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 347.8177 - mae: 347.7941 - val_loss: 324.6237 - val_mae: 324.5986 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 334.2631 - mae: 334.2368 - val_loss: 310.8105 - val_mae: 310.7827 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 321.3566 - mae: 321.3275 - val_loss: 293.8860 - val_mae: 293.8553 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 302.2329 - mae: 302.2010 - val_loss: 272.0951 - val_mae: 272.0614 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 280.9659 - mae: 280.9307 - val_loss: 251.0611 - val_mae: 251.0238 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 261.4414 - mae: 261.4025 - val_loss: 231.6410 - val_mae: 231.5998 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 243.3307 - mae: 243.2876 - val_loss: 214.4895 - val_mae: 214.4441 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 228.1057 - mae: 228.0584 - val_loss: 199.3095 - val_mae: 199.2599 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 213.5576 - mae: 213.5062 - val_loss: 186.7725 - val_mae: 186.7189 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 202.1882 - mae: 202.1330 - val_loss: 176.8379 - val_mae: 176.7806 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 191.4922 - mae: 191.4335 - val_loss: 169.7318 - val_mae: 169.6714 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 185.0599 - mae: 184.9983 - val_loss: 163.7591 - val_mae: 163.6962 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 562.3477\n",
      "LV_RMSE_12h: 623.5441\n",
      "LV_MAE_24h: 95.2557\n",
      "LV_RMSE_24h: 140.1554\n",
      "LV_MAE_48h: 112.4511\n",
      "LV_RMSE_48h: 164.5508\n",
      "LV_MAE_72h: 105.3994\n",
      "LV_RMSE_72h: 159.3930\n",
      "LV_MAE_mean: 218.8635\n",
      "LV_RMSE_mean: 271.9109\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 386.4017\n",
      "RMSE_12h: 465.4965\n",
      "MAE_24h: 118.8603\n",
      "RMSE_24h: 168.2228\n",
      "MAE_48h: 115.9451\n",
      "RMSE_48h: 165.8533\n",
      "MAE_72h: 116.5193\n",
      "RMSE_72h: 166.8610\n",
      "MAE_mean: 184.4316\n",
      "RMSE_mean: 241.6084\n",
      "\n",
      "=== Station S3092011 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1377 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1354, 24, 400) Ytr2: (1354, 4) \n",
      "  Xva3: (197, 24, 400) Yva2: (197, 4) \n",
      "  Xte3: (348, 24, 400) Yte2: (348, 4)\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 3s 67ms/step - loss: 397.1663 - mae: 397.1535 - val_loss: 400.8048 - val_mae: 400.7920 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 391.3418 - mae: 391.3291 - val_loss: 393.1503 - val_mae: 393.1374 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 382.3387 - mae: 382.3256 - val_loss: 383.3873 - val_mae: 383.3740 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 372.0687 - mae: 372.0551 - val_loss: 372.5153 - val_mae: 372.5012 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 360.6701 - mae: 360.6556 - val_loss: 361.2022 - val_mae: 361.1871 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 349.0870 - mae: 349.0714 - val_loss: 348.6486 - val_mae: 348.6322 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 336.8270 - mae: 336.8099 - val_loss: 335.3877 - val_mae: 335.3697 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 323.4146 - mae: 323.3957 - val_loss: 321.9372 - val_mae: 321.9172 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 310.3694 - mae: 310.3485 - val_loss: 308.0220 - val_mae: 307.9999 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 296.4642 - mae: 296.4411 - val_loss: 293.5438 - val_mae: 293.5193 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 281.5368 - mae: 281.5111 - val_loss: 278.0621 - val_mae: 278.0350 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 265.4312 - mae: 265.4028 - val_loss: 260.3304 - val_mae: 260.3005 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 248.5393 - mae: 248.5081 - val_loss: 241.7937 - val_mae: 241.7608 - lr: 0.0010\n",
      "Epoch 14/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 13ms/step - loss: 231.5433 - mae: 231.5090 - val_loss: 223.8408 - val_mae: 223.8048 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 216.6065 - mae: 216.5692 - val_loss: 209.1600 - val_mae: 209.1209 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 204.5113 - mae: 204.4709 - val_loss: 198.4821 - val_mae: 198.4401 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 194.1252 - mae: 194.0819 - val_loss: 190.0784 - val_mae: 190.0336 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 184.6145 - mae: 184.5685 - val_loss: 180.9023 - val_mae: 180.8547 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 176.9142 - mae: 176.8653 - val_loss: 172.7135 - val_mae: 172.6630 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 170.5413 - mae: 170.4896 - val_loss: 166.7389 - val_mae: 166.6858 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 521.9569\n",
      "LV_RMSE_12h: 605.8431\n",
      "LV_MAE_24h: 87.0172\n",
      "LV_RMSE_24h: 116.0265\n",
      "LV_MAE_48h: 102.6351\n",
      "LV_RMSE_48h: 144.3970\n",
      "LV_MAE_72h: 92.7701\n",
      "LV_RMSE_72h: 126.9343\n",
      "LV_MAE_mean: 201.0948\n",
      "LV_RMSE_mean: 248.3002\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 358.9119\n",
      "RMSE_12h: 446.0221\n",
      "MAE_24h: 116.8576\n",
      "RMSE_24h: 169.8946\n",
      "MAE_48h: 122.7303\n",
      "RMSE_48h: 176.7906\n",
      "MAE_72h: 123.3553\n",
      "RMSE_72h: 176.9063\n",
      "MAE_mean: 180.4638\n",
      "RMSE_mean: 242.4034\n",
      "\n",
      "=== Station S3092012 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1377 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1354, 24, 400) Ytr2: (1354, 4) \n",
      "  Xva3: (197, 24, 400) Yva2: (197, 4) \n",
      "  Xte3: (348, 24, 400) Yte2: (348, 4)\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 3s 64ms/step - loss: 2215.1035 - mae: 2215.0906 - val_loss: 2241.2178 - val_mae: 2241.2051 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 2210.6572 - mae: 2210.6445 - val_loss: 2234.1221 - val_mae: 2234.1091 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 2201.2527 - mae: 2201.2400 - val_loss: 2222.2744 - val_mae: 2222.2610 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 2187.9504 - mae: 2187.9368 - val_loss: 2206.8647 - val_mae: 2206.8506 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 2170.6272 - mae: 2170.6128 - val_loss: 2187.3606 - val_mae: 2187.3452 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 2149.0308 - mae: 2149.0149 - val_loss: 2163.2791 - val_mae: 2163.2620 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 2123.1731 - mae: 2123.1555 - val_loss: 2134.4885 - val_mae: 2134.4695 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 2091.7708 - mae: 2091.7510 - val_loss: 2100.9087 - val_mae: 2100.8870 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 2057.9194 - mae: 2057.8965 - val_loss: 2064.6208 - val_mae: 2064.5964 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 2021.0079 - mae: 2020.9823 - val_loss: 2027.5277 - val_mae: 2027.5001 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1985.1265 - mae: 1985.0975 - val_loss: 1992.3708 - val_mae: 1992.3398 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1950.2928 - mae: 1950.2600 - val_loss: 1956.6577 - val_mae: 1956.6228 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1914.9701 - mae: 1914.9337 - val_loss: 1920.5275 - val_mae: 1920.4885 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1879.1274 - mae: 1879.0869 - val_loss: 1884.7188 - val_mae: 1884.6758 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1844.7645 - mae: 1844.7195 - val_loss: 1849.8835 - val_mae: 1849.8362 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 1812.4304 - mae: 1812.3805 - val_loss: 1815.7660 - val_mae: 1815.7139 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1778.9956 - mae: 1778.9417 - val_loss: 1782.3508 - val_mae: 1782.2939 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1745.2158 - mae: 1745.1567 - val_loss: 1749.9149 - val_mae: 1749.8531 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1714.2119 - mae: 1714.1479 - val_loss: 1717.0411 - val_mae: 1716.9739 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1683.0078 - mae: 1682.9384 - val_loss: 1682.7823 - val_mae: 1682.7097 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 2313.3276\n",
      "LV_RMSE_12h: 2594.0083\n",
      "LV_MAE_24h: 402.1552\n",
      "LV_RMSE_24h: 615.9161\n",
      "LV_MAE_48h: 538.3161\n",
      "LV_RMSE_48h: 829.8513\n",
      "LV_MAE_72h: 441.3190\n",
      "LV_RMSE_72h: 696.2057\n",
      "LV_MAE_mean: 923.7795\n",
      "LV_RMSE_mean: 1183.9954\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 1495.6062\n",
      "RMSE_12h: 1877.5723\n",
      "MAE_24h: 1511.8571\n",
      "RMSE_24h: 1897.3831\n",
      "MAE_48h: 1503.5647\n",
      "RMSE_48h: 1884.8066\n",
      "MAE_72h: 1515.9938\n",
      "RMSE_72h: 1900.3311\n",
      "MAE_mean: 1506.7555\n",
      "RMSE_mean: 1890.0232\n",
      "\n",
      "=== Station S3092031 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1377 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1354, 24, 400) Ytr2: (1354, 4) \n",
      "  Xva3: (197, 24, 400) Yva2: (197, 4) \n",
      "  Xte3: (348, 24, 400) Yte2: (348, 4)\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 3s 68ms/step - loss: 452.6302 - mae: 452.6174 - val_loss: 447.1302 - val_mae: 447.1173 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 447.0052 - mae: 446.9923 - val_loss: 439.4563 - val_mae: 439.4433 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 437.7819 - mae: 437.7687 - val_loss: 429.2661 - val_mae: 429.2526 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 427.3359 - mae: 427.3222 - val_loss: 418.2758 - val_mae: 418.2616 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 415.8972 - mae: 415.8825 - val_loss: 406.3882 - val_mae: 406.3730 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 403.9640 - mae: 403.9482 - val_loss: 393.4861 - val_mae: 393.4696 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 391.3325 - mae: 391.3153 - val_loss: 379.2112 - val_mae: 379.1930 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 377.2570 - mae: 377.2379 - val_loss: 365.6800 - val_mae: 365.6598 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 364.4099 - mae: 364.3888 - val_loss: 352.5041 - val_mae: 352.4818 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 351.8860 - mae: 351.8628 - val_loss: 339.4556 - val_mae: 339.4311 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 339.5731 - mae: 339.5475 - val_loss: 326.5392 - val_mae: 326.5123 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 326.5212 - mae: 326.4932 - val_loss: 311.0057 - val_mae: 310.9761 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 311.9931 - mae: 311.9625 - val_loss: 295.6148 - val_mae: 295.5825 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 296.1510 - mae: 296.1174 - val_loss: 277.3071 - val_mae: 277.2719 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 279.5626 - mae: 279.5259 - val_loss: 257.8096 - val_mae: 257.7712 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 260.6701 - mae: 260.6302 - val_loss: 237.4916 - val_mae: 237.4497 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 241.8190 - mae: 241.7754 - val_loss: 219.9027 - val_mae: 219.8570 - lr: 0.0010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 225.4120 - mae: 225.3646 - val_loss: 205.9106 - val_mae: 205.8610 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 212.2665 - mae: 212.2151 - val_loss: 191.4580 - val_mae: 191.4044 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 201.9116 - mae: 201.8565 - val_loss: 181.6770 - val_mae: 181.6200 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 581.3190\n",
      "LV_RMSE_12h: 641.2326\n",
      "LV_MAE_24h: 96.5632\n",
      "LV_RMSE_24h: 145.0650\n",
      "LV_MAE_48h: 120.3506\n",
      "LV_RMSE_48h: 174.1791\n",
      "LV_MAE_72h: 115.5690\n",
      "LV_RMSE_72h: 172.9597\n",
      "LV_MAE_mean: 228.4504\n",
      "LV_RMSE_mean: 283.3591\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 405.0073\n",
      "RMSE_12h: 478.9200\n",
      "MAE_24h: 144.5514\n",
      "RMSE_24h: 196.9810\n",
      "MAE_48h: 143.1354\n",
      "RMSE_48h: 196.7338\n",
      "MAE_72h: 141.4980\n",
      "RMSE_72h: 193.4302\n",
      "MAE_mean: 208.5480\n",
      "RMSE_mean: 266.5162\n",
      "\n",
      "=== Station S3092052 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1377 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1354, 24, 400) Ytr2: (1354, 4) \n",
      "  Xva3: (197, 24, 400) Yva2: (197, 4) \n",
      "  Xte3: (348, 24, 400) Yte2: (348, 4)\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 3s 65ms/step - loss: 1562.0634 - mae: 1562.0502 - val_loss: 1559.8961 - val_mae: 1559.8833 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1555.4352 - mae: 1555.4222 - val_loss: 1550.2463 - val_mae: 1550.2332 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1543.3558 - mae: 1543.3427 - val_loss: 1535.8290 - val_mae: 1535.8153 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1527.5253 - mae: 1527.5111 - val_loss: 1517.5111 - val_mae: 1517.4962 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1506.6573 - mae: 1506.6420 - val_loss: 1494.3712 - val_mae: 1494.3550 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1481.4889 - mae: 1481.4719 - val_loss: 1466.0851 - val_mae: 1466.0669 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1451.0970 - mae: 1451.0779 - val_loss: 1432.4847 - val_mae: 1432.4641 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1416.0100 - mae: 1415.9883 - val_loss: 1395.6726 - val_mae: 1395.6489 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1379.0103 - mae: 1378.9854 - val_loss: 1358.3248 - val_mae: 1358.2981 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1341.8232 - mae: 1341.7949 - val_loss: 1321.7915 - val_mae: 1321.7611 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1308.4146 - mae: 1308.3827 - val_loss: 1287.7935 - val_mae: 1287.7593 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1274.3804 - mae: 1274.3445 - val_loss: 1254.2400 - val_mae: 1254.2018 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1242.0607 - mae: 1242.0206 - val_loss: 1220.2867 - val_mae: 1220.2441 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1211.0574 - mae: 1211.0131 - val_loss: 1187.1827 - val_mae: 1187.1357 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 1178.0288 - mae: 1177.9796 - val_loss: 1154.5167 - val_mae: 1154.4648 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1147.6882 - mae: 1147.6342 - val_loss: 1122.4670 - val_mae: 1122.4104 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1117.2679 - mae: 1117.2090 - val_loss: 1091.7029 - val_mae: 1091.6410 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1087.8439 - mae: 1087.7798 - val_loss: 1063.2701 - val_mae: 1063.2030 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1061.5244 - mae: 1061.4550 - val_loss: 1032.5743 - val_mae: 1032.5020 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1030.9398 - mae: 1030.8652 - val_loss: 995.2267 - val_mae: 995.1489 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 1529.4425\n",
      "LV_RMSE_12h: 1675.7455\n",
      "LV_MAE_24h: 261.8419\n",
      "LV_RMSE_24h: 435.1469\n",
      "LV_MAE_48h: 357.1437\n",
      "LV_RMSE_48h: 571.5217\n",
      "LV_MAE_72h: 299.3563\n",
      "LV_RMSE_72h: 505.4571\n",
      "LV_MAE_mean: 611.9462\n",
      "LV_RMSE_mean: 796.9678\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 962.5117\n",
      "RMSE_12h: 1161.3982\n",
      "MAE_24h: 893.4321\n",
      "RMSE_24h: 1090.8516\n",
      "MAE_48h: 875.6819\n",
      "RMSE_48h: 1064.8615\n",
      "MAE_72h: 879.9844\n",
      "RMSE_72h: 1072.1111\n",
      "MAE_mean: 902.9025\n",
      "RMSE_mean: 1097.3057\n",
      "\n",
      "=== Station S3092064 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1377 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1354, 24, 400) Ytr2: (1354, 4) \n",
      "  Xva3: (197, 24, 400) Yva2: (197, 4) \n",
      "  Xte3: (348, 24, 400) Yte2: (348, 4)\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 3s 63ms/step - loss: 1549.5422 - mae: 1549.5295 - val_loss: 1537.9885 - val_mae: 1537.9757 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1543.8180 - mae: 1543.8051 - val_loss: 1529.5302 - val_mae: 1529.5170 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1533.3672 - mae: 1533.3540 - val_loss: 1516.8470 - val_mae: 1516.8335 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1518.9546 - mae: 1518.9407 - val_loss: 1499.9740 - val_mae: 1499.9594 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 1499.5110 - mae: 1499.4956 - val_loss: 1477.9458 - val_mae: 1477.9296 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1475.3055 - mae: 1475.2885 - val_loss: 1450.5293 - val_mae: 1450.5111 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1446.2645 - mae: 1446.2452 - val_loss: 1418.8972 - val_mae: 1418.8766 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1413.4014 - mae: 1413.3794 - val_loss: 1386.2103 - val_mae: 1386.1869 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 1381.5594 - mae: 1381.5345 - val_loss: 1354.2429 - val_mae: 1354.2162 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1349.5673 - mae: 1349.5391 - val_loss: 1322.5909 - val_mae: 1322.5605 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1318.1387 - mae: 1318.1068 - val_loss: 1290.1039 - val_mae: 1290.0698 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1287.3447 - mae: 1287.3090 - val_loss: 1259.0153 - val_mae: 1258.9772 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1255.9014 - mae: 1255.8616 - val_loss: 1228.5295 - val_mae: 1228.4871 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1226.2509 - mae: 1226.2063 - val_loss: 1199.0239 - val_mae: 1198.9771 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1196.6577 - mae: 1196.6086 - val_loss: 1169.7803 - val_mae: 1169.7285 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1171.0938 - mae: 1171.0399 - val_loss: 1141.4528 - val_mae: 1141.3961 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1141.0668 - mae: 1141.0078 - val_loss: 1112.6558 - val_mae: 1112.5939 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1112.6805 - mae: 1112.6165 - val_loss: 1085.0447 - val_mae: 1084.9774 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1086.2339 - mae: 1086.1642 - val_loss: 1055.8492 - val_mae: 1055.7764 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1055.6648 - mae: 1055.5892 - val_loss: 1017.5624 - val_mae: 1017.4836 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 1645.9425\n",
      "LV_RMSE_12h: 1832.1991\n",
      "LV_MAE_24h: 261.9914\n",
      "LV_RMSE_24h: 398.8094\n",
      "LV_MAE_48h: 347.7500\n",
      "LV_RMSE_48h: 533.2499\n",
      "LV_MAE_72h: 284.1753\n",
      "LV_RMSE_72h: 441.0355\n",
      "LV_MAE_mean: 634.9648\n",
      "LV_RMSE_mean: 801.3235\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 988.4019\n",
      "RMSE_12h: 1208.4794\n",
      "MAE_24h: 915.8356\n",
      "RMSE_24h: 1130.4773\n",
      "MAE_48h: 922.1719\n",
      "RMSE_48h: 1139.0924\n",
      "MAE_72h: 929.7903\n",
      "RMSE_72h: 1150.4226\n",
      "MAE_mean: 939.0499\n",
      "RMSE_mean: 1157.1179\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Station S3102011 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1209 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1186, 24, 400) Ytr2: (1186, 4) \n",
      "  Xva3: (173, 24, 400) Yva2: (173, 4) \n",
      "  Xte3: (300, 24, 400) Yte2: (300, 4)\n",
      "Epoch 1/20\n",
      "10/10 [==============================] - 3s 74ms/step - loss: 545.1039 - mae: 545.0911 - val_loss: 1362.4260 - val_mae: 1362.4133 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 539.7560 - mae: 539.7432 - val_loss: 1354.9982 - val_mae: 1354.9852 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 530.9964 - mae: 530.9834 - val_loss: 1344.7621 - val_mae: 1344.7488 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 519.8188 - mae: 519.8053 - val_loss: 1331.8969 - val_mae: 1331.8828 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 506.0648 - mae: 506.0504 - val_loss: 1315.6610 - val_mae: 1315.6460 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 490.3939 - mae: 490.3784 - val_loss: 1296.5946 - val_mae: 1296.5785 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 475.1320 - mae: 475.1153 - val_loss: 1275.2760 - val_mae: 1275.2583 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 459.9484 - mae: 459.9300 - val_loss: 1251.6844 - val_mae: 1251.6652 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 444.9586 - mae: 444.9385 - val_loss: 1226.3619 - val_mae: 1226.3407 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 430.4112 - mae: 430.3891 - val_loss: 1198.9854 - val_mae: 1198.9620 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 416.2250 - mae: 416.2009 - val_loss: 1169.9801 - val_mae: 1169.9547 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 403.3909 - mae: 403.3645 - val_loss: 1141.5127 - val_mae: 1141.4849 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 392.1477 - mae: 392.1190 - val_loss: 1116.7314 - val_mae: 1116.7014 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 382.3007 - mae: 382.2699 - val_loss: 1095.0802 - val_mae: 1095.0482 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 374.7601 - mae: 374.7272 - val_loss: 1075.3788 - val_mae: 1075.3448 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 366.5989 - mae: 366.5641 - val_loss: 1059.1755 - val_mae: 1059.1395 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 353.2874 - mae: 353.2506 - val_loss: 1037.9767 - val_mae: 1037.9386 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 339.1963 - mae: 339.1573 - val_loss: 1018.6696 - val_mae: 1018.6293 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 328.9183 - mae: 328.8770 - val_loss: 997.3645 - val_mae: 997.3217 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 317.8194 - mae: 317.7757 - val_loss: 977.8287 - val_mae: 977.7836 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 1199.3567\n",
      "LV_RMSE_12h: 1303.0818\n",
      "LV_MAE_24h: 102.5767\n",
      "LV_RMSE_24h: 218.4242\n",
      "LV_MAE_48h: 179.4167\n",
      "LV_RMSE_48h: 335.2091\n",
      "LV_MAE_72h: 194.2400\n",
      "LV_RMSE_72h: 348.5547\n",
      "LV_MAE_mean: 418.8975\n",
      "LV_RMSE_mean: 551.3174\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 1028.0138\n",
      "RMSE_12h: 1224.8982\n",
      "MAE_24h: 961.9644\n",
      "RMSE_24h: 1151.0819\n",
      "MAE_48h: 941.1284\n",
      "RMSE_48h: 1128.6160\n",
      "MAE_72h: 942.3137\n",
      "RMSE_72h: 1129.2679\n",
      "MAE_mean: 968.3550\n",
      "RMSE_mean: 1158.4659\n",
      "\n",
      "=== Station S3102013 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1209 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1186, 24, 400) Ytr2: (1186, 4) \n",
      "  Xva3: (173, 24, 400) Yva2: (173, 4) \n",
      "  Xte3: (300, 24, 400) Yte2: (300, 4)\n",
      "Epoch 1/20\n",
      "10/10 [==============================] - 3s 68ms/step - loss: 1924.4047 - mae: 1924.3916 - val_loss: 2729.0903 - val_mae: 2729.0774 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 1919.7964 - mae: 1919.7831 - val_loss: 2722.1597 - val_mae: 2722.1467 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 1911.4484 - mae: 1911.4351 - val_loss: 2711.7769 - val_mae: 2711.7634 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 1900.4263 - mae: 1900.4125 - val_loss: 2698.8440 - val_mae: 2698.8296 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 1886.4684 - mae: 1886.4539 - val_loss: 2682.5122 - val_mae: 2682.4968 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 1869.0782 - mae: 1869.0621 - val_loss: 2662.2766 - val_mae: 2662.2598 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 1847.4553 - mae: 1847.4374 - val_loss: 2637.7817 - val_mae: 2637.7632 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "10/10 [==============================] - 0s 19ms/step - loss: 1821.9896 - mae: 1821.9703 - val_loss: 2608.7820 - val_mae: 2608.7612 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 1791.9064 - mae: 1791.8846 - val_loss: 2575.5122 - val_mae: 2575.4888 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 1758.4413 - mae: 1758.4167 - val_loss: 2537.7949 - val_mae: 2537.7686 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 1721.6250 - mae: 1721.5972 - val_loss: 2495.9578 - val_mae: 2495.9280 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 1682.0748 - mae: 1682.0436 - val_loss: 2450.6587 - val_mae: 2450.6252 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 1643.3098 - mae: 1643.2748 - val_loss: 2403.3896 - val_mae: 2403.3523 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 1604.1310 - mae: 1604.0919 - val_loss: 2353.6587 - val_mae: 2353.6169 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 1567.9034 - mae: 1567.8601 - val_loss: 2303.3440 - val_mae: 2303.2981 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 1530.3776 - mae: 1530.3296 - val_loss: 2255.1379 - val_mae: 2255.0874 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 1496.7910 - mae: 1496.7386 - val_loss: 2210.0557 - val_mae: 2210.0005 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 1462.9664 - mae: 1462.9094 - val_loss: 2167.0864 - val_mae: 2167.0266 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 1434.4885 - mae: 1434.4266 - val_loss: 2125.3213 - val_mae: 2125.2568 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 1407.6183 - mae: 1407.5516 - val_loss: 2085.8713 - val_mae: 2085.8020 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 2398.4700\n",
      "LV_RMSE_12h: 2605.9346\n",
      "LV_MAE_24h: 205.3167\n",
      "LV_RMSE_24h: 436.7631\n",
      "LV_MAE_48h: 358.6867\n",
      "LV_RMSE_48h: 670.5381\n",
      "LV_MAE_72h: 388.5333\n",
      "LV_RMSE_72h: 697.1479\n",
      "LV_MAE_mean: 837.7517\n",
      "LV_RMSE_mean: 1102.5959\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 2051.9204\n",
      "RMSE_12h: 2439.0759\n",
      "MAE_24h: 2045.1619\n",
      "RMSE_24h: 2412.7527\n",
      "MAE_48h: 2069.4014\n",
      "RMSE_48h: 2442.7861\n",
      "MAE_72h: 2099.4836\n",
      "RMSE_72h: 2477.5386\n",
      "MAE_mean: 2066.4917\n",
      "RMSE_mean: 2443.0383\n",
      "\n",
      "=== Station S311847 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1376 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1353, 24, 400) Ytr2: (1353, 4) \n",
      "  Xva3: (197, 24, 400) Yva2: (197, 4) \n",
      "  Xte3: (347, 24, 400) Yte2: (347, 4)\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 3s 66ms/step - loss: 399.4299 - mae: 399.4172 - val_loss: 416.5425 - val_mae: 416.5299 - lr: 0.0010\n",
      "Epoch 2/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 13ms/step - loss: 394.6313 - mae: 394.6186 - val_loss: 409.5185 - val_mae: 409.5057 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 385.9671 - mae: 385.9542 - val_loss: 399.0345 - val_mae: 399.0213 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 374.2650 - mae: 374.2515 - val_loss: 385.4583 - val_mae: 385.4442 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 359.8963 - mae: 359.8817 - val_loss: 370.0614 - val_mae: 370.0463 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 344.8345 - mae: 344.8187 - val_loss: 354.2476 - val_mae: 354.2310 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 329.3524 - mae: 329.3351 - val_loss: 338.3284 - val_mae: 338.3102 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 314.7522 - mae: 314.7332 - val_loss: 324.3156 - val_mae: 324.2954 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 302.8045 - mae: 302.7836 - val_loss: 312.6335 - val_mae: 312.6114 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 291.7116 - mae: 291.6887 - val_loss: 302.6830 - val_mae: 302.6591 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 282.7512 - mae: 282.7263 - val_loss: 293.9091 - val_mae: 293.8831 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 275.2826 - mae: 275.2557 - val_loss: 286.5683 - val_mae: 286.5404 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 269.0170 - mae: 268.9883 - val_loss: 279.1436 - val_mae: 279.1139 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 259.7324 - mae: 259.7019 - val_loss: 264.1245 - val_mae: 264.0930 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 243.4683 - mae: 243.4358 - val_loss: 248.5131 - val_mae: 248.4793 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 228.3138 - mae: 228.2789 - val_loss: 233.7995 - val_mae: 233.7631 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 215.9111 - mae: 215.8734 - val_loss: 219.8302 - val_mae: 219.7907 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 204.8281 - mae: 204.7873 - val_loss: 206.6225 - val_mae: 206.5799 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 194.3599 - mae: 194.3159 - val_loss: 194.9558 - val_mae: 194.9101 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 185.9896 - mae: 185.9426 - val_loss: 184.3796 - val_mae: 184.3309 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 497.7983\n",
      "LV_RMSE_12h: 555.4208\n",
      "LV_MAE_24h: 100.0692\n",
      "LV_RMSE_24h: 152.7893\n",
      "LV_MAE_48h: 120.8444\n",
      "LV_RMSE_48h: 184.4260\n",
      "LV_MAE_72h: 108.6254\n",
      "LV_RMSE_72h: 172.5219\n",
      "LV_MAE_mean: 206.8343\n",
      "LV_RMSE_mean: 266.2895\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 330.5367\n",
      "RMSE_12h: 409.1338\n",
      "MAE_24h: 125.4407\n",
      "RMSE_24h: 188.1848\n",
      "MAE_48h: 124.0098\n",
      "RMSE_48h: 186.3074\n",
      "MAE_72h: 113.9237\n",
      "RMSE_72h: 169.3315\n",
      "MAE_mean: 173.4777\n",
      "RMSE_mean: 238.2393\n",
      "\n",
      "=== Station S312421 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1376 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1353, 24, 400) Ytr2: (1353, 4) \n",
      "  Xva3: (197, 24, 400) Yva2: (197, 4) \n",
      "  Xte3: (348, 24, 400) Yte2: (348, 4)\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 3s 74ms/step - loss: 2928.3843 - mae: 2928.3716 - val_loss: 2942.5349 - val_mae: 2942.5222 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 2921.1917 - mae: 2921.1790 - val_loss: 2932.5688 - val_mae: 2932.5559 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 2909.4575 - mae: 2909.4441 - val_loss: 2918.8811 - val_mae: 2918.8674 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 2894.0908 - mae: 2894.0771 - val_loss: 2901.2737 - val_mae: 2901.2595 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 2874.7798 - mae: 2874.7646 - val_loss: 2878.9993 - val_mae: 2878.9834 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 2850.2708 - mae: 2850.2544 - val_loss: 2851.8369 - val_mae: 2851.8198 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 2820.9146 - mae: 2820.8967 - val_loss: 2819.6321 - val_mae: 2819.6123 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 2786.6165 - mae: 2786.5955 - val_loss: 2782.1863 - val_mae: 2782.1641 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 2746.9646 - mae: 2746.9414 - val_loss: 2739.4309 - val_mae: 2739.4055 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 2701.7747 - mae: 2701.7478 - val_loss: 2691.2063 - val_mae: 2691.1770 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 2650.6475 - mae: 2650.6167 - val_loss: 2637.3911 - val_mae: 2637.3577 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 2593.1089 - mae: 2593.0732 - val_loss: 2577.9309 - val_mae: 2577.8926 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 2531.9287 - mae: 2531.8884 - val_loss: 2512.9170 - val_mae: 2512.8735 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 2464.2690 - mae: 2464.2229 - val_loss: 2443.0583 - val_mae: 2443.0093 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 2394.3933 - mae: 2394.3416 - val_loss: 2369.8477 - val_mae: 2369.7925 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 2320.9570 - mae: 2320.8989 - val_loss: 2297.0449 - val_mae: 2296.9829 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 2252.2002 - mae: 2252.1353 - val_loss: 2229.1887 - val_mae: 2229.1199 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 2188.4028 - mae: 2188.3308 - val_loss: 2166.0166 - val_mae: 2165.9409 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 2126.6641 - mae: 2126.5854 - val_loss: 2107.0972 - val_mae: 2107.0144 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 2063.6123 - mae: 2063.5269 - val_loss: 2051.8403 - val_mae: 2051.7507 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 2356.0862\n",
      "LV_RMSE_12h: 2597.7253\n",
      "LV_MAE_24h: 395.5891\n",
      "LV_RMSE_24h: 624.1216\n",
      "LV_MAE_48h: 514.8017\n",
      "LV_RMSE_48h: 784.7961\n",
      "LV_MAE_72h: 405.4397\n",
      "LV_RMSE_72h: 617.4187\n",
      "LV_MAE_mean: 917.9792\n",
      "LV_RMSE_mean: 1156.0154\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 1914.6708\n",
      "RMSE_12h: 2303.9165\n",
      "MAE_24h: 1979.1379\n",
      "RMSE_24h: 2356.9670\n",
      "MAE_48h: 1994.5000\n",
      "RMSE_48h: 2377.3267\n",
      "MAE_72h: 1928.2886\n",
      "RMSE_72h: 2298.7747\n",
      "MAE_mean: 1954.1493\n",
      "RMSE_mean: 2334.2463\n",
      "\n",
      "=== Station S312513 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1376 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1353, 24, 400) Ytr2: (1353, 4) \n",
      "  Xva3: (197, 24, 400) Yva2: (197, 4) \n",
      "  Xte3: (348, 24, 400) Yte2: (348, 4)\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 3s 65ms/step - loss: 2309.7783 - mae: 2309.7656 - val_loss: 2303.6392 - val_mae: 2303.6265 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 2305.4209 - mae: 2305.4080 - val_loss: 2297.0747 - val_mae: 2297.0618 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 2297.0149 - mae: 2297.0017 - val_loss: 2286.7434 - val_mae: 2286.7302 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 2285.3560 - mae: 2285.3423 - val_loss: 2273.5027 - val_mae: 2273.4888 - lr: 0.0010\n",
      "Epoch 5/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 14ms/step - loss: 2270.9045 - mae: 2270.8901 - val_loss: 2256.8308 - val_mae: 2256.8159 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 2252.7112 - mae: 2252.6956 - val_loss: 2236.2656 - val_mae: 2236.2493 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 2230.1438 - mae: 2230.1265 - val_loss: 2211.6069 - val_mae: 2211.5886 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 2203.6660 - mae: 2203.6470 - val_loss: 2182.6199 - val_mae: 2182.5994 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 2172.6323 - mae: 2172.6106 - val_loss: 2149.1951 - val_mae: 2149.1721 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 2136.7329 - mae: 2136.7085 - val_loss: 2110.9736 - val_mae: 2110.9475 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 2096.2532 - mae: 2096.2253 - val_loss: 2067.9224 - val_mae: 2067.8928 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 2051.0229 - mae: 2050.9915 - val_loss: 2020.3584 - val_mae: 2020.3248 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 2002.1580 - mae: 2002.1227 - val_loss: 1968.2220 - val_mae: 1968.1843 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1948.2335 - mae: 1948.1936 - val_loss: 1911.4911 - val_mae: 1911.4486 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1890.6012 - mae: 1890.5568 - val_loss: 1850.2415 - val_mae: 1850.1937 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1826.8542 - mae: 1826.8043 - val_loss: 1784.4226 - val_mae: 1784.3693 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 1757.1788 - mae: 1757.1227 - val_loss: 1713.8534 - val_mae: 1713.7939 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1688.0708 - mae: 1688.0085 - val_loss: 1638.7706 - val_mae: 1638.7046 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1608.9558 - mae: 1608.8866 - val_loss: 1559.2944 - val_mae: 1559.2214 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1533.3295 - mae: 1533.2532 - val_loss: 1479.0789 - val_mae: 1478.9988 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 1455.2587\n",
      "LV_RMSE_12h: 1633.3792\n",
      "LV_MAE_24h: 348.9885\n",
      "LV_RMSE_24h: 536.7026\n",
      "LV_MAE_48h: 366.2098\n",
      "LV_RMSE_48h: 548.5556\n",
      "LV_MAE_72h: 373.8736\n",
      "LV_RMSE_72h: 574.6136\n",
      "LV_MAE_mean: 636.0826\n",
      "LV_RMSE_mean: 823.3127\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 1342.4037\n",
      "RMSE_12h: 1610.4868\n",
      "MAE_24h: 1354.2405\n",
      "RMSE_24h: 1615.0221\n",
      "MAE_48h: 1354.7760\n",
      "RMSE_48h: 1618.1144\n",
      "MAE_72h: 1379.3218\n",
      "RMSE_72h: 1639.2675\n",
      "MAE_mean: 1357.6854\n",
      "RMSE_mean: 1620.7227\n",
      "\n",
      "=== Station S312523 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1376 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1353, 24, 400) Ytr2: (1353, 4) \n",
      "  Xva3: (197, 24, 400) Yva2: (197, 4) \n",
      "  Xte3: (348, 24, 400) Yte2: (348, 4)\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 3s 63ms/step - loss: 3072.6553 - mae: 3072.6426 - val_loss: 3092.3403 - val_mae: 3092.3276 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 3066.5317 - mae: 3066.5193 - val_loss: 3083.7776 - val_mae: 3083.7646 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 3056.1152 - mae: 3056.1021 - val_loss: 3071.0452 - val_mae: 3071.0315 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 3041.6934 - mae: 3041.6797 - val_loss: 3054.5591 - val_mae: 3054.5444 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 3023.2917 - mae: 3023.2769 - val_loss: 3033.5593 - val_mae: 3033.5435 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 3000.4714 - mae: 3000.4548 - val_loss: 3007.6089 - val_mae: 3007.5913 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 2972.0757 - mae: 2972.0574 - val_loss: 2976.4568 - val_mae: 2976.4368 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 2938.7417 - mae: 2938.7205 - val_loss: 2939.9319 - val_mae: 2939.9092 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 2899.9587 - mae: 2899.9348 - val_loss: 2897.9219 - val_mae: 2897.8960 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 2855.4668 - mae: 2855.4387 - val_loss: 2850.3103 - val_mae: 2850.2805 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 2804.2036 - mae: 2804.1719 - val_loss: 2797.0125 - val_mae: 2796.9785 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 2747.5073 - mae: 2747.4709 - val_loss: 2737.8960 - val_mae: 2737.8567 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 2688.0698 - mae: 2688.0281 - val_loss: 2673.1831 - val_mae: 2673.1384 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 2620.9768 - mae: 2620.9299 - val_loss: 2604.0444 - val_mae: 2603.9939 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 2553.0413 - mae: 2552.9883 - val_loss: 2534.4832 - val_mae: 2534.4265 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 2484.8989 - mae: 2484.8394 - val_loss: 2467.5640 - val_mae: 2467.5007 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 2418.1819 - mae: 2418.1157 - val_loss: 2403.6746 - val_mae: 2403.6045 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 2358.0137 - mae: 2357.9404 - val_loss: 2342.9688 - val_mae: 2342.8916 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 2296.7092 - mae: 2296.6292 - val_loss: 2284.0771 - val_mae: 2283.9929 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 2238.7273 - mae: 2238.6394 - val_loss: 2227.7271 - val_mae: 2227.6355 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 2575.5776\n",
      "LV_RMSE_12h: 2837.4827\n",
      "LV_MAE_24h: 489.1035\n",
      "LV_RMSE_24h: 791.0669\n",
      "LV_MAE_48h: 633.8190\n",
      "LV_RMSE_48h: 981.6530\n",
      "LV_MAE_72h: 479.0230\n",
      "LV_RMSE_72h: 770.2415\n",
      "LV_MAE_mean: 1044.3807\n",
      "LV_RMSE_mean: 1345.1111\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 2065.1938\n",
      "RMSE_12h: 2499.0869\n",
      "MAE_24h: 2078.1050\n",
      "RMSE_24h: 2492.1768\n",
      "MAE_48h: 2061.3467\n",
      "RMSE_48h: 2474.7368\n",
      "MAE_72h: 2094.7375\n",
      "RMSE_72h: 2510.7314\n",
      "MAE_mean: 2074.8457\n",
      "RMSE_mean: 2494.1831\n",
      "\n",
      "=== Station S312569 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1376 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1353, 24, 400) Ytr2: (1353, 4) \n",
      "  Xva3: (197, 24, 400) Yva2: (197, 4) \n",
      "  Xte3: (347, 24, 400) Yte2: (347, 4)\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 3s 65ms/step - loss: 1066.0479 - mae: 1066.0352 - val_loss: 2031.1204 - val_mae: 2031.1075 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1059.2162 - mae: 1059.2032 - val_loss: 2021.1615 - val_mae: 2021.1484 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 1048.8176 - mae: 1048.8042 - val_loss: 2007.8829 - val_mae: 2007.8693 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1036.1078 - mae: 1036.0938 - val_loss: 1991.4030 - val_mae: 1991.3883 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1021.2624 - mae: 1021.2473 - val_loss: 1971.2170 - val_mae: 1971.2012 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1003.7094 - mae: 1003.6929 - val_loss: 1946.9116 - val_mae: 1946.8944 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 983.2193 - mae: 983.2010 - val_loss: 1918.4343 - val_mae: 1918.4149 - lr: 0.0010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 959.5744 - mae: 959.5540 - val_loss: 1885.9222 - val_mae: 1885.9005 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 933.9780 - mae: 933.9550 - val_loss: 1850.1553 - val_mae: 1850.1307 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 905.9371 - mae: 905.9112 - val_loss: 1812.3375 - val_mae: 1812.3099 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 877.2174 - mae: 877.1882 - val_loss: 1772.4644 - val_mae: 1772.4332 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 848.8676 - mae: 848.8348 - val_loss: 1731.9578 - val_mae: 1731.9231 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 822.1268 - mae: 822.0903 - val_loss: 1691.5273 - val_mae: 1691.4885 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 795.2238 - mae: 795.1833 - val_loss: 1650.7836 - val_mae: 1650.7408 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 769.4733 - mae: 769.4286 - val_loss: 1610.7559 - val_mae: 1610.7087 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 746.8280 - mae: 746.7791 - val_loss: 1572.6722 - val_mae: 1572.6208 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 724.0214 - mae: 723.9680 - val_loss: 1534.9185 - val_mae: 1534.8627 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 697.2537 - mae: 697.1956 - val_loss: 1496.1821 - val_mae: 1496.1215 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 671.8089 - mae: 671.7462 - val_loss: 1454.0424 - val_mae: 1453.9768 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 638.7021 - mae: 638.6345 - val_loss: 1412.1776 - val_mae: 1412.1069 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 1713.3920\n",
      "LV_RMSE_12h: 1943.7411\n",
      "LV_MAE_24h: 394.2795\n",
      "LV_RMSE_24h: 598.6133\n",
      "LV_MAE_48h: 459.3631\n",
      "LV_RMSE_48h: 678.4743\n",
      "LV_MAE_72h: 386.7579\n",
      "LV_RMSE_72h: 577.4298\n",
      "LV_MAE_mean: 738.4481\n",
      "LV_RMSE_mean: 949.5647\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 1318.0518\n",
      "RMSE_12h: 1587.5844\n",
      "MAE_24h: 1254.9889\n",
      "RMSE_24h: 1519.8649\n",
      "MAE_48h: 1254.0596\n",
      "RMSE_48h: 1521.3113\n",
      "MAE_72h: 1275.7255\n",
      "RMSE_72h: 1544.1294\n",
      "MAE_mean: 1275.7064\n",
      "RMSE_mean: 1543.2225\n",
      "\n",
      "=== Station S312805 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1359 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1336, 24, 400) Ytr2: (1336, 4) \n",
      "  Xva3: (195, 24, 400) Yva2: (195, 4) \n",
      "  Xte3: (342, 24, 400) Yte2: (342, 4)\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 3s 67ms/step - loss: 78.3774 - mae: 78.3646 - val_loss: 75.2047 - val_mae: 75.1918 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 72.7460 - mae: 72.7331 - val_loss: 67.7567 - val_mae: 67.7436 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 64.9559 - mae: 64.9426 - val_loss: 60.2144 - val_mae: 60.2008 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 57.4957 - mae: 57.4818 - val_loss: 54.0007 - val_mae: 53.9863 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 51.2078 - mae: 51.1930 - val_loss: 48.9470 - val_mae: 48.9317 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 46.0719 - mae: 46.0561 - val_loss: 44.6453 - val_mae: 44.6290 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 42.1524 - mae: 42.1357 - val_loss: 40.9802 - val_mae: 40.9630 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 38.5744 - mae: 38.5568 - val_loss: 36.5278 - val_mae: 36.5099 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 35.1525 - mae: 35.1344 - val_loss: 32.9477 - val_mae: 32.9293 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 31.8116 - mae: 31.7930 - val_loss: 29.6575 - val_mae: 29.6386 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 29.1214 - mae: 29.1022 - val_loss: 27.4524 - val_mae: 27.4329 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 27.1228 - mae: 27.1030 - val_loss: 25.0554 - val_mae: 25.0353 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 25.4223 - mae: 25.4019 - val_loss: 23.6801 - val_mae: 23.6593 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 23.9598 - mae: 23.9388 - val_loss: 21.7126 - val_mae: 21.6913 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 22.1104 - mae: 22.0888 - val_loss: 19.8613 - val_mae: 19.8393 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 20.4925 - mae: 20.4701 - val_loss: 17.8753 - val_mae: 17.8523 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 18.5963 - mae: 18.5729 - val_loss: 15.9871 - val_mae: 15.9632 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 17.4689 - mae: 17.4446 - val_loss: 14.4800 - val_mae: 14.4552 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 16.5285 - mae: 16.5034 - val_loss: 13.5329 - val_mae: 13.5075 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 15.7872 - mae: 15.7616 - val_loss: 13.3489 - val_mae: 13.3232 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 84.1491\n",
      "LV_RMSE_12h: 94.6831\n",
      "LV_MAE_24h: 18.9269\n",
      "LV_RMSE_24h: 27.1635\n",
      "LV_MAE_48h: 20.9357\n",
      "LV_RMSE_48h: 29.4984\n",
      "LV_MAE_72h: 19.1111\n",
      "LV_RMSE_72h: 26.4144\n",
      "LV_MAE_mean: 35.7807\n",
      "LV_RMSE_mean: 44.4398\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 16.5543\n",
      "RMSE_12h: 23.2191\n",
      "MAE_24h: 15.2068\n",
      "RMSE_24h: 21.8900\n",
      "MAE_48h: 15.2154\n",
      "RMSE_48h: 21.8490\n",
      "MAE_72h: 15.8032\n",
      "RMSE_72h: 22.3479\n",
      "MAE_mean: 15.6949\n",
      "RMSE_mean: 22.3265\n",
      "\n",
      "=== Station S312896 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1376 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1353, 24, 400) Ytr2: (1353, 4) \n",
      "  Xva3: (197, 24, 400) Yva2: (197, 4) \n",
      "  Xte3: (348, 24, 400) Yte2: (348, 4)\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 3s 65ms/step - loss: 2538.1150 - mae: 2538.1023 - val_loss: 2544.8154 - val_mae: 2544.8027 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 2531.6680 - mae: 2531.6550 - val_loss: 2535.8525 - val_mae: 2535.8398 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 2521.0137 - mae: 2521.0005 - val_loss: 2523.1023 - val_mae: 2523.0889 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 2506.5461 - mae: 2506.5325 - val_loss: 2506.5952 - val_mae: 2506.5813 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 2488.2944 - mae: 2488.2795 - val_loss: 2485.7295 - val_mae: 2485.7139 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 2465.4124 - mae: 2465.3962 - val_loss: 2460.1848 - val_mae: 2460.1675 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 2437.7454 - mae: 2437.7271 - val_loss: 2429.6860 - val_mae: 2429.6665 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 2404.7617 - mae: 2404.7410 - val_loss: 2394.0405 - val_mae: 2394.0183 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 2366.9709 - mae: 2366.9473 - val_loss: 2353.1750 - val_mae: 2353.1497 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 2322.9495 - mae: 2322.9226 - val_loss: 2306.9910 - val_mae: 2306.9619 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 2275.1084 - mae: 2275.0779 - val_loss: 2255.7307 - val_mae: 2255.6978 - lr: 0.0010\n",
      "Epoch 12/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 13ms/step - loss: 2221.7043 - mae: 2221.6692 - val_loss: 2201.5159 - val_mae: 2201.4785 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 2166.2100 - mae: 2166.1702 - val_loss: 2147.3284 - val_mae: 2147.2856 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 2112.4836 - mae: 2112.4387 - val_loss: 2093.9355 - val_mae: 2093.8875 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 2060.9001 - mae: 2060.8496 - val_loss: 2042.1792 - val_mae: 2042.1260 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 2008.7313 - mae: 2008.6755 - val_loss: 1992.3389 - val_mae: 1992.2798 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1960.0356 - mae: 1959.9741 - val_loss: 1944.2521 - val_mae: 1944.1871 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1913.9572 - mae: 1913.8895 - val_loss: 1898.6187 - val_mae: 1898.5477 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1863.5237 - mae: 1863.4503 - val_loss: 1853.0640 - val_mae: 1852.9867 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1819.8938 - mae: 1819.8137 - val_loss: 1807.6383 - val_mae: 1807.5547 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 2244.0288\n",
      "LV_RMSE_12h: 2569.8447\n",
      "LV_MAE_24h: 400.2443\n",
      "LV_RMSE_24h: 540.3645\n",
      "LV_MAE_48h: 506.3103\n",
      "LV_RMSE_48h: 682.0897\n",
      "LV_MAE_72h: 407.7557\n",
      "LV_RMSE_72h: 557.8669\n",
      "LV_MAE_mean: 889.5847\n",
      "LV_RMSE_mean: 1087.5415\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 1694.4073\n",
      "RMSE_12h: 2040.2781\n",
      "MAE_24h: 1717.9244\n",
      "RMSE_24h: 2055.4675\n",
      "MAE_48h: 1676.7051\n",
      "RMSE_48h: 2004.5446\n",
      "MAE_72h: 1743.7128\n",
      "RMSE_72h: 2092.5479\n",
      "MAE_mean: 1708.1875\n",
      "RMSE_mean: 2048.2095\n",
      "\n",
      "=== Station S313038 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1376 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1353, 24, 400) Ytr2: (1353, 4) \n",
      "  Xva3: (197, 24, 400) Yva2: (197, 4) \n",
      "  Xte3: (347, 24, 400) Yte2: (347, 4)\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 3s 71ms/step - loss: 446.0845 - mae: 446.0716 - val_loss: 448.1334 - val_mae: 448.1205 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 440.0302 - mae: 440.0172 - val_loss: 439.4885 - val_mae: 439.4754 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 429.5122 - mae: 429.4989 - val_loss: 426.7314 - val_mae: 426.7178 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 415.3125 - mae: 415.2986 - val_loss: 410.8795 - val_mae: 410.8651 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 399.2014 - mae: 399.1865 - val_loss: 394.8684 - val_mae: 394.8526 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 383.7899 - mae: 383.7735 - val_loss: 379.5930 - val_mae: 379.5757 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 369.3228 - mae: 369.3048 - val_loss: 365.1732 - val_mae: 365.1541 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 355.0661 - mae: 355.0463 - val_loss: 351.7627 - val_mae: 351.7418 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 343.0403 - mae: 343.0184 - val_loss: 339.5407 - val_mae: 339.5177 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 330.6701 - mae: 330.6461 - val_loss: 328.1192 - val_mae: 328.0939 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 320.8175 - mae: 320.7913 - val_loss: 318.0739 - val_mae: 318.0464 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 310.4462 - mae: 310.4177 - val_loss: 308.3619 - val_mae: 308.3321 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 301.2063 - mae: 301.1755 - val_loss: 296.2126 - val_mae: 296.1806 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 287.3233 - mae: 287.2902 - val_loss: 280.8012 - val_mae: 280.7668 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 270.5526 - mae: 270.5171 - val_loss: 264.7548 - val_mae: 264.7177 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 253.4575 - mae: 253.4192 - val_loss: 248.7201 - val_mae: 248.6801 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 239.8143 - mae: 239.7728 - val_loss: 233.1012 - val_mae: 233.0578 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 225.9210 - mae: 225.8760 - val_loss: 219.6516 - val_mae: 219.6046 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 213.8264 - mae: 213.7780 - val_loss: 209.3224 - val_mae: 209.2718 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 203.5567 - mae: 203.5048 - val_loss: 201.4387 - val_mae: 201.3849 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 479.3833\n",
      "LV_RMSE_12h: 558.7821\n",
      "LV_MAE_24h: 117.0865\n",
      "LV_RMSE_24h: 189.2453\n",
      "LV_MAE_48h: 164.9395\n",
      "LV_RMSE_48h: 250.4328\n",
      "LV_MAE_72h: 139.3141\n",
      "LV_RMSE_72h: 220.5581\n",
      "LV_MAE_mean: 225.1808\n",
      "LV_RMSE_mean: 304.7546\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 344.8164\n",
      "RMSE_12h: 434.7628\n",
      "MAE_24h: 125.8725\n",
      "RMSE_24h: 197.1809\n",
      "MAE_48h: 127.6914\n",
      "RMSE_48h: 199.9997\n",
      "MAE_72h: 125.3138\n",
      "RMSE_72h: 196.9814\n",
      "MAE_mean: 180.9236\n",
      "RMSE_mean: 257.2312\n",
      "\n",
      "=== Station S313111 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1376 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1353, 24, 400) Ytr2: (1353, 4) \n",
      "  Xva3: (197, 24, 400) Yva2: (197, 4) \n",
      "  Xte3: (348, 24, 400) Yte2: (348, 4)\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 3s 67ms/step - loss: 2330.0581 - mae: 2330.0457 - val_loss: 2335.9998 - val_mae: 2335.9871 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 2324.6553 - mae: 2324.6426 - val_loss: 2328.1423 - val_mae: 2328.1294 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 2315.2595 - mae: 2315.2463 - val_loss: 2316.9209 - val_mae: 2316.9077 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 2302.5732 - mae: 2302.5591 - val_loss: 2302.6077 - val_mae: 2302.5933 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 2286.5505 - mae: 2286.5361 - val_loss: 2284.3928 - val_mae: 2284.3774 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 2266.9114 - mae: 2266.8950 - val_loss: 2262.1262 - val_mae: 2262.1094 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 2242.7583 - mae: 2242.7405 - val_loss: 2235.6328 - val_mae: 2235.6140 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 2214.1843 - mae: 2214.1646 - val_loss: 2204.6702 - val_mae: 2204.6487 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 2181.2725 - mae: 2181.2500 - val_loss: 2169.2021 - val_mae: 2169.1782 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 2143.6375 - mae: 2143.6123 - val_loss: 2129.1624 - val_mae: 2129.1355 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 2101.4253 - mae: 2101.3967 - val_loss: 2084.6545 - val_mae: 2084.6238 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 2054.4163 - mae: 2054.3838 - val_loss: 2036.2637 - val_mae: 2036.2290 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 0s 18ms/step - loss: 2006.1271 - mae: 2006.0906 - val_loss: 1985.5588 - val_mae: 1985.5198 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 1955.5791 - mae: 1955.5381 - val_loss: 1935.3179 - val_mae: 1935.2742 - lr: 0.0010\n",
      "Epoch 15/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 16ms/step - loss: 1909.2360 - mae: 1909.1899 - val_loss: 1888.2009 - val_mae: 1888.1525 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1862.3564 - mae: 1862.3058 - val_loss: 1843.8853 - val_mae: 1843.8319 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1819.1108 - mae: 1819.0553 - val_loss: 1800.8831 - val_mae: 1800.8246 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1777.6755 - mae: 1777.6150 - val_loss: 1759.3151 - val_mae: 1759.2512 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 1737.2051 - mae: 1737.1392 - val_loss: 1718.7649 - val_mae: 1718.6958 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1697.5800 - mae: 1697.5089 - val_loss: 1680.7864 - val_mae: 1680.7118 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 2156.4541\n",
      "LV_RMSE_12h: 2428.7178\n",
      "LV_MAE_24h: 355.9856\n",
      "LV_RMSE_24h: 525.5207\n",
      "LV_MAE_48h: 462.3161\n",
      "LV_RMSE_48h: 677.3971\n",
      "LV_MAE_72h: 393.2126\n",
      "LV_RMSE_72h: 592.5190\n",
      "LV_MAE_mean: 841.9921\n",
      "LV_RMSE_mean: 1056.0387\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 1556.6224\n",
      "RMSE_12h: 1935.2256\n",
      "MAE_24h: 1591.6472\n",
      "RMSE_24h: 1959.5554\n",
      "MAE_48h: 1606.6967\n",
      "RMSE_48h: 1978.1630\n",
      "MAE_72h: 1545.5636\n",
      "RMSE_72h: 1901.7340\n",
      "MAE_mean: 1575.1324\n",
      "RMSE_mean: 1943.6694\n",
      "\n",
      "=== Station S313432 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1376 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1353, 24, 400) Ytr2: (1353, 4) \n",
      "  Xva3: (197, 24, 400) Yva2: (197, 4) \n",
      "  Xte3: (348, 24, 400) Yte2: (348, 4)\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 3s 71ms/step - loss: 3640.0020 - mae: 3639.9890 - val_loss: 3665.3933 - val_mae: 3665.3806 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 0s 17ms/step - loss: 3633.1426 - mae: 3633.1296 - val_loss: 3655.6423 - val_mae: 3655.6294 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 3621.8164 - mae: 3621.8030 - val_loss: 3642.4744 - val_mae: 3642.4609 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 3607.3333 - mae: 3607.3196 - val_loss: 3625.8774 - val_mae: 3625.8633 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 0s 20ms/step - loss: 3588.7051 - mae: 3588.6907 - val_loss: 3605.0015 - val_mae: 3604.9861 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 3566.3625 - mae: 3566.3462 - val_loss: 3579.5046 - val_mae: 3579.4875 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 3538.6042 - mae: 3538.5862 - val_loss: 3549.1599 - val_mae: 3549.1406 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 3506.2188 - mae: 3506.1985 - val_loss: 3513.7593 - val_mae: 3513.7375 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 3468.3093 - mae: 3468.2861 - val_loss: 3473.1865 - val_mae: 3473.1619 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 3424.9014 - mae: 3424.8750 - val_loss: 3427.3386 - val_mae: 3427.3101 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 3376.3130 - mae: 3376.2830 - val_loss: 3376.1292 - val_mae: 3376.0967 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 3323.8201 - mae: 3323.7856 - val_loss: 3319.6548 - val_mae: 3319.6174 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 3264.0942 - mae: 3264.0552 - val_loss: 3258.1094 - val_mae: 3258.0671 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 3203.0103 - mae: 3202.9661 - val_loss: 3193.9619 - val_mae: 3193.9143 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 3142.0000 - mae: 3141.9497 - val_loss: 3132.1973 - val_mae: 3132.1440 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 3081.4272 - mae: 3081.3713 - val_loss: 3072.7009 - val_mae: 3072.6416 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 3023.7905 - mae: 3023.7290 - val_loss: 3015.5247 - val_mae: 3015.4595 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 2966.2251 - mae: 2966.1570 - val_loss: 2961.6353 - val_mae: 2961.5635 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 2914.7173 - mae: 2914.6433 - val_loss: 2909.1750 - val_mae: 2909.0972 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 2861.3796 - mae: 2861.2986 - val_loss: 2857.2585 - val_mae: 2857.1741 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 3592.7415\n",
      "LV_RMSE_12h: 3987.4685\n",
      "LV_MAE_24h: 564.4339\n",
      "LV_RMSE_24h: 821.3937\n",
      "LV_MAE_48h: 715.9943\n",
      "LV_RMSE_48h: 1061.1199\n",
      "LV_MAE_72h: 605.9109\n",
      "LV_RMSE_72h: 886.4847\n",
      "LV_MAE_mean: 1369.7701\n",
      "LV_RMSE_mean: 1689.1168\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 2695.3455\n",
      "RMSE_12h: 3332.0369\n",
      "MAE_24h: 2703.2607\n",
      "RMSE_24h: 3316.4170\n",
      "MAE_48h: 2736.4839\n",
      "RMSE_48h: 3357.0010\n",
      "MAE_72h: 2725.0840\n",
      "RMSE_72h: 3342.9419\n",
      "MAE_mean: 2715.0435\n",
      "RMSE_mean: 3337.0991\n",
      "\n",
      "=== Station S313438 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1376 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1353, 24, 400) Ytr2: (1353, 4) \n",
      "  Xva3: (197, 24, 400) Yva2: (197, 4) \n",
      "  Xte3: (348, 24, 400) Yte2: (348, 4)\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 3s 68ms/step - loss: 3085.7795 - mae: 3085.7664 - val_loss: 3031.8845 - val_mae: 3031.8718 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 3079.8955 - mae: 3079.8828 - val_loss: 3023.0200 - val_mae: 3023.0066 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 3069.1501 - mae: 3069.1370 - val_loss: 3010.2036 - val_mae: 3010.1899 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 3054.6819 - mae: 3054.6675 - val_loss: 2993.6292 - val_mae: 2993.6145 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 3036.1775 - mae: 3036.1624 - val_loss: 2972.4141 - val_mae: 2972.3979 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 3012.8682 - mae: 3012.8513 - val_loss: 2946.2888 - val_mae: 2946.2710 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 2984.4592 - mae: 2984.4402 - val_loss: 2915.0161 - val_mae: 2914.9961 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 2951.1243 - mae: 2951.1025 - val_loss: 2878.4128 - val_mae: 2878.3899 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 2912.0042 - mae: 2911.9797 - val_loss: 2836.3865 - val_mae: 2836.3601 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 2867.9907 - mae: 2867.9634 - val_loss: 2788.7976 - val_mae: 2788.7681 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 2816.7886 - mae: 2816.7568 - val_loss: 2735.5862 - val_mae: 2735.5520 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 2760.0786 - mae: 2760.0425 - val_loss: 2676.6123 - val_mae: 2676.5735 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 2699.8977 - mae: 2699.8567 - val_loss: 2612.0696 - val_mae: 2612.0251 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 2634.1638 - mae: 2634.1169 - val_loss: 2543.8296 - val_mae: 2543.7798 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 2569.0588 - mae: 2569.0063 - val_loss: 2477.1125 - val_mae: 2477.0564 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 2502.7512 - mae: 2502.6921 - val_loss: 2413.3987 - val_mae: 2413.3362 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 2443.1177 - mae: 2443.0522 - val_loss: 2352.8391 - val_mae: 2352.7703 - lr: 0.0010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 2388.8701 - mae: 2388.7983 - val_loss: 2299.3955 - val_mae: 2299.3203 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 2336.2239 - mae: 2336.1455 - val_loss: 2248.6279 - val_mae: 2248.5461 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 2284.0349 - mae: 2283.9502 - val_loss: 2197.3037 - val_mae: 2197.2151 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 2678.1782\n",
      "LV_RMSE_12h: 2976.6611\n",
      "LV_MAE_24h: 504.3362\n",
      "LV_RMSE_24h: 761.6923\n",
      "LV_MAE_48h: 607.8046\n",
      "LV_RMSE_48h: 923.7449\n",
      "LV_MAE_72h: 590.1465\n",
      "LV_RMSE_72h: 909.2809\n",
      "LV_MAE_mean: 1095.1165\n",
      "LV_RMSE_mean: 1392.8448\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 2023.0773\n",
      "RMSE_12h: 2491.8542\n",
      "MAE_24h: 2104.5410\n",
      "RMSE_24h: 2568.4536\n",
      "MAE_48h: 2084.8413\n",
      "RMSE_48h: 2547.8896\n",
      "MAE_72h: 2055.9490\n",
      "RMSE_72h: 2510.8853\n",
      "MAE_mean: 2067.1021\n",
      "RMSE_mean: 2529.7705\n",
      "\n",
      "=== Station S313684 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1376 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1353, 24, 400) Ytr2: (1353, 4) \n",
      "  Xva3: (197, 24, 400) Yva2: (197, 4) \n",
      "  Xte3: (348, 24, 400) Yte2: (348, 4)\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 3s 68ms/step - loss: 2642.9473 - mae: 2642.9343 - val_loss: 2647.4536 - val_mae: 2647.4409 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 2638.0754 - mae: 2638.0623 - val_loss: 2639.9109 - val_mae: 2639.8979 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 2628.5908 - mae: 2628.5779 - val_loss: 2628.3577 - val_mae: 2628.3442 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 2615.7344 - mae: 2615.7207 - val_loss: 2613.6931 - val_mae: 2613.6790 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 2599.5894 - mae: 2599.5747 - val_loss: 2595.0239 - val_mae: 2595.0085 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 2579.0481 - mae: 2579.0322 - val_loss: 2572.1909 - val_mae: 2572.1738 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 0s 17ms/step - loss: 2554.2068 - mae: 2554.1887 - val_loss: 2544.9155 - val_mae: 2544.8965 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 2525.1797 - mae: 2525.1592 - val_loss: 2512.9238 - val_mae: 2512.9023 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 2490.9548 - mae: 2490.9321 - val_loss: 2476.0305 - val_mae: 2476.0063 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 2452.1189 - mae: 2452.0930 - val_loss: 2434.4417 - val_mae: 2434.4143 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 2407.2004 - mae: 2407.1716 - val_loss: 2387.7571 - val_mae: 2387.7258 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 2357.8750 - mae: 2357.8420 - val_loss: 2335.9700 - val_mae: 2335.9346 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 2305.5427 - mae: 2305.5051 - val_loss: 2279.1646 - val_mae: 2279.1243 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 2246.0449 - mae: 2246.0024 - val_loss: 2217.3867 - val_mae: 2217.3413 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 2182.7505 - mae: 2182.7026 - val_loss: 2150.5203 - val_mae: 2150.4692 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 2113.5361 - mae: 2113.4827 - val_loss: 2078.6428 - val_mae: 2078.5857 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 2039.3296 - mae: 2039.2699 - val_loss: 2001.7008 - val_mae: 2001.6371 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1962.7977 - mae: 1962.7310 - val_loss: 1919.7479 - val_mae: 1919.6772 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 1878.1382 - mae: 1878.0641 - val_loss: 1833.2151 - val_mae: 1833.1368 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 1791.9326 - mae: 1791.8508 - val_loss: 1743.8500 - val_mae: 1743.7637 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 1738.0690\n",
      "LV_RMSE_12h: 1948.5936\n",
      "LV_MAE_24h: 339.0316\n",
      "LV_RMSE_24h: 451.7633\n",
      "LV_MAE_48h: 399.7069\n",
      "LV_RMSE_48h: 546.4778\n",
      "LV_MAE_72h: 327.7672\n",
      "LV_RMSE_72h: 465.5584\n",
      "LV_MAE_mean: 701.1437\n",
      "LV_RMSE_mean: 853.0983\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 1614.3243\n",
      "RMSE_12h: 1912.5597\n",
      "MAE_24h: 1567.1715\n",
      "RMSE_24h: 1863.3951\n",
      "MAE_48h: 1639.2791\n",
      "RMSE_48h: 1936.4249\n",
      "MAE_72h: 1647.8113\n",
      "RMSE_72h: 1941.5082\n",
      "MAE_mean: 1617.1465\n",
      "RMSE_mean: 1913.4720\n",
      "\n",
      "=== Station S313965 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1344 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1321, 24, 400) Ytr2: (1321, 4) \n",
      "  Xva3: (193, 24, 400) Yva2: (193, 4) \n",
      "  Xte3: (338, 24, 400) Yte2: (338, 4)\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 3s 69ms/step - loss: 429.4893 - mae: 429.4764 - val_loss: 423.7846 - val_mae: 423.7717 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 422.6623 - mae: 422.6493 - val_loss: 414.3190 - val_mae: 414.3059 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 411.4743 - mae: 411.4609 - val_loss: 401.4258 - val_mae: 401.4121 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 397.3869 - mae: 397.3730 - val_loss: 386.1431 - val_mae: 386.1285 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 382.1819 - mae: 382.1669 - val_loss: 370.6190 - val_mae: 370.6034 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 367.0643 - mae: 367.0481 - val_loss: 356.0399 - val_mae: 356.0228 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 352.4698 - mae: 352.4521 - val_loss: 341.6363 - val_mae: 341.6176 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 338.6579 - mae: 338.6385 - val_loss: 327.3528 - val_mae: 327.3323 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 324.0912 - mae: 324.0699 - val_loss: 313.4018 - val_mae: 313.3793 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 309.9625 - mae: 309.9390 - val_loss: 299.0595 - val_mae: 299.0347 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 296.2865 - mae: 296.2607 - val_loss: 285.6490 - val_mae: 285.6219 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 283.7263 - mae: 283.6982 - val_loss: 272.4866 - val_mae: 272.4571 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 269.3704 - mae: 269.3398 - val_loss: 256.9569 - val_mae: 256.9249 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 253.3705 - mae: 253.3374 - val_loss: 239.2575 - val_mae: 239.2229 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 237.0044 - mae: 236.9686 - val_loss: 222.0448 - val_mae: 222.0074 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 220.7081 - mae: 220.6695 - val_loss: 207.3944 - val_mae: 207.3540 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 206.0602 - mae: 206.0184 - val_loss: 191.8772 - val_mae: 191.8336 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 192.7043 - mae: 192.6594 - val_loss: 178.9274 - val_mae: 178.8807 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 180.9033 - mae: 180.8552 - val_loss: 168.5074 - val_mae: 168.4575 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 172.4140 - mae: 172.3626 - val_loss: 160.6516 - val_mae: 160.5985 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 451.4822\n",
      "LV_RMSE_12h: 499.5618\n",
      "LV_MAE_24h: 93.3580\n",
      "LV_RMSE_24h: 145.6619\n",
      "LV_MAE_48h: 117.4083\n",
      "LV_RMSE_48h: 179.8392\n",
      "LV_MAE_72h: 95.6331\n",
      "LV_RMSE_72h: 143.4360\n",
      "LV_MAE_mean: 189.4704\n",
      "LV_RMSE_mean: 242.1247\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 341.2626\n",
      "RMSE_12h: 405.3051\n",
      "MAE_24h: 90.6046\n",
      "RMSE_24h: 133.4770\n",
      "MAE_48h: 84.3388\n",
      "RMSE_48h: 129.6762\n",
      "MAE_72h: 81.6980\n",
      "RMSE_72h: 124.6964\n",
      "MAE_mean: 149.4760\n",
      "RMSE_mean: 198.2887\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Station S313979 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1376 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1353, 24, 400) Ytr2: (1353, 4) \n",
      "  Xva3: (197, 24, 400) Yva2: (197, 4) \n",
      "  Xte3: (348, 24, 400) Yte2: (348, 4)\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 3s 70ms/step - loss: 2482.1787 - mae: 2482.1660 - val_loss: 2481.0454 - val_mae: 2481.0327 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 2476.2942 - mae: 2476.2817 - val_loss: 2472.7129 - val_mae: 2472.7000 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 2466.3191 - mae: 2466.3062 - val_loss: 2460.9106 - val_mae: 2460.8972 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 2452.9961 - mae: 2452.9827 - val_loss: 2446.0193 - val_mae: 2446.0051 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 2436.8250 - mae: 2436.8103 - val_loss: 2427.5537 - val_mae: 2427.5383 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 2416.7256 - mae: 2416.7100 - val_loss: 2405.1152 - val_mae: 2405.0986 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 2392.7185 - mae: 2392.7009 - val_loss: 2378.5173 - val_mae: 2378.4988 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 2364.0376 - mae: 2364.0183 - val_loss: 2347.5183 - val_mae: 2347.4978 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 2331.2178 - mae: 2331.1960 - val_loss: 2311.8413 - val_mae: 2311.8176 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 2293.1721 - mae: 2293.1475 - val_loss: 2271.6021 - val_mae: 2271.5754 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 2250.6138 - mae: 2250.5857 - val_loss: 2226.7932 - val_mae: 2226.7629 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 2204.5295 - mae: 2204.4976 - val_loss: 2177.7117 - val_mae: 2177.6777 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 2154.7188 - mae: 2154.6831 - val_loss: 2126.8721 - val_mae: 2126.8337 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 0s 19ms/step - loss: 2104.1689 - mae: 2104.1282 - val_loss: 2077.0151 - val_mae: 2076.9722 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 2057.5190 - mae: 2057.4744 - val_loss: 2031.1548 - val_mae: 2031.1072 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 2011.9493 - mae: 2011.8995 - val_loss: 1986.6400 - val_mae: 1986.5875 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 1968.0519 - mae: 1967.9976 - val_loss: 1942.3495 - val_mae: 1942.2920 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 0s 17ms/step - loss: 1924.2043 - mae: 1924.1447 - val_loss: 1899.4296 - val_mae: 1899.3669 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 1882.0604 - mae: 1881.9952 - val_loss: 1857.1257 - val_mae: 1857.0577 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1840.1949 - mae: 1840.1244 - val_loss: 1815.1704 - val_mae: 1815.0968 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 2321.3765\n",
      "LV_RMSE_12h: 2563.4019\n",
      "LV_MAE_24h: 411.6897\n",
      "LV_RMSE_24h: 639.6459\n",
      "LV_MAE_48h: 514.2213\n",
      "LV_RMSE_48h: 764.6671\n",
      "LV_MAE_72h: 457.1925\n",
      "LV_RMSE_72h: 686.1321\n",
      "LV_MAE_mean: 926.1200\n",
      "LV_RMSE_mean: 1163.4618\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 1715.8707\n",
      "RMSE_12h: 2084.5962\n",
      "MAE_24h: 1754.5912\n",
      "RMSE_24h: 2114.1968\n",
      "MAE_48h: 1732.8483\n",
      "RMSE_48h: 2093.6860\n",
      "MAE_72h: 1751.0446\n",
      "RMSE_72h: 2123.2483\n",
      "MAE_mean: 1738.5886\n",
      "RMSE_mean: 2103.9319\n",
      "\n",
      "=== Station S314014 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1338 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1315, 24, 400) Ytr2: (1315, 4) \n",
      "  Xva3: (192, 24, 400) Yva2: (192, 4) \n",
      "  Xte3: (336, 24, 400) Yte2: (336, 4)\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 3s 70ms/step - loss: 205.1909 - mae: 205.1783 - val_loss: 214.0185 - val_mae: 214.0059 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 198.6380 - mae: 198.6253 - val_loss: 205.1998 - val_mae: 205.1870 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 189.4466 - mae: 189.4335 - val_loss: 195.0149 - val_mae: 195.0015 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 179.8950 - mae: 179.8812 - val_loss: 184.9488 - val_mae: 184.9344 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 170.3111 - mae: 170.2963 - val_loss: 175.0099 - val_mae: 174.9944 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 160.5078 - mae: 160.4918 - val_loss: 165.3198 - val_mae: 165.3029 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 151.1354 - mae: 151.1178 - val_loss: 156.6077 - val_mae: 156.5892 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 144.2262 - mae: 144.2070 - val_loss: 149.7218 - val_mae: 149.7018 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 138.3727 - mae: 138.3520 - val_loss: 144.5422 - val_mae: 144.5206 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 135.1007 - mae: 135.0785 - val_loss: 140.8515 - val_mae: 140.8284 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 132.3607 - mae: 132.3372 - val_loss: 138.6210 - val_mae: 138.5968 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 130.6779 - mae: 130.6533 - val_loss: 135.7672 - val_mae: 135.7422 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 127.8413 - mae: 127.8160 - val_loss: 131.7368 - val_mae: 131.7112 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 122.7019 - mae: 122.6760 - val_loss: 125.0825 - val_mae: 125.0561 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 115.5945 - mae: 115.5677 - val_loss: 116.7018 - val_mae: 116.6743 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 108.6685 - mae: 108.6404 - val_loss: 108.9939 - val_mae: 108.9651 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 100.9817 - mae: 100.9523 - val_loss: 98.0038 - val_mae: 97.9736 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 93.8218 - mae: 93.7910 - val_loss: 90.3370 - val_mae: 90.3054 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 88.7574 - mae: 88.7252 - val_loss: 85.9860 - val_mae: 85.9530 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 86.4211 - mae: 86.3876 - val_loss: 82.5656 - val_mae: 82.5315 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 235.5298\n",
      "LV_RMSE_12h: 262.8288\n",
      "LV_MAE_24h: 45.5357\n",
      "LV_RMSE_24h: 71.1615\n",
      "LV_MAE_48h: 55.9494\n",
      "LV_RMSE_48h: 88.2915\n",
      "LV_MAE_72h: 49.5327\n",
      "LV_RMSE_72h: 78.5607\n",
      "LV_MAE_mean: 96.6369\n",
      "LV_RMSE_mean: 125.2106\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 158.0116\n",
      "RMSE_12h: 191.9129\n",
      "MAE_24h: 50.2307\n",
      "RMSE_24h: 75.6292\n",
      "MAE_48h: 48.5506\n",
      "RMSE_48h: 72.5065\n",
      "MAE_72h: 45.9502\n",
      "RMSE_72h: 67.4010\n",
      "MAE_mean: 75.6858\n",
      "RMSE_mean: 101.8624\n",
      "\n",
      "=== Station S314291 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 604 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (581, 24, 400) Ytr2: (581, 4) \n",
      "  Xva3: (87, 24, 400) Yva2: (87, 4) \n",
      "  Xte3: (127, 24, 400) Yte2: (127, 4)\n",
      "Epoch 1/20\n",
      "5/5 [==============================] - 3s 144ms/step - loss: 210.8249 - mae: 210.8121 - val_loss: 197.9968 - val_mae: 197.9840 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 209.1479 - mae: 209.1351 - val_loss: 196.1471 - val_mae: 196.1342 - lr: 0.0010\n",
      "Epoch 3/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 17ms/step - loss: 207.2711 - mae: 207.2583 - val_loss: 193.9256 - val_mae: 193.9126 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 204.7579 - mae: 204.7449 - val_loss: 191.4611 - val_mae: 191.4480 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 202.2291 - mae: 202.2159 - val_loss: 188.8954 - val_mae: 188.8820 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 199.5629 - mae: 199.5494 - val_loss: 186.3358 - val_mae: 186.3222 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 196.7787 - mae: 196.7650 - val_loss: 183.9648 - val_mae: 183.9509 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 194.2115 - mae: 194.1974 - val_loss: 181.6376 - val_mae: 181.6232 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 191.6920 - mae: 191.6775 - val_loss: 179.2599 - val_mae: 179.2451 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 189.2184 - mae: 189.2034 - val_loss: 176.9615 - val_mae: 176.9462 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 186.7779 - mae: 186.7625 - val_loss: 174.3058 - val_mae: 174.2900 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 184.1648 - mae: 184.1488 - val_loss: 171.6254 - val_mae: 171.6090 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 181.6826 - mae: 181.6660 - val_loss: 168.6215 - val_mae: 168.6046 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 178.6691 - mae: 178.6519 - val_loss: 165.3961 - val_mae: 165.3785 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 175.4371 - mae: 175.4193 - val_loss: 161.8900 - val_mae: 161.8717 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 171.6141 - mae: 171.5955 - val_loss: 157.8027 - val_mae: 157.7836 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 167.8048 - mae: 167.7854 - val_loss: 153.5212 - val_mae: 153.5012 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 162.9882 - mae: 162.9679 - val_loss: 149.0008 - val_mae: 148.9799 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 158.5079 - mae: 158.4866 - val_loss: 144.1011 - val_mae: 144.0791 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 153.0375 - mae: 153.0152 - val_loss: 138.7547 - val_mae: 138.7316 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 282.4409\n",
      "LV_RMSE_12h: 328.4130\n",
      "LV_MAE_24h: 71.6850\n",
      "LV_RMSE_24h: 111.7415\n",
      "LV_MAE_48h: 70.3307\n",
      "LV_RMSE_48h: 113.5981\n",
      "LV_MAE_72h: 54.4567\n",
      "LV_RMSE_72h: 89.6780\n",
      "LV_MAE_mean: 119.7283\n",
      "LV_RMSE_mean: 160.8577\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 141.6910\n",
      "RMSE_12h: 215.4347\n",
      "MAE_24h: 87.3146\n",
      "RMSE_24h: 142.7985\n",
      "MAE_48h: 103.8131\n",
      "RMSE_48h: 162.5553\n",
      "MAE_72h: 108.9131\n",
      "RMSE_72h: 171.4160\n",
      "MAE_mean: 110.4330\n",
      "RMSE_mean: 173.0511\n",
      "\n",
      "=== Station S314379 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1376 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1353, 24, 400) Ytr2: (1353, 4) \n",
      "  Xva3: (197, 24, 400) Yva2: (197, 4) \n",
      "  Xte3: (348, 24, 400) Yte2: (348, 4)\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 3s 65ms/step - loss: 954.3904 - mae: 954.3777 - val_loss: 1017.4966 - val_mae: 1017.4840 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 948.9523 - mae: 948.9395 - val_loss: 1009.1844 - val_mae: 1009.1715 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 938.6283 - mae: 938.6151 - val_loss: 996.4153 - val_mae: 996.4017 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 924.0917 - mae: 924.0777 - val_loss: 979.8586 - val_mae: 979.8442 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 905.3937 - mae: 905.3789 - val_loss: 958.6597 - val_mae: 958.6439 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 882.5267 - mae: 882.5101 - val_loss: 932.8683 - val_mae: 932.8507 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 853.9984 - mae: 853.9798 - val_loss: 903.2259 - val_mae: 903.2061 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 820.6082 - mae: 820.5871 - val_loss: 869.7771 - val_mae: 869.7545 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 782.1696 - mae: 782.1457 - val_loss: 832.3995 - val_mae: 832.3737 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 738.4073 - mae: 738.3800 - val_loss: 791.9537 - val_mae: 791.9243 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 693.4791 - mae: 693.4479 - val_loss: 752.2182 - val_mae: 752.1848 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 653.3135 - mae: 653.2783 - val_loss: 717.5773 - val_mae: 717.5397 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 619.5018 - mae: 619.4626 - val_loss: 686.3260 - val_mae: 686.2844 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 590.5470 - mae: 590.5037 - val_loss: 658.1251 - val_mae: 658.0795 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 565.9048 - mae: 565.8574 - val_loss: 633.5255 - val_mae: 633.4760 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 543.1093 - mae: 543.0580 - val_loss: 611.2965 - val_mae: 611.2429 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 522.1960 - mae: 522.1407 - val_loss: 591.8605 - val_mae: 591.8030 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 505.2845 - mae: 505.2254 - val_loss: 574.7120 - val_mae: 574.6508 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 490.6653 - mae: 490.6023 - val_loss: 560.4089 - val_mae: 560.3439 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 467.6570 - mae: 467.5903 - val_loss: 528.1096 - val_mae: 528.0410 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 946.1437\n",
      "LV_RMSE_12h: 1065.9558\n",
      "LV_MAE_24h: 203.4052\n",
      "LV_RMSE_24h: 338.5939\n",
      "LV_MAE_48h: 329.2960\n",
      "LV_RMSE_48h: 454.1074\n",
      "LV_MAE_72h: 334.3707\n",
      "LV_RMSE_72h: 436.8881\n",
      "LV_MAE_mean: 453.3039\n",
      "LV_RMSE_mean: 573.8863\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 569.9653\n",
      "RMSE_12h: 704.9556\n",
      "MAE_24h: 478.5425\n",
      "RMSE_24h: 613.6306\n",
      "MAE_48h: 439.8745\n",
      "RMSE_48h: 550.0787\n",
      "MAE_72h: 402.2387\n",
      "RMSE_72h: 470.6303\n",
      "MAE_mean: 472.6553\n",
      "RMSE_mean: 584.8238\n",
      "\n",
      "=== Station S314666 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 952 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (929, 24, 400) Ytr2: (929, 4) \n",
      "  Xva3: (137, 24, 400) Yva2: (137, 4) \n",
      "  Xte3: (225, 24, 400) Yte2: (225, 4)\n",
      "Epoch 1/20\n",
      "8/8 [==============================] - 3s 94ms/step - loss: 355.6529 - mae: 355.6401 - val_loss: 405.1824 - val_mae: 405.1696 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 352.4067 - mae: 352.3939 - val_loss: 400.4495 - val_mae: 400.4366 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 346.7716 - mae: 346.7586 - val_loss: 393.2790 - val_mae: 393.2658 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 339.1740 - mae: 339.1608 - val_loss: 384.5599 - val_mae: 384.5464 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 330.4259 - mae: 330.4121 - val_loss: 374.7759 - val_mae: 374.7618 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 321.3293 - mae: 321.3148 - val_loss: 364.7268 - val_mae: 364.7119 - lr: 0.0010\n",
      "Epoch 7/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 16ms/step - loss: 312.4110 - mae: 312.3958 - val_loss: 354.6856 - val_mae: 354.6699 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 303.4153 - mae: 303.3991 - val_loss: 344.8219 - val_mae: 344.8051 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 294.3550 - mae: 294.3377 - val_loss: 335.3690 - val_mae: 335.3510 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 286.0117 - mae: 285.9933 - val_loss: 326.4432 - val_mae: 326.4240 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 278.1795 - mae: 278.1599 - val_loss: 317.8622 - val_mae: 317.8417 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 270.9496 - mae: 270.9286 - val_loss: 309.8098 - val_mae: 309.7878 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 264.5849 - mae: 264.5625 - val_loss: 302.3170 - val_mae: 302.2937 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 258.1402 - mae: 258.1162 - val_loss: 295.3014 - val_mae: 295.2766 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 252.6679 - mae: 252.6425 - val_loss: 288.4305 - val_mae: 288.4041 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 248.8579 - mae: 248.8310 - val_loss: 282.3262 - val_mae: 282.2983 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 243.5467 - mae: 243.5182 - val_loss: 275.9872 - val_mae: 275.9579 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 240.0859 - mae: 240.0560 - val_loss: 269.0950 - val_mae: 269.0643 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 233.5069 - mae: 233.4756 - val_loss: 255.8894 - val_mae: 255.8574 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 226.5098 - mae: 226.4773 - val_loss: 244.6707 - val_mae: 244.6374 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 463.4800\n",
      "LV_RMSE_12h: 519.7515\n",
      "LV_MAE_24h: 132.9822\n",
      "LV_RMSE_24h: 195.6503\n",
      "LV_MAE_48h: 165.6756\n",
      "LV_RMSE_48h: 223.3993\n",
      "LV_MAE_72h: 179.3600\n",
      "LV_RMSE_72h: 252.0382\n",
      "LV_MAE_mean: 235.3744\n",
      "LV_RMSE_mean: 297.7098\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 282.9364\n",
      "RMSE_12h: 348.9455\n",
      "MAE_24h: 195.9010\n",
      "RMSE_24h: 243.5040\n",
      "MAE_48h: 193.2074\n",
      "RMSE_48h: 242.3216\n",
      "MAE_72h: 195.3856\n",
      "RMSE_72h: 240.8575\n",
      "MAE_mean: 216.8576\n",
      "RMSE_mean: 268.9072\n",
      "\n",
      "=== Station S314679 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1376 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1353, 24, 400) Ytr2: (1353, 4) \n",
      "  Xva3: (197, 24, 400) Yva2: (197, 4) \n",
      "  Xte3: (347, 24, 400) Yte2: (347, 4)\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 3s 65ms/step - loss: 218.7497 - mae: 218.7369 - val_loss: 221.2027 - val_mae: 221.1899 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 214.1351 - mae: 214.1223 - val_loss: 213.9312 - val_mae: 213.9183 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 204.6853 - mae: 204.6722 - val_loss: 202.6265 - val_mae: 202.6131 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 193.0747 - mae: 193.0610 - val_loss: 191.3703 - val_mae: 191.3562 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 182.0278 - mae: 182.0133 - val_loss: 181.2243 - val_mae: 181.2092 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 172.2295 - mae: 172.2139 - val_loss: 172.2770 - val_mae: 172.2608 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 163.4771 - mae: 163.4603 - val_loss: 164.3930 - val_mae: 164.3754 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 155.7620 - mae: 155.7439 - val_loss: 157.3120 - val_mae: 157.2930 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 149.0997 - mae: 149.0801 - val_loss: 151.2973 - val_mae: 151.2769 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 143.5550 - mae: 143.5340 - val_loss: 146.8110 - val_mae: 146.7893 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 139.4972 - mae: 139.4748 - val_loss: 142.8429 - val_mae: 142.8198 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 135.0591 - mae: 135.0355 - val_loss: 137.8120 - val_mae: 137.7877 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 128.8252 - mae: 128.8004 - val_loss: 130.8050 - val_mae: 130.7795 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 120.4719 - mae: 120.4459 - val_loss: 119.4916 - val_mae: 119.4648 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 108.1792 - mae: 108.1517 - val_loss: 105.3492 - val_mae: 105.3207 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 95.7788 - mae: 95.7493 - val_loss: 93.3313 - val_mae: 93.3006 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 86.0145 - mae: 85.9828 - val_loss: 83.3019 - val_mae: 83.2689 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 77.8821 - mae: 77.8482 - val_loss: 75.3783 - val_mae: 75.3432 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 72.6671 - mae: 72.6312 - val_loss: 70.2919 - val_mae: 70.2552 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 69.8448 - mae: 69.8075 - val_loss: 65.9651 - val_mae: 65.9271 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 260.3746\n",
      "LV_RMSE_12h: 285.9936\n",
      "LV_MAE_24h: 42.3977\n",
      "LV_RMSE_24h: 64.3893\n",
      "LV_MAE_48h: 45.1268\n",
      "LV_RMSE_48h: 68.0842\n",
      "LV_MAE_72h: 42.0144\n",
      "LV_RMSE_72h: 66.3108\n",
      "LV_MAE_mean: 97.4784\n",
      "LV_RMSE_mean: 121.1945\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 175.5910\n",
      "RMSE_12h: 204.7603\n",
      "MAE_24h: 34.9187\n",
      "RMSE_24h: 51.1874\n",
      "MAE_48h: 33.5269\n",
      "RMSE_48h: 50.4616\n",
      "MAE_72h: 33.4446\n",
      "RMSE_72h: 49.7335\n",
      "MAE_mean: 69.3703\n",
      "RMSE_mean: 89.0357\n",
      "\n",
      "=== Station S314681 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1376 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1353, 24, 400) Ytr2: (1353, 4) \n",
      "  Xva3: (197, 24, 400) Yva2: (197, 4) \n",
      "  Xte3: (348, 24, 400) Yte2: (348, 4)\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 3s 67ms/step - loss: 1878.0651 - mae: 1878.0525 - val_loss: 1843.5756 - val_mae: 1843.5629 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1871.7090 - mae: 1871.6963 - val_loss: 1835.1400 - val_mae: 1835.1273 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1862.1399 - mae: 1862.1271 - val_loss: 1824.2377 - val_mae: 1824.2246 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 1850.1230 - mae: 1850.1096 - val_loss: 1810.8307 - val_mae: 1810.8171 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1835.3342 - mae: 1835.3204 - val_loss: 1794.0663 - val_mae: 1794.0518 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 1817.1700 - mae: 1817.1548 - val_loss: 1773.9175 - val_mae: 1773.9016 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1795.5074 - mae: 1795.4907 - val_loss: 1750.1323 - val_mae: 1750.1149 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1770.4780 - mae: 1770.4594 - val_loss: 1722.6287 - val_mae: 1722.6093 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 1740.7457 - mae: 1740.7252 - val_loss: 1691.2272 - val_mae: 1691.2056 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1707.8832 - mae: 1707.8604 - val_loss: 1655.8881 - val_mae: 1655.8638 - lr: 0.0010\n",
      "Epoch 11/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 13ms/step - loss: 1670.5759 - mae: 1670.5503 - val_loss: 1616.5164 - val_mae: 1616.4889 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1628.9310 - mae: 1628.9021 - val_loss: 1573.0803 - val_mae: 1573.0493 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1583.9740 - mae: 1583.9414 - val_loss: 1525.7650 - val_mae: 1525.7303 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1537.1298 - mae: 1537.0933 - val_loss: 1475.8407 - val_mae: 1475.8019 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 1485.5145 - mae: 1485.4736 - val_loss: 1426.2404 - val_mae: 1426.1971 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 1435.7733 - mae: 1435.7281 - val_loss: 1378.7101 - val_mae: 1378.6622 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 1389.9293 - mae: 1389.8794 - val_loss: 1334.6935 - val_mae: 1334.6409 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 1347.1486 - mae: 1347.0940 - val_loss: 1293.2262 - val_mae: 1293.1688 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1307.4950 - mae: 1307.4355 - val_loss: 1252.7959 - val_mae: 1252.7336 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1266.1824 - mae: 1266.1178 - val_loss: 1214.0308 - val_mae: 1213.9635 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 1490.1954\n",
      "LV_RMSE_12h: 1655.2479\n",
      "LV_MAE_24h: 232.9540\n",
      "LV_RMSE_24h: 340.9041\n",
      "LV_MAE_48h: 292.2155\n",
      "LV_RMSE_48h: 430.2537\n",
      "LV_MAE_72h: 246.1810\n",
      "LV_RMSE_72h: 359.1088\n",
      "LV_MAE_mean: 565.3865\n",
      "LV_RMSE_mean: 696.3787\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 1154.6549\n",
      "RMSE_12h: 1380.0547\n",
      "MAE_24h: 1179.4384\n",
      "RMSE_24h: 1396.2179\n",
      "MAE_48h: 1195.6844\n",
      "RMSE_48h: 1417.4188\n",
      "MAE_72h: 1202.8375\n",
      "RMSE_72h: 1426.4865\n",
      "MAE_mean: 1183.1538\n",
      "RMSE_mean: 1405.0444\n",
      "\n",
      "=== Station S314723 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1376 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1353, 24, 400) Ytr2: (1353, 4) \n",
      "  Xva3: (197, 24, 400) Yva2: (197, 4) \n",
      "  Xte3: (347, 24, 400) Yte2: (347, 4)\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 3s 64ms/step - loss: 315.9231 - mae: 315.9104 - val_loss: 329.4144 - val_mae: 329.4017 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 309.2159 - mae: 309.2031 - val_loss: 320.1458 - val_mae: 320.1327 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 299.2538 - mae: 299.2406 - val_loss: 310.0097 - val_mae: 309.9961 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 289.3752 - mae: 289.3612 - val_loss: 300.5488 - val_mae: 300.5344 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 280.4279 - mae: 280.4129 - val_loss: 291.6199 - val_mae: 291.6043 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 271.8091 - mae: 271.7930 - val_loss: 283.0846 - val_mae: 283.0676 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 263.7067 - mae: 263.6891 - val_loss: 275.3244 - val_mae: 275.3060 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 256.3759 - mae: 256.3568 - val_loss: 268.2051 - val_mae: 268.1851 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 250.8485 - mae: 250.8277 - val_loss: 262.2004 - val_mae: 262.1786 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 244.8628 - mae: 244.8403 - val_loss: 256.1898 - val_mae: 256.1664 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 237.7788 - mae: 237.7547 - val_loss: 247.0121 - val_mae: 246.9871 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 226.8842 - mae: 226.8584 - val_loss: 234.1962 - val_mae: 234.1694 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 214.0204 - mae: 213.9927 - val_loss: 221.4507 - val_mae: 221.4218 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 203.0172 - mae: 202.9871 - val_loss: 208.0057 - val_mae: 207.9741 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 189.6351 - mae: 189.6022 - val_loss: 193.0725 - val_mae: 193.0379 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 174.8618 - mae: 174.8257 - val_loss: 175.4305 - val_mae: 175.3925 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 157.6808 - mae: 157.6410 - val_loss: 155.3947 - val_mae: 155.3526 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 141.0011 - mae: 140.9571 - val_loss: 139.4979 - val_mae: 139.4514 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 128.0112 - mae: 127.9628 - val_loss: 126.9251 - val_mae: 126.8744 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 120.2620 - mae: 120.2098 - val_loss: 120.6845 - val_mae: 120.6305 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 482.4553\n",
      "LV_RMSE_12h: 537.7581\n",
      "LV_MAE_24h: 84.5389\n",
      "LV_RMSE_24h: 153.8172\n",
      "LV_MAE_48h: 91.2104\n",
      "LV_RMSE_48h: 162.5590\n",
      "LV_MAE_72h: 92.4323\n",
      "LV_RMSE_72h: 168.8005\n",
      "LV_MAE_mean: 187.6592\n",
      "LV_RMSE_mean: 255.7337\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 294.6857\n",
      "RMSE_12h: 394.1455\n",
      "MAE_24h: 83.6021\n",
      "RMSE_24h: 126.8738\n",
      "MAE_48h: 82.4372\n",
      "RMSE_48h: 126.5975\n",
      "MAE_72h: 76.9420\n",
      "RMSE_72h: 122.0620\n",
      "MAE_mean: 134.4167\n",
      "RMSE_mean: 192.4197\n",
      "\n",
      "=== Station S314803 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1374 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1351, 24, 400) Ytr2: (1351, 4) \n",
      "  Xva3: (197, 24, 400) Yva2: (197, 4) \n",
      "  Xte3: (347, 24, 400) Yte2: (347, 4)\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 3s 66ms/step - loss: 1850.8712 - mae: 1850.8588 - val_loss: 1897.6437 - val_mae: 1897.6310 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 1844.8290 - mae: 1844.8164 - val_loss: 1888.4766 - val_mae: 1888.4636 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1833.6355 - mae: 1833.6222 - val_loss: 1875.0189 - val_mae: 1875.0054 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1818.9183 - mae: 1818.9045 - val_loss: 1858.0653 - val_mae: 1858.0508 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1800.4652 - mae: 1800.4502 - val_loss: 1836.8176 - val_mae: 1836.8019 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1777.2472 - mae: 1777.2306 - val_loss: 1810.8708 - val_mae: 1810.8533 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 1749.4004 - mae: 1749.3820 - val_loss: 1779.9686 - val_mae: 1779.9487 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1716.8131 - mae: 1716.7922 - val_loss: 1743.9788 - val_mae: 1743.9564 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1679.4149 - mae: 1679.3910 - val_loss: 1702.7690 - val_mae: 1702.7435 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1635.5587 - mae: 1635.5316 - val_loss: 1655.9543 - val_mae: 1655.9252 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 1589.5334 - mae: 1589.5026 - val_loss: 1604.8448 - val_mae: 1604.8115 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 1537.7418 - mae: 1537.7067 - val_loss: 1552.9290 - val_mae: 1552.8912 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 1487.9382 - mae: 1487.8986 - val_loss: 1503.6071 - val_mae: 1503.5645 - lr: 0.0010\n",
      "Epoch 14/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 14ms/step - loss: 1439.0309 - mae: 1438.9862 - val_loss: 1456.0482 - val_mae: 1456.0007 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1394.7151 - mae: 1394.6654 - val_loss: 1409.5540 - val_mae: 1409.5011 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1346.7401 - mae: 1346.6849 - val_loss: 1364.0081 - val_mae: 1363.9501 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1302.8035 - mae: 1302.7429 - val_loss: 1318.7537 - val_mae: 1318.6898 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1259.0668 - mae: 1259.0006 - val_loss: 1274.1405 - val_mae: 1274.0709 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1216.1011 - mae: 1216.0289 - val_loss: 1230.2592 - val_mae: 1230.1836 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1173.5605 - mae: 1173.4822 - val_loss: 1187.3781 - val_mae: 1187.2963 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 1533.5822\n",
      "LV_RMSE_12h: 1744.6779\n",
      "LV_MAE_24h: 331.3372\n",
      "LV_RMSE_24h: 506.2502\n",
      "LV_MAE_48h: 407.1009\n",
      "LV_RMSE_48h: 591.3973\n",
      "LV_MAE_72h: 341.5245\n",
      "LV_RMSE_72h: 481.6758\n",
      "LV_MAE_mean: 653.3862\n",
      "LV_RMSE_mean: 831.0003\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 1089.7676\n",
      "RMSE_12h: 1302.1694\n",
      "MAE_24h: 1082.8143\n",
      "RMSE_24h: 1291.6899\n",
      "MAE_48h: 1102.5739\n",
      "RMSE_48h: 1315.8875\n",
      "MAE_72h: 1069.9110\n",
      "RMSE_72h: 1272.5643\n",
      "MAE_mean: 1086.2667\n",
      "RMSE_mean: 1295.5778\n",
      "\n",
      "=== Station S314910 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1376 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1353, 24, 400) Ytr2: (1353, 4) \n",
      "  Xva3: (197, 24, 400) Yva2: (197, 4) \n",
      "  Xte3: (347, 24, 400) Yte2: (347, 4)\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 3s 66ms/step - loss: 235.3960 - mae: 235.3831 - val_loss: 237.9811 - val_mae: 237.9682 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 227.6952 - mae: 227.6822 - val_loss: 227.3838 - val_mae: 227.3707 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 215.7260 - mae: 215.7126 - val_loss: 213.5973 - val_mae: 213.5836 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 201.8993 - mae: 201.8853 - val_loss: 198.9770 - val_mae: 198.9624 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 188.3625 - mae: 188.3475 - val_loss: 185.0472 - val_mae: 185.0314 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 175.4376 - mae: 175.4213 - val_loss: 172.4272 - val_mae: 172.4100 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 163.5542 - mae: 163.5363 - val_loss: 160.3709 - val_mae: 160.3521 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 152.4185 - mae: 152.3989 - val_loss: 150.0980 - val_mae: 150.0775 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 143.6978 - mae: 143.6765 - val_loss: 142.2272 - val_mae: 142.2048 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 137.2136 - mae: 137.1906 - val_loss: 137.0232 - val_mae: 136.9992 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 131.5612 - mae: 131.5366 - val_loss: 130.1830 - val_mae: 130.1575 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 119.6825 - mae: 119.6564 - val_loss: 115.7841 - val_mae: 115.7571 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 104.8252 - mae: 104.7973 - val_loss: 103.0933 - val_mae: 103.0642 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 94.0039 - mae: 93.9736 - val_loss: 92.6265 - val_mae: 92.5950 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 86.3275 - mae: 86.2950 - val_loss: 86.9070 - val_mae: 86.8736 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 83.5629 - mae: 83.5289 - val_loss: 85.2550 - val_mae: 85.2206 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 82.4273 - mae: 82.3928 - val_loss: 84.3374 - val_mae: 84.3028 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 81.1486 - mae: 81.1141 - val_loss: 82.0171 - val_mae: 81.9825 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 79.7224 - mae: 79.6878 - val_loss: 81.1321 - val_mae: 81.0974 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 78.2269 - mae: 78.1920 - val_loss: 80.0494 - val_mae: 80.0143 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 238.6888\n",
      "LV_RMSE_12h: 262.8450\n",
      "LV_MAE_24h: 52.1787\n",
      "LV_RMSE_24h: 79.8150\n",
      "LV_MAE_48h: 64.3112\n",
      "LV_RMSE_48h: 99.4189\n",
      "LV_MAE_72h: 56.9654\n",
      "LV_RMSE_72h: 89.8835\n",
      "LV_MAE_mean: 103.0360\n",
      "LV_RMSE_mean: 132.9906\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 168.2022\n",
      "RMSE_12h: 202.3114\n",
      "MAE_24h: 49.5754\n",
      "RMSE_24h: 74.9400\n",
      "MAE_48h: 48.4702\n",
      "RMSE_48h: 74.0402\n",
      "MAE_72h: 48.2411\n",
      "RMSE_72h: 72.4330\n",
      "MAE_mean: 78.6222\n",
      "RMSE_mean: 105.9312\n",
      "\n",
      "=== Station S314936 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1376 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1353, 24, 400) Ytr2: (1353, 4) \n",
      "  Xva3: (197, 24, 400) Yva2: (197, 4) \n",
      "  Xte3: (348, 24, 400) Yte2: (348, 4)\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 3s 66ms/step - loss: 2693.0730 - mae: 2693.0603 - val_loss: 2669.4639 - val_mae: 2669.4512 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 2687.7358 - mae: 2687.7231 - val_loss: 2661.2043 - val_mae: 2661.1914 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 2677.6265 - mae: 2677.6133 - val_loss: 2649.0505 - val_mae: 2649.0371 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 2663.8787 - mae: 2663.8647 - val_loss: 2633.3191 - val_mae: 2633.3047 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 2646.5381 - mae: 2646.5232 - val_loss: 2613.5220 - val_mae: 2613.5061 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 2624.7944 - mae: 2624.7783 - val_loss: 2589.2109 - val_mae: 2589.1936 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 2598.3018 - mae: 2598.2834 - val_loss: 2560.1326 - val_mae: 2560.1133 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 2567.1025 - mae: 2567.0818 - val_loss: 2526.1135 - val_mae: 2526.0916 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 2531.0405 - mae: 2531.0171 - val_loss: 2487.1458 - val_mae: 2487.1208 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 2489.9639 - mae: 2489.9373 - val_loss: 2443.0686 - val_mae: 2443.0400 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 2442.5876 - mae: 2442.5579 - val_loss: 2393.7603 - val_mae: 2393.7278 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 2391.3274 - mae: 2391.2927 - val_loss: 2339.2825 - val_mae: 2339.2456 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 2334.6692 - mae: 2334.6304 - val_loss: 2279.9727 - val_mae: 2279.9309 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 2275.1843 - mae: 2275.1399 - val_loss: 2218.5305 - val_mae: 2218.4829 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 2217.6353 - mae: 2217.5852 - val_loss: 2160.1135 - val_mae: 2160.0610 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 2161.2847 - mae: 2161.2290 - val_loss: 2106.6570 - val_mae: 2106.5984 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 2108.6584 - mae: 2108.5977 - val_loss: 2055.9241 - val_mae: 2055.8599 - lr: 0.0010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 2059.8037 - mae: 2059.7366 - val_loss: 2006.7037 - val_mae: 2006.6334 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 2012.0262 - mae: 2011.9531 - val_loss: 1960.3506 - val_mae: 1960.2742 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1963.1439 - mae: 1963.0647 - val_loss: 1917.8735 - val_mae: 1917.7909 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 2502.1753\n",
      "LV_RMSE_12h: 2720.2581\n",
      "LV_MAE_24h: 452.9885\n",
      "LV_RMSE_24h: 754.9625\n",
      "LV_MAE_48h: 605.7299\n",
      "LV_RMSE_48h: 1009.8221\n",
      "LV_MAE_72h: 529.5977\n",
      "LV_RMSE_72h: 884.7482\n",
      "LV_MAE_mean: 1022.6228\n",
      "LV_RMSE_mean: 1342.4478\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 1751.1038\n",
      "RMSE_12h: 2200.0557\n",
      "MAE_24h: 1802.3093\n",
      "RMSE_24h: 2247.2004\n",
      "MAE_48h: 1797.2274\n",
      "RMSE_48h: 2237.3269\n",
      "MAE_72h: 1782.0938\n",
      "RMSE_72h: 2205.2625\n",
      "MAE_mean: 1783.1836\n",
      "RMSE_mean: 2222.4614\n",
      "\n",
      "=== Station S314983 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1376 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1353, 24, 400) Ytr2: (1353, 4) \n",
      "  Xva3: (197, 24, 400) Yva2: (197, 4) \n",
      "  Xte3: (347, 24, 400) Yte2: (347, 4)\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 3s 64ms/step - loss: 389.7505 - mae: 389.7377 - val_loss: 425.8587 - val_mae: 425.8459 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 382.6977 - mae: 382.6848 - val_loss: 415.9467 - val_mae: 415.9336 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 371.0753 - mae: 371.0621 - val_loss: 402.4255 - val_mae: 402.4120 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 356.8698 - mae: 356.8558 - val_loss: 386.5175 - val_mae: 386.5029 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 341.4482 - mae: 341.4332 - val_loss: 369.5549 - val_mae: 369.5392 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 325.0874 - mae: 325.0710 - val_loss: 351.9924 - val_mae: 351.9751 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 308.0204 - mae: 308.0022 - val_loss: 334.3403 - val_mae: 334.3211 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 291.4470 - mae: 291.4268 - val_loss: 317.1459 - val_mae: 317.1244 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 277.2318 - mae: 277.2094 - val_loss: 301.8326 - val_mae: 301.8089 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 263.9687 - mae: 263.9440 - val_loss: 288.8788 - val_mae: 288.8528 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 252.9723 - mae: 252.9452 - val_loss: 278.7415 - val_mae: 278.7132 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 244.1832 - mae: 244.1538 - val_loss: 269.9124 - val_mae: 269.8817 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 236.4417 - mae: 236.4101 - val_loss: 259.3365 - val_mae: 259.3036 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 225.4435 - mae: 225.4098 - val_loss: 245.7795 - val_mae: 245.7446 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 213.7722 - mae: 213.7364 - val_loss: 234.8731 - val_mae: 234.8361 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 204.4412 - mae: 204.4033 - val_loss: 223.6202 - val_mae: 223.5812 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 196.3459 - mae: 196.3059 - val_loss: 212.0943 - val_mae: 212.0532 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 186.1519 - mae: 186.1099 - val_loss: 203.1707 - val_mae: 203.1276 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 178.0265 - mae: 177.9824 - val_loss: 195.6972 - val_mae: 195.6518 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 173.0525 - mae: 173.0061 - val_loss: 189.5179 - val_mae: 189.4703 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 418.8127\n",
      "LV_RMSE_12h: 471.5195\n",
      "LV_MAE_24h: 123.0231\n",
      "LV_RMSE_24h: 175.8655\n",
      "LV_MAE_48h: 162.3084\n",
      "LV_RMSE_48h: 221.9117\n",
      "LV_MAE_72h: 151.0951\n",
      "LV_RMSE_72h: 214.1032\n",
      "LV_MAE_mean: 213.8098\n",
      "LV_RMSE_mean: 270.8500\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 297.6062\n",
      "RMSE_12h: 357.8936\n",
      "MAE_24h: 125.2703\n",
      "RMSE_24h: 175.0182\n",
      "MAE_48h: 121.3053\n",
      "RMSE_48h: 171.6958\n",
      "MAE_72h: 123.8028\n",
      "RMSE_72h: 171.8002\n",
      "MAE_mean: 166.9962\n",
      "RMSE_mean: 219.1019\n",
      "\n",
      "=== Station S315060 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1377 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1354, 24, 400) Ytr2: (1354, 4) \n",
      "  Xva3: (197, 24, 400) Yva2: (197, 4) \n",
      "  Xte3: (348, 24, 400) Yte2: (348, 4)\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 3s 69ms/step - loss: 1126.9904 - mae: 1126.9777 - val_loss: 1079.1903 - val_mae: 1079.1776 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 1120.0874 - mae: 1120.0748 - val_loss: 1070.3583 - val_mae: 1070.3453 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 1109.7373 - mae: 1109.7240 - val_loss: 1059.1227 - val_mae: 1059.1093 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1097.5056 - mae: 1097.4918 - val_loss: 1045.7626 - val_mae: 1045.7483 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1082.9359 - mae: 1082.9210 - val_loss: 1030.6948 - val_mae: 1030.6792 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 1067.2159 - mae: 1067.1998 - val_loss: 1013.9675 - val_mae: 1013.9502 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 1049.8942 - mae: 1049.8760 - val_loss: 996.1055 - val_mae: 996.0862 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1030.7047 - mae: 1030.6846 - val_loss: 977.2540 - val_mae: 977.2322 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1010.8609 - mae: 1010.8381 - val_loss: 957.2958 - val_mae: 957.2714 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 989.6683 - mae: 989.6425 - val_loss: 936.7395 - val_mae: 936.7120 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 968.7884 - mae: 968.7594 - val_loss: 914.8575 - val_mae: 914.8265 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 945.9728 - mae: 945.9402 - val_loss: 890.0694 - val_mae: 890.0346 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 918.6111 - mae: 918.5745 - val_loss: 858.7725 - val_mae: 858.7335 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 886.2944 - mae: 886.2535 - val_loss: 825.6256 - val_mae: 825.5820 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 851.2471 - mae: 851.2014 - val_loss: 792.4691 - val_mae: 792.4203 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 817.7426 - mae: 817.6913 - val_loss: 758.4672 - val_mae: 758.4126 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 782.2804 - mae: 782.2230 - val_loss: 722.4730 - val_mae: 722.4122 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 744.2941 - mae: 744.2305 - val_loss: 689.1234 - val_mae: 689.0561 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 711.8763 - mae: 711.8060 - val_loss: 656.9606 - val_mae: 656.8862 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 680.8436 - mae: 680.7662 - val_loss: 625.0726 - val_mae: 624.9913 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 1312.0374\n",
      "LV_RMSE_12h: 1458.2002\n",
      "LV_MAE_24h: 217.9770\n",
      "LV_RMSE_24h: 320.6536\n",
      "LV_MAE_48h: 281.8132\n",
      "LV_RMSE_48h: 411.5486\n",
      "LV_MAE_72h: 248.7586\n",
      "LV_RMSE_72h: 371.4127\n",
      "LV_MAE_mean: 515.1465\n",
      "LV_RMSE_mean: 640.4537\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 878.4678\n",
      "RMSE_12h: 1048.3206\n",
      "MAE_24h: 516.2536\n",
      "RMSE_24h: 672.3251\n",
      "MAE_48h: 498.5339\n",
      "RMSE_48h: 648.3486\n",
      "MAE_72h: 514.2606\n",
      "RMSE_72h: 664.6629\n",
      "MAE_mean: 601.8790\n",
      "RMSE_mean: 758.4142\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Station S315822 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1377 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1354, 24, 400) Ytr2: (1354, 4) \n",
      "  Xva3: (197, 24, 400) Yva2: (197, 4) \n",
      "  Xte3: (348, 24, 400) Yte2: (348, 4)\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 3s 66ms/step - loss: 790.5720 - mae: 790.5594 - val_loss: 786.2192 - val_mae: 786.2065 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 783.2388 - mae: 783.2262 - val_loss: 775.8662 - val_mae: 775.8533 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 770.9395 - mae: 770.9265 - val_loss: 761.6006 - val_mae: 761.5872 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 756.0353 - mae: 756.0217 - val_loss: 745.3683 - val_mae: 745.3541 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 739.2300 - mae: 739.2153 - val_loss: 728.0853 - val_mae: 728.0699 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 721.4105 - mae: 721.3945 - val_loss: 709.8337 - val_mae: 709.8167 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 702.8506 - mae: 702.8327 - val_loss: 690.9352 - val_mae: 690.9163 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 683.4759 - mae: 683.4559 - val_loss: 671.3643 - val_mae: 671.3431 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 663.7708 - mae: 663.7486 - val_loss: 650.5487 - val_mae: 650.5249 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 642.4850 - mae: 642.4600 - val_loss: 628.3107 - val_mae: 628.2841 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 619.3749 - mae: 619.3469 - val_loss: 605.7927 - val_mae: 605.7629 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 598.0657 - mae: 598.0344 - val_loss: 586.3055 - val_mae: 586.2722 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 577.3603 - mae: 577.3253 - val_loss: 566.1904 - val_mae: 566.1533 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 554.6287 - mae: 554.5901 - val_loss: 541.2802 - val_mae: 541.2395 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 0s 22ms/step - loss: 526.9268 - mae: 526.8843 - val_loss: 511.4733 - val_mae: 511.4285 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 0s 17ms/step - loss: 497.1653 - mae: 497.1185 - val_loss: 480.2104 - val_mae: 480.1610 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 0s 18ms/step - loss: 465.7432 - mae: 465.6916 - val_loss: 449.7669 - val_mae: 449.7124 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 434.5914 - mae: 434.5347 - val_loss: 420.2469 - val_mae: 420.1871 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 407.8779 - mae: 407.8157 - val_loss: 392.9429 - val_mae: 392.8775 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 379.8575 - mae: 379.7896 - val_loss: 368.4139 - val_mae: 368.3428 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 889.4857\n",
      "LV_RMSE_12h: 993.4590\n",
      "LV_MAE_24h: 156.2558\n",
      "LV_RMSE_24h: 225.3179\n",
      "LV_MAE_48h: 209.9138\n",
      "LV_RMSE_48h: 286.6604\n",
      "LV_MAE_72h: 189.4540\n",
      "LV_RMSE_72h: 267.6811\n",
      "LV_MAE_mean: 361.2773\n",
      "LV_RMSE_mean: 443.2796\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 629.0617\n",
      "RMSE_12h: 743.4653\n",
      "MAE_24h: 277.3344\n",
      "RMSE_24h: 361.8156\n",
      "MAE_48h: 271.3604\n",
      "RMSE_48h: 354.3839\n",
      "MAE_72h: 272.2595\n",
      "RMSE_72h: 355.6736\n",
      "MAE_mean: 362.5040\n",
      "RMSE_mean: 453.8346\n",
      "\n",
      "=== Station S315888 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1377 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1354, 24, 400) Ytr2: (1354, 4) \n",
      "  Xva3: (197, 24, 400) Yva2: (197, 4) \n",
      "  Xte3: (348, 24, 400) Yte2: (348, 4)\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 3s 65ms/step - loss: 716.7444 - mae: 716.7315 - val_loss: 713.6241 - val_mae: 713.6113 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 712.0408 - mae: 712.0278 - val_loss: 706.4483 - val_mae: 706.4351 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 703.0079 - mae: 702.9946 - val_loss: 695.2175 - val_mae: 695.2039 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 690.5849 - mae: 690.5709 - val_loss: 681.2411 - val_mae: 681.2267 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 675.3560 - mae: 675.3410 - val_loss: 664.9587 - val_mae: 664.9431 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 658.6243 - mae: 658.6080 - val_loss: 647.7657 - val_mae: 647.7485 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 640.6093 - mae: 640.5912 - val_loss: 629.8417 - val_mae: 629.8225 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 621.8814 - mae: 621.8613 - val_loss: 610.9827 - val_mae: 610.9614 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 602.5086 - mae: 602.4863 - val_loss: 591.4866 - val_mae: 591.4628 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 582.4544 - mae: 582.4294 - val_loss: 571.4361 - val_mae: 571.4095 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 562.8557 - mae: 562.8278 - val_loss: 551.2435 - val_mae: 551.2137 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 542.9304 - mae: 542.8992 - val_loss: 532.2823 - val_mae: 532.2494 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 525.0259 - mae: 524.9914 - val_loss: 514.2028 - val_mae: 514.1665 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 507.4929 - mae: 507.4550 - val_loss: 496.1018 - val_mae: 496.0620 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 489.6150 - mae: 489.5735 - val_loss: 476.5791 - val_mae: 476.5356 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 470.3834 - mae: 470.3382 - val_loss: 455.9036 - val_mae: 455.8564 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 449.8574 - mae: 449.8083 - val_loss: 432.4883 - val_mae: 432.4371 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 424.6371 - mae: 424.5841 - val_loss: 404.5076 - val_mae: 404.4521 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 401.2231 - mae: 401.1657 - val_loss: 382.9619 - val_mae: 382.9020 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 381.4188 - mae: 381.3568 - val_loss: 363.2782 - val_mae: 363.2137 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 876.0747\n",
      "LV_RMSE_12h: 991.3050\n",
      "LV_MAE_24h: 155.5977\n",
      "LV_RMSE_24h: 218.2380\n",
      "LV_MAE_48h: 183.4856\n",
      "LV_RMSE_48h: 256.7828\n",
      "LV_MAE_72h: 188.2012\n",
      "LV_RMSE_72h: 258.9456\n",
      "LV_MAE_mean: 350.8398\n",
      "LV_RMSE_mean: 431.3178\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 567.4412\n",
      "RMSE_12h: 675.2793\n",
      "MAE_24h: 351.0816\n",
      "RMSE_24h: 443.1648\n",
      "MAE_48h: 353.3701\n",
      "RMSE_48h: 456.3521\n",
      "MAE_72h: 346.8200\n",
      "RMSE_72h: 442.3103\n",
      "MAE_mean: 404.6782\n",
      "RMSE_mean: 504.2766\n",
      "\n",
      "=== Station S315913 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1377 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1354, 24, 400) Ytr2: (1354, 4) \n",
      "  Xva3: (197, 24, 400) Yva2: (197, 4) \n",
      "  Xte3: (348, 24, 400) Yte2: (348, 4)\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 3s 65ms/step - loss: 647.0782 - mae: 647.0655 - val_loss: 629.4628 - val_mae: 629.4501 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 641.0836 - mae: 641.0707 - val_loss: 621.2328 - val_mae: 621.2199 - lr: 0.0010\n",
      "Epoch 3/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 13ms/step - loss: 631.1326 - mae: 631.1194 - val_loss: 609.4504 - val_mae: 609.4370 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 618.2893 - mae: 618.2755 - val_loss: 595.2125 - val_mae: 595.1982 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 603.1620 - mae: 603.1471 - val_loss: 579.7002 - val_mae: 579.6846 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 587.4456 - mae: 587.4294 - val_loss: 563.6161 - val_mae: 563.5991 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 571.3749 - mae: 571.3571 - val_loss: 547.1065 - val_mae: 547.0876 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 555.4880 - mae: 555.4683 - val_loss: 530.5320 - val_mae: 530.5111 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 539.3469 - mae: 539.3251 - val_loss: 513.7050 - val_mae: 513.6818 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 522.2352 - mae: 522.2110 - val_loss: 497.4954 - val_mae: 497.4697 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 507.4353 - mae: 507.4083 - val_loss: 481.7205 - val_mae: 481.6921 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 492.1565 - mae: 492.1269 - val_loss: 467.0535 - val_mae: 467.0224 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 478.7007 - mae: 478.6682 - val_loss: 453.0595 - val_mae: 453.0254 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 464.7034 - mae: 464.6680 - val_loss: 439.3166 - val_mae: 439.2794 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 451.4792 - mae: 451.4407 - val_loss: 423.9182 - val_mae: 423.8779 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 437.1135 - mae: 437.0718 - val_loss: 407.2106 - val_mae: 407.1670 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 419.3414 - mae: 419.2964 - val_loss: 388.6125 - val_mae: 388.5655 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 401.2399 - mae: 401.1914 - val_loss: 370.8253 - val_mae: 370.7748 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 383.2205 - mae: 383.1683 - val_loss: 351.3158 - val_mae: 351.2615 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 364.7839 - mae: 364.7277 - val_loss: 334.1209 - val_mae: 334.0625 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 758.2730\n",
      "LV_RMSE_12h: 833.7490\n",
      "LV_MAE_24h: 124.4052\n",
      "LV_RMSE_24h: 183.5386\n",
      "LV_MAE_48h: 148.9425\n",
      "LV_RMSE_48h: 215.8436\n",
      "LV_MAE_72h: 137.0172\n",
      "LV_RMSE_72h: 204.0074\n",
      "LV_MAE_mean: 292.1595\n",
      "LV_RMSE_mean: 359.2846\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 501.1382\n",
      "RMSE_12h: 573.2630\n",
      "MAE_24h: 287.2737\n",
      "RMSE_24h: 350.6714\n",
      "MAE_48h: 271.4300\n",
      "RMSE_48h: 329.7377\n",
      "MAE_72h: 295.4301\n",
      "RMSE_72h: 370.6340\n",
      "MAE_mean: 338.8181\n",
      "RMSE_mean: 406.0765\n",
      "\n",
      "=== Station S315927 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1377 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1354, 24, 400) Ytr2: (1354, 4) \n",
      "  Xva3: (197, 24, 400) Yva2: (197, 4) \n",
      "  Xte3: (348, 24, 400) Yte2: (348, 4)\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 3s 64ms/step - loss: 3077.7061 - mae: 3077.6929 - val_loss: 3073.7690 - val_mae: 3073.7563 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 3070.9995 - mae: 3070.9871 - val_loss: 3064.0942 - val_mae: 3064.0813 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 3059.4045 - mae: 3059.3914 - val_loss: 3050.5750 - val_mae: 3050.5615 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 3044.5674 - mae: 3044.5535 - val_loss: 3033.1145 - val_mae: 3033.0999 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 3024.5913 - mae: 3024.5767 - val_loss: 3010.8037 - val_mae: 3010.7878 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 2999.9922 - mae: 2999.9753 - val_loss: 2983.5242 - val_mae: 2983.5063 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 2970.7883 - mae: 2970.7693 - val_loss: 2951.0369 - val_mae: 2951.0168 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 2936.0552 - mae: 2936.0337 - val_loss: 2913.1602 - val_mae: 2913.1375 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 2896.2322 - mae: 2896.2083 - val_loss: 2869.7935 - val_mae: 2869.7671 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 2849.2727 - mae: 2849.2451 - val_loss: 2820.7737 - val_mae: 2820.7437 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 2798.6233 - mae: 2798.5916 - val_loss: 2766.0945 - val_mae: 2766.0605 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 2742.3564 - mae: 2742.3201 - val_loss: 2705.7825 - val_mae: 2705.7434 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 2679.1235 - mae: 2679.0820 - val_loss: 2639.7158 - val_mae: 2639.6709 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 2610.8010 - mae: 2610.7542 - val_loss: 2568.5234 - val_mae: 2568.4731 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 2538.1760 - mae: 2538.1230 - val_loss: 2496.1931 - val_mae: 2496.1365 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 2468.6125 - mae: 2468.5530 - val_loss: 2425.1282 - val_mae: 2425.0645 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 2400.1948 - mae: 2400.1282 - val_loss: 2356.7637 - val_mae: 2356.6931 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 2326.9470 - mae: 2326.8738 - val_loss: 2289.5012 - val_mae: 2289.4236 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 2263.0063 - mae: 2262.9253 - val_loss: 2221.6353 - val_mae: 2221.5500 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 2196.8472 - mae: 2196.7588 - val_loss: 2152.6990 - val_mae: 2152.6062 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 2349.1868\n",
      "LV_RMSE_12h: 2662.5725\n",
      "LV_MAE_24h: 407.0258\n",
      "LV_RMSE_24h: 572.2393\n",
      "LV_MAE_48h: 518.8592\n",
      "LV_RMSE_48h: 727.5716\n",
      "LV_MAE_72h: 474.6293\n",
      "LV_RMSE_72h: 623.8753\n",
      "LV_MAE_mean: 937.4253\n",
      "LV_RMSE_mean: 1146.5647\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 2005.7118\n",
      "RMSE_12h: 2399.6885\n",
      "MAE_24h: 2042.7119\n",
      "RMSE_24h: 2420.7776\n",
      "MAE_48h: 2047.7089\n",
      "RMSE_48h: 2430.2888\n",
      "MAE_72h: 2048.3550\n",
      "RMSE_72h: 2432.8372\n",
      "MAE_mean: 2036.1219\n",
      "RMSE_mean: 2420.8979\n",
      "\n",
      "=== Station S315956 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1376 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1353, 24, 400) Ytr2: (1353, 4) \n",
      "  Xva3: (197, 24, 400) Yva2: (197, 4) \n",
      "  Xte3: (348, 24, 400) Yte2: (348, 4)\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 3s 64ms/step - loss: 230.1979 - mae: 230.1849 - val_loss: 228.0061 - val_mae: 227.9932 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 224.7287 - mae: 224.7157 - val_loss: 220.3742 - val_mae: 220.3611 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 215.7553 - mae: 215.7421 - val_loss: 209.8415 - val_mae: 209.8280 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 204.4014 - mae: 204.3876 - val_loss: 197.7532 - val_mae: 197.7389 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 192.4492 - mae: 192.4346 - val_loss: 185.7585 - val_mae: 185.7432 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 180.4676 - mae: 180.4518 - val_loss: 174.1795 - val_mae: 174.1631 - lr: 0.0010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 168.8731 - mae: 168.8560 - val_loss: 163.3696 - val_mae: 163.3517 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 158.3947 - mae: 158.3761 - val_loss: 153.6383 - val_mae: 153.6188 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 149.5466 - mae: 149.5264 - val_loss: 145.9727 - val_mae: 145.9516 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 142.6810 - mae: 142.6592 - val_loss: 140.2759 - val_mae: 140.2533 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 137.9590 - mae: 137.9358 - val_loss: 135.0446 - val_mae: 135.0205 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 132.3446 - mae: 132.3200 - val_loss: 128.9888 - val_mae: 128.9634 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 125.2113 - mae: 125.1854 - val_loss: 117.5816 - val_mae: 117.5549 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 114.0349 - mae: 114.0075 - val_loss: 108.0780 - val_mae: 108.0496 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 105.7966 - mae: 105.7673 - val_loss: 99.2952 - val_mae: 99.2648 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 97.7228 - mae: 97.6916 - val_loss: 92.1309 - val_mae: 92.0986 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 91.6281 - mae: 91.5951 - val_loss: 86.2699 - val_mae: 86.2359 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 87.8207 - mae: 87.7862 - val_loss: 80.6451 - val_mae: 80.6099 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 83.9330 - mae: 83.8973 - val_loss: 77.5331 - val_mae: 77.4967 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 81.3873 - mae: 81.3506 - val_loss: 74.4467 - val_mae: 74.4096 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 246.6149\n",
      "LV_RMSE_12h: 275.1198\n",
      "LV_MAE_24h: 49.8477\n",
      "LV_RMSE_24h: 77.8191\n",
      "LV_MAE_48h: 57.8649\n",
      "LV_RMSE_48h: 84.4895\n",
      "LV_MAE_72h: 53.4655\n",
      "LV_RMSE_72h: 78.2302\n",
      "LV_MAE_mean: 101.9483\n",
      "LV_RMSE_mean: 128.9146\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 172.9866\n",
      "RMSE_12h: 205.2889\n",
      "MAE_24h: 44.2761\n",
      "RMSE_24h: 62.6499\n",
      "MAE_48h: 45.9327\n",
      "RMSE_48h: 64.9413\n",
      "MAE_72h: 46.7138\n",
      "RMSE_72h: 65.7749\n",
      "MAE_mean: 77.4773\n",
      "RMSE_mean: 99.6638\n",
      "\n",
      "=== Station S315982 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1377 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1354, 24, 400) Ytr2: (1354, 4) \n",
      "  Xva3: (197, 24, 400) Yva2: (197, 4) \n",
      "  Xte3: (348, 24, 400) Yte2: (348, 4)\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 3s 64ms/step - loss: 2306.8472 - mae: 2306.8345 - val_loss: 2323.6113 - val_mae: 2323.5986 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 2300.3293 - mae: 2300.3164 - val_loss: 2314.3242 - val_mae: 2314.3113 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 2289.3054 - mae: 2289.2920 - val_loss: 2301.3313 - val_mae: 2301.3176 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 2274.8633 - mae: 2274.8491 - val_loss: 2284.5632 - val_mae: 2284.5488 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 2255.7573 - mae: 2255.7419 - val_loss: 2263.3354 - val_mae: 2263.3196 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 2232.6040 - mae: 2232.5874 - val_loss: 2237.3384 - val_mae: 2237.3208 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 2204.5806 - mae: 2204.5618 - val_loss: 2206.3484 - val_mae: 2206.3286 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 2171.2991 - mae: 2171.2783 - val_loss: 2170.1609 - val_mae: 2170.1384 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 2133.4138 - mae: 2133.3899 - val_loss: 2128.7122 - val_mae: 2128.6865 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 2088.5354 - mae: 2088.5081 - val_loss: 2081.8247 - val_mae: 2081.7952 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 2041.1744 - mae: 2041.1433 - val_loss: 2029.7167 - val_mae: 2029.6831 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1987.8472 - mae: 1987.8115 - val_loss: 1973.9238 - val_mae: 1973.8856 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1931.7593 - mae: 1931.7186 - val_loss: 1916.9895 - val_mae: 1916.9460 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1875.7578 - mae: 1875.7123 - val_loss: 1862.8241 - val_mae: 1862.7754 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1818.9841 - mae: 1818.9327 - val_loss: 1810.1399 - val_mae: 1810.0857 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1765.8519 - mae: 1765.7950 - val_loss: 1756.9301 - val_mae: 1756.8698 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1712.0594 - mae: 1711.9965 - val_loss: 1703.2114 - val_mae: 1703.1450 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1657.4574 - mae: 1657.3884 - val_loss: 1650.6361 - val_mae: 1650.5635 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1607.2856 - mae: 1607.2100 - val_loss: 1601.8226 - val_mae: 1601.7433 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1557.8026 - mae: 1557.7208 - val_loss: 1556.3342 - val_mae: 1556.2484 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 2023.0488\n",
      "LV_RMSE_12h: 2227.5972\n",
      "LV_MAE_24h: 393.8535\n",
      "LV_RMSE_24h: 631.9861\n",
      "LV_MAE_48h: 552.0057\n",
      "LV_RMSE_48h: 835.8712\n",
      "LV_MAE_72h: 435.3678\n",
      "LV_RMSE_72h: 691.7426\n",
      "LV_MAE_mean: 851.0690\n",
      "LV_RMSE_mean: 1096.7992\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 1441.7623\n",
      "RMSE_12h: 1785.2167\n",
      "MAE_24h: 1453.1324\n",
      "RMSE_24h: 1781.1062\n",
      "MAE_48h: 1427.4183\n",
      "RMSE_48h: 1752.1139\n",
      "MAE_72h: 1432.4342\n",
      "RMSE_72h: 1757.9138\n",
      "MAE_mean: 1438.6868\n",
      "RMSE_mean: 1769.0876\n",
      "\n",
      "=== Station S315983 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1130 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1107, 24, 400) Ytr2: (1107, 4) \n",
      "  Xva3: (162, 24, 400) Yva2: (162, 4) \n",
      "  Xte3: (277, 24, 400) Yte2: (277, 4)\n",
      "Epoch 1/20\n",
      "9/9 [==============================] - 3s 83ms/step - loss: 157.6753 - mae: 157.6627 - val_loss: 152.6581 - val_mae: 152.6455 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 152.7328 - mae: 152.7200 - val_loss: 146.0277 - val_mae: 146.0148 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 144.9431 - mae: 144.9302 - val_loss: 136.6149 - val_mae: 136.6017 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 134.9388 - mae: 134.9254 - val_loss: 125.7797 - val_mae: 125.7659 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 124.2011 - mae: 124.1870 - val_loss: 115.1479 - val_mae: 115.1333 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 113.7232 - mae: 113.7081 - val_loss: 105.1394 - val_mae: 105.1238 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 103.9362 - mae: 103.9202 - val_loss: 96.1887 - val_mae: 96.1719 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 95.4226 - mae: 95.4053 - val_loss: 88.2795 - val_mae: 88.2615 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 87.9399 - mae: 87.9213 - val_loss: 82.2289 - val_mae: 82.2095 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 82.2341 - mae: 82.2143 - val_loss: 77.5194 - val_mae: 77.4988 - lr: 0.0010\n",
      "Epoch 11/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 15ms/step - loss: 77.8462 - mae: 77.8251 - val_loss: 72.5862 - val_mae: 72.5646 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 73.5579 - mae: 73.5358 - val_loss: 67.6334 - val_mae: 67.6108 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 69.4599 - mae: 69.4369 - val_loss: 61.4416 - val_mae: 61.4180 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 65.8002 - mae: 65.7763 - val_loss: 56.8997 - val_mae: 56.8753 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 63.7630 - mae: 63.7384 - val_loss: 53.5693 - val_mae: 53.5443 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 61.5962 - mae: 61.5710 - val_loss: 51.8234 - val_mae: 51.7979 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 59.8929 - mae: 59.8671 - val_loss: 50.6484 - val_mae: 50.6224 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 58.8250 - mae: 58.7987 - val_loss: 49.5575 - val_mae: 49.5309 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 57.8985 - mae: 57.8717 - val_loss: 48.3501 - val_mae: 48.3231 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 56.6190 - mae: 56.5917 - val_loss: 47.2346 - val_mae: 47.2071 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 134.3141\n",
      "LV_RMSE_12h: 153.7401\n",
      "LV_MAE_24h: 31.7978\n",
      "LV_RMSE_24h: 45.4161\n",
      "LV_MAE_48h: 38.5343\n",
      "LV_RMSE_48h: 54.2452\n",
      "LV_MAE_72h: 31.6787\n",
      "LV_RMSE_72h: 44.6670\n",
      "LV_MAE_mean: 59.0812\n",
      "LV_RMSE_mean: 74.5171\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 89.4955\n",
      "RMSE_12h: 104.2266\n",
      "MAE_24h: 33.7703\n",
      "RMSE_24h: 47.6136\n",
      "MAE_48h: 33.4809\n",
      "RMSE_48h: 47.2404\n",
      "MAE_72h: 31.9744\n",
      "RMSE_72h: 45.0548\n",
      "MAE_mean: 47.1803\n",
      "RMSE_mean: 61.0339\n",
      "\n",
      "=== Station S316045 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1377 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1354, 24, 400) Ytr2: (1354, 4) \n",
      "  Xva3: (197, 24, 400) Yva2: (197, 4) \n",
      "  Xte3: (348, 24, 400) Yte2: (348, 4)\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 3s 66ms/step - loss: 2466.0376 - mae: 2466.0249 - val_loss: 2469.2712 - val_mae: 2469.2585 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 2460.3765 - mae: 2460.3640 - val_loss: 2461.1138 - val_mae: 2461.1008 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 2450.4539 - mae: 2450.4409 - val_loss: 2449.3362 - val_mae: 2449.3228 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 2437.3108 - mae: 2437.2971 - val_loss: 2434.0393 - val_mae: 2434.0251 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 2420.0142 - mae: 2419.9995 - val_loss: 2414.5935 - val_mae: 2414.5781 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 2398.6580 - mae: 2398.6414 - val_loss: 2390.7109 - val_mae: 2390.6938 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 2373.0012 - mae: 2372.9832 - val_loss: 2362.1301 - val_mae: 2362.1111 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 2342.6360 - mae: 2342.6160 - val_loss: 2328.8711 - val_mae: 2328.8496 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 2307.1470 - mae: 2307.1240 - val_loss: 2290.7637 - val_mae: 2290.7390 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 2266.4021 - mae: 2266.3762 - val_loss: 2247.9160 - val_mae: 2247.8884 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 2222.1189 - mae: 2222.0898 - val_loss: 2200.7219 - val_mae: 2200.6899 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 2173.9536 - mae: 2173.9199 - val_loss: 2150.5034 - val_mae: 2150.4673 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 2124.3245 - mae: 2124.2866 - val_loss: 2101.2820 - val_mae: 2101.2417 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 2076.1736 - mae: 2076.1311 - val_loss: 2055.6597 - val_mae: 2055.6145 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 2030.1195 - mae: 2030.0720 - val_loss: 2011.7401 - val_mae: 2011.6901 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1989.9542 - mae: 1989.9016 - val_loss: 1969.0032 - val_mae: 1968.9480 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1946.3486 - mae: 1946.2911 - val_loss: 1926.3348 - val_mae: 1926.2744 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1904.5764 - mae: 1904.5138 - val_loss: 1884.1328 - val_mae: 1884.0669 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1861.3774 - mae: 1861.3091 - val_loss: 1843.8051 - val_mae: 1843.7335 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1824.3926 - mae: 1824.3187 - val_loss: 1805.9532 - val_mae: 1805.8760 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 2393.0259\n",
      "LV_RMSE_12h: 2679.7783\n",
      "LV_MAE_24h: 415.0489\n",
      "LV_RMSE_24h: 632.6689\n",
      "LV_MAE_48h: 554.9971\n",
      "LV_RMSE_48h: 830.6391\n",
      "LV_MAE_72h: 459.2557\n",
      "LV_RMSE_72h: 717.1494\n",
      "LV_MAE_mean: 955.5819\n",
      "LV_RMSE_mean: 1215.0590\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 1671.6654\n",
      "RMSE_12h: 2107.1533\n",
      "MAE_24h: 1664.2244\n",
      "RMSE_24h: 2079.9246\n",
      "MAE_48h: 1668.0111\n",
      "RMSE_48h: 2083.9875\n",
      "MAE_72h: 1678.2877\n",
      "RMSE_72h: 2095.0122\n",
      "MAE_mean: 1670.5471\n",
      "RMSE_mean: 2091.5195\n",
      "\n",
      "=== Station S316204 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1377 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1354, 24, 400) Ytr2: (1354, 4) \n",
      "  Xva3: (197, 24, 400) Yva2: (197, 4) \n",
      "  Xte3: (348, 24, 400) Yte2: (348, 4)\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 3s 65ms/step - loss: 1723.0486 - mae: 1723.0358 - val_loss: 1707.7180 - val_mae: 1707.7054 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1718.0642 - mae: 1718.0519 - val_loss: 1700.8464 - val_mae: 1700.8337 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1709.7875 - mae: 1709.7745 - val_loss: 1690.9692 - val_mae: 1690.9561 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1698.7197 - mae: 1698.7064 - val_loss: 1678.0912 - val_mae: 1678.0775 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1683.9830 - mae: 1683.9688 - val_loss: 1661.4232 - val_mae: 1661.4086 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1665.7600 - mae: 1665.7449 - val_loss: 1640.7393 - val_mae: 1640.7230 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1643.2031 - mae: 1643.1865 - val_loss: 1616.2162 - val_mae: 1616.1982 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1616.7789 - mae: 1616.7604 - val_loss: 1587.7616 - val_mae: 1587.7416 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1587.4453 - mae: 1587.4244 - val_loss: 1555.9867 - val_mae: 1555.9641 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1554.6715 - mae: 1554.6479 - val_loss: 1523.3685 - val_mae: 1523.3431 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1521.3619 - mae: 1521.3351 - val_loss: 1491.8081 - val_mae: 1491.7795 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1489.7101 - mae: 1489.6802 - val_loss: 1461.8317 - val_mae: 1461.7999 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1457.6611 - mae: 1457.6279 - val_loss: 1433.1658 - val_mae: 1433.1307 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1429.0538 - mae: 1429.0172 - val_loss: 1406.0563 - val_mae: 1406.0175 - lr: 0.0010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1399.2789 - mae: 1399.2385 - val_loss: 1379.9989 - val_mae: 1379.9562 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1373.0927 - mae: 1373.0485 - val_loss: 1354.6440 - val_mae: 1354.5974 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1345.7107 - mae: 1345.6625 - val_loss: 1329.2732 - val_mae: 1329.2227 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1318.2328 - mae: 1318.1804 - val_loss: 1303.3904 - val_mae: 1303.3357 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1295.1730 - mae: 1295.1165 - val_loss: 1278.2467 - val_mae: 1278.1876 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1269.9468 - mae: 1269.8857 - val_loss: 1253.9681 - val_mae: 1253.9045 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 2078.4109\n",
      "LV_RMSE_12h: 2353.9182\n",
      "LV_MAE_24h: 335.9684\n",
      "LV_RMSE_24h: 477.3739\n",
      "LV_MAE_48h: 412.7644\n",
      "LV_RMSE_48h: 577.5818\n",
      "LV_MAE_72h: 385.2011\n",
      "LV_RMSE_72h: 525.6752\n",
      "LV_MAE_mean: 803.0862\n",
      "LV_RMSE_mean: 983.6373\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 1302.2596\n",
      "RMSE_12h: 1653.0134\n",
      "MAE_24h: 1306.0518\n",
      "RMSE_24h: 1654.4468\n",
      "MAE_48h: 1318.8837\n",
      "RMSE_48h: 1668.0332\n",
      "MAE_72h: 1352.1637\n",
      "RMSE_72h: 1720.3799\n",
      "MAE_mean: 1319.8397\n",
      "RMSE_mean: 1673.9683\n",
      "\n",
      "=== Station S316259 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1375 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1352, 24, 400) Ytr2: (1352, 4) \n",
      "  Xva3: (197, 24, 400) Yva2: (197, 4) \n",
      "  Xte3: (347, 24, 400) Yte2: (347, 4)\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 3s 66ms/step - loss: 46.0018 - mae: 45.9889 - val_loss: 45.2058 - val_mae: 45.1930 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 42.4161 - mae: 42.4032 - val_loss: 41.0366 - val_mae: 41.0236 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 38.1443 - mae: 38.1312 - val_loss: 36.6367 - val_mae: 36.6232 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 33.7439 - mae: 33.7303 - val_loss: 32.5459 - val_mae: 32.5319 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 29.5315 - mae: 29.5172 - val_loss: 28.7756 - val_mae: 28.7609 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 25.9228 - mae: 25.9077 - val_loss: 25.2013 - val_mae: 25.1858 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 22.0572 - mae: 22.0414 - val_loss: 21.9030 - val_mae: 21.8868 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 19.1879 - mae: 19.1715 - val_loss: 19.4860 - val_mae: 19.4693 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 16.7821 - mae: 16.7652 - val_loss: 17.5996 - val_mae: 17.5824 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 15.4947 - mae: 15.4773 - val_loss: 16.1867 - val_mae: 16.1690 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 14.3092 - mae: 14.2913 - val_loss: 14.9961 - val_mae: 14.9780 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 13.4222 - mae: 13.4039 - val_loss: 13.9664 - val_mae: 13.9478 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 12.6992 - mae: 12.6803 - val_loss: 13.3310 - val_mae: 13.3119 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 12.3774 - mae: 12.3582 - val_loss: 13.0808 - val_mae: 13.0614 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 12.2566 - mae: 12.2371 - val_loss: 12.9387 - val_mae: 12.9192 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 12.1423 - mae: 12.1228 - val_loss: 12.6456 - val_mae: 12.6261 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 11.9375 - mae: 11.9181 - val_loss: 12.6446 - val_mae: 12.6252 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 12.0791 - mae: 12.0597 - val_loss: 12.8547 - val_mae: 12.8353 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 11.9593 - mae: 11.9400 - val_loss: 12.8853 - val_mae: 12.8659 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 11.8320 - mae: 11.8127 - val_loss: 12.8194 - val_mae: 12.8001 - lr: 5.0000e-04\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 73.5014\n",
      "LV_RMSE_12h: 82.6599\n",
      "LV_MAE_24h: 15.5187\n",
      "LV_RMSE_24h: 23.8999\n",
      "LV_MAE_48h: 17.5591\n",
      "LV_RMSE_48h: 26.7728\n",
      "LV_MAE_72h: 17.8357\n",
      "LV_RMSE_72h: 26.8353\n",
      "LV_MAE_mean: 31.1037\n",
      "LV_RMSE_mean: 40.0420\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 15.1381\n",
      "RMSE_12h: 24.4486\n",
      "MAE_24h: 14.6885\n",
      "RMSE_24h: 23.3613\n",
      "MAE_48h: 16.5181\n",
      "RMSE_48h: 26.8261\n",
      "MAE_72h: 17.4673\n",
      "RMSE_72h: 27.8592\n",
      "MAE_mean: 15.9530\n",
      "RMSE_mean: 25.6238\n",
      "\n",
      "=== Station S316315 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1266 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1243, 24, 400) Ytr2: (1243, 4) \n",
      "  Xva3: (181, 24, 400) Yva2: (181, 4) \n",
      "  Xte3: (316, 24, 400) Yte2: (316, 4)\n",
      "Epoch 1/20\n",
      "10/10 [==============================] - 3s 69ms/step - loss: 165.3983 - mae: 165.3853 - val_loss: 167.2039 - val_mae: 167.1909 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 160.6013 - mae: 160.5882 - val_loss: 160.3175 - val_mae: 160.3043 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 152.7066 - mae: 152.6933 - val_loss: 151.4216 - val_mae: 151.4080 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 144.0692 - mae: 144.0554 - val_loss: 142.7242 - val_mae: 142.7100 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 135.7230 - mae: 135.7084 - val_loss: 134.2953 - val_mae: 134.2803 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 127.2977 - mae: 127.2823 - val_loss: 125.9424 - val_mae: 125.9264 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 119.6350 - mae: 119.6185 - val_loss: 118.2436 - val_mae: 118.2264 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 112.7068 - mae: 112.6890 - val_loss: 111.5480 - val_mae: 111.5296 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 107.0182 - mae: 106.9992 - val_loss: 105.8013 - val_mae: 105.7815 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 101.4818 - mae: 101.4615 - val_loss: 100.3665 - val_mae: 100.3455 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 97.9766 - mae: 97.9550 - val_loss: 95.8309 - val_mae: 95.8087 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 94.8273 - mae: 94.8047 - val_loss: 91.7440 - val_mae: 91.7209 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 91.4305 - mae: 91.4069 - val_loss: 88.1421 - val_mae: 88.1181 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 88.9446 - mae: 88.9203 - val_loss: 85.1562 - val_mae: 85.1315 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 86.5575 - mae: 86.5326 - val_loss: 80.7712 - val_mae: 80.7460 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 83.9361 - mae: 83.9107 - val_loss: 77.5035 - val_mae: 77.4780 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 81.4384 - mae: 81.4126 - val_loss: 73.3688 - val_mae: 73.3428 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 78.8755 - mae: 78.8492 - val_loss: 70.4147 - val_mae: 70.3881 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 75.8936 - mae: 75.8667 - val_loss: 66.6975 - val_mae: 66.6703 - lr: 0.0010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/20\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 73.3295 - mae: 73.3020 - val_loss: 63.3845 - val_mae: 63.3565 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 187.5506\n",
      "LV_RMSE_12h: 215.4211\n",
      "LV_MAE_24h: 37.3260\n",
      "LV_RMSE_24h: 54.7778\n",
      "LV_MAE_48h: 42.2943\n",
      "LV_RMSE_48h: 61.1679\n",
      "LV_MAE_72h: 38.3101\n",
      "LV_RMSE_72h: 55.3091\n",
      "LV_MAE_mean: 76.3703\n",
      "LV_RMSE_mean: 96.6690\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 126.2878\n",
      "RMSE_12h: 147.6685\n",
      "MAE_24h: 48.5700\n",
      "RMSE_24h: 60.7781\n",
      "MAE_48h: 49.6982\n",
      "RMSE_48h: 61.7797\n",
      "MAE_72h: 49.7706\n",
      "RMSE_72h: 61.7655\n",
      "MAE_mean: 68.5816\n",
      "RMSE_mean: 82.9980\n",
      "\n",
      "=== Station S316328 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1377 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1354, 24, 400) Ytr2: (1354, 4) \n",
      "  Xva3: (197, 24, 400) Yva2: (197, 4) \n",
      "  Xte3: (348, 24, 400) Yte2: (348, 4)\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 3s 64ms/step - loss: 3887.1377 - mae: 3887.1245 - val_loss: 3878.4194 - val_mae: 3878.4065 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 3880.3962 - mae: 3880.3838 - val_loss: 3868.5452 - val_mae: 3868.5317 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 3868.1292 - mae: 3868.1160 - val_loss: 3853.6396 - val_mae: 3853.6262 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 3851.3525 - mae: 3851.3386 - val_loss: 3834.4233 - val_mae: 3834.4087 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 3830.2175 - mae: 3830.2024 - val_loss: 3810.7302 - val_mae: 3810.7141 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 3803.9900 - mae: 3803.9731 - val_loss: 3781.8594 - val_mae: 3781.8413 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 3772.8413 - mae: 3772.8220 - val_loss: 3747.5891 - val_mae: 3747.5686 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 3735.9905 - mae: 3735.9685 - val_loss: 3707.7246 - val_mae: 3707.7012 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 3694.0640 - mae: 3694.0388 - val_loss: 3662.1909 - val_mae: 3662.1641 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 3645.5303 - mae: 3645.5020 - val_loss: 3610.8276 - val_mae: 3610.7969 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 3592.4526 - mae: 3592.4199 - val_loss: 3553.6455 - val_mae: 3553.6104 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 0s 21ms/step - loss: 3532.4084 - mae: 3532.3711 - val_loss: 3490.5767 - val_mae: 3490.5364 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 3466.5872 - mae: 3466.5444 - val_loss: 3422.5786 - val_mae: 3422.5327 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 3397.3416 - mae: 3397.2927 - val_loss: 3353.2773 - val_mae: 3353.2253 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 3326.8755 - mae: 3326.8206 - val_loss: 3284.7798 - val_mae: 3284.7214 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 3258.9509 - mae: 3258.8896 - val_loss: 3219.3950 - val_mae: 3219.3298 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 3196.5569 - mae: 3196.4890 - val_loss: 3157.9329 - val_mae: 3157.8611 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 3132.7563 - mae: 3132.6816 - val_loss: 3096.6833 - val_mae: 3096.6047 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 3075.6426 - mae: 3075.5605 - val_loss: 3036.9854 - val_mae: 3036.8997 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 3016.3965 - mae: 3016.3074 - val_loss: 2980.4236 - val_mae: 2980.3306 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 3710.8333\n",
      "LV_RMSE_12h: 4177.4233\n",
      "LV_MAE_24h: 601.2874\n",
      "LV_RMSE_24h: 850.6697\n",
      "LV_MAE_48h: 755.3851\n",
      "LV_RMSE_48h: 1086.2172\n",
      "LV_MAE_72h: 630.8477\n",
      "LV_RMSE_72h: 895.6570\n",
      "LV_MAE_mean: 1424.5884\n",
      "LV_RMSE_mean: 1752.4918\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 2805.1096\n",
      "RMSE_12h: 3453.9846\n",
      "MAE_24h: 2873.2424\n",
      "RMSE_24h: 3507.4185\n",
      "MAE_48h: 2887.9944\n",
      "RMSE_48h: 3527.3770\n",
      "MAE_72h: 2839.4709\n",
      "RMSE_72h: 3469.1584\n",
      "MAE_mean: 2851.4543\n",
      "RMSE_mean: 3489.4846\n",
      "\n",
      "=== Station S316329 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1266 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1243, 24, 400) Ytr2: (1243, 4) \n",
      "  Xva3: (181, 24, 400) Yva2: (181, 4) \n",
      "  Xte3: (316, 24, 400) Yte2: (316, 4)\n",
      "Epoch 1/20\n",
      "10/10 [==============================] - 3s 72ms/step - loss: 153.2250 - mae: 153.2123 - val_loss: 150.7789 - val_mae: 150.7662 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 147.5854 - mae: 147.5727 - val_loss: 142.7750 - val_mae: 142.7621 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 138.4704 - mae: 138.4574 - val_loss: 132.8566 - val_mae: 132.8434 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 128.7120 - mae: 128.6985 - val_loss: 123.4216 - val_mae: 123.4078 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 119.8288 - mae: 119.8146 - val_loss: 114.7675 - val_mae: 114.7528 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 111.5669 - mae: 111.5519 - val_loss: 106.8375 - val_mae: 106.8219 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 104.3668 - mae: 104.3507 - val_loss: 99.4778 - val_mae: 99.4611 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 98.0083 - mae: 97.9911 - val_loss: 93.7013 - val_mae: 93.6834 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 93.6433 - mae: 93.6250 - val_loss: 90.1475 - val_mae: 90.1285 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 90.5578 - mae: 90.5384 - val_loss: 88.2405 - val_mae: 88.2206 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 89.1470 - mae: 89.1268 - val_loss: 85.8284 - val_mae: 85.8079 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 85.8452 - mae: 85.8244 - val_loss: 79.5091 - val_mae: 79.4881 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 80.7555 - mae: 80.7342 - val_loss: 72.7591 - val_mae: 72.7374 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 75.8553 - mae: 75.8332 - val_loss: 66.6202 - val_mae: 66.5976 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 71.8438 - mae: 71.8208 - val_loss: 60.6002 - val_mae: 60.5768 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 69.2311 - mae: 69.2074 - val_loss: 57.9605 - val_mae: 57.9364 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 67.1826 - mae: 67.1584 - val_loss: 55.8387 - val_mae: 55.8143 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 65.9017 - mae: 65.8771 - val_loss: 54.6716 - val_mae: 54.6467 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 64.6073 - mae: 64.5822 - val_loss: 52.7851 - val_mae: 52.7597 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 63.0566 - mae: 63.0311 - val_loss: 51.8261 - val_mae: 51.8002 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 157.3291\n",
      "LV_RMSE_12h: 176.9902\n",
      "LV_MAE_24h: 33.4778\n",
      "LV_RMSE_24h: 50.0810\n",
      "LV_MAE_48h: 41.7816\n",
      "LV_RMSE_48h: 61.1671\n",
      "LV_MAE_72h: 34.0760\n",
      "LV_RMSE_72h: 51.2624\n",
      "LV_MAE_mean: 66.6661\n",
      "LV_RMSE_mean: 84.8752\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 101.0898\n",
      "RMSE_12h: 121.6810\n",
      "MAE_24h: 33.3687\n",
      "RMSE_24h: 50.5507\n",
      "MAE_48h: 32.0338\n",
      "RMSE_48h: 48.5157\n",
      "MAE_72h: 30.8675\n",
      "RMSE_72h: 46.8192\n",
      "MAE_mean: 49.3399\n",
      "RMSE_mean: 66.8917\n",
      "\n",
      "=== Station S316399 ===\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1377 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1354, 24, 400) Ytr2: (1354, 4) \n",
      "  Xva3: (197, 24, 400) Yva2: (197, 4) \n",
      "  Xte3: (348, 24, 400) Yte2: (348, 4)\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 3s 65ms/step - loss: 1896.2479 - mae: 1896.2352 - val_loss: 1866.5134 - val_mae: 1866.5007 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1892.2644 - mae: 1892.2515 - val_loss: 1860.5103 - val_mae: 1860.4974 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 1884.6384 - mae: 1884.6254 - val_loss: 1851.1058 - val_mae: 1851.0927 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1874.1290 - mae: 1874.1157 - val_loss: 1838.9122 - val_mae: 1838.8984 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1860.3872 - mae: 1860.3732 - val_loss: 1823.3258 - val_mae: 1823.3110 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 1843.0288 - mae: 1843.0134 - val_loss: 1803.8317 - val_mae: 1803.8157 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1822.2278 - mae: 1822.2111 - val_loss: 1780.5621 - val_mae: 1780.5444 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1796.9758 - mae: 1796.9570 - val_loss: 1753.3157 - val_mae: 1753.2960 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1768.0487 - mae: 1768.0281 - val_loss: 1722.0074 - val_mae: 1721.9852 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 1734.4370 - mae: 1734.4135 - val_loss: 1686.5610 - val_mae: 1686.5359 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1697.5371 - mae: 1697.5107 - val_loss: 1646.9243 - val_mae: 1646.8960 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1656.6549 - mae: 1656.6252 - val_loss: 1603.1368 - val_mae: 1603.1049 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1611.3320 - mae: 1611.2983 - val_loss: 1555.4252 - val_mae: 1555.3893 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1561.9924 - mae: 1561.9547 - val_loss: 1504.7988 - val_mae: 1504.7585 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 1509.6113 - mae: 1509.5691 - val_loss: 1453.6536 - val_mae: 1453.6085 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1460.0267 - mae: 1459.9795 - val_loss: 1404.5769 - val_mae: 1404.5270 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1411.9320 - mae: 1411.8798 - val_loss: 1358.9968 - val_mae: 1358.9419 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1365.4115 - mae: 1365.3544 - val_loss: 1316.0486 - val_mae: 1315.9885 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1324.0941 - mae: 1324.0319 - val_loss: 1274.8358 - val_mae: 1274.7706 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1286.8812 - mae: 1286.8138 - val_loss: 1235.7954 - val_mae: 1235.7251 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 1519.0403\n",
      "LV_RMSE_12h: 1685.4423\n",
      "LV_MAE_24h: 231.6954\n",
      "LV_RMSE_24h: 342.6130\n",
      "LV_MAE_48h: 289.8994\n",
      "LV_RMSE_48h: 432.0157\n",
      "LV_MAE_72h: 241.7529\n",
      "LV_RMSE_72h: 356.2535\n",
      "LV_MAE_mean: 570.5970\n",
      "LV_RMSE_mean: 704.0811\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 1184.2838\n",
      "RMSE_12h: 1419.1064\n",
      "MAE_24h: 1234.9490\n",
      "RMSE_24h: 1466.1217\n",
      "MAE_48h: 1193.0039\n",
      "RMSE_48h: 1415.1960\n",
      "MAE_72h: 1194.7903\n",
      "RMSE_72h: 1417.5424\n",
      "MAE_mean: 1201.7568\n",
      "RMSE_mean: 1429.4916\n",
      "\n",
      "=== Station S316414 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1377 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1354, 24, 400) Ytr2: (1354, 4) \n",
      "  Xva3: (197, 24, 400) Yva2: (197, 4) \n",
      "  Xte3: (348, 24, 400) Yte2: (348, 4)\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 3s 64ms/step - loss: 3028.0791 - mae: 3028.0669 - val_loss: 3072.5266 - val_mae: 3072.5137 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 3022.5947 - mae: 3022.5820 - val_loss: 3064.2476 - val_mae: 3064.2341 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 3012.1543 - mae: 3012.1414 - val_loss: 3051.3508 - val_mae: 3051.3369 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 2997.6245 - mae: 2997.6106 - val_loss: 3034.2397 - val_mae: 3034.2253 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 2978.3164 - mae: 2978.3013 - val_loss: 3012.4277 - val_mae: 3012.4111 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 2954.0557 - mae: 2954.0388 - val_loss: 2985.3157 - val_mae: 2985.2974 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 2924.9128 - mae: 2924.8933 - val_loss: 2952.7217 - val_mae: 2952.7009 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 2889.6519 - mae: 2889.6299 - val_loss: 2914.4531 - val_mae: 2914.4292 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 2849.1746 - mae: 2849.1492 - val_loss: 2870.3630 - val_mae: 2870.3354 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 2801.7192 - mae: 2801.6897 - val_loss: 2820.3921 - val_mae: 2820.3604 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 2750.2761 - mae: 2750.2427 - val_loss: 2764.9248 - val_mae: 2764.8884 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 2692.0283 - mae: 2691.9897 - val_loss: 2705.8015 - val_mae: 2705.7598 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 2632.8730 - mae: 2632.8291 - val_loss: 2646.6746 - val_mae: 2646.6274 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 2573.1030 - mae: 2573.0530 - val_loss: 2590.0427 - val_mae: 2589.9897 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 2515.5398 - mae: 2515.4841 - val_loss: 2535.1194 - val_mae: 2535.0601 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 2460.1162 - mae: 2460.0544 - val_loss: 2483.1111 - val_mae: 2483.0457 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 2407.1526 - mae: 2407.0840 - val_loss: 2432.5537 - val_mae: 2432.4817 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 2353.0845 - mae: 2353.0095 - val_loss: 2381.1504 - val_mae: 2381.0715 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 2305.0203 - mae: 2304.9385 - val_loss: 2330.1196 - val_mae: 2330.0337 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 2253.4851 - mae: 2253.3962 - val_loss: 2281.8643 - val_mae: 2281.7712 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 3119.0662\n",
      "LV_RMSE_12h: 3422.5554\n",
      "LV_MAE_24h: 494.2414\n",
      "LV_RMSE_24h: 750.1166\n",
      "LV_MAE_48h: 622.9741\n",
      "LV_RMSE_48h: 970.5306\n",
      "LV_MAE_72h: 533.0316\n",
      "LV_RMSE_72h: 808.1335\n",
      "LV_MAE_mean: 1192.3284\n",
      "LV_RMSE_mean: 1487.8340\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 2099.3728\n",
      "RMSE_12h: 2594.6875\n",
      "MAE_24h: 2177.7834\n",
      "RMSE_24h: 2687.1523\n",
      "MAE_48h: 2207.9685\n",
      "RMSE_48h: 2723.4744\n",
      "MAE_72h: 2218.5405\n",
      "RMSE_72h: 2736.5002\n",
      "MAE_mean: 2175.9165\n",
      "RMSE_mean: 2685.4536\n",
      "\n",
      "=== Station S316484 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1131 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1108, 24, 400) Ytr2: (1108, 4) \n",
      "  Xva3: (162, 24, 400) Yva2: (162, 4) \n",
      "  Xte3: (277, 24, 400) Yte2: (277, 4)\n",
      "Epoch 1/20\n",
      "9/9 [==============================] - 3s 79ms/step - loss: 310.7332 - mae: 310.7206 - val_loss: 291.3452 - val_mae: 291.3326 - lr: 0.0010\n",
      "Epoch 2/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 15ms/step - loss: 306.7944 - mae: 306.7817 - val_loss: 285.7519 - val_mae: 285.7390 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 299.8675 - mae: 299.8546 - val_loss: 277.0990 - val_mae: 277.0859 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 290.1429 - mae: 290.1297 - val_loss: 266.3104 - val_mae: 266.2969 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 278.4966 - mae: 278.4828 - val_loss: 254.3974 - val_mae: 254.3831 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 265.7532 - mae: 265.7386 - val_loss: 241.7171 - val_mae: 241.7019 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 252.2421 - mae: 252.2264 - val_loss: 228.4434 - val_mae: 228.4270 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 237.5180 - mae: 237.5010 - val_loss: 214.8947 - val_mae: 214.8769 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 224.0478 - mae: 224.0294 - val_loss: 201.3854 - val_mae: 201.3661 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 210.5412 - mae: 210.5212 - val_loss: 189.1025 - val_mae: 189.0815 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 199.2695 - mae: 199.2478 - val_loss: 178.8372 - val_mae: 178.8145 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 188.9442 - mae: 188.9208 - val_loss: 170.5320 - val_mae: 170.5076 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 181.1210 - mae: 181.0958 - val_loss: 164.2679 - val_mae: 164.2418 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "9/9 [==============================] - 0s 17ms/step - loss: 174.8152 - mae: 174.7885 - val_loss: 159.9629 - val_mae: 159.9354 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 169.4542 - mae: 169.4261 - val_loss: 153.4785 - val_mae: 153.4497 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 161.8250 - mae: 161.7957 - val_loss: 144.7341 - val_mae: 144.7040 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 154.1086 - mae: 154.0780 - val_loss: 138.7422 - val_mae: 138.7109 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 147.8595 - mae: 147.8275 - val_loss: 132.6099 - val_mae: 132.5770 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 141.0118 - mae: 140.9783 - val_loss: 126.5538 - val_mae: 126.5195 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 135.5133 - mae: 135.4783 - val_loss: 121.5000 - val_mae: 121.4641 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 298.9170\n",
      "LV_RMSE_12h: 343.6152\n",
      "LV_MAE_24h: 66.2852\n",
      "LV_RMSE_24h: 97.5439\n",
      "LV_MAE_48h: 78.3249\n",
      "LV_RMSE_48h: 111.3382\n",
      "LV_MAE_72h: 68.7040\n",
      "LV_RMSE_72h: 98.0201\n",
      "LV_MAE_mean: 128.0578\n",
      "LV_RMSE_mean: 162.6293\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 203.7240\n",
      "RMSE_12h: 241.7715\n",
      "MAE_24h: 100.1091\n",
      "RMSE_24h: 124.6982\n",
      "MAE_48h: 99.0638\n",
      "RMSE_48h: 124.7950\n",
      "MAE_72h: 94.8115\n",
      "RMSE_72h: 119.2992\n",
      "MAE_mean: 124.4271\n",
      "RMSE_mean: 152.6410\n",
      "\n",
      "=== Station S317089 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1376 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1353, 24, 400) Ytr2: (1353, 4) \n",
      "  Xva3: (197, 24, 400) Yva2: (197, 4) \n",
      "  Xte3: (348, 24, 400) Yte2: (348, 4)\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 3s 66ms/step - loss: 266.3735 - mae: 266.3609 - val_loss: 265.4042 - val_mae: 265.3916 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 260.5464 - mae: 260.5337 - val_loss: 256.6432 - val_mae: 256.6303 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 250.0077 - mae: 249.9946 - val_loss: 244.4343 - val_mae: 244.4209 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 237.5559 - mae: 237.5422 - val_loss: 231.6995 - val_mae: 231.6852 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 225.4100 - mae: 225.3953 - val_loss: 218.9534 - val_mae: 218.9380 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 213.9442 - mae: 213.9283 - val_loss: 207.1221 - val_mae: 207.1054 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 203.6462 - mae: 203.6289 - val_loss: 196.5833 - val_mae: 196.5652 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 193.8424 - mae: 193.8235 - val_loss: 186.4591 - val_mae: 186.4393 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 185.7517 - mae: 185.7311 - val_loss: 177.4644 - val_mae: 177.4429 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 177.9518 - mae: 177.9296 - val_loss: 169.9567 - val_mae: 169.9335 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 171.9144 - mae: 171.8905 - val_loss: 163.0232 - val_mae: 162.9984 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 165.0299 - mae: 165.0044 - val_loss: 154.6202 - val_mae: 154.5940 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 155.7106 - mae: 155.6836 - val_loss: 145.2404 - val_mae: 145.2125 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 144.2657 - mae: 144.2370 - val_loss: 132.9849 - val_mae: 132.9550 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 132.0575 - mae: 132.0266 - val_loss: 120.8806 - val_mae: 120.8484 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 121.2052 - mae: 121.1720 - val_loss: 111.3356 - val_mae: 111.3010 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 112.7572 - mae: 112.7216 - val_loss: 103.6250 - val_mae: 103.5881 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 106.6585 - mae: 106.6207 - val_loss: 99.0917 - val_mae: 99.0528 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 100.9137 - mae: 100.8740 - val_loss: 95.0845 - val_mae: 95.0438 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 98.4674 - mae: 98.4261 - val_loss: 93.1571 - val_mae: 93.1151 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 297.5575\n",
      "LV_RMSE_12h: 326.0129\n",
      "LV_MAE_24h: 66.8305\n",
      "LV_RMSE_24h: 95.2057\n",
      "LV_MAE_48h: 84.0948\n",
      "LV_RMSE_48h: 116.2838\n",
      "LV_MAE_72h: 72.7126\n",
      "LV_RMSE_72h: 103.1561\n",
      "LV_MAE_mean: 130.2989\n",
      "LV_RMSE_mean: 160.1646\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 208.6136\n",
      "RMSE_12h: 255.2776\n",
      "MAE_24h: 59.0384\n",
      "RMSE_24h: 84.6870\n",
      "MAE_48h: 55.9407\n",
      "RMSE_48h: 82.0495\n",
      "MAE_72h: 59.0845\n",
      "RMSE_72h: 84.1736\n",
      "MAE_mean: 95.6693\n",
      "RMSE_mean: 126.5469\n",
      "\n",
      "=== Station S317791 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1377 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1354, 24, 400) Ytr2: (1354, 4) \n",
      "  Xva3: (197, 24, 400) Yva2: (197, 4) \n",
      "  Xte3: (348, 24, 400) Yte2: (348, 4)\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 3s 66ms/step - loss: 580.2635 - mae: 580.2507 - val_loss: 466.3676 - val_mae: 466.3548 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 574.1155 - mae: 574.1026 - val_loss: 457.6185 - val_mae: 457.6053 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 563.6743 - mae: 563.6609 - val_loss: 445.3945 - val_mae: 445.3809 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 550.2064 - mae: 550.1923 - val_loss: 429.7715 - val_mae: 429.7570 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 532.6567 - mae: 532.6417 - val_loss: 410.3436 - val_mae: 410.3278 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 511.8010 - mae: 511.7845 - val_loss: 387.6992 - val_mae: 387.6818 - lr: 0.0010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 488.2678 - mae: 488.2496 - val_loss: 364.1516 - val_mae: 364.1324 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 463.2680 - mae: 463.2477 - val_loss: 342.5645 - val_mae: 342.5429 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 440.8515 - mae: 440.8289 - val_loss: 324.1154 - val_mae: 324.0914 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 420.1237 - mae: 420.0986 - val_loss: 308.2867 - val_mae: 308.2603 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 402.1974 - mae: 402.1699 - val_loss: 293.9971 - val_mae: 293.9681 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 384.5186 - mae: 384.4885 - val_loss: 282.0681 - val_mae: 282.0365 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 370.3840 - mae: 370.3512 - val_loss: 272.5811 - val_mae: 272.5467 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 356.4593 - mae: 356.4237 - val_loss: 265.7918 - val_mae: 265.7547 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 345.1531 - mae: 345.1148 - val_loss: 260.7233 - val_mae: 260.6836 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 334.7659 - mae: 334.7251 - val_loss: 254.4156 - val_mae: 254.3734 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 323.7255 - mae: 323.6823 - val_loss: 246.2254 - val_mae: 246.1808 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 312.8630 - mae: 312.8174 - val_loss: 238.0045 - val_mae: 237.9576 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 302.4747 - mae: 302.4266 - val_loss: 230.7598 - val_mae: 230.7104 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 292.6419 - mae: 292.5915 - val_loss: 223.0694 - val_mae: 223.0177 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 709.0057\n",
      "LV_RMSE_12h: 864.5609\n",
      "LV_MAE_24h: 265.2874\n",
      "LV_RMSE_24h: 374.3725\n",
      "LV_MAE_48h: 309.0115\n",
      "LV_RMSE_48h: 413.5822\n",
      "LV_MAE_72h: 276.3218\n",
      "LV_RMSE_72h: 386.9136\n",
      "LV_MAE_mean: 389.9066\n",
      "LV_RMSE_mean: 509.8573\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 472.5897\n",
      "RMSE_12h: 624.0356\n",
      "MAE_24h: 319.7302\n",
      "RMSE_24h: 465.2226\n",
      "MAE_48h: 355.0574\n",
      "RMSE_48h: 525.9613\n",
      "MAE_72h: 357.7000\n",
      "RMSE_72h: 526.8538\n",
      "MAE_mean: 376.2693\n",
      "RMSE_mean: 535.5184\n",
      "\n",
      "=== Station S317796 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1092 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1069, 24, 400) Ytr2: (1069, 4) \n",
      "  Xva3: (157, 24, 400) Yva2: (157, 4) \n",
      "  Xte3: (265, 24, 400) Yte2: (265, 4)\n",
      "Epoch 1/20\n",
      "9/9 [==============================] - 3s 79ms/step - loss: 24.9597 - mae: 24.9469 - val_loss: 25.9597 - val_mae: 25.9468 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 22.2928 - mae: 22.2798 - val_loss: 23.4445 - val_mae: 23.4314 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 19.6383 - mae: 19.6251 - val_loss: 20.7811 - val_mae: 20.7678 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 17.1944 - mae: 17.1809 - val_loss: 17.9227 - val_mae: 17.9089 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 14.8710 - mae: 14.8570 - val_loss: 14.8509 - val_mae: 14.8367 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 12.9363 - mae: 12.9219 - val_loss: 12.3690 - val_mae: 12.3544 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 11.8236 - mae: 11.8088 - val_loss: 11.3370 - val_mae: 11.3220 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 11.0352 - mae: 11.0201 - val_loss: 10.6290 - val_mae: 10.6138 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 10.5436 - mae: 10.5282 - val_loss: 10.0719 - val_mae: 10.0564 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 10.2533 - mae: 10.2378 - val_loss: 9.7430 - val_mae: 9.7275 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 10.2808 - mae: 10.2653 - val_loss: 10.2255 - val_mae: 10.2100 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 10.0714 - mae: 10.0559 - val_loss: 10.0421 - val_mae: 10.0266 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 10.0917 - mae: 10.0762 - val_loss: 9.9807 - val_mae: 9.9652 - lr: 5.0000e-04\n",
      "Epoch 14/20\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 10.0707 - mae: 10.0553 - val_loss: 10.0734 - val_mae: 10.0579 - lr: 5.0000e-04\n",
      "Epoch 15/20\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 9.9709 - mae: 9.9555 - val_loss: 9.9359 - val_mae: 9.9204 - lr: 2.5000e-04\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 50.6906\n",
      "LV_RMSE_12h: 60.2019\n",
      "LV_MAE_24h: 14.3434\n",
      "LV_RMSE_24h: 23.4196\n",
      "LV_MAE_48h: 17.8943\n",
      "LV_RMSE_48h: 28.7899\n",
      "LV_MAE_72h: 20.7811\n",
      "LV_RMSE_72h: 32.8125\n",
      "LV_MAE_mean: 25.9274\n",
      "LV_RMSE_mean: 36.3060\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 16.1838\n",
      "RMSE_12h: 27.3279\n",
      "MAE_24h: 17.5750\n",
      "RMSE_24h: 30.1076\n",
      "MAE_48h: 22.5662\n",
      "RMSE_48h: 38.0323\n",
      "MAE_72h: 26.7574\n",
      "RMSE_72h: 41.9213\n",
      "MAE_mean: 20.7706\n",
      "RMSE_mean: 34.3473\n",
      "\n",
      "=== Station S317802 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1377 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1354, 24, 400) Ytr2: (1354, 4) \n",
      "  Xva3: (197, 24, 400) Yva2: (197, 4) \n",
      "  Xte3: (348, 24, 400) Yte2: (348, 4)\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 3s 67ms/step - loss: 1398.7677 - mae: 1398.7551 - val_loss: 1311.4943 - val_mae: 1311.4816 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 1392.6132 - mae: 1392.6005 - val_loss: 1302.8525 - val_mae: 1302.8396 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1382.1881 - mae: 1382.1750 - val_loss: 1290.5907 - val_mae: 1290.5773 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 1368.7823 - mae: 1368.7688 - val_loss: 1274.7242 - val_mae: 1274.7102 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1350.6937 - mae: 1350.6792 - val_loss: 1254.6327 - val_mae: 1254.6173 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1328.4866 - mae: 1328.4703 - val_loss: 1230.1183 - val_mae: 1230.1012 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1302.4631 - mae: 1302.4453 - val_loss: 1200.9972 - val_mae: 1200.9780 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1271.1217 - mae: 1271.1017 - val_loss: 1167.0756 - val_mae: 1167.0538 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1234.9199 - mae: 1234.8971 - val_loss: 1128.2848 - val_mae: 1128.2603 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1193.8760 - mae: 1193.8500 - val_loss: 1085.0333 - val_mae: 1085.0054 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 1150.0721 - mae: 1150.0426 - val_loss: 1040.0953 - val_mae: 1040.0636 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1104.7339 - mae: 1104.7002 - val_loss: 998.2336 - val_mae: 998.1978 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1062.3287 - mae: 1062.2913 - val_loss: 961.0715 - val_mae: 961.0315 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1025.3042 - mae: 1025.2623 - val_loss: 927.7071 - val_mae: 927.6628 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 988.1539 - mae: 988.1077 - val_loss: 896.1610 - val_mae: 896.1123 - lr: 0.0010\n",
      "Epoch 16/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 13ms/step - loss: 958.1560 - mae: 958.1054 - val_loss: 866.4534 - val_mae: 866.4004 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 929.7541 - mae: 929.6990 - val_loss: 838.6199 - val_mae: 838.5624 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 897.9672 - mae: 897.9078 - val_loss: 813.3745 - val_mae: 813.3125 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 874.5013 - mae: 874.4373 - val_loss: 790.1782 - val_mae: 790.1117 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 850.9487 - mae: 850.8802 - val_loss: 767.5546 - val_mae: 767.4836 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 1324.9626\n",
      "LV_RMSE_12h: 1479.5287\n",
      "LV_MAE_24h: 247.1236\n",
      "LV_RMSE_24h: 353.7973\n",
      "LV_MAE_48h: 327.1121\n",
      "LV_RMSE_48h: 454.8682\n",
      "LV_MAE_72h: 318.6293\n",
      "LV_RMSE_72h: 446.9412\n",
      "LV_MAE_mean: 554.4569\n",
      "LV_RMSE_mean: 683.7838\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 784.4186\n",
      "RMSE_12h: 959.5781\n",
      "MAE_24h: 793.6671\n",
      "RMSE_24h: 979.0817\n",
      "MAE_48h: 818.0086\n",
      "RMSE_48h: 1018.5652\n",
      "MAE_72h: 797.3745\n",
      "RMSE_72h: 989.4785\n",
      "MAE_mean: 798.3672\n",
      "RMSE_mean: 986.6759\n",
      "\n",
      "=== Station S317852 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1377 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1354, 24, 400) Ytr2: (1354, 4) \n",
      "  Xva3: (197, 24, 400) Yva2: (197, 4) \n",
      "  Xte3: (348, 24, 400) Yte2: (348, 4)\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 3s 64ms/step - loss: 3025.0098 - mae: 3024.9968 - val_loss: 3049.2849 - val_mae: 3049.2722 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 3019.9272 - mae: 3019.9143 - val_loss: 3042.2598 - val_mae: 3042.2468 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 3010.9692 - mae: 3010.9565 - val_loss: 3031.1174 - val_mae: 3031.1040 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 2998.5664 - mae: 2998.5522 - val_loss: 3016.6621 - val_mae: 3016.6475 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 2982.0457 - mae: 2982.0308 - val_loss: 2998.1694 - val_mae: 2998.1538 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 2961.7952 - mae: 2961.7786 - val_loss: 2975.2080 - val_mae: 2975.1909 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 2937.0208 - mae: 2937.0027 - val_loss: 2947.4329 - val_mae: 2947.4138 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 2906.6931 - mae: 2906.6726 - val_loss: 2914.9089 - val_mae: 2914.8870 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 2872.1602 - mae: 2872.1367 - val_loss: 2877.4451 - val_mae: 2877.4202 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 2832.5420 - mae: 2832.5159 - val_loss: 2835.0388 - val_mae: 2835.0105 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 2788.1704 - mae: 2788.1406 - val_loss: 2788.1155 - val_mae: 2788.0830 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 2739.8896 - mae: 2739.8557 - val_loss: 2737.9241 - val_mae: 2737.8877 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 2691.2820 - mae: 2691.2432 - val_loss: 2687.0105 - val_mae: 2686.9692 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 2640.7598 - mae: 2640.7163 - val_loss: 2637.0537 - val_mae: 2637.0073 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 2589.9836 - mae: 2589.9353 - val_loss: 2586.9685 - val_mae: 2586.9170 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 2541.2239 - mae: 2541.1702 - val_loss: 2539.2476 - val_mae: 2539.1904 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 2495.2009 - mae: 2495.1414 - val_loss: 2494.2402 - val_mae: 2494.1772 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 2446.7019 - mae: 2446.6365 - val_loss: 2448.9934 - val_mae: 2448.9248 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 2402.5798 - mae: 2402.5088 - val_loss: 2402.1685 - val_mae: 2402.0940 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 2359.5200 - mae: 2359.4426 - val_loss: 2354.8728 - val_mae: 2354.7915 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 3106.3477\n",
      "LV_RMSE_12h: 3500.8123\n",
      "LV_MAE_24h: 522.9626\n",
      "LV_RMSE_24h: 773.7491\n",
      "LV_MAE_48h: 691.2960\n",
      "LV_RMSE_48h: 1013.2727\n",
      "LV_MAE_72h: 581.0374\n",
      "LV_RMSE_72h: 864.5178\n",
      "LV_MAE_mean: 1225.4109\n",
      "LV_RMSE_mean: 1538.0879\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 2229.5037\n",
      "RMSE_12h: 2806.9355\n",
      "MAE_24h: 2246.0938\n",
      "RMSE_24h: 2800.9065\n",
      "MAE_48h: 2270.8005\n",
      "RMSE_48h: 2834.2097\n",
      "MAE_72h: 2250.3757\n",
      "RMSE_72h: 2811.9939\n",
      "MAE_mean: 2249.1936\n",
      "RMSE_mean: 2813.5115\n",
      "\n",
      "=== Station S317909 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1377 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1354, 24, 400) Ytr2: (1354, 4) \n",
      "  Xva3: (197, 24, 400) Yva2: (197, 4) \n",
      "  Xte3: (348, 24, 400) Yte2: (348, 4)\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 3s 64ms/step - loss: 831.2191 - mae: 831.2062 - val_loss: 827.7336 - val_mae: 827.7208 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 823.3190 - mae: 823.3060 - val_loss: 816.6574 - val_mae: 816.6443 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 810.4507 - mae: 810.4372 - val_loss: 801.8326 - val_mae: 801.8187 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 794.6091 - mae: 794.5948 - val_loss: 784.5493 - val_mae: 784.5342 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 776.4083 - mae: 776.3928 - val_loss: 766.1786 - val_mae: 766.1622 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 757.5162 - mae: 757.4989 - val_loss: 746.9633 - val_mae: 746.9450 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 737.5403 - mae: 737.5212 - val_loss: 726.9240 - val_mae: 726.9036 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 716.6016 - mae: 716.5801 - val_loss: 705.6584 - val_mae: 705.6355 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 0s 22ms/step - loss: 695.1259 - mae: 695.1016 - val_loss: 682.8760 - val_mae: 682.8501 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 671.9501 - mae: 671.9229 - val_loss: 658.4263 - val_mae: 658.3972 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 647.8493 - mae: 647.8185 - val_loss: 634.3272 - val_mae: 634.2944 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 623.9048 - mae: 623.8702 - val_loss: 612.8454 - val_mae: 612.8087 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 0s 20ms/step - loss: 602.2680 - mae: 602.2294 - val_loss: 592.0027 - val_mae: 591.9619 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 579.5558 - mae: 579.5132 - val_loss: 565.9636 - val_mae: 565.9187 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 551.0206 - mae: 550.9738 - val_loss: 537.6160 - val_mae: 537.5667 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 524.6934 - mae: 524.6419 - val_loss: 508.7896 - val_mae: 508.7354 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 495.0977 - mae: 495.0411 - val_loss: 479.9597 - val_mae: 479.9001 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 465.3146 - mae: 465.2527 - val_loss: 453.4964 - val_mae: 453.4313 - lr: 0.0010\n",
      "Epoch 19/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 13ms/step - loss: 441.4004 - mae: 441.3327 - val_loss: 428.3470 - val_mae: 428.2761 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 416.9006 - mae: 416.8271 - val_loss: 404.3527 - val_mae: 404.2759 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 924.5488\n",
      "LV_RMSE_12h: 1031.3285\n",
      "LV_MAE_24h: 165.6236\n",
      "LV_RMSE_24h: 243.4492\n",
      "LV_MAE_48h: 219.0690\n",
      "LV_RMSE_48h: 303.9532\n",
      "LV_MAE_72h: 196.5345\n",
      "LV_RMSE_72h: 281.7388\n",
      "LV_MAE_mean: 376.4440\n",
      "LV_RMSE_mean: 465.1174\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 638.4092\n",
      "RMSE_12h: 737.2656\n",
      "MAE_24h: 318.4491\n",
      "RMSE_24h: 392.0460\n",
      "MAE_48h: 298.4495\n",
      "RMSE_48h: 367.2531\n",
      "MAE_72h: 306.2605\n",
      "RMSE_72h: 378.2314\n",
      "MAE_mean: 390.3921\n",
      "RMSE_mean: 468.6990\n",
      "\n",
      "=== Station S317947 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1377 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1354, 24, 400) Ytr2: (1354, 4) \n",
      "  Xva3: (197, 24, 400) Yva2: (197, 4) \n",
      "  Xte3: (348, 24, 400) Yte2: (348, 4)\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 3s 65ms/step - loss: 642.4285 - mae: 642.4156 - val_loss: 633.1481 - val_mae: 633.1354 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 636.6846 - mae: 636.6718 - val_loss: 624.8241 - val_mae: 624.8111 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 626.9848 - mae: 626.9716 - val_loss: 613.7075 - val_mae: 613.6940 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 615.4777 - mae: 615.4640 - val_loss: 601.0756 - val_mae: 601.0613 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 602.2391 - mae: 602.2244 - val_loss: 587.6778 - val_mae: 587.6624 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 588.7214 - mae: 588.7054 - val_loss: 573.6542 - val_mae: 573.6375 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 574.6238 - mae: 574.6064 - val_loss: 559.0445 - val_mae: 559.0261 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 559.4368 - mae: 559.4175 - val_loss: 543.2354 - val_mae: 543.2151 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 543.6035 - mae: 543.5823 - val_loss: 526.1398 - val_mae: 526.1171 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 525.4369 - mae: 525.4133 - val_loss: 508.9417 - val_mae: 508.9166 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 509.2279 - mae: 509.2017 - val_loss: 492.7762 - val_mae: 492.7484 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 492.0699 - mae: 492.0408 - val_loss: 477.0564 - val_mae: 477.0256 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 476.8553 - mae: 476.8231 - val_loss: 461.4273 - val_mae: 461.3935 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 458.0034 - mae: 457.9681 - val_loss: 441.0799 - val_mae: 441.0427 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 436.6058 - mae: 436.5671 - val_loss: 418.2635 - val_mae: 418.2227 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 414.7108 - mae: 414.6683 - val_loss: 395.6234 - val_mae: 395.5786 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 392.0533 - mae: 392.0066 - val_loss: 372.8793 - val_mae: 372.8301 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 368.1128 - mae: 368.0616 - val_loss: 352.4160 - val_mae: 352.3622 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 348.8039 - mae: 348.7480 - val_loss: 331.5955 - val_mae: 331.5368 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 327.5516 - mae: 327.4907 - val_loss: 310.2858 - val_mae: 310.2220 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 762.1494\n",
      "LV_RMSE_12h: 862.6317\n",
      "LV_MAE_24h: 130.1006\n",
      "LV_RMSE_24h: 186.5421\n",
      "LV_MAE_48h: 171.0000\n",
      "LV_RMSE_48h: 232.5039\n",
      "LV_MAE_72h: 153.9828\n",
      "LV_RMSE_72h: 215.9600\n",
      "LV_MAE_mean: 304.3082\n",
      "LV_RMSE_mean: 374.4094\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 519.6080\n",
      "RMSE_12h: 613.3422\n",
      "MAE_24h: 245.6904\n",
      "RMSE_24h: 319.6493\n",
      "MAE_48h: 248.7048\n",
      "RMSE_48h: 323.0678\n",
      "MAE_72h: 246.8732\n",
      "RMSE_72h: 317.2188\n",
      "MAE_mean: 315.2191\n",
      "RMSE_mean: 393.3195\n",
      "\n",
      "=== Station S318135 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1377 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1354, 24, 400) Ytr2: (1354, 4) \n",
      "  Xva3: (197, 24, 400) Yva2: (197, 4) \n",
      "  Xte3: (348, 24, 400) Yte2: (348, 4)\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 3s 65ms/step - loss: 831.5524 - mae: 831.5397 - val_loss: 838.6004 - val_mae: 838.5877 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 825.1729 - mae: 825.1602 - val_loss: 829.4062 - val_mae: 829.3932 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 814.1970 - mae: 814.1839 - val_loss: 816.6110 - val_mae: 816.5977 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 799.8920 - mae: 799.8781 - val_loss: 799.8018 - val_mae: 799.7874 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 780.7174 - mae: 780.7026 - val_loss: 778.3206 - val_mae: 778.3049 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 757.0726 - mae: 757.0562 - val_loss: 752.3187 - val_mae: 752.3012 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 730.6035 - mae: 730.5850 - val_loss: 724.7338 - val_mae: 724.7141 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 703.5720 - mae: 703.5513 - val_loss: 698.8223 - val_mae: 698.8002 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 678.4213 - mae: 678.3979 - val_loss: 673.3698 - val_mae: 673.3448 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 653.5322 - mae: 653.5061 - val_loss: 648.3631 - val_mae: 648.3353 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 629.3622 - mae: 629.3330 - val_loss: 623.9567 - val_mae: 623.9257 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 606.1137 - mae: 606.0812 - val_loss: 600.7023 - val_mae: 600.6680 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 582.5698 - mae: 582.5338 - val_loss: 576.0660 - val_mae: 576.0281 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 556.7970 - mae: 556.7573 - val_loss: 547.5668 - val_mae: 547.5249 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 526.9922 - mae: 526.9485 - val_loss: 515.7722 - val_mae: 515.7261 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 496.1173 - mae: 496.0692 - val_loss: 481.1375 - val_mae: 481.0868 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 461.7458 - mae: 461.6929 - val_loss: 447.6863 - val_mae: 447.6306 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 428.4269 - mae: 428.3690 - val_loss: 416.7636 - val_mae: 416.7026 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 400.5250 - mae: 400.4616 - val_loss: 387.1762 - val_mae: 387.1099 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 373.5922 - mae: 373.5234 - val_loss: 359.2267 - val_mae: 359.1547 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 840.2586\n",
      "LV_RMSE_12h: 936.1046\n",
      "LV_MAE_24h: 77.8966\n",
      "LV_RMSE_24h: 126.0665\n",
      "LV_MAE_48h: 124.8534\n",
      "LV_RMSE_48h: 179.5110\n",
      "LV_MAE_72h: 140.2615\n",
      "LV_RMSE_72h: 200.4739\n",
      "LV_MAE_mean: 295.8175\n",
      "LV_RMSE_mean: 360.5390\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 590.9547\n",
      "RMSE_12h: 708.6398\n",
      "MAE_24h: 285.6717\n",
      "RMSE_24h: 378.9942\n",
      "MAE_48h: 259.3869\n",
      "RMSE_48h: 343.4165\n",
      "MAE_72h: 286.2445\n",
      "RMSE_72h: 381.8121\n",
      "MAE_mean: 355.5645\n",
      "RMSE_mean: 453.2156\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Station S318434 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1376 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1353, 24, 400) Ytr2: (1353, 4) \n",
      "  Xva3: (197, 24, 400) Yva2: (197, 4) \n",
      "  Xte3: (348, 24, 400) Yte2: (348, 4)\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 3s 65ms/step - loss: 225.8058 - mae: 225.7929 - val_loss: 234.3741 - val_mae: 234.3611 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 219.6647 - mae: 219.6517 - val_loss: 226.0915 - val_mae: 226.0784 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 210.8268 - mae: 210.8135 - val_loss: 216.6505 - val_mae: 216.6369 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 201.5560 - mae: 201.5422 - val_loss: 207.7007 - val_mae: 207.6864 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 192.7973 - mae: 192.7827 - val_loss: 199.6283 - val_mae: 199.6130 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 184.8122 - mae: 184.7966 - val_loss: 192.4199 - val_mae: 192.4036 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 178.2014 - mae: 178.1845 - val_loss: 185.9869 - val_mae: 185.9695 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 172.4957 - mae: 172.4778 - val_loss: 180.7963 - val_mae: 180.7776 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 168.1958 - mae: 168.1766 - val_loss: 176.2012 - val_mae: 176.1813 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 163.2886 - mae: 163.2681 - val_loss: 171.4801 - val_mae: 171.4589 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 158.1582 - mae: 158.1364 - val_loss: 163.6542 - val_mae: 163.6317 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 149.3943 - mae: 149.3712 - val_loss: 153.1003 - val_mae: 153.0764 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 138.9767 - mae: 138.9521 - val_loss: 142.2559 - val_mae: 142.2303 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 128.6039 - mae: 128.5775 - val_loss: 132.1916 - val_mae: 132.1641 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 119.9097 - mae: 119.8813 - val_loss: 123.9137 - val_mae: 123.8843 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 113.7152 - mae: 113.6850 - val_loss: 118.4461 - val_mae: 118.4149 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 109.8471 - mae: 109.8152 - val_loss: 115.0511 - val_mae: 115.0184 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 106.9626 - mae: 106.9294 - val_loss: 112.1928 - val_mae: 112.1589 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 104.6269 - mae: 104.5927 - val_loss: 110.4748 - val_mae: 110.4400 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 102.6629 - mae: 102.6278 - val_loss: 109.3640 - val_mae: 109.3283 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 283.6753\n",
      "LV_RMSE_12h: 331.0835\n",
      "LV_MAE_24h: 74.9856\n",
      "LV_RMSE_24h: 116.3269\n",
      "LV_MAE_48h: 96.8534\n",
      "LV_RMSE_48h: 154.1722\n",
      "LV_MAE_72h: 83.9310\n",
      "LV_RMSE_72h: 141.4830\n",
      "LV_MAE_mean: 134.8614\n",
      "LV_RMSE_mean: 185.7664\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 184.2464\n",
      "RMSE_12h: 247.9195\n",
      "MAE_24h: 77.6855\n",
      "RMSE_24h: 122.5348\n",
      "MAE_48h: 74.7627\n",
      "RMSE_48h: 119.4530\n",
      "MAE_72h: 70.9987\n",
      "RMSE_72h: 114.2557\n",
      "MAE_mean: 101.9233\n",
      "RMSE_mean: 151.0407\n",
      "\n",
      "=== Station S318460 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1222 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1199, 24, 400) Ytr2: (1199, 4) \n",
      "  Xva3: (175, 24, 400) Yva2: (175, 4) \n",
      "  Xte3: (304, 24, 400) Yte2: (304, 4)\n",
      "Epoch 1/20\n",
      "10/10 [==============================] - 3s 70ms/step - loss: 136.4358 - mae: 136.4229 - val_loss: 139.9161 - val_mae: 139.9032 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 130.9576 - mae: 130.9446 - val_loss: 131.8419 - val_mae: 131.8287 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 121.3453 - mae: 121.3319 - val_loss: 120.4137 - val_mae: 120.4000 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 109.0945 - mae: 109.0805 - val_loss: 106.8153 - val_mae: 106.8008 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 95.7466 - mae: 95.7316 - val_loss: 93.4582 - val_mae: 93.4426 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 83.5936 - mae: 83.5775 - val_loss: 83.4591 - val_mae: 83.4423 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 74.9166 - mae: 74.8993 - val_loss: 77.0179 - val_mae: 76.9998 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 69.5788 - mae: 69.5603 - val_loss: 73.6170 - val_mae: 73.5978 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 67.2007 - mae: 67.1811 - val_loss: 71.9140 - val_mae: 71.8940 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 65.3423 - mae: 65.3222 - val_loss: 69.6378 - val_mae: 69.6174 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 62.3846 - mae: 62.3640 - val_loss: 66.7872 - val_mae: 66.7664 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 58.4862 - mae: 58.4652 - val_loss: 63.3278 - val_mae: 63.3064 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 54.6259 - mae: 54.6043 - val_loss: 61.5475 - val_mae: 61.5254 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 51.8289 - mae: 51.8065 - val_loss: 59.5347 - val_mae: 59.5119 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 49.1087 - mae: 49.0856 - val_loss: 57.8537 - val_mae: 57.8302 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 46.8405 - mae: 46.8166 - val_loss: 56.1378 - val_mae: 56.1134 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 44.8708 - mae: 44.8460 - val_loss: 54.7370 - val_mae: 54.7117 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 43.5358 - mae: 43.5102 - val_loss: 54.2567 - val_mae: 54.2307 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 41.9441 - mae: 41.9178 - val_loss: 52.7663 - val_mae: 52.7394 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 40.3707 - mae: 40.3436 - val_loss: 51.2149 - val_mae: 51.1873 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 135.2961\n",
      "LV_RMSE_12h: 153.9164\n",
      "LV_MAE_24h: 46.8454\n",
      "LV_RMSE_24h: 66.5986\n",
      "LV_MAE_48h: 58.3553\n",
      "LV_RMSE_48h: 78.4066\n",
      "LV_MAE_72h: 53.7533\n",
      "LV_RMSE_72h: 71.9031\n",
      "LV_MAE_mean: 73.5625\n",
      "LV_RMSE_mean: 92.7062\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 80.9925\n",
      "RMSE_12h: 104.4790\n",
      "MAE_24h: 45.7734\n",
      "RMSE_24h: 64.7839\n",
      "MAE_48h: 46.6906\n",
      "RMSE_48h: 67.1561\n",
      "MAE_72h: 47.4456\n",
      "RMSE_72h: 67.7344\n",
      "MAE_mean: 55.2255\n",
      "RMSE_mean: 76.0384\n",
      "\n",
      "=== Station S318485 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1376 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1353, 24, 400) Ytr2: (1353, 4) \n",
      "  Xva3: (197, 24, 400) Yva2: (197, 4) \n",
      "  Xte3: (348, 24, 400) Yte2: (348, 4)\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 3s 67ms/step - loss: 359.9181 - mae: 359.9055 - val_loss: 392.4286 - val_mae: 392.4160 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 354.5687 - mae: 354.5561 - val_loss: 384.7720 - val_mae: 384.7593 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 345.4065 - mae: 345.3936 - val_loss: 373.9244 - val_mae: 373.9113 - lr: 0.0010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 333.6865 - mae: 333.6732 - val_loss: 361.0229 - val_mae: 361.0092 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 321.1920 - mae: 321.1779 - val_loss: 347.5592 - val_mae: 347.5444 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 308.0089 - mae: 307.9937 - val_loss: 334.0819 - val_mae: 334.0660 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 294.9570 - mae: 294.9405 - val_loss: 320.8173 - val_mae: 320.8000 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 282.3548 - mae: 282.3368 - val_loss: 307.8051 - val_mae: 307.7862 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 270.6297 - mae: 270.6100 - val_loss: 295.3378 - val_mae: 295.3171 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 258.9906 - mae: 258.9692 - val_loss: 283.9797 - val_mae: 283.9572 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 248.5359 - mae: 248.5126 - val_loss: 273.8362 - val_mae: 273.8117 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 240.1542 - mae: 240.1290 - val_loss: 262.2180 - val_mae: 262.1917 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 227.3991 - mae: 227.3719 - val_loss: 247.8797 - val_mae: 247.8514 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 213.8466 - mae: 213.8174 - val_loss: 235.2787 - val_mae: 235.2483 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 202.8780 - mae: 202.8466 - val_loss: 224.4686 - val_mae: 224.4361 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 194.7544 - mae: 194.7209 - val_loss: 214.6788 - val_mae: 214.6441 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 186.6808 - mae: 186.6452 - val_loss: 205.1791 - val_mae: 205.1421 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 178.7531 - mae: 178.7151 - val_loss: 197.2544 - val_mae: 197.2151 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 172.0425 - mae: 172.0021 - val_loss: 189.0374 - val_mae: 188.9957 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 165.3643 - mae: 165.3215 - val_loss: 180.1303 - val_mae: 180.0861 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 462.0891\n",
      "LV_RMSE_12h: 560.4761\n",
      "LV_MAE_24h: 122.1724\n",
      "LV_RMSE_24h: 200.2456\n",
      "LV_MAE_48h: 156.5747\n",
      "LV_RMSE_48h: 235.2237\n",
      "LV_MAE_72h: 150.4339\n",
      "LV_RMSE_72h: 230.0352\n",
      "LV_MAE_mean: 222.8175\n",
      "LV_RMSE_mean: 306.4951\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 294.1779\n",
      "RMSE_12h: 400.7160\n",
      "MAE_24h: 129.3641\n",
      "RMSE_24h: 226.4690\n",
      "MAE_48h: 138.8286\n",
      "RMSE_48h: 241.0333\n",
      "MAE_72h: 132.1280\n",
      "RMSE_72h: 222.1399\n",
      "MAE_mean: 173.6246\n",
      "RMSE_mean: 272.5895\n",
      "\n",
      "=== Station S318511 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1376 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1353, 24, 400) Ytr2: (1353, 4) \n",
      "  Xva3: (197, 24, 400) Yva2: (197, 4) \n",
      "  Xte3: (347, 24, 400) Yte2: (347, 4)\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 3s 78ms/step - loss: 376.6296 - mae: 376.6168 - val_loss: 389.8949 - val_mae: 389.8821 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 371.6202 - mae: 371.6074 - val_loss: 382.4049 - val_mae: 382.3920 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 362.8192 - mae: 362.8060 - val_loss: 372.5527 - val_mae: 372.5393 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 353.3700 - mae: 353.3562 - val_loss: 363.1273 - val_mae: 363.1132 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 344.5012 - mae: 344.4867 - val_loss: 353.2072 - val_mae: 353.1921 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 335.4849 - mae: 335.4694 - val_loss: 343.6632 - val_mae: 343.6469 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 326.7102 - mae: 326.6934 - val_loss: 334.0024 - val_mae: 333.9848 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 316.6509 - mae: 316.6327 - val_loss: 323.1312 - val_mae: 323.1119 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 305.2893 - mae: 305.2692 - val_loss: 310.0797 - val_mae: 310.0586 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 291.1531 - mae: 291.1311 - val_loss: 295.1054 - val_mae: 295.0821 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 276.0486 - mae: 276.0242 - val_loss: 280.7081 - val_mae: 280.6822 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 0s 17ms/step - loss: 260.8235 - mae: 260.7964 - val_loss: 265.2435 - val_mae: 265.2148 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 246.0046 - mae: 245.9746 - val_loss: 249.7490 - val_mae: 249.7173 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 231.7982 - mae: 231.7650 - val_loss: 235.1527 - val_mae: 235.1176 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 217.6008 - mae: 217.5643 - val_loss: 222.3339 - val_mae: 222.2954 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 205.3910 - mae: 205.3510 - val_loss: 209.5582 - val_mae: 209.5162 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 192.6969 - mae: 192.6532 - val_loss: 196.7429 - val_mae: 196.6971 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 180.7497 - mae: 180.7023 - val_loss: 185.2089 - val_mae: 185.1593 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 170.0889 - mae: 170.0377 - val_loss: 174.9936 - val_mae: 174.9403 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 160.9926 - mae: 160.9377 - val_loss: 165.2353 - val_mae: 165.1784 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 493.2306\n",
      "LV_RMSE_12h: 558.1225\n",
      "LV_MAE_24h: 95.4380\n",
      "LV_RMSE_24h: 152.6607\n",
      "LV_MAE_48h: 126.4006\n",
      "LV_RMSE_48h: 195.2463\n",
      "LV_MAE_72h: 107.8213\n",
      "LV_RMSE_72h: 162.8258\n",
      "LV_MAE_mean: 205.7226\n",
      "LV_RMSE_mean: 267.2138\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 305.4928\n",
      "RMSE_12h: 398.3286\n",
      "MAE_24h: 104.2505\n",
      "RMSE_24h: 156.3309\n",
      "MAE_48h: 101.4902\n",
      "RMSE_48h: 155.5825\n",
      "MAE_72h: 99.8588\n",
      "RMSE_72h: 153.4417\n",
      "MAE_mean: 152.7731\n",
      "RMSE_mean: 215.9209\n",
      "\n",
      "=== Station S318550 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1377 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1354, 24, 400) Ytr2: (1354, 4) \n",
      "  Xva3: (197, 24, 400) Yva2: (197, 4) \n",
      "  Xte3: (348, 24, 400) Yte2: (348, 4)\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 3s 64ms/step - loss: 441.1574 - mae: 441.1447 - val_loss: 435.2239 - val_mae: 435.2112 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 436.2943 - mae: 436.2814 - val_loss: 428.2898 - val_mae: 428.2767 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 428.0974 - mae: 428.0841 - val_loss: 419.0809 - val_mae: 419.0674 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 418.6669 - mae: 418.6529 - val_loss: 408.8155 - val_mae: 408.8011 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 408.1157 - mae: 408.1008 - val_loss: 397.7526 - val_mae: 397.7371 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 396.9810 - mae: 396.9649 - val_loss: 385.7083 - val_mae: 385.6913 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 384.8894 - mae: 384.8716 - val_loss: 373.1881 - val_mae: 373.1694 - lr: 0.0010\n",
      "Epoch 8/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 13ms/step - loss: 372.2832 - mae: 372.2635 - val_loss: 360.1785 - val_mae: 360.1577 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 359.2092 - mae: 359.1874 - val_loss: 346.6772 - val_mae: 346.6541 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 344.5699 - mae: 344.5457 - val_loss: 331.9146 - val_mae: 331.8889 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 328.9760 - mae: 328.9491 - val_loss: 313.5503 - val_mae: 313.5218 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 308.2328 - mae: 308.2029 - val_loss: 290.3994 - val_mae: 290.3677 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 285.8763 - mae: 285.8430 - val_loss: 268.1344 - val_mae: 268.0992 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 265.9488 - mae: 265.9118 - val_loss: 247.7522 - val_mae: 247.7130 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 247.5961 - mae: 247.5551 - val_loss: 231.1718 - val_mae: 231.1284 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 231.4114 - mae: 231.3662 - val_loss: 215.4590 - val_mae: 215.4113 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 216.2337 - mae: 216.1842 - val_loss: 203.2660 - val_mae: 203.2142 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 205.0988 - mae: 205.0452 - val_loss: 192.9229 - val_mae: 192.8671 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 195.1782 - mae: 195.1210 - val_loss: 185.3159 - val_mae: 185.2567 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 187.3046 - mae: 187.2441 - val_loss: 179.2191 - val_mae: 179.1569 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 568.4052\n",
      "LV_RMSE_12h: 653.3721\n",
      "LV_MAE_24h: 95.6236\n",
      "LV_RMSE_24h: 128.1770\n",
      "LV_MAE_48h: 113.1121\n",
      "LV_RMSE_48h: 158.6239\n",
      "LV_MAE_72h: 105.3362\n",
      "LV_RMSE_72h: 148.5948\n",
      "LV_MAE_mean: 220.6192\n",
      "LV_RMSE_mean: 272.1920\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 378.2335\n",
      "RMSE_12h: 468.1013\n",
      "MAE_24h: 126.8235\n",
      "RMSE_24h: 180.2078\n",
      "MAE_48h: 127.8144\n",
      "RMSE_48h: 181.1061\n",
      "MAE_72h: 133.1169\n",
      "RMSE_72h: 189.2785\n",
      "MAE_mean: 191.4971\n",
      "RMSE_mean: 254.6735\n",
      "\n",
      "=== Station S318604 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1377 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1354, 24, 400) Ytr2: (1354, 4) \n",
      "  Xva3: (197, 24, 400) Yva2: (197, 4) \n",
      "  Xte3: (348, 24, 400) Yte2: (348, 4)\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 3s 63ms/step - loss: 125.3863 - mae: 125.3734 - val_loss: 124.9576 - val_mae: 124.9447 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 122.4337 - mae: 122.4208 - val_loss: 120.7765 - val_mae: 120.7634 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 118.1964 - mae: 118.1832 - val_loss: 115.7085 - val_mae: 115.6951 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 113.5575 - mae: 113.5439 - val_loss: 110.0228 - val_mae: 110.0088 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 108.2505 - mae: 108.2362 - val_loss: 103.5765 - val_mae: 103.5617 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 102.1831 - mae: 102.1678 - val_loss: 96.3095 - val_mae: 96.2935 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 96.1430 - mae: 96.1265 - val_loss: 89.2831 - val_mae: 89.2659 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 89.6911 - mae: 89.6732 - val_loss: 82.2030 - val_mae: 82.1843 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 82.6379 - mae: 82.6185 - val_loss: 74.7474 - val_mae: 74.7270 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 75.0838 - mae: 75.0626 - val_loss: 67.3390 - val_mae: 67.3167 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 67.1311 - mae: 67.1078 - val_loss: 60.8725 - val_mae: 60.8479 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 61.0567 - mae: 61.0311 - val_loss: 55.6391 - val_mae: 55.6122 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 56.1572 - mae: 56.1293 - val_loss: 51.2581 - val_mae: 51.2290 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 51.6305 - mae: 51.6006 - val_loss: 48.9460 - val_mae: 48.9150 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 48.8932 - mae: 48.8614 - val_loss: 46.5505 - val_mae: 46.5177 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 47.0177 - mae: 46.9841 - val_loss: 43.5730 - val_mae: 43.5386 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 45.1822 - mae: 45.1471 - val_loss: 41.7136 - val_mae: 41.6778 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 43.0789 - mae: 43.0425 - val_loss: 39.8880 - val_mae: 39.8509 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 41.5709 - mae: 41.5331 - val_loss: 38.5023 - val_mae: 38.4638 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 39.8370 - mae: 39.7979 - val_loss: 36.7372 - val_mae: 36.6974 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 222.8851\n",
      "LV_RMSE_12h: 262.5912\n",
      "LV_MAE_24h: 32.6264\n",
      "LV_RMSE_24h: 49.7294\n",
      "LV_MAE_48h: 40.8132\n",
      "LV_RMSE_48h: 60.4991\n",
      "LV_MAE_72h: 39.7471\n",
      "LV_RMSE_72h: 60.9201\n",
      "LV_MAE_mean: 84.0180\n",
      "LV_RMSE_mean: 108.4350\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 86.5756\n",
      "RMSE_12h: 135.5558\n",
      "MAE_24h: 45.7813\n",
      "RMSE_24h: 67.5914\n",
      "MAE_48h: 48.3739\n",
      "RMSE_48h: 73.0998\n",
      "MAE_72h: 54.5383\n",
      "RMSE_72h: 82.4954\n",
      "MAE_mean: 58.8173\n",
      "RMSE_mean: 89.6856\n",
      "\n",
      "=== Station S318699 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1375 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1352, 24, 400) Ytr2: (1352, 4) \n",
      "  Xva3: (197, 24, 400) Yva2: (197, 4) \n",
      "  Xte3: (347, 24, 400) Yte2: (347, 4)\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 3s 68ms/step - loss: 256.2648 - mae: 256.2520 - val_loss: 258.1877 - val_mae: 258.1748 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 249.0027 - mae: 248.9898 - val_loss: 248.1551 - val_mae: 248.1421 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 237.4979 - mae: 237.4846 - val_loss: 235.6156 - val_mae: 235.6020 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 224.6155 - mae: 224.6016 - val_loss: 222.8969 - val_mae: 222.8825 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 211.9846 - mae: 211.9697 - val_loss: 209.9209 - val_mae: 209.9053 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 199.2664 - mae: 199.2503 - val_loss: 196.9961 - val_mae: 196.9791 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 187.4228 - mae: 187.4052 - val_loss: 186.0192 - val_mae: 186.0006 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 176.9160 - mae: 176.8967 - val_loss: 176.3924 - val_mae: 176.3721 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 168.0121 - mae: 167.9910 - val_loss: 169.0781 - val_mae: 169.0560 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 161.0392 - mae: 161.0164 - val_loss: 163.7538 - val_mae: 163.7300 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 155.1684 - mae: 155.1440 - val_loss: 157.6389 - val_mae: 157.6135 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 147.9131 - mae: 147.8871 - val_loss: 149.7411 - val_mae: 149.7143 - lr: 0.0010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 139.7094 - mae: 139.6820 - val_loss: 142.2218 - val_mae: 142.1935 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 131.2645 - mae: 131.2355 - val_loss: 131.3257 - val_mae: 131.2956 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 120.6551 - mae: 120.6242 - val_loss: 119.7207 - val_mae: 119.6888 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 110.9498 - mae: 110.9171 - val_loss: 109.4168 - val_mae: 109.3832 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 106.1947 - mae: 106.1605 - val_loss: 106.2391 - val_mae: 106.2042 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 101.3451 - mae: 101.3098 - val_loss: 101.0362 - val_mae: 101.0003 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 97.8976 - mae: 97.8612 - val_loss: 97.4301 - val_mae: 97.3931 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 94.9378 - mae: 94.9001 - val_loss: 94.4965 - val_mae: 94.4582 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 281.4294\n",
      "LV_RMSE_12h: 323.5089\n",
      "LV_MAE_24h: 58.9885\n",
      "LV_RMSE_24h: 92.4766\n",
      "LV_MAE_48h: 74.2046\n",
      "LV_RMSE_48h: 113.9027\n",
      "LV_MAE_72h: 61.8876\n",
      "LV_RMSE_72h: 94.0679\n",
      "LV_MAE_mean: 119.1275\n",
      "LV_RMSE_mean: 155.9890\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 188.1638\n",
      "RMSE_12h: 234.4593\n",
      "MAE_24h: 59.1263\n",
      "RMSE_24h: 94.9034\n",
      "MAE_48h: 60.3310\n",
      "RMSE_48h: 98.2743\n",
      "MAE_72h: 60.6235\n",
      "RMSE_72h: 98.9516\n",
      "MAE_mean: 92.0611\n",
      "RMSE_mean: 131.6471\n",
      "\n",
      "=== Station S318711 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1377 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1354, 24, 400) Ytr2: (1354, 4) \n",
      "  Xva3: (197, 24, 400) Yva2: (197, 4) \n",
      "  Xte3: (348, 24, 400) Yte2: (348, 4)\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 3s 67ms/step - loss: 2983.0227 - mae: 2983.0103 - val_loss: 2876.6599 - val_mae: 2876.6472 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 0s 17ms/step - loss: 2977.2942 - mae: 2977.2815 - val_loss: 2868.6777 - val_mae: 2868.6646 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 2967.5608 - mae: 2967.5474 - val_loss: 2857.2729 - val_mae: 2857.2595 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 2954.9392 - mae: 2954.9253 - val_loss: 2842.4873 - val_mae: 2842.4727 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 2938.2405 - mae: 2938.2253 - val_loss: 2823.6985 - val_mae: 2823.6833 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 2917.6465 - mae: 2917.6301 - val_loss: 2800.6289 - val_mae: 2800.6121 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 2892.6357 - mae: 2892.6177 - val_loss: 2773.0188 - val_mae: 2772.9998 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 2863.0583 - mae: 2863.0381 - val_loss: 2740.9138 - val_mae: 2740.8921 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 2829.6135 - mae: 2829.5913 - val_loss: 2704.1758 - val_mae: 2704.1516 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 2789.6604 - mae: 2789.6353 - val_loss: 2662.6543 - val_mae: 2662.6270 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 2745.8259 - mae: 2745.7971 - val_loss: 2616.2488 - val_mae: 2616.2178 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 2697.7087 - mae: 2697.6758 - val_loss: 2564.9912 - val_mae: 2564.9563 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 2644.7593 - mae: 2644.7219 - val_loss: 2508.8987 - val_mae: 2508.8589 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 2587.4927 - mae: 2587.4504 - val_loss: 2448.0564 - val_mae: 2448.0115 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 2522.2185 - mae: 2522.1709 - val_loss: 2383.1946 - val_mae: 2383.1443 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 2458.1528 - mae: 2458.1001 - val_loss: 2315.6006 - val_mae: 2315.5444 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 2388.5576 - mae: 2388.4988 - val_loss: 2247.1990 - val_mae: 2247.1365 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 2316.4055 - mae: 2316.3403 - val_loss: 2180.3564 - val_mae: 2180.2874 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 2249.7410 - mae: 2249.6689 - val_loss: 2116.5396 - val_mae: 2116.4641 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 2185.9751 - mae: 2185.8965 - val_loss: 2055.7053 - val_mae: 2055.6226 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 2266.3938\n",
      "LV_RMSE_12h: 2530.5923\n",
      "LV_MAE_24h: 402.9282\n",
      "LV_RMSE_24h: 615.8884\n",
      "LV_MAE_48h: 517.9396\n",
      "LV_RMSE_48h: 794.1476\n",
      "LV_MAE_72h: 476.8649\n",
      "LV_RMSE_72h: 698.6583\n",
      "LV_MAE_mean: 916.0317\n",
      "LV_RMSE_mean: 1159.8217\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 1964.2164\n",
      "RMSE_12h: 2354.1328\n",
      "MAE_24h: 2081.7954\n",
      "RMSE_24h: 2456.5850\n",
      "MAE_48h: 1971.8887\n",
      "RMSE_48h: 2348.6357\n",
      "MAE_72h: 2002.6758\n",
      "RMSE_72h: 2378.1025\n",
      "MAE_mean: 2005.1440\n",
      "RMSE_mean: 2384.3640\n",
      "\n",
      "=== Station S318756 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1160 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1137, 24, 400) Ytr2: (1137, 4) \n",
      "  Xva3: (166, 24, 400) Yva2: (166, 4) \n",
      "  Xte3: (286, 24, 400) Yte2: (286, 4)\n",
      "Epoch 1/20\n",
      "9/9 [==============================] - 3s 78ms/step - loss: 734.8121 - mae: 734.7993 - val_loss: 793.8800 - val_mae: 793.8671 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 729.5204 - mae: 729.5075 - val_loss: 786.9125 - val_mae: 786.8994 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 720.9724 - mae: 720.9592 - val_loss: 776.9620 - val_mae: 776.9486 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 710.2821 - mae: 710.2686 - val_loss: 765.0293 - val_mae: 765.0153 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 697.6667 - mae: 697.6525 - val_loss: 751.7297 - val_mae: 751.7151 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 684.5234 - mae: 684.5082 - val_loss: 738.5870 - val_mae: 738.5712 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 671.7497 - mae: 671.7334 - val_loss: 725.8908 - val_mae: 725.8739 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 659.2458 - mae: 659.2283 - val_loss: 712.8845 - val_mae: 712.8663 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 646.9172 - mae: 646.8982 - val_loss: 700.1171 - val_mae: 700.0974 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 634.5385 - mae: 634.5181 - val_loss: 687.7842 - val_mae: 687.7627 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 622.8881 - mae: 622.8658 - val_loss: 675.3088 - val_mae: 675.2856 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 610.8553 - mae: 610.8312 - val_loss: 662.1312 - val_mae: 662.1060 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 598.0041 - mae: 597.9780 - val_loss: 649.3838 - val_mae: 649.3564 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 586.3941 - mae: 586.3658 - val_loss: 636.3956 - val_mae: 636.3660 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 574.2348 - mae: 574.2042 - val_loss: 622.7341 - val_mae: 622.7020 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 560.6979 - mae: 560.6647 - val_loss: 607.9187 - val_mae: 607.8842 - lr: 0.0010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/20\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 548.3065 - mae: 548.2708 - val_loss: 592.1805 - val_mae: 592.1433 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 533.6599 - mae: 533.6214 - val_loss: 572.3466 - val_mae: 572.3066 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 518.0161 - mae: 517.9748 - val_loss: 552.3019 - val_mae: 552.2590 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 502.2162 - mae: 502.1719 - val_loss: 533.7984 - val_mae: 533.7523 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 981.2168\n",
      "LV_RMSE_12h: 1079.1998\n",
      "LV_MAE_24h: 162.6713\n",
      "LV_RMSE_24h: 260.2000\n",
      "LV_MAE_48h: 199.4266\n",
      "LV_RMSE_48h: 316.2482\n",
      "LV_MAE_72h: 174.2832\n",
      "LV_RMSE_72h: 273.7867\n",
      "LV_MAE_mean: 379.3995\n",
      "LV_RMSE_mean: 482.3586\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 600.9305\n",
      "RMSE_12h: 751.7766\n",
      "MAE_24h: 440.4049\n",
      "RMSE_24h: 591.4684\n",
      "MAE_48h: 398.9533\n",
      "RMSE_48h: 535.4485\n",
      "MAE_72h: 387.6582\n",
      "RMSE_72h: 523.4220\n",
      "MAE_mean: 456.9868\n",
      "RMSE_mean: 600.5288\n",
      "\n",
      "=== Station S318803 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 942 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (919, 24, 400) Ytr2: (919, 4) \n",
      "  Xva3: (135, 24, 400) Yva2: (135, 4) \n",
      "  Xte3: (223, 24, 400) Yte2: (223, 4)\n",
      "Epoch 1/20\n",
      "8/8 [==============================] - 3s 89ms/step - loss: 656.3597 - mae: 656.3469 - val_loss: 607.3558 - val_mae: 607.3431 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 653.3809 - mae: 653.3681 - val_loss: 602.9966 - val_mae: 602.9838 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 647.8977 - mae: 647.8848 - val_loss: 595.9113 - val_mae: 595.8981 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 639.9498 - mae: 639.9365 - val_loss: 586.9036 - val_mae: 586.8901 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 630.3494 - mae: 630.3358 - val_loss: 576.0924 - val_mae: 576.0784 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 619.1716 - mae: 619.1573 - val_loss: 563.8761 - val_mae: 563.8613 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 607.3464 - mae: 607.3311 - val_loss: 550.9422 - val_mae: 550.9264 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 594.7869 - mae: 594.7706 - val_loss: 537.9880 - val_mae: 537.9711 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 582.5251 - mae: 582.5078 - val_loss: 524.7152 - val_mae: 524.6970 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 569.7268 - mae: 569.7081 - val_loss: 511.2619 - val_mae: 511.2422 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 556.5126 - mae: 556.4923 - val_loss: 497.7833 - val_mae: 497.7621 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 544.5608 - mae: 544.5389 - val_loss: 484.7534 - val_mae: 484.7305 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 532.0974 - mae: 532.0739 - val_loss: 472.0089 - val_mae: 471.9841 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 520.6096 - mae: 520.5842 - val_loss: 458.8708 - val_mae: 458.8442 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 507.1800 - mae: 507.1526 - val_loss: 445.8040 - val_mae: 445.7753 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 495.0663 - mae: 495.0367 - val_loss: 432.4133 - val_mae: 432.3824 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 481.6130 - mae: 481.5811 - val_loss: 419.3915 - val_mae: 419.3582 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 467.7680 - mae: 467.7337 - val_loss: 407.5202 - val_mae: 407.4843 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 454.6859 - mae: 454.6491 - val_loss: 396.5891 - val_mae: 396.5507 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 444.9925 - mae: 444.9532 - val_loss: 385.8154 - val_mae: 385.7746 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 816.0986\n",
      "LV_RMSE_12h: 861.0989\n",
      "LV_MAE_24h: 82.2556\n",
      "LV_RMSE_24h: 155.3596\n",
      "LV_MAE_48h: 140.1928\n",
      "LV_RMSE_48h: 255.1974\n",
      "LV_MAE_72h: 216.2646\n",
      "LV_RMSE_72h: 382.5031\n",
      "LV_MAE_mean: 313.7029\n",
      "LV_RMSE_mean: 413.5397\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 496.9890\n",
      "RMSE_12h: 589.1769\n",
      "MAE_24h: 426.6866\n",
      "RMSE_24h: 504.1534\n",
      "MAE_48h: 448.2303\n",
      "RMSE_48h: 541.9409\n",
      "MAE_72h: 429.7979\n",
      "RMSE_72h: 505.9814\n",
      "MAE_mean: 450.4260\n",
      "RMSE_mean: 535.3132\n",
      "\n",
      "=== Station S318817 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1160 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1137, 24, 400) Ytr2: (1137, 4) \n",
      "  Xva3: (166, 24, 400) Yva2: (166, 4) \n",
      "  Xte3: (286, 24, 400) Yte2: (286, 4)\n",
      "Epoch 1/20\n",
      "9/9 [==============================] - 3s 78ms/step - loss: 524.4792 - mae: 524.4664 - val_loss: 551.8522 - val_mae: 551.8394 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 519.9232 - mae: 519.9102 - val_loss: 545.4792 - val_mae: 545.4662 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 512.0613 - mae: 512.0482 - val_loss: 536.0308 - val_mae: 536.0174 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 501.8423 - mae: 501.8286 - val_loss: 524.6605 - val_mae: 524.6465 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 489.5132 - mae: 489.4988 - val_loss: 511.4185 - val_mae: 511.4036 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 475.6855 - mae: 475.6702 - val_loss: 497.2185 - val_mae: 497.2025 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 461.7242 - mae: 461.7077 - val_loss: 482.6298 - val_mae: 482.6125 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 447.3151 - mae: 447.2972 - val_loss: 468.0968 - val_mae: 468.0780 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 433.0791 - mae: 433.0596 - val_loss: 453.6682 - val_mae: 453.6478 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 419.0778 - mae: 419.0566 - val_loss: 439.1833 - val_mae: 439.1610 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 405.1859 - mae: 405.1628 - val_loss: 424.3603 - val_mae: 424.3361 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 391.0998 - mae: 391.0746 - val_loss: 409.0749 - val_mae: 409.0485 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 375.9017 - mae: 375.8742 - val_loss: 394.5107 - val_mae: 394.4819 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 364.1398 - mae: 364.1100 - val_loss: 381.3025 - val_mae: 381.2714 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 351.8923 - mae: 351.8601 - val_loss: 369.3413 - val_mae: 369.3077 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 341.0285 - mae: 340.9939 - val_loss: 358.3405 - val_mae: 358.3045 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 331.8014 - mae: 331.7643 - val_loss: 347.9174 - val_mae: 347.8790 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 321.9748 - mae: 321.9354 - val_loss: 337.9476 - val_mae: 337.9067 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 313.6913 - mae: 313.6493 - val_loss: 326.0316 - val_mae: 325.9883 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 302.6901 - mae: 302.6457 - val_loss: 312.1409 - val_mae: 312.0951 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 600.8706\n",
      "LV_RMSE_12h: 689.1396\n",
      "LV_MAE_24h: 132.0594\n",
      "LV_RMSE_24h: 203.3713\n",
      "LV_MAE_48h: 168.0524\n",
      "LV_RMSE_48h: 242.9401\n",
      "LV_MAE_72h: 157.1573\n",
      "LV_RMSE_72h: 230.5982\n",
      "LV_MAE_mean: 264.5350\n",
      "LV_RMSE_mean: 341.5123\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 352.9681\n",
      "RMSE_12h: 408.5598\n",
      "MAE_24h: 297.3856\n",
      "RMSE_24h: 342.2050\n",
      "MAE_48h: 293.7724\n",
      "RMSE_48h: 345.2479\n",
      "MAE_72h: 289.3979\n",
      "RMSE_72h: 349.9238\n",
      "MAE_mean: 308.3810\n",
      "RMSE_mean: 361.4841\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Station S318950 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1377 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1354, 24, 400) Ytr2: (1354, 4) \n",
      "  Xva3: (197, 24, 400) Yva2: (197, 4) \n",
      "  Xte3: (348, 24, 400) Yte2: (348, 4)\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 3s 65ms/step - loss: 3689.1814 - mae: 3689.1685 - val_loss: 3367.0295 - val_mae: 3367.0168 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 3681.6738 - mae: 3681.6609 - val_loss: 3356.2319 - val_mae: 3356.2190 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 3668.8228 - mae: 3668.8096 - val_loss: 3341.1890 - val_mae: 3341.1755 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 3652.4634 - mae: 3652.4495 - val_loss: 3322.4893 - val_mae: 3322.4746 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 3631.3276 - mae: 3631.3125 - val_loss: 3299.0085 - val_mae: 3298.9924 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 3605.5908 - mae: 3605.5740 - val_loss: 3270.5198 - val_mae: 3270.5020 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 3575.1218 - mae: 3575.1025 - val_loss: 3236.8101 - val_mae: 3236.7893 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 3538.9546 - mae: 3538.9329 - val_loss: 3197.6694 - val_mae: 3197.6460 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 3497.2283 - mae: 3497.2039 - val_loss: 3152.9341 - val_mae: 3152.9075 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 3450.9502 - mae: 3450.9216 - val_loss: 3102.5989 - val_mae: 3102.5686 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 3397.0005 - mae: 3396.9683 - val_loss: 3046.4924 - val_mae: 3046.4575 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 3338.6484 - mae: 3338.6111 - val_loss: 2984.5320 - val_mae: 2984.4922 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 3274.3254 - mae: 3274.2830 - val_loss: 2917.0330 - val_mae: 2916.9875 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 3203.7383 - mae: 3203.6904 - val_loss: 2844.4448 - val_mae: 2844.3933 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 3126.3464 - mae: 3126.2920 - val_loss: 2767.3186 - val_mae: 2767.2605 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 3046.7720 - mae: 3046.7109 - val_loss: 2686.4409 - val_mae: 2686.3760 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 2961.8435 - mae: 2961.7751 - val_loss: 2602.0361 - val_mae: 2601.9634 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 2872.2109 - mae: 2872.1348 - val_loss: 2513.4929 - val_mae: 2513.4121 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 2781.1064 - mae: 2781.0215 - val_loss: 2421.9746 - val_mae: 2421.8853 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 2685.5220 - mae: 2685.4285 - val_loss: 2329.7085 - val_mae: 2329.6104 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 2251.6150\n",
      "LV_RMSE_12h: 2520.8801\n",
      "LV_MAE_24h: 568.1265\n",
      "LV_RMSE_24h: 739.4310\n",
      "LV_MAE_48h: 649.0345\n",
      "LV_RMSE_48h: 858.6270\n",
      "LV_MAE_72h: 598.9224\n",
      "LV_RMSE_72h: 797.8701\n",
      "LV_MAE_mean: 1016.9246\n",
      "LV_RMSE_mean: 1229.2020\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 1858.6387\n",
      "RMSE_12h: 2234.9387\n",
      "MAE_24h: 1864.5959\n",
      "RMSE_24h: 2227.2783\n",
      "MAE_48h: 1898.5815\n",
      "RMSE_48h: 2272.1440\n",
      "MAE_72h: 1890.1350\n",
      "RMSE_72h: 2261.6675\n",
      "MAE_mean: 1877.9878\n",
      "RMSE_mean: 2249.0071\n",
      "\n",
      "=== Station S319015 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1377 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1354, 24, 400) Ytr2: (1354, 4) \n",
      "  Xva3: (197, 24, 400) Yva2: (197, 4) \n",
      "  Xte3: (348, 24, 400) Yte2: (348, 4)\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 3s 65ms/step - loss: 431.7490 - mae: 431.7363 - val_loss: 433.5423 - val_mae: 433.5295 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 425.5851 - mae: 425.5723 - val_loss: 425.4393 - val_mae: 425.4263 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 416.0535 - mae: 416.0403 - val_loss: 415.2141 - val_mae: 415.2007 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 405.3560 - mae: 405.3422 - val_loss: 403.9142 - val_mae: 403.8999 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 393.3884 - mae: 393.3737 - val_loss: 391.9059 - val_mae: 391.8905 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 380.8570 - mae: 380.8411 - val_loss: 378.6892 - val_mae: 378.6724 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 368.1420 - mae: 368.1244 - val_loss: 364.8824 - val_mae: 364.8639 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 354.0103 - mae: 353.9910 - val_loss: 350.6811 - val_mae: 350.6606 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 339.6260 - mae: 339.6045 - val_loss: 335.7986 - val_mae: 335.7758 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 324.8318 - mae: 324.8079 - val_loss: 320.3120 - val_mae: 320.2867 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 309.1230 - mae: 309.0964 - val_loss: 303.5266 - val_mae: 303.4985 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 292.2919 - mae: 292.2625 - val_loss: 285.8336 - val_mae: 285.8024 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 274.6447 - mae: 274.6121 - val_loss: 268.7334 - val_mae: 268.6990 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 259.1215 - mae: 259.0857 - val_loss: 252.4710 - val_mae: 252.4335 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 244.5321 - mae: 244.4931 - val_loss: 236.8886 - val_mae: 236.8479 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 232.5471 - mae: 232.5051 - val_loss: 225.2783 - val_mae: 225.2345 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 221.0105 - mae: 220.9656 - val_loss: 214.5011 - val_mae: 214.4547 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 209.1769 - mae: 209.1293 - val_loss: 203.2530 - val_mae: 203.2038 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 198.7663 - mae: 198.7159 - val_loss: 192.7917 - val_mae: 192.7396 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 187.5645 - mae: 187.5112 - val_loss: 185.6975 - val_mae: 185.6427 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 525.0632\n",
      "LV_RMSE_12h: 612.4185\n",
      "LV_MAE_24h: 72.1983\n",
      "LV_RMSE_24h: 101.6289\n",
      "LV_MAE_48h: 104.6379\n",
      "LV_RMSE_48h: 144.9716\n",
      "LV_MAE_72h: 111.5287\n",
      "LV_RMSE_72h: 151.5665\n",
      "LV_MAE_mean: 203.3570\n",
      "LV_RMSE_mean: 252.6464\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 373.4252\n",
      "RMSE_12h: 459.5262\n",
      "MAE_24h: 107.5323\n",
      "RMSE_24h: 163.8056\n",
      "MAE_48h: 106.0564\n",
      "RMSE_48h: 162.2193\n",
      "MAE_72h: 116.7370\n",
      "RMSE_72h: 176.1280\n",
      "MAE_mean: 175.9377\n",
      "RMSE_mean: 240.4198\n",
      "\n",
      "=== Station S319101 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1376 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1353, 24, 400) Ytr2: (1353, 4) \n",
      "  Xva3: (197, 24, 400) Yva2: (197, 4) \n",
      "  Xte3: (348, 24, 400) Yte2: (348, 4)\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 3s 64ms/step - loss: 132.0116 - mae: 131.9989 - val_loss: 127.3857 - val_mae: 127.3730 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 125.9922 - mae: 125.9794 - val_loss: 119.9131 - val_mae: 119.9001 - lr: 0.0010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 118.1577 - mae: 118.1446 - val_loss: 111.9801 - val_mae: 111.9668 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 109.9174 - mae: 109.9037 - val_loss: 103.8983 - val_mae: 103.8841 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 102.1648 - mae: 102.1503 - val_loss: 96.0782 - val_mae: 96.0631 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 94.8430 - mae: 94.8274 - val_loss: 89.5039 - val_mae: 89.4877 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 88.7444 - mae: 88.7277 - val_loss: 84.0666 - val_mae: 84.0492 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 83.2369 - mae: 83.2189 - val_loss: 79.0406 - val_mae: 79.0219 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 78.7600 - mae: 78.7408 - val_loss: 73.7146 - val_mae: 73.6947 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 72.2551 - mae: 72.2348 - val_loss: 67.0260 - val_mae: 67.0050 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 65.1144 - mae: 65.0928 - val_loss: 59.4151 - val_mae: 59.3927 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 57.5855 - mae: 57.5626 - val_loss: 52.7666 - val_mae: 52.7430 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 52.3721 - mae: 52.3480 - val_loss: 48.9820 - val_mae: 48.9573 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 49.2455 - mae: 49.2204 - val_loss: 46.3205 - val_mae: 46.2950 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 47.0779 - mae: 47.0522 - val_loss: 44.1973 - val_mae: 44.1713 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 46.0756 - mae: 46.0493 - val_loss: 42.3758 - val_mae: 42.3492 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 44.1499 - mae: 44.1231 - val_loss: 40.5708 - val_mae: 40.5436 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 42.3618 - mae: 42.3341 - val_loss: 38.4728 - val_mae: 38.4446 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 40.2959 - mae: 40.2674 - val_loss: 36.3009 - val_mae: 36.2718 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 37.7094 - mae: 37.6798 - val_loss: 33.7974 - val_mae: 33.7671 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 142.8247\n",
      "LV_RMSE_12h: 156.7131\n",
      "LV_MAE_24h: 28.2356\n",
      "LV_RMSE_24h: 39.7938\n",
      "LV_MAE_48h: 33.8736\n",
      "LV_RMSE_48h: 47.4675\n",
      "LV_MAE_72h: 29.8822\n",
      "LV_RMSE_72h: 43.5319\n",
      "LV_MAE_mean: 58.7040\n",
      "LV_RMSE_mean: 71.8766\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 59.7225\n",
      "RMSE_12h: 69.4831\n",
      "MAE_24h: 26.3229\n",
      "RMSE_24h: 39.1713\n",
      "MAE_48h: 24.8764\n",
      "RMSE_48h: 37.7578\n",
      "MAE_72h: 25.5644\n",
      "RMSE_72h: 37.0044\n",
      "MAE_mean: 34.1216\n",
      "RMSE_mean: 45.8541\n",
      "\n",
      "=== Station S319119 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1377 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1354, 24, 400) Ytr2: (1354, 4) \n",
      "  Xva3: (197, 24, 400) Yva2: (197, 4) \n",
      "  Xte3: (348, 24, 400) Yte2: (348, 4)\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 3s 66ms/step - loss: 1377.6478 - mae: 1377.6351 - val_loss: 1347.7369 - val_mae: 1347.7242 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1370.6188 - mae: 1370.6061 - val_loss: 1338.4238 - val_mae: 1338.4110 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1359.8339 - mae: 1359.8208 - val_loss: 1325.7916 - val_mae: 1325.7782 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1345.8452 - mae: 1345.8314 - val_loss: 1309.8068 - val_mae: 1309.7925 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 1327.8761 - mae: 1327.8615 - val_loss: 1289.6868 - val_mae: 1289.6711 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 1305.7188 - mae: 1305.7026 - val_loss: 1264.9329 - val_mae: 1264.9156 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1279.0435 - mae: 1279.0251 - val_loss: 1235.3922 - val_mae: 1235.3729 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1247.1869 - mae: 1247.1664 - val_loss: 1201.0630 - val_mae: 1201.0411 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1210.4606 - mae: 1210.4375 - val_loss: 1161.7648 - val_mae: 1161.7400 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 1170.0094 - mae: 1169.9830 - val_loss: 1118.7701 - val_mae: 1118.7419 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 1127.5908 - mae: 1127.5610 - val_loss: 1077.0787 - val_mae: 1077.0468 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1088.8988 - mae: 1088.8651 - val_loss: 1039.4530 - val_mae: 1039.4171 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1051.5792 - mae: 1051.5416 - val_loss: 1004.1923 - val_mae: 1004.1525 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1019.3294 - mae: 1019.2878 - val_loss: 970.8732 - val_mae: 970.8293 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 987.0906 - mae: 987.0449 - val_loss: 938.4756 - val_mae: 938.4276 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 958.0516 - mae: 958.0016 - val_loss: 908.7921 - val_mae: 908.7397 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 928.8442 - mae: 928.7897 - val_loss: 881.9813 - val_mae: 881.9245 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 901.9247 - mae: 901.8660 - val_loss: 856.0161 - val_mae: 855.9550 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 876.8887 - mae: 876.8255 - val_loss: 826.7119 - val_mae: 826.6462 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 847.1965 - mae: 847.1289 - val_loss: 794.1978 - val_mae: 794.1273 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 1175.0518\n",
      "LV_RMSE_12h: 1265.2933\n",
      "LV_MAE_24h: 228.4195\n",
      "LV_RMSE_24h: 350.1093\n",
      "LV_MAE_48h: 278.2500\n",
      "LV_RMSE_48h: 418.9352\n",
      "LV_MAE_72h: 248.6897\n",
      "LV_RMSE_72h: 368.6096\n",
      "LV_MAE_mean: 482.6028\n",
      "LV_RMSE_mean: 600.7368\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 773.9973\n",
      "RMSE_12h: 920.9699\n",
      "MAE_24h: 697.5175\n",
      "RMSE_24h: 839.6091\n",
      "MAE_48h: 696.5149\n",
      "RMSE_48h: 841.0060\n",
      "MAE_72h: 702.0710\n",
      "RMSE_72h: 850.9524\n",
      "MAE_mean: 717.5252\n",
      "RMSE_mean: 863.1343\n",
      "\n",
      "=== Station S319129 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1377 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1354, 24, 400) Ytr2: (1354, 4) \n",
      "  Xva3: (197, 24, 400) Yva2: (197, 4) \n",
      "  Xte3: (348, 24, 400) Yte2: (348, 4)\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 3s 65ms/step - loss: 1505.2263 - mae: 1505.2135 - val_loss: 1485.2274 - val_mae: 1485.2146 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1500.8120 - mae: 1500.7994 - val_loss: 1478.8105 - val_mae: 1478.7976 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1492.7211 - mae: 1492.7079 - val_loss: 1468.7494 - val_mae: 1468.7361 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1481.2926 - mae: 1481.2787 - val_loss: 1455.2283 - val_mae: 1455.2144 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 1465.9902 - mae: 1465.9760 - val_loss: 1438.1764 - val_mae: 1438.1614 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 1447.3378 - mae: 1447.3220 - val_loss: 1417.1971 - val_mae: 1417.1808 - lr: 0.0010\n",
      "Epoch 7/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 14ms/step - loss: 1424.2087 - mae: 1424.1915 - val_loss: 1391.8837 - val_mae: 1391.8655 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1397.1067 - mae: 1397.0876 - val_loss: 1362.0774 - val_mae: 1362.0570 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1365.3918 - mae: 1365.3702 - val_loss: 1327.9338 - val_mae: 1327.9109 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1329.1482 - mae: 1329.1240 - val_loss: 1289.3452 - val_mae: 1289.3192 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1289.3667 - mae: 1289.3390 - val_loss: 1247.4353 - val_mae: 1247.4058 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 1247.8300 - mae: 1247.7986 - val_loss: 1206.6791 - val_mae: 1206.6458 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1208.7665 - mae: 1208.7314 - val_loss: 1168.6343 - val_mae: 1168.5972 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1172.2378 - mae: 1172.1990 - val_loss: 1133.2775 - val_mae: 1133.2366 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1138.2830 - mae: 1138.2401 - val_loss: 1099.2372 - val_mae: 1099.1921 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1106.4976 - mae: 1106.4507 - val_loss: 1067.0851 - val_mae: 1067.0358 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1076.5316 - mae: 1076.4806 - val_loss: 1036.2362 - val_mae: 1036.1827 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1045.0541 - mae: 1044.9988 - val_loss: 1007.1096 - val_mae: 1007.0517 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 1017.6601 - mae: 1017.6003 - val_loss: 979.8675 - val_mae: 979.8051 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 994.5323 - mae: 994.4680 - val_loss: 953.8793 - val_mae: 953.8125 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 1269.4340\n",
      "LV_RMSE_12h: 1374.5239\n",
      "LV_MAE_24h: 242.9454\n",
      "LV_RMSE_24h: 372.9684\n",
      "LV_MAE_48h: 297.6638\n",
      "LV_RMSE_48h: 447.8344\n",
      "LV_MAE_72h: 264.7356\n",
      "LV_RMSE_72h: 393.2475\n",
      "LV_MAE_mean: 518.6947\n",
      "LV_RMSE_mean: 647.1436\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 874.3566\n",
      "RMSE_12h: 1044.9280\n",
      "MAE_24h: 855.8917\n",
      "RMSE_24h: 1007.6659\n",
      "MAE_48h: 871.2235\n",
      "RMSE_48h: 1033.3748\n",
      "MAE_72h: 866.7755\n",
      "RMSE_72h: 1027.9287\n",
      "MAE_mean: 867.0618\n",
      "RMSE_mean: 1028.4744\n",
      "\n",
      "=== Station S319292 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1377 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1354, 24, 400) Ytr2: (1354, 4) \n",
      "  Xva3: (197, 24, 400) Yva2: (197, 4) \n",
      "  Xte3: (348, 24, 400) Yte2: (348, 4)\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 3s 65ms/step - loss: 214.6274 - mae: 214.6147 - val_loss: 196.8669 - val_mae: 196.8542 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 209.5922 - mae: 209.5794 - val_loss: 189.4676 - val_mae: 189.4547 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 200.5453 - mae: 200.5322 - val_loss: 178.5817 - val_mae: 178.5683 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 188.2726 - mae: 188.2588 - val_loss: 164.1144 - val_mae: 164.1002 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 172.2992 - mae: 172.2845 - val_loss: 146.5395 - val_mae: 146.5240 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 153.4861 - mae: 153.4700 - val_loss: 127.1164 - val_mae: 127.0994 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 134.8526 - mae: 134.8348 - val_loss: 109.0375 - val_mae: 109.0187 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 119.4393 - mae: 119.4197 - val_loss: 95.5885 - val_mae: 95.5679 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 110.2719 - mae: 110.2506 - val_loss: 87.3953 - val_mae: 87.3731 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 106.1916 - mae: 106.1689 - val_loss: 83.2688 - val_mae: 83.2456 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 103.8704 - mae: 103.8468 - val_loss: 80.5553 - val_mae: 80.5313 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 100.5416 - mae: 100.5174 - val_loss: 78.1353 - val_mae: 78.1109 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 94.5052 - mae: 94.4805 - val_loss: 75.3147 - val_mae: 75.2895 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 90.8001 - mae: 90.7743 - val_loss: 72.9711 - val_mae: 72.9447 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 87.6739 - mae: 87.6470 - val_loss: 71.6730 - val_mae: 71.6456 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 84.7262 - mae: 84.6983 - val_loss: 70.4864 - val_mae: 70.4579 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 82.6277 - mae: 82.5988 - val_loss: 68.7944 - val_mae: 68.7650 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 80.4747 - mae: 80.4449 - val_loss: 67.7156 - val_mae: 67.6853 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 78.7162 - mae: 78.6854 - val_loss: 66.6015 - val_mae: 66.5702 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 77.0831 - mae: 77.0513 - val_loss: 65.1229 - val_mae: 65.0905 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 274.8419\n",
      "LV_RMSE_12h: 338.3253\n",
      "LV_MAE_24h: 71.2960\n",
      "LV_RMSE_24h: 111.9440\n",
      "LV_MAE_48h: 80.4425\n",
      "LV_RMSE_48h: 125.6219\n",
      "LV_MAE_72h: 87.0460\n",
      "LV_RMSE_72h: 134.5515\n",
      "LV_MAE_mean: 128.4066\n",
      "LV_RMSE_mean: 177.6107\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 169.3200\n",
      "RMSE_12h: 241.4747\n",
      "MAE_24h: 94.7712\n",
      "RMSE_24h: 161.0189\n",
      "MAE_48h: 104.7290\n",
      "RMSE_48h: 174.9533\n",
      "MAE_72h: 112.4689\n",
      "RMSE_72h: 183.6100\n",
      "MAE_mean: 120.3223\n",
      "RMSE_mean: 190.2642\n",
      "\n",
      "=== Station S319416 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1341 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1318, 24, 400) Ytr2: (1318, 4) \n",
      "  Xva3: (192, 24, 400) Yva2: (192, 4) \n",
      "  Xte3: (338, 24, 400) Yte2: (338, 4)\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 3s 65ms/step - loss: 7.7189 - mae: 7.7062 - val_loss: 5.9069 - val_mae: 5.8941 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 5.6845 - mae: 5.6716 - val_loss: 4.6116 - val_mae: 4.5987 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 4.5603 - mae: 4.5474 - val_loss: 4.3841 - val_mae: 4.3711 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 4.2376 - mae: 4.2246 - val_loss: 4.2455 - val_mae: 4.2324 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 4.1242 - mae: 4.1112 - val_loss: 4.0839 - val_mae: 4.0709 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 3.9776 - mae: 3.9646 - val_loss: 4.1186 - val_mae: 4.1056 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 0s 21ms/step - loss: 3.8972 - mae: 3.8842 - val_loss: 3.9966 - val_mae: 3.9836 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 3.8131 - mae: 3.8002 - val_loss: 4.0043 - val_mae: 3.9913 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 3.7314 - mae: 3.7184 - val_loss: 3.9059 - val_mae: 3.8930 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 3.6257 - mae: 3.6127 - val_loss: 3.8535 - val_mae: 3.8405 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 3.5564 - mae: 3.5434 - val_loss: 3.9279 - val_mae: 3.9148 - lr: 0.0010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 3.5255 - mae: 3.5125 - val_loss: 3.9075 - val_mae: 3.8945 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 3.4998 - mae: 3.4867 - val_loss: 3.8438 - val_mae: 3.8307 - lr: 5.0000e-04\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 3.4154 - mae: 3.4023 - val_loss: 3.9136 - val_mae: 3.9005 - lr: 5.0000e-04\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 3.3788 - mae: 3.3656 - val_loss: 3.8287 - val_mae: 3.8155 - lr: 5.0000e-04\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 3.3013 - mae: 3.2881 - val_loss: 3.8727 - val_mae: 3.8595 - lr: 5.0000e-04\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 3.2953 - mae: 3.2821 - val_loss: 3.8446 - val_mae: 3.8314 - lr: 5.0000e-04\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 3.2924 - mae: 3.2792 - val_loss: 3.8322 - val_mae: 3.8190 - lr: 2.5000e-04\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 3.2848 - mae: 3.2716 - val_loss: 3.8061 - val_mae: 3.7929 - lr: 2.5000e-04\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 3.2759 - mae: 3.2627 - val_loss: 3.8406 - val_mae: 3.8274 - lr: 2.5000e-04\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 18.4201\n",
      "LV_RMSE_12h: 25.5309\n",
      "LV_MAE_24h: 7.1302\n",
      "LV_RMSE_24h: 11.9248\n",
      "LV_MAE_48h: 7.1657\n",
      "LV_RMSE_48h: 11.5241\n",
      "LV_MAE_72h: 7.7515\n",
      "LV_RMSE_72h: 12.3245\n",
      "LV_MAE_mean: 10.1169\n",
      "LV_RMSE_mean: 15.3261\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 7.3200\n",
      "RMSE_12h: 12.8617\n",
      "MAE_24h: 7.9187\n",
      "RMSE_24h: 13.9498\n",
      "MAE_48h: 9.2416\n",
      "RMSE_48h: 16.3841\n",
      "MAE_72h: 9.9118\n",
      "RMSE_72h: 17.4870\n",
      "MAE_mean: 8.5980\n",
      "RMSE_mean: 15.1707\n",
      "\n",
      "=== Station S319444 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1377 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1354, 24, 400) Ytr2: (1354, 4) \n",
      "  Xva3: (197, 24, 400) Yva2: (197, 4) \n",
      "  Xte3: (348, 24, 400) Yte2: (348, 4)\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 3s 65ms/step - loss: 491.8154 - mae: 491.8025 - val_loss: 424.8969 - val_mae: 424.8841 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 487.6331 - mae: 487.6203 - val_loss: 418.5814 - val_mae: 418.5683 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 479.4845 - mae: 479.4713 - val_loss: 408.4941 - val_mae: 408.4806 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 468.1655 - mae: 468.1518 - val_loss: 395.5576 - val_mae: 395.5433 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 453.2657 - mae: 453.2510 - val_loss: 379.0719 - val_mae: 379.0565 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 434.9626 - mae: 434.9465 - val_loss: 359.3398 - val_mae: 359.3227 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 413.8311 - mae: 413.8133 - val_loss: 338.6780 - val_mae: 338.6591 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 393.0520 - mae: 393.0322 - val_loss: 320.1609 - val_mae: 320.1398 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 373.6760 - mae: 373.6539 - val_loss: 305.7160 - val_mae: 305.6927 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 359.6720 - mae: 359.6477 - val_loss: 295.3307 - val_mae: 295.3052 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 348.9614 - mae: 348.9350 - val_loss: 288.2755 - val_mae: 288.2479 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 340.1107 - mae: 340.0822 - val_loss: 282.9411 - val_mae: 282.9115 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 332.7978 - mae: 332.7674 - val_loss: 278.4896 - val_mae: 278.4582 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 326.0754 - mae: 326.0432 - val_loss: 273.8857 - val_mae: 273.8526 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 317.8284 - mae: 317.7946 - val_loss: 265.9011 - val_mae: 265.8663 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 307.5674 - mae: 307.5318 - val_loss: 258.0291 - val_mae: 257.9924 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 296.6027 - mae: 296.5650 - val_loss: 252.1594 - val_mae: 252.1205 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 287.5349 - mae: 287.4950 - val_loss: 245.8524 - val_mae: 245.8113 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 277.2199 - mae: 277.1777 - val_loss: 239.3669 - val_mae: 239.3232 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 267.0279 - mae: 266.9831 - val_loss: 233.1199 - val_mae: 233.0737 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 748.2213\n",
      "LV_RMSE_12h: 873.4150\n",
      "LV_MAE_24h: 193.1264\n",
      "LV_RMSE_24h: 338.0190\n",
      "LV_MAE_48h: 175.8736\n",
      "LV_RMSE_48h: 274.6997\n",
      "LV_MAE_72h: 193.5259\n",
      "LV_RMSE_72h: 283.6362\n",
      "LV_MAE_mean: 327.6868\n",
      "LV_RMSE_mean: 442.4425\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 466.6768\n",
      "RMSE_12h: 636.3674\n",
      "MAE_24h: 282.6461\n",
      "RMSE_24h: 454.1915\n",
      "MAE_48h: 283.3342\n",
      "RMSE_48h: 463.5359\n",
      "MAE_72h: 287.3523\n",
      "RMSE_72h: 457.3431\n",
      "MAE_mean: 330.0023\n",
      "RMSE_mean: 502.8595\n",
      "\n",
      "=== Station S319673 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1377 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1354, 24, 400) Ytr2: (1354, 4) \n",
      "  Xva3: (197, 24, 400) Yva2: (197, 4) \n",
      "  Xte3: (348, 24, 400) Yte2: (348, 4)\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 3s 64ms/step - loss: 523.0806 - mae: 523.0678 - val_loss: 461.0608 - val_mae: 461.0480 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 516.9518 - mae: 516.9389 - val_loss: 451.7000 - val_mae: 451.6869 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 505.6291 - mae: 505.6157 - val_loss: 438.4681 - val_mae: 438.4545 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 491.0138 - mae: 490.9998 - val_loss: 421.6676 - val_mae: 421.6530 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 471.9724 - mae: 471.9574 - val_loss: 400.8901 - val_mae: 400.8742 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 449.5049 - mae: 449.4882 - val_loss: 377.5371 - val_mae: 377.5194 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 425.2604 - mae: 425.2418 - val_loss: 354.4741 - val_mae: 354.4542 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 401.2731 - mae: 401.2522 - val_loss: 333.9631 - val_mae: 333.9408 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 380.8003 - mae: 380.7769 - val_loss: 316.6031 - val_mae: 316.5783 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 362.6797 - mae: 362.6537 - val_loss: 301.6066 - val_mae: 301.5792 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 347.6060 - mae: 347.5775 - val_loss: 289.1227 - val_mae: 289.0927 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 334.4314 - mae: 334.4001 - val_loss: 278.2960 - val_mae: 278.2633 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 320.4783 - mae: 320.4445 - val_loss: 266.2799 - val_mae: 266.2445 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 305.2918 - mae: 305.2553 - val_loss: 255.1334 - val_mae: 255.0953 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 290.9813 - mae: 290.9420 - val_loss: 244.0129 - val_mae: 243.9720 - lr: 0.0010\n",
      "Epoch 16/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 13ms/step - loss: 277.6144 - mae: 277.5723 - val_loss: 234.2836 - val_mae: 234.2400 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 263.6720 - mae: 263.6271 - val_loss: 226.5934 - val_mae: 226.5469 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 251.0530 - mae: 251.0053 - val_loss: 220.1446 - val_mae: 220.0952 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 242.3065 - mae: 242.2559 - val_loss: 214.8249 - val_mae: 214.7726 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 233.1636 - mae: 233.1100 - val_loss: 209.7003 - val_mae: 209.6453 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 684.4512\n",
      "LV_RMSE_12h: 833.0909\n",
      "LV_MAE_24h: 204.4741\n",
      "LV_RMSE_24h: 325.5459\n",
      "LV_MAE_48h: 221.0919\n",
      "LV_RMSE_48h: 328.8046\n",
      "LV_MAE_72h: 229.8908\n",
      "LV_RMSE_72h: 349.6541\n",
      "LV_MAE_mean: 334.9770\n",
      "LV_RMSE_mean: 459.2739\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 471.5959\n",
      "RMSE_12h: 619.4938\n",
      "MAE_24h: 247.1782\n",
      "RMSE_24h: 375.6443\n",
      "MAE_48h: 259.7900\n",
      "RMSE_48h: 396.2177\n",
      "MAE_72h: 268.2477\n",
      "RMSE_72h: 404.8419\n",
      "MAE_mean: 311.7029\n",
      "RMSE_mean: 449.0494\n",
      "\n",
      "=== Station S319795 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1376 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1353, 24, 400) Ytr2: (1353, 4) \n",
      "  Xva3: (197, 24, 400) Yva2: (197, 4) \n",
      "  Xte3: (348, 24, 400) Yte2: (348, 4)\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 3s 64ms/step - loss: 528.1348 - mae: 528.1221 - val_loss: 544.8011 - val_mae: 544.7885 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 522.4500 - mae: 522.4373 - val_loss: 536.5408 - val_mae: 536.5280 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 512.4218 - mae: 512.4087 - val_loss: 524.4614 - val_mae: 524.4481 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 499.0031 - mae: 498.9894 - val_loss: 509.3415 - val_mae: 509.3273 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 483.6310 - mae: 483.6163 - val_loss: 492.6971 - val_mae: 492.6816 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 467.6190 - mae: 467.6030 - val_loss: 476.9828 - val_mae: 476.9658 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 452.1005 - mae: 452.0827 - val_loss: 461.7293 - val_mae: 461.7105 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 436.6761 - mae: 436.6564 - val_loss: 446.1368 - val_mae: 446.1160 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 422.2211 - mae: 422.1993 - val_loss: 431.9469 - val_mae: 431.9240 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 408.2758 - mae: 408.2519 - val_loss: 418.7698 - val_mae: 418.7444 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 395.0947 - mae: 395.0683 - val_loss: 405.2898 - val_mae: 405.2619 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 380.6164 - mae: 380.5873 - val_loss: 389.5664 - val_mae: 389.5357 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 361.5121 - mae: 361.4803 - val_loss: 370.2382 - val_mae: 370.2046 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 342.6816 - mae: 342.6466 - val_loss: 351.5226 - val_mae: 351.4858 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 324.0997 - mae: 324.0613 - val_loss: 333.3586 - val_mae: 333.3183 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 307.0755 - mae: 307.0337 - val_loss: 315.7570 - val_mae: 315.7132 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 291.4888 - mae: 291.4434 - val_loss: 298.8921 - val_mae: 298.8447 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 276.5213 - mae: 276.4723 - val_loss: 280.8911 - val_mae: 280.8401 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 258.2212 - mae: 258.1685 - val_loss: 265.4133 - val_mae: 265.3585 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 246.3412 - mae: 246.2847 - val_loss: 252.5066 - val_mae: 252.4481 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 657.9023\n",
      "LV_RMSE_12h: 757.8198\n",
      "LV_MAE_24h: 112.6954\n",
      "LV_RMSE_24h: 182.3313\n",
      "LV_MAE_48h: 136.5632\n",
      "LV_RMSE_48h: 212.3247\n",
      "LV_MAE_72h: 122.1121\n",
      "LV_RMSE_72h: 183.9114\n",
      "LV_MAE_mean: 257.3182\n",
      "LV_RMSE_mean: 334.0968\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 442.7057\n",
      "RMSE_12h: 551.9016\n",
      "MAE_24h: 184.2594\n",
      "RMSE_24h: 270.6741\n",
      "MAE_48h: 180.3564\n",
      "RMSE_48h: 260.6411\n",
      "MAE_72h: 184.5284\n",
      "RMSE_72h: 267.7302\n",
      "MAE_mean: 247.9625\n",
      "RMSE_mean: 337.7368\n",
      "\n",
      "=== Station S320046 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1376 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1353, 24, 400) Ytr2: (1353, 4) \n",
      "  Xva3: (197, 24, 400) Yva2: (197, 4) \n",
      "  Xte3: (348, 24, 400) Yte2: (348, 4)\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 3s 66ms/step - loss: 58.3271 - mae: 58.3145 - val_loss: 57.7120 - val_mae: 57.6994 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 53.6715 - mae: 53.6587 - val_loss: 51.9906 - val_mae: 51.9777 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 48.2141 - mae: 48.2010 - val_loss: 46.4830 - val_mae: 46.4696 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 43.1440 - mae: 43.1303 - val_loss: 41.5429 - val_mae: 41.5287 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 38.8643 - mae: 38.8498 - val_loss: 37.2016 - val_mae: 37.1866 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 34.8769 - mae: 34.8615 - val_loss: 33.5775 - val_mae: 33.5616 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 31.0338 - mae: 31.0176 - val_loss: 29.7161 - val_mae: 29.6995 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 27.5236 - mae: 27.5068 - val_loss: 26.7034 - val_mae: 26.6862 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 25.0115 - mae: 24.9941 - val_loss: 25.0192 - val_mae: 25.0016 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 23.3811 - mae: 23.3633 - val_loss: 23.1269 - val_mae: 23.1089 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 22.2136 - mae: 22.1954 - val_loss: 21.8892 - val_mae: 21.8706 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 21.0261 - mae: 21.0074 - val_loss: 20.7460 - val_mae: 20.7269 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 19.9300 - mae: 19.9106 - val_loss: 19.3417 - val_mae: 19.3219 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 18.5061 - mae: 18.4860 - val_loss: 17.7369 - val_mae: 17.7164 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 17.5456 - mae: 17.5247 - val_loss: 16.7742 - val_mae: 16.7530 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 16.9414 - mae: 16.9199 - val_loss: 15.8473 - val_mae: 15.8255 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 16.3091 - mae: 16.2871 - val_loss: 15.4797 - val_mae: 15.4575 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 16.1455 - mae: 16.1231 - val_loss: 15.1628 - val_mae: 15.1403 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 15.5207 - mae: 15.4980 - val_loss: 15.1142 - val_mae: 15.0915 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 15.4759 - mae: 15.4530 - val_loss: 14.9283 - val_mae: 14.9054 - lr: 0.0010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 71.6609\n",
      "LV_RMSE_12h: 81.3698\n",
      "LV_MAE_24h: 13.6897\n",
      "LV_RMSE_24h: 21.0398\n",
      "LV_MAE_48h: 17.7414\n",
      "LV_RMSE_48h: 26.6006\n",
      "LV_MAE_72h: 16.8822\n",
      "LV_RMSE_72h: 26.3831\n",
      "LV_MAE_mean: 29.9935\n",
      "LV_RMSE_mean: 38.8483\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 14.3986\n",
      "RMSE_12h: 21.6522\n",
      "MAE_24h: 14.7514\n",
      "RMSE_24h: 21.6409\n",
      "MAE_48h: 13.9611\n",
      "RMSE_48h: 20.8811\n",
      "MAE_72h: 14.2973\n",
      "RMSE_72h: 21.3259\n",
      "MAE_mean: 14.3521\n",
      "RMSE_mean: 21.3750\n",
      "\n",
      "=== Station S320332 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1377 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1354, 24, 400) Ytr2: (1354, 4) \n",
      "  Xva3: (197, 24, 400) Yva2: (197, 4) \n",
      "  Xte3: (348, 24, 400) Yte2: (348, 4)\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 3s 66ms/step - loss: 159.7891 - mae: 159.7763 - val_loss: 142.4292 - val_mae: 142.4164 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 154.5005 - mae: 154.4876 - val_loss: 135.2200 - val_mae: 135.2069 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 147.3061 - mae: 147.2928 - val_loss: 127.6418 - val_mae: 127.6282 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 140.3226 - mae: 140.3087 - val_loss: 120.7018 - val_mae: 120.6874 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 133.8835 - mae: 133.8687 - val_loss: 115.0229 - val_mae: 115.0075 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 128.6514 - mae: 128.6355 - val_loss: 111.0093 - val_mae: 110.9928 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 124.7523 - mae: 124.7352 - val_loss: 108.4116 - val_mae: 108.3939 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 121.7230 - mae: 121.7047 - val_loss: 106.4583 - val_mae: 106.4395 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 118.0023 - mae: 117.9829 - val_loss: 104.0944 - val_mae: 104.0744 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 114.1725 - mae: 114.1521 - val_loss: 100.6331 - val_mae: 100.6120 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 108.7068 - mae: 108.6853 - val_loss: 94.1880 - val_mae: 94.1657 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 100.4010 - mae: 100.3781 - val_loss: 84.5510 - val_mae: 84.5274 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 89.0974 - mae: 89.0731 - val_loss: 74.6571 - val_mae: 74.6317 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 78.0254 - mae: 77.9991 - val_loss: 65.4881 - val_mae: 65.4605 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 67.9667 - mae: 67.9382 - val_loss: 61.5804 - val_mae: 61.5508 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 63.1684 - mae: 63.1382 - val_loss: 59.3260 - val_mae: 59.2951 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 60.5399 - mae: 60.5088 - val_loss: 56.1320 - val_mae: 56.1003 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 58.6885 - mae: 58.6565 - val_loss: 54.3012 - val_mae: 54.2686 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 57.0194 - mae: 56.9866 - val_loss: 53.9896 - val_mae: 53.9564 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 55.5117 - mae: 55.4782 - val_loss: 52.4567 - val_mae: 52.4227 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 272.4368\n",
      "LV_RMSE_12h: 299.1870\n",
      "LV_MAE_24h: 46.3448\n",
      "LV_RMSE_24h: 70.8759\n",
      "LV_MAE_48h: 53.0603\n",
      "LV_RMSE_48h: 78.3613\n",
      "LV_MAE_72h: 50.8448\n",
      "LV_RMSE_72h: 78.3155\n",
      "LV_MAE_mean: 105.6717\n",
      "LV_RMSE_mean: 131.6849\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 136.1413\n",
      "RMSE_12h: 190.5146\n",
      "MAE_24h: 50.5933\n",
      "RMSE_24h: 81.1407\n",
      "MAE_48h: 53.7829\n",
      "RMSE_48h: 89.1839\n",
      "MAE_72h: 57.9770\n",
      "RMSE_72h: 94.3229\n",
      "MAE_mean: 74.6236\n",
      "RMSE_mean: 113.7905\n",
      "\n",
      "=== Station S320514 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1264 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1241, 24, 400) Ytr2: (1241, 4) \n",
      "  Xva3: (181, 24, 400) Yva2: (181, 4) \n",
      "  Xte3: (316, 24, 400) Yte2: (316, 4)\n",
      "Epoch 1/20\n",
      "10/10 [==============================] - 3s 82ms/step - loss: 456.0627 - mae: 456.0501 - val_loss: 460.0623 - val_mae: 460.0497 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 449.7987 - mae: 449.7861 - val_loss: 451.8724 - val_mae: 451.8596 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 440.0113 - mae: 439.9984 - val_loss: 440.1488 - val_mae: 440.1356 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "10/10 [==============================] - 0s 25ms/step - loss: 427.1174 - mae: 427.1040 - val_loss: 425.7324 - val_mae: 425.7186 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 411.6864 - mae: 411.6722 - val_loss: 408.5993 - val_mae: 408.5845 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 394.1082 - mae: 394.0930 - val_loss: 390.6174 - val_mae: 390.6014 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 376.1263 - mae: 376.1098 - val_loss: 372.0149 - val_mae: 371.9975 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 358.7228 - mae: 358.7047 - val_loss: 353.2356 - val_mae: 353.2165 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 341.1037 - mae: 341.0839 - val_loss: 335.5373 - val_mae: 335.5165 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 324.8406 - mae: 324.8189 - val_loss: 319.1631 - val_mae: 319.1403 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 309.8528 - mae: 309.8290 - val_loss: 303.5434 - val_mae: 303.5185 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 294.3634 - mae: 294.3375 - val_loss: 289.2228 - val_mae: 289.1956 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 280.9603 - mae: 280.9321 - val_loss: 276.3759 - val_mae: 276.3463 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 269.3186 - mae: 269.2881 - val_loss: 265.4466 - val_mae: 265.4148 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 258.5315 - mae: 258.4986 - val_loss: 255.2073 - val_mae: 255.1732 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 250.5255 - mae: 250.4905 - val_loss: 246.0098 - val_mae: 245.9736 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 241.8834 - mae: 241.8463 - val_loss: 238.4199 - val_mae: 238.3816 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 235.3224 - mae: 235.2831 - val_loss: 227.7215 - val_mae: 227.6810 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 223.5363 - mae: 223.4950 - val_loss: 213.6410 - val_mae: 213.5984 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 212.5137 - mae: 212.4702 - val_loss: 196.7030 - val_mae: 196.6581 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 432.2247\n",
      "LV_RMSE_12h: 482.0769\n",
      "LV_MAE_24h: 94.8734\n",
      "LV_RMSE_24h: 145.4400\n",
      "LV_MAE_48h: 113.8038\n",
      "LV_RMSE_48h: 161.2553\n",
      "LV_MAE_72h: 91.6297\n",
      "LV_RMSE_72h: 133.4297\n",
      "LV_MAE_mean: 183.1329\n",
      "LV_RMSE_mean: 230.5505\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 293.7569\n",
      "RMSE_12h: 330.7456\n",
      "MAE_24h: 160.1503\n",
      "RMSE_24h: 189.6614\n",
      "MAE_48h: 155.9289\n",
      "RMSE_48h: 184.8206\n",
      "MAE_72h: 155.8644\n",
      "RMSE_72h: 184.9631\n",
      "MAE_mean: 191.4251\n",
      "RMSE_mean: 222.5477\n",
      "\n",
      "=== Station S320552 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1377 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1354, 24, 400) Ytr2: (1354, 4) \n",
      "  Xva3: (197, 24, 400) Yva2: (197, 4) \n",
      "  Xte3: (348, 24, 400) Yte2: (348, 4)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "11/11 [==============================] - 3s 65ms/step - loss: 1121.9537 - mae: 1121.9407 - val_loss: 1060.3247 - val_mae: 1060.3119 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1115.1821 - mae: 1115.1692 - val_loss: 1050.8369 - val_mae: 1050.8239 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1103.7466 - mae: 1103.7334 - val_loss: 1037.1757 - val_mae: 1037.1619 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1088.8021 - mae: 1088.7878 - val_loss: 1019.9120 - val_mae: 1019.8973 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1069.2385 - mae: 1069.2234 - val_loss: 998.0927 - val_mae: 998.0766 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1045.4581 - mae: 1045.4414 - val_loss: 971.5175 - val_mae: 971.4996 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1017.1553 - mae: 1017.1365 - val_loss: 940.7780 - val_mae: 940.7578 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 984.4747 - mae: 984.4532 - val_loss: 909.1099 - val_mae: 909.0871 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 951.9697 - mae: 951.9456 - val_loss: 877.8637 - val_mae: 877.8378 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 919.7943 - mae: 919.7668 - val_loss: 847.7068 - val_mae: 847.6777 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 888.2768 - mae: 888.2460 - val_loss: 817.8547 - val_mae: 817.8220 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 857.4967 - mae: 857.4622 - val_loss: 789.2479 - val_mae: 789.2114 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 828.8582 - mae: 828.8201 - val_loss: 762.3755 - val_mae: 762.3350 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 802.0584 - mae: 802.0162 - val_loss: 738.1430 - val_mae: 738.0985 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 776.0758 - mae: 776.0295 - val_loss: 714.5117 - val_mae: 714.4630 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 751.8228 - mae: 751.7722 - val_loss: 691.2154 - val_mae: 691.1624 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 725.1813 - mae: 725.1263 - val_loss: 667.3750 - val_mae: 667.3175 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 695.0219 - mae: 694.9625 - val_loss: 640.7323 - val_mae: 640.6702 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 666.3098 - mae: 666.2457 - val_loss: 611.2567 - val_mae: 611.1898 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 635.5164 - mae: 635.4472 - val_loss: 584.9015 - val_mae: 584.8294 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 1040.6724\n",
      "LV_RMSE_12h: 1130.9353\n",
      "LV_MAE_24h: 204.7902\n",
      "LV_RMSE_24h: 348.7518\n",
      "LV_MAE_48h: 283.7385\n",
      "LV_RMSE_48h: 456.4782\n",
      "LV_MAE_72h: 228.1264\n",
      "LV_RMSE_72h: 394.8301\n",
      "LV_MAE_mean: 439.3319\n",
      "LV_RMSE_mean: 582.7488\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 687.2321\n",
      "RMSE_12h: 815.1263\n",
      "MAE_24h: 488.6869\n",
      "RMSE_24h: 636.5726\n",
      "MAE_48h: 475.1418\n",
      "RMSE_48h: 613.5111\n",
      "MAE_72h: 455.4957\n",
      "RMSE_72h: 582.0475\n",
      "MAE_mean: 526.6392\n",
      "RMSE_mean: 661.8144\n",
      "\n",
      "=== Station S3411034 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1377 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1354, 24, 400) Ytr2: (1354, 4) \n",
      "  Xva3: (197, 24, 400) Yva2: (197, 4) \n",
      "  Xte3: (348, 24, 400) Yte2: (348, 4)\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 3s 65ms/step - loss: 624.1320 - mae: 624.1194 - val_loss: 530.3726 - val_mae: 530.3601 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 618.4985 - mae: 618.4859 - val_loss: 522.3690 - val_mae: 522.3563 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 609.0406 - mae: 609.0278 - val_loss: 511.2471 - val_mae: 511.2341 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 596.5660 - mae: 596.5527 - val_loss: 496.9338 - val_mae: 496.9200 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 580.2800 - mae: 580.2658 - val_loss: 478.8753 - val_mae: 478.8604 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 560.0179 - mae: 560.0024 - val_loss: 457.4118 - val_mae: 457.3954 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 537.4854 - mae: 537.4683 - val_loss: 435.0931 - val_mae: 435.0750 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 514.2509 - mae: 514.2319 - val_loss: 414.9287 - val_mae: 414.9085 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 492.8371 - mae: 492.8159 - val_loss: 398.6563 - val_mae: 398.6339 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 473.8294 - mae: 473.8060 - val_loss: 385.4286 - val_mae: 385.4040 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 457.7832 - mae: 457.7575 - val_loss: 373.4017 - val_mae: 373.3748 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 444.4388 - mae: 444.4108 - val_loss: 362.8425 - val_mae: 362.8132 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 431.2133 - mae: 431.1828 - val_loss: 353.6021 - val_mae: 353.5703 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 419.0754 - mae: 419.0426 - val_loss: 345.3980 - val_mae: 345.3640 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 408.1702 - mae: 408.1352 - val_loss: 337.8250 - val_mae: 337.7885 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 398.6800 - mae: 398.6426 - val_loss: 332.0449 - val_mae: 332.0062 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 390.0225 - mae: 389.9829 - val_loss: 325.5701 - val_mae: 325.5292 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 379.9939 - mae: 379.9520 - val_loss: 317.0510 - val_mae: 317.0079 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 366.1305 - mae: 366.0865 - val_loss: 305.5394 - val_mae: 305.4940 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 349.6547 - mae: 349.6082 - val_loss: 291.5979 - val_mae: 291.5500 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 752.6983\n",
      "LV_RMSE_12h: 890.8803\n",
      "LV_MAE_24h: 164.9425\n",
      "LV_RMSE_24h: 248.6225\n",
      "LV_MAE_48h: 187.5862\n",
      "LV_RMSE_48h: 274.0308\n",
      "LV_MAE_72h: 176.4167\n",
      "LV_RMSE_72h: 276.0343\n",
      "LV_MAE_mean: 320.4109\n",
      "LV_RMSE_mean: 422.3920\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 477.5373\n",
      "RMSE_12h: 627.2214\n",
      "MAE_24h: 299.6597\n",
      "RMSE_24h: 445.4383\n",
      "MAE_48h: 307.1309\n",
      "RMSE_48h: 452.9489\n",
      "MAE_72h: 320.2711\n",
      "RMSE_72h: 475.0528\n",
      "MAE_mean: 351.1497\n",
      "RMSE_mean: 500.1653\n",
      "\n",
      "=== Station S3411051 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1377 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1354, 24, 400) Ytr2: (1354, 4) \n",
      "  Xva3: (197, 24, 400) Yva2: (197, 4) \n",
      "  Xte3: (348, 24, 400) Yte2: (348, 4)\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 3s 65ms/step - loss: 115.1962 - mae: 115.1834 - val_loss: 117.7280 - val_mae: 117.7152 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 111.1948 - mae: 111.1820 - val_loss: 112.6253 - val_mae: 112.6124 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 106.5344 - mae: 106.5215 - val_loss: 106.9042 - val_mae: 106.8911 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 101.8496 - mae: 101.8363 - val_loss: 101.1557 - val_mae: 101.1421 - lr: 0.0010\n",
      "Epoch 5/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 13ms/step - loss: 96.7087 - mae: 96.6948 - val_loss: 95.0499 - val_mae: 95.0355 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 91.3846 - mae: 91.3698 - val_loss: 89.0028 - val_mae: 88.9875 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 85.9172 - mae: 85.9014 - val_loss: 83.0194 - val_mae: 83.0030 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 80.6821 - mae: 80.6652 - val_loss: 77.0796 - val_mae: 77.0621 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 74.5808 - mae: 74.5627 - val_loss: 71.2254 - val_mae: 71.2066 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 67.8205 - mae: 67.8011 - val_loss: 65.2985 - val_mae: 65.2782 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 60.3836 - mae: 60.3626 - val_loss: 60.3251 - val_mae: 60.3031 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 54.3273 - mae: 54.3044 - val_loss: 55.3857 - val_mae: 55.3617 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 50.7130 - mae: 50.6882 - val_loss: 53.0990 - val_mae: 53.0733 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 47.9444 - mae: 47.9182 - val_loss: 51.3819 - val_mae: 51.3550 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 46.2554 - mae: 46.2281 - val_loss: 49.1946 - val_mae: 49.1666 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 44.2151 - mae: 44.1867 - val_loss: 46.8249 - val_mae: 46.7959 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 42.6618 - mae: 42.6324 - val_loss: 44.4865 - val_mae: 44.4565 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 40.7095 - mae: 40.6791 - val_loss: 42.5289 - val_mae: 42.4978 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 38.5944 - mae: 38.5628 - val_loss: 39.8050 - val_mae: 39.7728 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 36.7682 - mae: 36.7355 - val_loss: 38.5441 - val_mae: 38.5107 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 214.3535\n",
      "LV_RMSE_12h: 247.8722\n",
      "LV_MAE_24h: 34.4397\n",
      "LV_RMSE_24h: 53.9498\n",
      "LV_MAE_48h: 46.0316\n",
      "LV_RMSE_48h: 70.1184\n",
      "LV_MAE_72h: 44.8764\n",
      "LV_RMSE_72h: 70.1392\n",
      "LV_MAE_mean: 84.9253\n",
      "LV_RMSE_mean: 110.5199\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 84.5263\n",
      "RMSE_12h: 128.4766\n",
      "MAE_24h: 51.2500\n",
      "RMSE_24h: 74.4537\n",
      "MAE_48h: 54.9187\n",
      "RMSE_48h: 80.6219\n",
      "MAE_72h: 59.5555\n",
      "RMSE_72h: 88.0792\n",
      "MAE_mean: 62.5626\n",
      "RMSE_mean: 92.9078\n",
      "\n",
      "=== Station S3411082 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1377 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1354, 24, 400) Ytr2: (1354, 4) \n",
      "  Xva3: (197, 24, 400) Yva2: (197, 4) \n",
      "  Xte3: (348, 24, 400) Yte2: (348, 4)\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 3s 64ms/step - loss: 2713.4995 - mae: 2713.4871 - val_loss: 2393.5479 - val_mae: 2393.5352 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 2707.8481 - mae: 2707.8352 - val_loss: 2385.3901 - val_mae: 2385.3770 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 2698.0193 - mae: 2698.0056 - val_loss: 2373.6208 - val_mae: 2373.6072 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 2684.9045 - mae: 2684.8906 - val_loss: 2358.5972 - val_mae: 2358.5828 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 2667.8284 - mae: 2667.8132 - val_loss: 2339.5898 - val_mae: 2339.5740 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 2647.2507 - mae: 2647.2336 - val_loss: 2316.2200 - val_mae: 2316.2024 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 2621.6379 - mae: 2621.6191 - val_loss: 2288.2891 - val_mae: 2288.2693 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 2591.7009 - mae: 2591.6802 - val_loss: 2255.5254 - val_mae: 2255.5034 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 2557.3369 - mae: 2557.3140 - val_loss: 2217.7695 - val_mae: 2217.7446 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 2515.8184 - mae: 2515.7920 - val_loss: 2174.8821 - val_mae: 2174.8535 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 2471.8630 - mae: 2471.8325 - val_loss: 2127.0762 - val_mae: 2127.0437 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 2422.9116 - mae: 2422.8770 - val_loss: 2074.3540 - val_mae: 2074.3169 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 2368.0884 - mae: 2368.0493 - val_loss: 2016.5986 - val_mae: 2016.5571 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 2307.3950 - mae: 2307.3511 - val_loss: 1954.0671 - val_mae: 1954.0201 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 2243.6616 - mae: 2243.6121 - val_loss: 1888.5801 - val_mae: 1888.5275 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 2175.5991 - mae: 2175.5437 - val_loss: 1821.8754 - val_mae: 1821.8164 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 2107.5986 - mae: 2107.5369 - val_loss: 1755.5879 - val_mae: 1755.5226 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 2036.4438 - mae: 2036.3756 - val_loss: 1691.9331 - val_mae: 1691.8607 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 1969.8048 - mae: 1969.7295 - val_loss: 1632.3198 - val_mae: 1632.2406 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1908.4884 - mae: 1908.4062 - val_loss: 1576.8639 - val_mae: 1576.7777 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 1808.0259\n",
      "LV_RMSE_12h: 2057.1228\n",
      "LV_MAE_24h: 436.7902\n",
      "LV_RMSE_24h: 577.2646\n",
      "LV_MAE_48h: 531.9626\n",
      "LV_RMSE_48h: 678.2300\n",
      "LV_MAE_72h: 519.2529\n",
      "LV_RMSE_72h: 663.6801\n",
      "LV_MAE_mean: 824.0079\n",
      "LV_RMSE_mean: 994.0743\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 1373.0684\n",
      "RMSE_12h: 1670.2437\n",
      "MAE_24h: 1465.6838\n",
      "RMSE_24h: 1762.8551\n",
      "MAE_48h: 1468.4059\n",
      "RMSE_48h: 1767.9478\n",
      "MAE_72h: 1410.2284\n",
      "RMSE_72h: 1698.7549\n",
      "MAE_mean: 1429.3467\n",
      "RMSE_mean: 1724.9503\n",
      "\n",
      "=== Station S3412024 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1377 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1354, 24, 400) Ytr2: (1354, 4) \n",
      "  Xva3: (197, 24, 400) Yva2: (197, 4) \n",
      "  Xte3: (348, 24, 400) Yte2: (348, 4)\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 3s 68ms/step - loss: 1508.5488 - mae: 1508.5361 - val_loss: 1468.4290 - val_mae: 1468.4159 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 1502.5791 - mae: 1502.5663 - val_loss: 1459.8971 - val_mae: 1459.8839 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1492.1445 - mae: 1492.1312 - val_loss: 1447.4602 - val_mae: 1447.4467 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1478.4348 - mae: 1478.4209 - val_loss: 1431.6843 - val_mae: 1431.6699 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1460.7024 - mae: 1460.6876 - val_loss: 1411.7860 - val_mae: 1411.7703 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 1438.7812 - mae: 1438.7649 - val_loss: 1387.4761 - val_mae: 1387.4587 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1412.6051 - mae: 1412.5869 - val_loss: 1358.6985 - val_mae: 1358.6791 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 1382.4623 - mae: 1382.4420 - val_loss: 1326.2848 - val_mae: 1326.2631 - lr: 0.0010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1349.1525 - mae: 1349.1294 - val_loss: 1293.0508 - val_mae: 1293.0261 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1316.0507 - mae: 1316.0249 - val_loss: 1261.5248 - val_mae: 1261.4972 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1284.9873 - mae: 1284.9585 - val_loss: 1231.4707 - val_mae: 1231.4399 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1257.3307 - mae: 1257.2983 - val_loss: 1204.4468 - val_mae: 1204.4127 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1231.5673 - mae: 1231.5316 - val_loss: 1178.9988 - val_mae: 1178.9612 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1207.6876 - mae: 1207.6483 - val_loss: 1154.6102 - val_mae: 1154.5691 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1181.4698 - mae: 1181.4270 - val_loss: 1131.6428 - val_mae: 1131.5978 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1160.9263 - mae: 1160.8795 - val_loss: 1109.7043 - val_mae: 1109.6555 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1138.2775 - mae: 1138.2268 - val_loss: 1088.6838 - val_mae: 1088.6310 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1114.4008 - mae: 1114.3463 - val_loss: 1066.2065 - val_mae: 1066.1498 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1095.5342 - mae: 1095.4757 - val_loss: 1039.7611 - val_mae: 1039.7003 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1062.8873 - mae: 1062.8246 - val_loss: 1005.2280 - val_mae: 1005.1628 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 1910.8822\n",
      "LV_RMSE_12h: 2097.6211\n",
      "LV_MAE_24h: 331.7989\n",
      "LV_RMSE_24h: 493.6194\n",
      "LV_MAE_48h: 364.9742\n",
      "LV_RMSE_48h: 534.9294\n",
      "LV_MAE_72h: 327.6408\n",
      "LV_RMSE_72h: 478.0723\n",
      "LV_MAE_mean: 733.8240\n",
      "LV_RMSE_mean: 901.0605\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 1153.9409\n",
      "RMSE_12h: 1477.9324\n",
      "MAE_24h: 1010.6580\n",
      "RMSE_24h: 1328.5889\n",
      "MAE_48h: 1013.8141\n",
      "RMSE_48h: 1350.6985\n",
      "MAE_72h: 1034.2244\n",
      "RMSE_72h: 1385.6522\n",
      "MAE_mean: 1053.1594\n",
      "RMSE_mean: 1385.7180\n",
      "\n",
      "=== Station S3412044 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1377 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1354, 24, 400) Ytr2: (1354, 4) \n",
      "  Xva3: (197, 24, 400) Yva2: (197, 4) \n",
      "  Xte3: (348, 24, 400) Yte2: (348, 4)\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 3s 66ms/step - loss: 1010.8044 - mae: 1010.7916 - val_loss: 958.4688 - val_mae: 958.4561 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 0s 21ms/step - loss: 1004.1915 - mae: 1004.1785 - val_loss: 949.0123 - val_mae: 948.9993 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 992.8975 - mae: 992.8844 - val_loss: 935.6652 - val_mae: 935.6516 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 978.0281 - mae: 978.0142 - val_loss: 918.2026 - val_mae: 918.1881 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 958.1576 - mae: 958.1425 - val_loss: 896.2779 - val_mae: 896.2619 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 934.2299 - mae: 934.2131 - val_loss: 869.9922 - val_mae: 869.9744 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 906.4006 - mae: 906.3817 - val_loss: 841.5400 - val_mae: 841.5198 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 877.7079 - mae: 877.6865 - val_loss: 813.7910 - val_mae: 813.7680 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 850.5342 - mae: 850.5099 - val_loss: 788.8234 - val_mae: 788.7974 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 827.4092 - mae: 827.3820 - val_loss: 766.8520 - val_mae: 766.8231 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 806.3484 - mae: 806.3181 - val_loss: 747.3927 - val_mae: 747.3607 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 787.1993 - mae: 787.1659 - val_loss: 730.4492 - val_mae: 730.4140 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 769.6952 - mae: 769.6585 - val_loss: 715.2314 - val_mae: 715.1929 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 752.7509 - mae: 752.7110 - val_loss: 698.9266 - val_mae: 698.8848 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 735.4000 - mae: 735.3566 - val_loss: 681.7363 - val_mae: 681.6912 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 717.4231 - mae: 717.3762 - val_loss: 662.5634 - val_mae: 662.5145 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 696.8820 - mae: 696.8314 - val_loss: 643.4131 - val_mae: 643.3604 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 675.5364 - mae: 675.4820 - val_loss: 621.4626 - val_mae: 621.4058 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 654.2550 - mae: 654.1964 - val_loss: 598.8071 - val_mae: 598.7460 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 631.6432 - mae: 631.5802 - val_loss: 575.6188 - val_mae: 575.5532 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 1384.0460\n",
      "LV_RMSE_12h: 1516.3506\n",
      "LV_MAE_24h: 256.4598\n",
      "LV_RMSE_24h: 391.5638\n",
      "LV_MAE_48h: 260.2011\n",
      "LV_RMSE_48h: 387.3146\n",
      "LV_MAE_72h: 250.3218\n",
      "LV_RMSE_72h: 365.8042\n",
      "LV_MAE_mean: 537.7572\n",
      "LV_RMSE_mean: 665.2583\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 843.0991\n",
      "RMSE_12h: 1062.0071\n",
      "MAE_24h: 612.8732\n",
      "RMSE_24h: 827.8870\n",
      "MAE_48h: 599.5276\n",
      "RMSE_48h: 819.1638\n",
      "MAE_72h: 616.1802\n",
      "RMSE_72h: 849.0668\n",
      "MAE_mean: 667.9200\n",
      "RMSE_mean: 889.5312\n",
      "\n",
      "=== Station S3413084 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1377 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1354, 24, 400) Ytr2: (1354, 4) \n",
      "  Xva3: (197, 24, 400) Yva2: (197, 4) \n",
      "  Xte3: (348, 24, 400) Yte2: (348, 4)\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 3s 65ms/step - loss: 2605.1362 - mae: 2605.1235 - val_loss: 2366.0083 - val_mae: 2365.9954 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 2598.5300 - mae: 2598.5171 - val_loss: 2356.4795 - val_mae: 2356.4663 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 2586.9373 - mae: 2586.9241 - val_loss: 2342.5647 - val_mae: 2342.5508 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 2571.1313 - mae: 2571.1174 - val_loss: 2324.2214 - val_mae: 2324.2065 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 2550.4351 - mae: 2550.4192 - val_loss: 2300.7866 - val_mae: 2300.7700 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 2524.6497 - mae: 2524.6321 - val_loss: 2271.5701 - val_mae: 2271.5515 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 2492.7896 - mae: 2492.7693 - val_loss: 2236.2373 - val_mae: 2236.2158 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 2454.6868 - mae: 2454.6638 - val_loss: 2194.6643 - val_mae: 2194.6396 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 2410.6323 - mae: 2410.6062 - val_loss: 2146.8569 - val_mae: 2146.8284 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 2360.0132 - mae: 2359.9827 - val_loss: 2092.6836 - val_mae: 2092.6506 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 2302.8184 - mae: 2302.7832 - val_loss: 2031.9924 - val_mae: 2031.9543 - lr: 0.0010\n",
      "Epoch 12/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 15ms/step - loss: 2240.0288 - mae: 2239.9885 - val_loss: 1964.8262 - val_mae: 1964.7823 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 2169.8262 - mae: 2169.7795 - val_loss: 1891.1525 - val_mae: 1891.1023 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 2093.4929 - mae: 2093.4395 - val_loss: 1811.3049 - val_mae: 1811.2479 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 2011.5054 - mae: 2011.4452 - val_loss: 1728.5839 - val_mae: 1728.5194 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1930.6531 - mae: 1930.5850 - val_loss: 1649.4053 - val_mae: 1649.3331 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1853.0154 - mae: 1852.9395 - val_loss: 1576.3799 - val_mae: 1576.2997 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1777.2227 - mae: 1777.1388 - val_loss: 1510.2988 - val_mae: 1510.2107 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1711.6603 - mae: 1711.5685 - val_loss: 1450.2083 - val_mae: 1450.1119 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 1653.8062 - mae: 1653.7063 - val_loss: 1394.8776 - val_mae: 1394.7732 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 1635.0747\n",
      "LV_RMSE_12h: 1843.0952\n",
      "LV_MAE_24h: 374.4885\n",
      "LV_RMSE_24h: 524.9490\n",
      "LV_MAE_48h: 452.0948\n",
      "LV_RMSE_48h: 625.0432\n",
      "LV_MAE_72h: 459.3851\n",
      "LV_RMSE_72h: 696.5499\n",
      "LV_MAE_mean: 730.2607\n",
      "LV_RMSE_mean: 922.4093\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 1244.4475\n",
      "RMSE_12h: 1481.2681\n",
      "MAE_24h: 1287.0693\n",
      "RMSE_24h: 1524.9500\n",
      "MAE_48h: 1284.0533\n",
      "RMSE_48h: 1519.0968\n",
      "MAE_72h: 1337.7573\n",
      "RMSE_72h: 1613.3187\n",
      "MAE_mean: 1288.3319\n",
      "RMSE_mean: 1534.6584\n",
      "\n",
      "=== Station S3415042 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 1317 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (1294, 24, 400) Ytr2: (1294, 4) \n",
      "  Xva3: (189, 24, 400) Yva2: (189, 4) \n",
      "  Xte3: (330, 24, 400) Yte2: (330, 4)\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 3s 65ms/step - loss: 60.5806 - mae: 60.5679 - val_loss: 53.4758 - val_mae: 53.4632 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 56.1551 - mae: 56.1425 - val_loss: 47.6331 - val_mae: 47.6204 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 49.7311 - mae: 49.7184 - val_loss: 41.5842 - val_mae: 41.5713 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 44.0693 - mae: 44.0562 - val_loss: 37.3471 - val_mae: 37.3338 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 40.1982 - mae: 40.1847 - val_loss: 34.8040 - val_mae: 34.7901 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 37.6365 - mae: 37.6225 - val_loss: 33.1730 - val_mae: 33.1588 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 35.5585 - mae: 35.5442 - val_loss: 30.5725 - val_mae: 30.5580 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 0s 15ms/step - loss: 33.1709 - mae: 33.1563 - val_loss: 27.9938 - val_mae: 27.9791 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 31.2549 - mae: 31.2400 - val_loss: 26.1172 - val_mae: 26.1021 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 29.9219 - mae: 29.9067 - val_loss: 24.5258 - val_mae: 24.5105 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 28.2233 - mae: 28.2079 - val_loss: 23.2653 - val_mae: 23.2498 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 27.0950 - mae: 27.0793 - val_loss: 22.1696 - val_mae: 22.1536 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 26.0549 - mae: 26.0387 - val_loss: 21.1981 - val_mae: 21.1816 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 24.7977 - mae: 24.7810 - val_loss: 20.1475 - val_mae: 20.1304 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 24.0116 - mae: 23.9942 - val_loss: 19.2172 - val_mae: 19.1995 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 22.8038 - mae: 22.7858 - val_loss: 18.1476 - val_mae: 18.1293 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 22.0586 - mae: 22.0400 - val_loss: 17.0588 - val_mae: 17.0398 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 20.9627 - mae: 20.9435 - val_loss: 16.4660 - val_mae: 16.4464 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 20.2031 - mae: 20.1833 - val_loss: 15.2810 - val_mae: 15.2609 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 19.4788 - mae: 19.4584 - val_loss: 14.4207 - val_mae: 14.4000 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 63.2576\n",
      "LV_RMSE_12h: 73.8966\n",
      "LV_MAE_24h: 14.9212\n",
      "LV_RMSE_24h: 21.7017\n",
      "LV_MAE_48h: 18.0333\n",
      "LV_RMSE_48h: 25.4772\n",
      "LV_MAE_72h: 15.0606\n",
      "LV_RMSE_72h: 21.7032\n",
      "LV_MAE_mean: 27.8182\n",
      "LV_RMSE_mean: 35.6947\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 19.5139\n",
      "RMSE_12h: 26.6076\n",
      "MAE_24h: 13.3526\n",
      "RMSE_24h: 18.0838\n",
      "MAE_48h: 13.2286\n",
      "RMSE_48h: 18.0931\n",
      "MAE_72h: 13.0371\n",
      "RMSE_72h: 17.8890\n",
      "MAE_mean: 14.7830\n",
      "RMSE_mean: 20.1684\n",
      "\n",
      "=== Station S3420081 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 218 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (195, 24, 400) Ytr2: (195, 4) \n",
      "  Xva3: (32, 24, 400) Yva2: (32, 4) \n",
      "  Xte3: (16, 24, 400) Yte2: (16, 4)\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 3s 526ms/step - loss: 145.8818 - mae: 145.8691 - val_loss: 139.1400 - val_mae: 139.1273 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 145.2777 - mae: 145.2650 - val_loss: 138.5508 - val_mae: 138.5381 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 144.6034 - mae: 144.5907 - val_loss: 137.8964 - val_mae: 137.8837 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 143.9051 - mae: 143.8924 - val_loss: 137.1391 - val_mae: 137.1264 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 143.0602 - mae: 143.0475 - val_loss: 136.2368 - val_mae: 136.2241 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 142.0818 - mae: 142.0690 - val_loss: 135.2779 - val_mae: 135.2651 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 141.0553 - mae: 141.0425 - val_loss: 134.2359 - val_mae: 134.2231 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 140.0075 - mae: 139.9947 - val_loss: 133.1277 - val_mae: 133.1149 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 138.8122 - mae: 138.7994 - val_loss: 132.0427 - val_mae: 132.0298 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 137.7444 - mae: 137.7315 - val_loss: 130.8795 - val_mae: 130.8666 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 136.7415 - mae: 136.7286 - val_loss: 129.7450 - val_mae: 129.7320 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 135.3220 - mae: 135.3090 - val_loss: 128.6504 - val_mae: 128.6373 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 134.0465 - mae: 134.0335 - val_loss: 127.5174 - val_mae: 127.5043 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 133.0093 - mae: 132.9962 - val_loss: 126.3458 - val_mae: 126.3326 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 131.8008 - mae: 131.7876 - val_loss: 125.1537 - val_mae: 125.1404 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 130.4574 - mae: 130.4441 - val_loss: 123.9313 - val_mae: 123.9179 - lr: 0.0010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 129.1863 - mae: 129.1730 - val_loss: 122.6807 - val_mae: 122.6672 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 127.8018 - mae: 127.7884 - val_loss: 121.4102 - val_mae: 121.3967 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 126.3768 - mae: 126.3632 - val_loss: 120.0627 - val_mae: 120.0490 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 124.8238 - mae: 124.8100 - val_loss: 118.6278 - val_mae: 118.6140 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 201.2500\n",
      "LV_RMSE_12h: 222.9355\n",
      "LV_MAE_24h: 17.9375\n",
      "LV_RMSE_24h: 24.3400\n",
      "LV_MAE_48h: 18.5000\n",
      "LV_RMSE_48h: 26.2869\n",
      "LV_MAE_72h: 68.5625\n",
      "LV_RMSE_72h: 95.6076\n",
      "LV_MAE_mean: 76.5625\n",
      "LV_RMSE_mean: 92.2925\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 88.4186\n",
      "RMSE_12h: 123.4778\n",
      "MAE_24h: 166.3672\n",
      "RMSE_24h: 190.8309\n",
      "MAE_48h: 152.5328\n",
      "RMSE_48h: 173.1497\n",
      "MAE_72h: 229.4411\n",
      "RMSE_72h: 265.1838\n",
      "MAE_mean: 159.1899\n",
      "RMSE_mean: 188.1605\n",
      "\n",
      "=== Station S3420084 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 218 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (195, 24, 400) Ytr2: (195, 4) \n",
      "  Xva3: (32, 24, 400) Yva2: (32, 4) \n",
      "  Xte3: (16, 24, 400) Yte2: (16, 4)\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 3s 533ms/step - loss: 356.0262 - mae: 356.0134 - val_loss: 380.8842 - val_mae: 380.8714 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 355.7137 - mae: 355.7009 - val_loss: 380.7228 - val_mae: 380.7100 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 355.2928 - mae: 355.2800 - val_loss: 380.5058 - val_mae: 380.4930 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 354.7447 - mae: 354.7318 - val_loss: 380.2345 - val_mae: 380.2216 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 354.0540 - mae: 354.0412 - val_loss: 379.8503 - val_mae: 379.8375 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 353.3315 - mae: 353.3186 - val_loss: 379.2229 - val_mae: 379.2100 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 352.4849 - mae: 352.4720 - val_loss: 378.3359 - val_mae: 378.3229 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 351.6156 - mae: 351.6026 - val_loss: 377.3989 - val_mae: 377.3859 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 350.5291 - mae: 350.5160 - val_loss: 376.4678 - val_mae: 376.4547 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 349.5432 - mae: 349.5301 - val_loss: 375.5663 - val_mae: 375.5531 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 348.5937 - mae: 348.5804 - val_loss: 374.6121 - val_mae: 374.5988 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 347.3134 - mae: 347.3001 - val_loss: 373.5468 - val_mae: 373.5334 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 346.2659 - mae: 346.2525 - val_loss: 372.5030 - val_mae: 372.4895 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 345.2643 - mae: 345.2509 - val_loss: 371.4868 - val_mae: 371.4731 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 343.8899 - mae: 343.8763 - val_loss: 370.4110 - val_mae: 370.3972 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 342.9301 - mae: 342.9163 - val_loss: 369.2748 - val_mae: 369.2609 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 341.6425 - mae: 341.6285 - val_loss: 368.0719 - val_mae: 368.0579 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 340.4306 - mae: 340.4165 - val_loss: 366.8836 - val_mae: 366.8694 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 338.6751 - mae: 338.6609 - val_loss: 365.6811 - val_mae: 365.6667 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 337.3441 - mae: 337.3297 - val_loss: 364.3821 - val_mae: 364.3675 - lr: 0.0010\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 589.8750\n",
      "LV_RMSE_12h: 853.2776\n",
      "LV_MAE_24h: 1150.4375\n",
      "LV_RMSE_24h: 1257.0111\n",
      "LV_MAE_48h: 502.7500\n",
      "LV_RMSE_48h: 812.9369\n",
      "LV_MAE_72h: 1283.0000\n",
      "LV_RMSE_72h: 1375.0116\n",
      "LV_MAE_mean: 881.5156\n",
      "LV_RMSE_mean: 1074.5593\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 419.8991\n",
      "RMSE_12h: 799.0060\n",
      "MAE_24h: 1367.0059\n",
      "RMSE_24h: 1489.2833\n",
      "MAE_48h: 619.4900\n",
      "RMSE_48h: 975.5472\n",
      "MAE_72h: 1504.5076\n",
      "RMSE_72h: 1621.8496\n",
      "MAE_mean: 977.7256\n",
      "RMSE_mean: 1221.4215\n",
      "\n",
      "=== Station S3420097 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[S3420097] ERROR: No training rows after alignment. Check the data index and feature build.\n",
      "\n",
      "=== Station S3422058 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[S3422058] ERROR: No training rows after alignment. Check the data index and feature build.\n",
      "\n",
      "=== Station S3423062 ===\n",
      "[neighbors] picked 30 neighbors\n",
      "[GB] computing importances on 168 rows, 1631 features...\n",
      "[select] kept top-400 features\n",
      "Shapes: \n",
      "  Xtr3: (145, 24, 400) Ytr2: (145, 4) \n",
      "  Xva3: (25, 24, 400) Yva2: (25, 4) \n",
      "  Xte3: (1, 24, 400) Yte2: (1, 4)\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 3s 551ms/step - loss: 4.6957 - mae: 4.6830 - val_loss: 3.6518 - val_mae: 3.6391 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 4.2489 - mae: 4.2361 - val_loss: 3.2844 - val_mae: 3.2717 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 3.8252 - mae: 3.8125 - val_loss: 2.9668 - val_mae: 2.9541 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 3.4730 - mae: 3.4603 - val_loss: 2.7234 - val_mae: 2.7107 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 3.2118 - mae: 3.1991 - val_loss: 2.4958 - val_mae: 2.4831 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 2.9434 - mae: 2.9307 - val_loss: 2.2927 - val_mae: 2.2799 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 2.6861 - mae: 2.6734 - val_loss: 2.1118 - val_mae: 2.0991 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 2.5063 - mae: 2.4936 - val_loss: 2.0010 - val_mae: 1.9882 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 2.3853 - mae: 2.3726 - val_loss: 1.9382 - val_mae: 1.9255 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 2.3345 - mae: 2.3217 - val_loss: 1.9113 - val_mae: 1.8985 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 2.2834 - mae: 2.2706 - val_loss: 1.9172 - val_mae: 1.9044 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 2.2718 - mae: 2.2590 - val_loss: 1.9298 - val_mae: 1.9170 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 2.2064 - mae: 2.1936 - val_loss: 1.9319 - val_mae: 1.9191 - lr: 5.0000e-04\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 2.1231 - mae: 2.1104 - val_loss: 1.9379 - val_mae: 1.9251 - lr: 5.0000e-04\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 2.2346 - mae: 2.2218 - val_loss: 1.9463 - val_mae: 1.9336 - lr: 2.5000e-04\n",
      "\n",
      "Baseline (LV) metrics:\n",
      "LV_MAE_12h: 15.0000\n",
      "LV_RMSE_12h: 15.0000\n",
      "LV_MAE_24h: 3.0000\n",
      "LV_RMSE_24h: 3.0000\n",
      "LV_MAE_48h: 0.0000\n",
      "LV_RMSE_48h: 0.0000\n",
      "LV_MAE_72h: 1.0000\n",
      "LV_RMSE_72h: 1.0000\n",
      "LV_MAE_mean: 4.7500\n",
      "LV_RMSE_mean: 4.7500\n",
      "\n",
      "Conv1D+LSTM Test metrics:\n",
      "MAE_12h: 7.8998\n",
      "RMSE_12h: 7.8998\n",
      "MAE_24h: 2.3801\n",
      "RMSE_24h: 2.3801\n",
      "MAE_48h: 0.9992\n",
      "RMSE_48h: 0.9992\n",
      "MAE_72h: 0.2810\n",
      "RMSE_72h: 0.2810\n",
      "MAE_mean: 2.8900\n",
      "RMSE_mean: 2.8900\n",
      "\n",
      "[summary] updated summary_all_stations.csv\n",
      "\n",
      "Computing overall metrics (macro & micro) from saved predictions...\n",
      "Overall (macro avg of station means): {'MAE_macro': 456.2397761038078, 'RMSE_macro': 572.301864700658}\n",
      "Overall (micro on pooled errors):     {'MAE_micro': 465.13788457645586, 'RMSE_micro': 979.9201174392617, 'n_samples': 542672}\n"
     ]
    }
   ],
   "source": [
    "# ======================= RESUME + SAMPLE + OVERALL METRICS =======================\n",
    "import os, pandas as pd, numpy as np\n",
    "\n",
    "# ---------- CONFIG (edit as needed) ----------\n",
    "STATION_SAMPLE_N        = 120           # None → use all remaining stations\n",
    "STATION_SAMPLE_METHOD   = \"stratified\"  # \"random\" | \"stratified\" | \"list\"\n",
    "INCLUDED_STATIONS_LIST  = None          # if method == \"list\", e.g. [\"S3001021\", \"S3001101\"]\n",
    "RANDOM_SEED             = 42\n",
    "SKIP_IF_EXISTS          = True          # skip if per_station/<station>/model.h5 exists\n",
    "\n",
    "# (Keep your original definitions for these in the prior cell)\n",
    "# Required globals: df (with DateTimeIndex), STATION_COL, FLOW_COL, HORIZONS,\n",
    "#                   ORDERED_COLS, LOOKBACK,\n",
    "#                   compute_flow_wide(), run_one_station_fast()\n",
    "\n",
    "# ---------- sanity checks ----------\n",
    "missing = []\n",
    "for name in [\"df\", \"STATION_COL\", \"FLOW_COL\", \"HORIZONS\", \"ORDERED_COLS\", \"LOOKBACK\"]:\n",
    "    if name not in globals():\n",
    "        missing.append(name)\n",
    "for fn in [\"compute_flow_wide\", \"run_one_station_fast\"]:\n",
    "    if fn not in globals():\n",
    "        missing.append(fn)\n",
    "if missing:\n",
    "    raise RuntimeError(\n",
    "        \"Missing required definitions: \"\n",
    "        + \", \".join(missing)\n",
    "        + \"\\nPlease re-run your big per-station cell first.\"\n",
    "    )\n",
    "\n",
    "# ---------- helpers ----------\n",
    "def list_trained_stations(base_dir=\"per_station\"):\n",
    "    if not os.path.exists(base_dir):\n",
    "        return []\n",
    "    done = []\n",
    "    for d in os.listdir(base_dir):\n",
    "        m = os.path.join(base_dir, d, \"model.h5\")\n",
    "        if os.path.exists(m):\n",
    "            done.append(d)\n",
    "    return sorted(done)\n",
    "\n",
    "def rebuild_summary_from_metrics(base_dir=\"per_station\", outfile=\"summary_all_stations.csv\"):\n",
    "    rows = []\n",
    "    if not os.path.exists(base_dir):\n",
    "        print(\"[summary] base_dir not found; nothing to rebuild.\")\n",
    "        return None\n",
    "    for s in os.listdir(base_dir):\n",
    "        mpath = os.path.join(base_dir, s, \"metrics.csv\")\n",
    "        if os.path.exists(mpath):\n",
    "            try:\n",
    "                mdf = pd.read_csv(mpath)\n",
    "                row = {\"station\": s}\n",
    "                row.update({k: float(v) for k, v in zip(mdf[\"metric\"], mdf[\"value\"])})\n",
    "                rows.append(row)\n",
    "            except Exception:\n",
    "                pass\n",
    "    if rows:\n",
    "        sdf = pd.DataFrame(rows)\n",
    "        if \"MAE_mean\" in sdf.columns:\n",
    "            sdf = sdf.sort_values(\"MAE_mean\")\n",
    "        sdf.to_csv(outfile, index=False)\n",
    "        print(f\"[summary] wrote {outfile} with {len(rows)} rows\")\n",
    "        return sdf\n",
    "    else:\n",
    "        print(\"[summary] no metrics found to rebuild.\")\n",
    "        return None\n",
    "\n",
    "def sample_stations(df, method=\"stratified\", n=None, seed=42, include_list=None, exclude_set=None):\n",
    "    stations_all = sorted(df[STATION_COL].dropna().unique().tolist())\n",
    "    if exclude_set:\n",
    "        stations_all = [s for s in stations_all if s not in exclude_set]\n",
    "\n",
    "    if method == \"list\":\n",
    "        keep = [s for s in (include_list or []) if s in stations_all]\n",
    "        return keep if (n is None or n >= len(keep)) else keep[:n]\n",
    "\n",
    "    if (n is None) or (n >= len(stations_all)):\n",
    "        return stations_all\n",
    "\n",
    "    rng = np.random.default_rng(seed)\n",
    "\n",
    "    if method == \"random\":\n",
    "        return sorted(rng.choice(stations_all, size=n, replace=False).tolist())\n",
    "\n",
    "    # default: stratified by average flow deciles\n",
    "    stats = (\n",
    "        df[[STATION_COL, FLOW_COL]]\n",
    "        .dropna()\n",
    "        .groupby(STATION_COL)[FLOW_COL]\n",
    "        .mean()\n",
    "        .rename(\"avg_flow\")\n",
    "        .to_frame()\n",
    "        .loc[stations_all]\n",
    "    )\n",
    "    try:\n",
    "        stats[\"bin\"] = pd.qcut(stats[\"avg_flow\"], q=10, labels=False, duplicates=\"drop\")\n",
    "    except Exception:\n",
    "        stats[\"bin\"] = 0\n",
    "\n",
    "    bins = stats[\"bin\"].unique()\n",
    "    total = len(stats)\n",
    "    alloc = {}\n",
    "    for b in sorted(bins):\n",
    "        count_b = (stats[\"bin\"] == b).sum()\n",
    "        alloc[b] = max(1, round(n * (count_b / total)))\n",
    "\n",
    "    diff = n - sum(alloc.values())\n",
    "    order = sorted(alloc, key=lambda b: alloc[b], reverse=(diff > 0))\n",
    "    i = 0\n",
    "    while diff != 0 and order:\n",
    "        b = order[i % len(order)]\n",
    "        if diff > 0:\n",
    "            alloc[b] += 1; diff -= 1\n",
    "        else:\n",
    "            if alloc[b] > 1:\n",
    "                alloc[b] -= 1; diff += 1\n",
    "        i += 1\n",
    "\n",
    "    picked = []\n",
    "    for b in sorted(bins):\n",
    "        pool = stats[stats[\"bin\"] == b].index.tolist()\n",
    "        if not pool:\n",
    "            continue\n",
    "        k = min(alloc[b], len(pool))\n",
    "        sel = rng.choice(pool, size=k, replace=False).tolist()\n",
    "        picked.extend(sel)\n",
    "    return sorted(picked[:n])\n",
    "\n",
    "def compute_overall_metrics(base_dir=\"per_station\"):\n",
    "    macro_rows, pooled_abs, pooled_sq = [], [], []\n",
    "    n_total = 0\n",
    "    for s in os.listdir(base_dir) if os.path.exists(base_dir) else []:\n",
    "        mpath = os.path.join(base_dir, s, \"metrics.csv\")\n",
    "        ppath = os.path.join(base_dir, s, \"preds_test.csv\")\n",
    "        if os.path.exists(mpath):\n",
    "            mdf = pd.read_csv(mpath)\n",
    "            m = {k:v for k,v in zip(mdf[\"metric\"], mdf[\"value\"])}\n",
    "            m[\"station\"] = s\n",
    "            macro_rows.append(m)\n",
    "        if os.path.exists(ppath):\n",
    "            pdf = pd.read_csv(ppath, index_col=0)\n",
    "            for col in pdf.columns:\n",
    "                if col.startswith(\"ytrue_\"):\n",
    "                    h = col.replace(\"ytrue_\", \"\")\n",
    "                    y    = pdf[col].values.astype(np.float64)\n",
    "                    yhat = pdf.get(\"ypred_\" + h)\n",
    "                    if yhat is None: \n",
    "                        continue\n",
    "                    yhat = yhat.values.astype(np.float64)\n",
    "                    err = y - yhat\n",
    "                    pooled_abs.append(np.abs(err))\n",
    "                    pooled_sq.append(err**2)\n",
    "                    n_total += len(err)\n",
    "    macro, micro = {}, {}\n",
    "    if macro_rows:\n",
    "        mdf = pd.DataFrame(macro_rows)\n",
    "        if \"MAE_mean\" in mdf.columns:\n",
    "            macro[\"MAE_macro\"]  = float(mdf[\"MAE_mean\"].mean())\n",
    "        if \"RMSE_mean\" in mdf.columns:\n",
    "            macro[\"RMSE_macro\"] = float(mdf[\"RMSE_mean\"].mean())\n",
    "    if pooled_abs and pooled_sq:\n",
    "        pooled_abs = np.concatenate(pooled_abs)\n",
    "        pooled_sq  = np.concatenate(pooled_sq)\n",
    "        micro[\"MAE_micro\"]  = float(pooled_abs.mean())\n",
    "        micro[\"RMSE_micro\"] = float(np.sqrt(pooled_sq.mean()))\n",
    "        micro[\"n_samples\"]  = int(n_total)\n",
    "    return {\"macro\": macro, \"micro\": micro}\n",
    "\n",
    "# ---------- main runner (resume-aware, sampling, skip-if-exists) ----------\n",
    "def run_all_stations_fast_resume(df):\n",
    "    if not isinstance(df.index, pd.DatetimeIndex):\n",
    "        raise ValueError(\"df must have a DateTimeIndex\")\n",
    "\n",
    "    os.makedirs(\"per_station\", exist_ok=True)\n",
    "\n",
    "    done = set(list_trained_stations(\"per_station\"))\n",
    "    print(f\"[resume] already-trained stations: {len(done)}\")\n",
    "    _ = rebuild_summary_from_metrics(\"per_station\", \"summary_all_stations.csv\")\n",
    "\n",
    "    print(\"[prep] computing flow_wide...\")\n",
    "    flow_wide = compute_flow_wide(df)\n",
    "\n",
    "    stations_all = sorted(df[STATION_COL].dropna().unique())\n",
    "    remaining = [s for s in stations_all if s not in done]\n",
    "    print(f\"[stations] total: {len(stations_all)} | remaining to train: {len(remaining)}\")\n",
    "\n",
    "    stations = sample_stations(\n",
    "        df=df,\n",
    "        method=STATION_SAMPLE_METHOD,\n",
    "        n=STATION_SAMPLE_N,\n",
    "        seed=RANDOM_SEED,\n",
    "        include_list=INCLUDED_STATIONS_LIST,\n",
    "        exclude_set=done,\n",
    "    )\n",
    "    print(f\"[sampling] selected {len(stations)} new stations to train \"\n",
    "          f\"(method='{STATION_SAMPLE_METHOD}', n={STATION_SAMPLE_N})\")\n",
    "\n",
    "    summary_rows = []\n",
    "    for s in stations:\n",
    "        try:\n",
    "            station_dir = f\"per_station/{s}\"\n",
    "            model_path  = f\"{station_dir}/model.h5\"\n",
    "            if SKIP_IF_EXISTS and os.path.exists(model_path):\n",
    "                print(f\"\\n=== Station {s} ===\")\n",
    "                print(\"[skip] model exists ->\", model_path)\n",
    "                metrics_csv = f\"{station_dir}/metrics.csv\"\n",
    "                if os.path.exists(metrics_csv):\n",
    "                    mdf = pd.read_csv(metrics_csv)\n",
    "                    row = {\"station\": s}\n",
    "                    row.update({k: float(v) for k, v in zip(mdf[\"metric\"], mdf[\"value\"])})\n",
    "                    summary_rows.append(row)\n",
    "                continue\n",
    "\n",
    "            row = run_one_station_fast(df, flow_wide, s)\n",
    "            summary_rows.append(row)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"[{s}] ERROR: {e}\")\n",
    "\n",
    "    if summary_rows:\n",
    "        new_df = pd.DataFrame(summary_rows)\n",
    "        try:\n",
    "            old_df = pd.read_csv(\"summary_all_stations.csv\")\n",
    "        except Exception:\n",
    "            old_df = pd.DataFrame()\n",
    "        if not old_df.empty:\n",
    "            comb = pd.concat([old_df, new_df], ignore_index=True)\n",
    "            comb = comb.sort_values(by=[\"station\"]).drop_duplicates(subset=[\"station\"], keep=\"last\")\n",
    "        else:\n",
    "            comb = new_df\n",
    "        if \"MAE_mean\" in comb.columns:\n",
    "            comb = comb.sort_values(\"MAE_mean\")\n",
    "        comb.to_csv(\"summary_all_stations.csv\", index=False)\n",
    "        print(\"\\n[summary] updated summary_all_stations.csv\")\n",
    "    else:\n",
    "        print(\"No new station results produced. Check inputs and schema.\")\n",
    "\n",
    "# ---------- Run ----------\n",
    "print(\"Re-checking done stations before resume...\")\n",
    "done_stations_now = list_trained_stations(\"per_station\")\n",
    "print(f\"{len(done_stations_now)} stations already trained.\")\n",
    "\n",
    "print(\"\\nStarting resume + sample run...\")\n",
    "run_all_stations_fast_resume(df)\n",
    "\n",
    "print(\"\\nComputing overall metrics (macro & micro) from saved predictions...\")\n",
    "overall = compute_overall_metrics(\"per_station\")\n",
    "print(\"Overall (macro avg of station means):\", overall[\"macro\"])\n",
    "print(\"Overall (micro on pooled errors):    \", overall[\"micro\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "7dbf66df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[saved] per-horizon overall metrics → per_station/overall_by_horizon_lstm.csv\n",
      "\n",
      "Per-horizon (macro):\n",
      "12h: {'MAE_macro': 530.8919310264218, 'RMSE_macro': 654.2381599898071}\n",
      "24h: {'MAE_macro': 431.3658694956429, 'RMSE_macro': 543.8627644009258}\n",
      "48h: {'MAE_macro': 430.51299292921794, 'RMSE_macro': 545.2601561775624}\n",
      "72h: {'MAE_macro': 432.18831017228007, 'RMSE_macro': 545.8463633614961}\n",
      "\n",
      "Per-horizon (micro):\n",
      "12h: {'MAE_micro': 544.1178594252028, 'RMSE_micro': 1013.4399441034329, 'n_samples': 135668}\n",
      "24h: {'MAE_micro': 438.3998942485628, 'RMSE_micro': 967.3142073957155, 'n_samples': 135668}\n",
      "48h: {'MAE_micro': 439.3299322840626, 'RMSE_micro': 970.0893454018855, 'n_samples': 135668}\n",
      "72h: {'MAE_micro': 438.70385234799545, 'RMSE_micro': 968.0615228654001, 'n_samples': 135668}\n",
      "\n",
      "Across horizons (macro mean of per-h): {'MAE_macro_all_h': 456.2397759058907, 'RMSE_macro_all_h': 572.3018609824478}\n",
      "Across horizons (micro pooled all-h):  {'MAE_micro_all_h': 465.13788457645603, 'RMSE_micro_all_h': 979.9201174392618, 'n_samples_all_h': 542672}\n"
     ]
    }
   ],
   "source": [
    "# ================== LSTM: OVERALL METRICS BY HORIZON (MACRO & MICRO) ==================\n",
    "import os, numpy as np, pandas as pd\n",
    "\n",
    "HORIZONS = [12, 24, 48, 72]\n",
    "BASE_DIR = \"per_station\"   # <- change if your LSTM outputs live elsewhere\n",
    "\n",
    "def compute_overall_by_horizon(base_dir=BASE_DIR, horizons=HORIZONS):\n",
    "    # containers\n",
    "    macro_lists = {h: {\"mae\": [], \"rmse\": []} for h in horizons}\n",
    "    micro_abs   = {h: [] for h in horizons}\n",
    "    micro_sq    = {h: [] for h in horizons}\n",
    "    micro_n     = {h: 0  for h in horizons}\n",
    "\n",
    "    # scan stations\n",
    "    if not os.path.exists(base_dir):\n",
    "        raise FileNotFoundError(f\"{base_dir} not found\")\n",
    "\n",
    "    stations = [d for d in os.listdir(base_dir) if os.path.isdir(os.path.join(base_dir, d))]\n",
    "    for s in stations:\n",
    "        ppath = os.path.join(base_dir, s, \"preds_test.csv\")\n",
    "        if not os.path.exists(ppath):\n",
    "            continue\n",
    "        pdf = pd.read_csv(ppath, index_col=0)\n",
    "\n",
    "        # compute per-station per-horizon metrics (to later macro-average)\n",
    "        station_mae = {}\n",
    "        station_rmse = {}\n",
    "        for h in horizons:\n",
    "            ytrue_col = f\"ytrue_y_{h}h\"\n",
    "            ypred_col = f\"ypred_y_{h}h\"\n",
    "            if ytrue_col not in pdf.columns or ypred_col not in pdf.columns:\n",
    "                continue\n",
    "            y  = pdf[ytrue_col].values.astype(np.float64)\n",
    "            yhat = pdf[ypred_col].values.astype(np.float64)\n",
    "            err = y - yhat\n",
    "            mae = np.abs(err).mean()\n",
    "            rmse = np.sqrt((err**2).mean())\n",
    "            station_mae[h] = mae\n",
    "            station_rmse[h] = rmse\n",
    "\n",
    "            # pool for micro\n",
    "            micro_abs[h].append(np.abs(err))\n",
    "            micro_sq[h].append(err**2)\n",
    "            micro_n[h] += len(err)\n",
    "\n",
    "        # push station metrics into macro containers\n",
    "        for h in station_mae:\n",
    "            macro_lists[h][\"mae\"].append(station_mae[h])\n",
    "            macro_lists[h][\"rmse\"].append(station_rmse[h])\n",
    "\n",
    "    # aggregate\n",
    "    macro_out = {}\n",
    "    micro_out = {}\n",
    "    rows = []\n",
    "    for h in horizons:\n",
    "        # macro\n",
    "        mae_macro = float(np.mean(macro_lists[h][\"mae\"])) if macro_lists[h][\"mae\"] else np.nan\n",
    "        rmse_macro = float(np.mean(macro_lists[h][\"rmse\"])) if macro_lists[h][\"rmse\"] else np.nan\n",
    "        macro_out[h] = {\"MAE_macro\": mae_macro, \"RMSE_macro\": rmse_macro}\n",
    "\n",
    "        # micro\n",
    "        if micro_abs[h] and micro_sq[h]:\n",
    "            abs_all = np.concatenate(micro_abs[h])\n",
    "            sq_all  = np.concatenate(micro_sq[h])\n",
    "            mae_micro = float(abs_all.mean())\n",
    "            rmse_micro = float(np.sqrt(sq_all.mean()))\n",
    "            n_samp = int(micro_n[h])\n",
    "        else:\n",
    "            mae_micro = np.nan; rmse_micro = np.nan; n_samp = 0\n",
    "\n",
    "        micro_out[h] = {\"MAE_micro\": mae_micro, \"RMSE_micro\": rmse_micro, \"n_samples\": n_samp}\n",
    "\n",
    "        rows.append({\n",
    "            \"horizon\": f\"{h}h\",\n",
    "            \"MAE_macro\": mae_macro, \"RMSE_macro\": rmse_macro,\n",
    "            \"MAE_micro\": mae_micro, \"RMSE_micro\": rmse_micro,\n",
    "            \"n_samples\": n_samp\n",
    "        })\n",
    "\n",
    "    # also compute all-horizons pooled (micro_all) and macro mean across horizons (macro_all)\n",
    "    # macro_all: average the per-horizon macro numbers (ignores horizon sample imbalance)\n",
    "    valid_macro_mae = [macro_out[h][\"MAE_macro\"] for h in horizons if not np.isnan(macro_out[h][\"MAE_macro\"])]\n",
    "    valid_macro_rmse= [macro_out[h][\"RMSE_macro\"] for h in horizons if not np.isnan(macro_out[h][\"RMSE_macro\"])]\n",
    "    macro_all = {\n",
    "        \"MAE_macro_all_h\": float(np.mean(valid_macro_mae)) if valid_macro_mae else np.nan,\n",
    "        \"RMSE_macro_all_h\": float(np.mean(valid_macro_rmse)) if valid_macro_rmse else np.nan\n",
    "    }\n",
    "\n",
    "    # micro_all: pool ALL horizons together (this should match your previous “Overall (micro)”)\n",
    "    pooled_abs_all = []\n",
    "    pooled_sq_all  = []\n",
    "    n_all = 0\n",
    "    for h in horizons:\n",
    "        if micro_abs[h] and micro_sq[h]:\n",
    "            pooled_abs_all.append(np.concatenate(micro_abs[h]))\n",
    "            pooled_sq_all.append(np.concatenate(micro_sq[h]))\n",
    "            n_all += micro_n[h]\n",
    "    if pooled_abs_all and pooled_sq_all:\n",
    "        pooled_abs_all = np.concatenate(pooled_abs_all)\n",
    "        pooled_sq_all  = np.concatenate(pooled_sq_all)\n",
    "        micro_all = {\n",
    "            \"MAE_micro_all_h\": float(pooled_abs_all.mean()),\n",
    "            \"RMSE_micro_all_h\": float(np.sqrt(pooled_sq_all.mean())),\n",
    "            \"n_samples_all_h\": int(n_all)\n",
    "        }\n",
    "    else:\n",
    "        micro_all = {\"MAE_micro_all_h\": np.nan, \"RMSE_micro_all_h\": np.nan, \"n_samples_all_h\": 0}\n",
    "\n",
    "    # save table\n",
    "    out_df = pd.DataFrame(rows)\n",
    "    out_csv = os.path.join(base_dir, \"overall_by_horizon_lstm.csv\")\n",
    "    out_df.to_csv(out_csv, index=False)\n",
    "    print(f\"[saved] per-horizon overall metrics → {out_csv}\")\n",
    "\n",
    "    return {\"macro_by_h\": macro_out, \"micro_by_h\": micro_out, \"macro_all\": macro_all, \"micro_all\": micro_all, \"table\": out_df}\n",
    "\n",
    "# -------- run it --------\n",
    "overall_h = compute_overall_by_horizon(BASE_DIR, HORIZONS)\n",
    "\n",
    "print(\"\\nPer-horizon (macro):\")\n",
    "for h, d in overall_h[\"macro_by_h\"].items():\n",
    "    print(f\"{h}h:\", d)\n",
    "\n",
    "print(\"\\nPer-horizon (micro):\")\n",
    "for h, d in overall_h[\"micro_by_h\"].items():\n",
    "    print(f\"{h}h:\", d)\n",
    "\n",
    "print(\"\\nAcross horizons (macro mean of per-h):\", overall_h[\"macro_all\"])\n",
    "print(\"Across horizons (micro pooled all-h): \", overall_h[\"micro_all\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "8c0d7a66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[saved] per-horizon overall metrics → per_station/overall_by_horizon_lstm.csv\n"
     ]
    }
   ],
   "source": [
    "HORIZONS = [12, 24, 48, 72]\n",
    "BASE_DIR = \"per_station\"   # keep this since it points to your LSTM results\n",
    "\n",
    "overall_h = compute_overall_by_horizon(BASE_DIR, HORIZONS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "2e722a7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[resume_rf] already-trained stations: 62\n",
      "[summary_rf] wrote summary_all_stations_rf.csv with 62 rows\n",
      "[prep] computing flow_wide...\n",
      "[stations] total: 1806 | remaining to train: 1744\n",
      "[sampling] selected 120 stations to train (method='stratified', n=120)\n",
      "\n",
      "=== [RF] Station S3009053 ===\n",
      "[GB] RF importances on 1376 rows, 1631 feats\n",
      "[select] kept 400 features\n",
      "\n",
      "=== [RF] Station S3009082 ===\n",
      "[GB] RF importances on 1376 rows, 1631 feats\n",
      "[select] kept 400 features\n",
      "\n",
      "=== [RF] Station S3011042 ===\n",
      "[GB] RF importances on 1377 rows, 1631 feats\n",
      "[select] kept 400 features\n",
      "\n",
      "=== [RF] Station S3016092 ===\n",
      "[GB] RF importances on 1377 rows, 1631 feats\n",
      "[select] kept 400 features\n",
      "\n",
      "=== [RF] Station S3016101 ===\n",
      "[GB] RF importances on 1377 rows, 1631 feats\n",
      "[select] kept 400 features\n",
      "\n",
      "=== [RF] Station S3017032 ===\n",
      "[GB] RF importances on 1377 rows, 1631 feats\n",
      "[select] kept 400 features\n",
      "\n",
      "=== [RF] Station S3024104 ===\n",
      "[GB] RF importances on 1132 rows, 1631 feats\n",
      "[select] kept 400 features\n",
      "\n",
      "=== [RF] Station S3025061 ===\n",
      "[GB] RF importances on 1377 rows, 1631 feats\n",
      "[select] kept 400 features\n",
      "\n",
      "=== [RF] Station S3025085 ===\n",
      "[GB] RF importances on 1376 rows, 1631 feats\n",
      "[select] kept 400 features\n",
      "\n",
      "=== [RF] Station S3026094 ===\n",
      "[GB] RF importances on 1360 rows, 1631 feats\n",
      "[select] kept 400 features\n",
      "\n",
      "=== [RF] Station S3027022 ===\n",
      "[GB] RF importances on 1288 rows, 1631 feats\n",
      "[select] kept 400 features\n",
      "\n",
      "=== [RF] Station S3028071 ===\n",
      "[GB] RF importances on 1377 rows, 1631 feats\n",
      "[select] kept 400 features\n",
      "\n",
      "=== [RF] Station S3029112 ===\n",
      "[GB] RF importances on 1377 rows, 1631 feats\n",
      "[select] kept 400 features\n",
      "\n",
      "=== [RF] Station S3031020 ===\n",
      "[GB] RF importances on 1377 rows, 1631 feats\n",
      "[select] kept 400 features\n",
      "\n",
      "=== [RF] Station S3036042 ===\n",
      "[GB] RF importances on 1377 rows, 1631 feats\n",
      "[select] kept 400 features\n",
      "\n",
      "=== [RF] Station S3036072 ===\n",
      "[GB] RF importances on 1377 rows, 1631 feats\n",
      "[select] kept 400 features\n",
      "\n",
      "=== [RF] Station S3036092 ===\n",
      "[GB] RF importances on 1377 rows, 1631 feats\n",
      "[select] kept 400 features\n",
      "\n",
      "=== [RF] Station S3038092 ===\n",
      "[GB] RF importances on 1376 rows, 1631 feats\n",
      "[select] kept 400 features\n",
      "\n",
      "=== [RF] Station S3039031 ===\n",
      "[GB] RF importances on 1131 rows, 1631 feats\n",
      "[select] kept 400 features\n",
      "\n",
      "=== [RF] Station S3043092 ===\n",
      "[GB] RF importances on 1376 rows, 1631 feats\n",
      "[select] kept 400 features\n",
      "\n",
      "=== [RF] Station S3046043 ===\n",
      "[GB] RF importances on 175 rows, 1631 feats\n",
      "[select] kept 400 features\n",
      "\n",
      "=== [RF] Station S3049021 ===\n",
      "[GB] RF importances on 1377 rows, 1631 feats\n",
      "[select] kept 400 features\n",
      "\n",
      "=== [RF] Station S3052091 ===\n",
      "[GB] RF importances on 1377 rows, 1631 feats\n",
      "[select] kept 400 features\n",
      "\n",
      "=== [RF] Station S3054021 ===\n",
      "[GB] RF importances on 1355 rows, 1631 feats\n",
      "[select] kept 400 features\n",
      "\n",
      "=== [RF] Station S3054052 ===\n",
      "[GB] RF importances on 1377 rows, 1631 feats\n",
      "[select] kept 400 features\n",
      "\n",
      "=== [RF] Station S3055011 ===\n",
      "[GB] RF importances on 1377 rows, 1631 feats\n",
      "[select] kept 400 features\n",
      "\n",
      "=== [RF] Station S3055032 ===\n",
      "[GB] RF importances on 1377 rows, 1631 feats\n",
      "[select] kept 400 features\n",
      "\n",
      "=== [RF] Station S3055035 ===\n",
      "[GB] RF importances on 1376 rows, 1631 feats\n",
      "[select] kept 400 features\n",
      "\n",
      "=== [RF] Station S3068051 ===\n",
      "[GB] RF importances on 1377 rows, 1631 feats\n",
      "[select] kept 400 features\n",
      "\n",
      "=== [RF] Station S3070082 ===\n",
      "[GB] RF importances on 1377 rows, 1631 feats\n",
      "[select] kept 400 features\n",
      "\n",
      "=== [RF] Station S3070084 ===\n",
      "[GB] RF importances on 1377 rows, 1631 feats\n",
      "[select] kept 400 features\n",
      "\n",
      "=== [RF] Station S3073062 ===\n",
      "[GB] RF importances on 1376 rows, 1631 feats\n",
      "[select] kept 400 features\n",
      "\n",
      "=== [RF] Station S3075083 ===\n",
      "[GB] RF importances on 1376 rows, 1631 feats\n",
      "[select] kept 400 features\n",
      "\n",
      "=== [RF] Station S3086051 ===\n",
      "[GB] RF importances on 1377 rows, 1631 feats\n",
      "[select] kept 400 features\n",
      "\n",
      "=== [RF] Station S3086072 ===\n",
      "[GB] RF importances on 1377 rows, 1631 feats\n",
      "[select] kept 400 features\n",
      "\n",
      "=== [RF] Station S3088072 ===\n",
      "[GB] RF importances on 1376 rows, 1631 feats\n",
      "[select] kept 400 features\n",
      "\n",
      "=== [RF] Station S3089061 ===\n",
      "[GB] RF importances on 1377 rows, 1631 feats\n",
      "[select] kept 400 features\n",
      "\n",
      "=== [RF] Station S3091033 ===\n",
      "[GB] RF importances on 1377 rows, 1631 feats\n",
      "[select] kept 400 features\n",
      "\n",
      "=== [RF] Station S3091074 ===\n",
      "[GB] RF importances on 1377 rows, 1631 feats\n",
      "[select] kept 400 features\n",
      "\n",
      "=== [RF] Station S3092051 ===\n",
      "[GB] RF importances on 1377 rows, 1631 feats\n",
      "[select] kept 400 features\n",
      "\n",
      "=== [RF] Station S3097011 ===\n",
      "[GB] RF importances on 1377 rows, 1631 feats\n",
      "[select] kept 400 features\n",
      "\n",
      "=== [RF] Station S311903 ===\n",
      "[GB] RF importances on 1376 rows, 1631 feats\n",
      "[select] kept 400 features\n",
      "\n",
      "=== [RF] Station S312142 ===\n",
      "[GB] RF importances on 0 rows, 1631 feats\n",
      "[RF S312142] ERROR: Found array with 0 sample(s) (shape=(0, 1631)) while a minimum of 1 is required by GradientBoostingRegressor.\n",
      "\n",
      "=== [RF] Station S312264 ===\n",
      "[GB] RF importances on 1376 rows, 1631 feats\n",
      "[select] kept 400 features\n",
      "\n",
      "=== [RF] Station S312421 ===\n",
      "[GB] RF importances on 1376 rows, 1631 feats\n",
      "[select] kept 400 features\n",
      "\n",
      "=== [RF] Station S312422 ===\n",
      "[GB] RF importances on 1376 rows, 1631 feats\n",
      "[select] kept 400 features\n",
      "\n",
      "=== [RF] Station S312515 ===\n",
      "[GB] RF importances on 1376 rows, 1631 feats\n",
      "[select] kept 400 features\n",
      "\n",
      "=== [RF] Station S312518 ===\n",
      "[GB] RF importances on 1375 rows, 1631 feats\n",
      "[select] kept 400 features\n",
      "\n",
      "=== [RF] Station S312651 ===\n",
      "[GB] RF importances on 1376 rows, 1631 feats\n",
      "[select] kept 400 features\n",
      "\n",
      "=== [RF] Station S312901 ===\n",
      "[GB] RF importances on 1376 rows, 1631 feats\n",
      "[select] kept 400 features\n",
      "\n",
      "=== [RF] Station S312947 ===\n",
      "[GB] RF importances on 957 rows, 1631 feats\n",
      "[select] kept 400 features\n",
      "\n",
      "=== [RF] Station S313054 ===\n",
      "[GB] RF importances on 1375 rows, 1631 feats\n",
      "[select] kept 400 features\n",
      "\n",
      "=== [RF] Station S313132 ===\n",
      "[GB] RF importances on 1376 rows, 1631 feats\n",
      "[select] kept 400 features\n",
      "\n",
      "=== [RF] Station S313172 ===\n",
      "[GB] RF importances on 1376 rows, 1631 feats\n",
      "[select] kept 400 features\n",
      "\n",
      "=== [RF] Station S313420 ===\n",
      "[GB] RF importances on 1376 rows, 1631 feats\n",
      "[select] kept 400 features\n",
      "\n",
      "=== [RF] Station S313432 ===\n",
      "[GB] RF importances on 1376 rows, 1631 feats\n",
      "[select] kept 400 features\n",
      "\n",
      "=== [RF] Station S313552 ===\n",
      "[GB] RF importances on 1376 rows, 1631 feats\n",
      "[select] kept 400 features\n",
      "\n",
      "=== [RF] Station S313956 ===\n",
      "[GB] RF importances on 1376 rows, 1631 feats\n",
      "[select] kept 400 features\n",
      "\n",
      "=== [RF] Station S313979 ===\n",
      "[GB] RF importances on 1376 rows, 1631 feats\n",
      "[select] kept 400 features\n",
      "\n",
      "=== [RF] Station S314129 ===\n",
      "[GB] RF importances on 1108 rows, 1631 feats\n",
      "[select] kept 400 features\n",
      "\n",
      "=== [RF] Station S314297 ===\n",
      "[GB] RF importances on 1374 rows, 1631 feats\n",
      "[select] kept 400 features\n",
      "\n",
      "=== [RF] Station S314514 ===\n",
      "[GB] RF importances on 1376 rows, 1631 feats\n",
      "[select] kept 400 features\n",
      "\n",
      "=== [RF] Station S314530 ===\n",
      "[GB] RF importances on 1376 rows, 1631 feats\n",
      "[select] kept 400 features\n",
      "\n",
      "=== [RF] Station S314646 ===\n",
      "[GB] RF importances on 1376 rows, 1631 feats\n",
      "[select] kept 400 features\n",
      "\n",
      "=== [RF] Station S314650 ===\n",
      "[GB] RF importances on 1376 rows, 1631 feats\n",
      "[select] kept 400 features\n",
      "\n",
      "=== [RF] Station S314967 ===\n",
      "[GB] RF importances on 1376 rows, 1631 feats\n",
      "[select] kept 400 features\n",
      "\n",
      "=== [RF] Station S315054 ===\n",
      "[GB] RF importances on 1377 rows, 1631 feats\n",
      "[select] kept 400 features\n",
      "\n",
      "=== [RF] Station S315824 ===\n",
      "[GB] RF importances on 1377 rows, 1631 feats\n",
      "[select] kept 400 features\n",
      "\n",
      "=== [RF] Station S315865 ===\n",
      "[GB] RF importances on 1377 rows, 1631 feats\n",
      "[select] kept 400 features\n",
      "\n",
      "=== [RF] Station S315874 ===\n",
      "[GB] RF importances on 1377 rows, 1631 feats\n",
      "[select] kept 400 features\n",
      "\n",
      "=== [RF] Station S315895 ===\n",
      "[GB] RF importances on 1377 rows, 1631 feats\n",
      "[select] kept 400 features\n",
      "\n",
      "=== [RF] Station S315983 ===\n",
      "[GB] RF importances on 1130 rows, 1631 feats\n",
      "[select] kept 400 features\n",
      "\n",
      "=== [RF] Station S315993 ===\n",
      "[GB] RF importances on 1377 rows, 1631 feats\n",
      "[select] kept 400 features\n",
      "\n",
      "=== [RF] Station S316019 ===\n",
      "[GB] RF importances on 1377 rows, 1631 feats\n",
      "[select] kept 400 features\n",
      "\n",
      "=== [RF] Station S316110 ===\n",
      "[GB] RF importances on 1283 rows, 1631 feats\n",
      "[select] kept 400 features\n",
      "\n",
      "=== [RF] Station S316161 ===\n",
      "[GB] RF importances on 1377 rows, 1631 feats\n",
      "[select] kept 400 features\n",
      "\n",
      "=== [RF] Station S316166 ===\n",
      "[GB] RF importances on 1377 rows, 1631 feats\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[select] kept 400 features\n",
      "\n",
      "=== [RF] Station S316188 ===\n",
      "[GB] RF importances on 1376 rows, 1631 feats\n",
      "[select] kept 400 features\n",
      "\n",
      "=== [RF] Station S316366 ===\n",
      "[GB] RF importances on 1376 rows, 1631 feats\n",
      "[select] kept 400 features\n",
      "\n",
      "=== [RF] Station S316387 ===\n",
      "[GB] RF importances on 1377 rows, 1631 feats\n",
      "[select] kept 400 features\n",
      "\n",
      "=== [RF] Station S316453 ===\n",
      "[GB] RF importances on 0 rows, 1631 feats\n",
      "[RF S316453] ERROR: Found array with 0 sample(s) (shape=(0, 1631)) while a minimum of 1 is required by GradientBoostingRegressor.\n",
      "\n",
      "=== [RF] Station S316670 ===\n",
      "[GB] RF importances on 1377 rows, 1631 feats\n",
      "[select] kept 400 features\n",
      "\n",
      "=== [RF] Station S317045 ===\n",
      "[GB] RF importances on 1377 rows, 1631 feats\n",
      "[select] kept 400 features\n",
      "\n",
      "=== [RF] Station S317736 ===\n",
      "[GB] RF importances on 1377 rows, 1631 feats\n",
      "[select] kept 400 features\n",
      "\n",
      "=== [RF] Station S317796 ===\n",
      "[GB] RF importances on 1092 rows, 1631 feats\n",
      "[select] kept 400 features\n",
      "\n",
      "=== [RF] Station S317843 ===\n",
      "[GB] RF importances on 1377 rows, 1631 feats\n",
      "[select] kept 400 features\n",
      "\n",
      "=== [RF] Station S317918 ===\n",
      "[GB] RF importances on 1314 rows, 1631 feats\n",
      "[select] kept 400 features\n",
      "\n",
      "=== [RF] Station S317956 ===\n",
      "[GB] RF importances on 1377 rows, 1631 feats\n",
      "[select] kept 400 features\n",
      "\n",
      "=== [RF] Station S317961 ===\n",
      "[GB] RF importances on 1376 rows, 1631 feats\n",
      "[select] kept 400 features\n",
      "\n",
      "=== [RF] Station S318383 ===\n",
      "[GB] RF importances on 1377 rows, 1631 feats\n",
      "[select] kept 400 features\n",
      "\n",
      "=== [RF] Station S318413 ===\n",
      "[GB] RF importances on 1376 rows, 1631 feats\n",
      "[select] kept 400 features\n",
      "\n",
      "=== [RF] Station S318434 ===\n",
      "[GB] RF importances on 1376 rows, 1631 feats\n",
      "[select] kept 400 features\n",
      "\n",
      "=== [RF] Station S318437 ===\n",
      "[GB] RF importances on 1377 rows, 1631 feats\n",
      "[select] kept 400 features\n",
      "\n",
      "=== [RF] Station S318509 ===\n",
      "[GB] RF importances on 1377 rows, 1631 feats\n",
      "[select] kept 400 features\n",
      "\n",
      "=== [RF] Station S318649 ===\n",
      "[GB] RF importances on 1377 rows, 1631 feats\n",
      "[select] kept 400 features\n",
      "\n",
      "=== [RF] Station S318738 ===\n",
      "[GB] RF importances on 0 rows, 1631 feats\n",
      "[RF S318738] ERROR: Found array with 0 sample(s) (shape=(0, 1631)) while a minimum of 1 is required by GradientBoostingRegressor.\n",
      "\n",
      "=== [RF] Station S318764 ===\n",
      "[GB] RF importances on 1377 rows, 1631 feats\n",
      "[select] kept 400 features\n",
      "\n",
      "=== [RF] Station S318961 ===\n",
      "[GB] RF importances on 1377 rows, 1631 feats\n",
      "[select] kept 400 features\n",
      "\n",
      "=== [RF] Station S319110 ===\n",
      "[GB] RF importances on 1377 rows, 1631 feats\n",
      "[select] kept 400 features\n",
      "\n",
      "=== [RF] Station S319119 ===\n",
      "[GB] RF importances on 1377 rows, 1631 feats\n",
      "[select] kept 400 features\n",
      "\n",
      "=== [RF] Station S319250 ===\n",
      "[GB] RF importances on 1376 rows, 1631 feats\n",
      "[select] kept 400 features\n",
      "\n",
      "=== [RF] Station S319295 ===\n",
      "[GB] RF importances on 1377 rows, 1631 feats\n",
      "[select] kept 400 features\n",
      "\n",
      "=== [RF] Station S319350 ===\n",
      "[GB] RF importances on 1377 rows, 1631 feats\n",
      "[select] kept 400 features\n",
      "\n",
      "=== [RF] Station S319482 ===\n",
      "[GB] RF importances on 1376 rows, 1631 feats\n",
      "[select] kept 400 features\n",
      "\n",
      "=== [RF] Station S319677 ===\n",
      "[GB] RF importances on 1355 rows, 1631 feats\n",
      "[select] kept 400 features\n",
      "\n",
      "=== [RF] Station S320501 ===\n",
      "[GB] RF importances on 1377 rows, 1631 feats\n",
      "[select] kept 400 features\n",
      "\n",
      "=== [RF] Station S320554 ===\n",
      "[GB] RF importances on 1376 rows, 1631 feats\n",
      "[select] kept 400 features\n",
      "\n",
      "=== [RF] Station S320660 ===\n",
      "[GB] RF importances on 1377 rows, 1631 feats\n",
      "[select] kept 400 features\n",
      "\n",
      "=== [RF] Station S3412021 ===\n",
      "[GB] RF importances on 1377 rows, 1631 feats\n",
      "[select] kept 400 features\n",
      "\n",
      "=== [RF] Station S3412054 ===\n",
      "[GB] RF importances on 1377 rows, 1631 feats\n",
      "[select] kept 400 features\n",
      "\n",
      "=== [RF] Station S3413015 ===\n",
      "[GB] RF importances on 1376 rows, 1631 feats\n",
      "[select] kept 400 features\n",
      "\n",
      "=== [RF] Station S3413044 ===\n",
      "[GB] RF importances on 1377 rows, 1631 feats\n",
      "[select] kept 400 features\n",
      "\n",
      "=== [RF] Station S3415024 ===\n",
      "[GB] RF importances on 1377 rows, 1631 feats\n",
      "[select] kept 400 features\n",
      "\n",
      "=== [RF] Station S3415051 ===\n",
      "[GB] RF importances on 1377 rows, 1631 feats\n",
      "[select] kept 400 features\n",
      "\n",
      "=== [RF] Station S3420043 ===\n",
      "[GB] RF importances on 1332 rows, 1631 feats\n",
      "[select] kept 400 features\n",
      "\n",
      "=== [RF] Station S3420054 ===\n",
      "[GB] RF importances on 1311 rows, 1631 feats\n",
      "[select] kept 400 features\n",
      "\n",
      "=== [RF] Station S3420081 ===\n",
      "[GB] RF importances on 218 rows, 1631 feats\n",
      "[select] kept 400 features\n",
      "\n",
      "=== [RF] Station S3422058 ===\n",
      "[GB] RF importances on 0 rows, 1631 feats\n",
      "[RF S3422058] ERROR: Found array with 0 sample(s) (shape=(0, 1631)) while a minimum of 1 is required by GradientBoostingRegressor.\n",
      "\n",
      "=== [RF] Station S3422059 ===\n",
      "[GB] RF importances on 59 rows, 1631 feats\n",
      "[select] kept 400 features\n",
      "[RF S3422059] ERROR: Found array with 0 sample(s) (shape=(0, 400)) while a minimum of 1 is required by RandomForestRegressor.\n",
      "\n",
      "=== [RF] Station S3423016 ===\n",
      "[GB] RF importances on 1376 rows, 1631 feats\n",
      "[select] kept 400 features\n",
      "Saved/updated summary_all_stations_rf.csv\n",
      "Overall RF (macro avg of station means): {'MAE_macro': 142.86427682316295, 'RMSE_macro': 222.08312959832347}\n",
      "Overall RF (micro on pooled errors):     {'MAE_micro': 146.02946007344184, 'RMSE_micro': 304.1494084747511, 'n_samples': 251900}\n"
     ]
    }
   ],
   "source": [
    "# ================== RF: RESUME + REPRESENTATIVE SAMPLING + OVERALL METRICS ==================\n",
    "import os, gc, warnings, joblib\n",
    "import numpy as np, pandas as pd\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from sklearn.ensemble import GradientBoostingRegressor, RandomForestRegressor\n",
    "\n",
    "# ---------------- CONFIG ----------------\n",
    "FLOW_COL        = \"Total Flow\"\n",
    "STATION_COL     = \"StationName\"\n",
    "HORIZONS        = [12, 24, 48, 72]\n",
    "ORDERED_COLS    = [f\"y_{h}h\" for h in HORIZONS]\n",
    "\n",
    "# Feature-building speed knobs\n",
    "NEIGHBORS       = 30\n",
    "LAG_SET         = list(range(1, 49)) + [72, 96, 120, 144, 168]\n",
    "TOP_K           = 400\n",
    "\n",
    "# GB importance (fast + shallow on subsample)\n",
    "GB_TREES        = 300\n",
    "GB_MAX_DEPTH    = 3\n",
    "GB_SUBSAMPLE    = 0.5\n",
    "IMP_SUBSAMP     = 10000\n",
    "\n",
    "# Random Forest params\n",
    "RF_PARAMS       = dict(n_estimators=400, max_depth=None, n_jobs=-1, random_state=42)\n",
    "\n",
    "# ---- NEW: sampling/resume knobs ----\n",
    "STATION_SAMPLE_N        = 120            # None → use all remaining\n",
    "STATION_SAMPLE_METHOD   = \"stratified\"   # \"random\" | \"stratified\" | \"list\"\n",
    "INCLUDED_STATIONS_LIST  = None           # only used if method == \"list\"\n",
    "RANDOM_SEED             = 42\n",
    "SKIP_IF_EXISTS          = True           # skip if metrics/model already saved\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
    "np.random.seed(42)\n",
    "\n",
    "# ---------------- helpers ----------------\n",
    "def time_split_index(idx, train_ratio=0.7, val_ratio=0.1):\n",
    "    n = len(idx); n_tr = int(n*train_ratio); n_va = int(n*val_ratio)\n",
    "    return idx[:n_tr], idx[n_tr:n_tr+n_va], idx[n_tr+n_va:]\n",
    "\n",
    "def metrics_by_horizon(y_true, y_pred):\n",
    "    res, maes, rmses = {}, [], []\n",
    "    for j, h in enumerate(HORIZONS):\n",
    "        mae  = mean_absolute_error(y_true[:, j], y_pred[:, j])\n",
    "        rmse = mean_squared_error(y_true[:, j], y_pred[:, j], squared=False)\n",
    "        res[f\"MAE_{h}h\"] = float(mae); res[f\"RMSE_{h}h\"] = float(rmse)\n",
    "        maes.append(mae); rmses.append(rmse)\n",
    "    res[\"MAE_mean\"]  = float(np.mean(maes)); res[\"RMSE_mean\"] = float(np.mean(rmses))\n",
    "    return res\n",
    "\n",
    "def lv_baseline_metrics(y_true_df, ref_series):\n",
    "    y_true = y_true_df.to_numpy()\n",
    "    ref_vals = ref_series.loc[y_true_df.index].values.astype(np.float32).reshape(-1, 1)\n",
    "    preds_lv = np.repeat(ref_vals, repeats=len(HORIZONS), axis=1)\n",
    "    res, maes, rmses = {}, [], []\n",
    "    for j, h in enumerate(HORIZONS):\n",
    "        mae  = mean_absolute_error(y_true[:, j], preds_lv[:, j])\n",
    "        rmse = mean_squared_error(y_true[:, j], preds_lv[:, j], squared=False)\n",
    "        res[f\"LV_MAE_{h}h\"] = float(mae); res[f\"LV_RMSE_{h}h\"] = float(rmse)\n",
    "        maes.append(mae); rmses.append(rmse)\n",
    "    res[\"LV_MAE_mean\"]  = float(np.mean(maes)); res[\"LV_RMSE_mean\"] = float(np.mean(rmses))\n",
    "    return res\n",
    "\n",
    "def clean_numeric(df_in):\n",
    "    X = df_in.copy()\n",
    "    bcols = X.select_dtypes(include=['bool']).columns\n",
    "    if len(bcols): X[bcols] = X[bcols].astype(np.int8)\n",
    "    for c in X.columns:\n",
    "        if X[c].dtype == object:\n",
    "            X[c] = pd.to_numeric(X[c], errors='coerce')\n",
    "    X = X.replace([np.inf, -np.inf], np.nan).fillna(0.0)\n",
    "    for c in X.columns:\n",
    "        if np.issubdtype(X[c].dtype, np.number):\n",
    "            X[c] = X[c].astype(np.float32)\n",
    "    return X\n",
    "\n",
    "# ---------------- neighbor + slim-lag builders ----------------\n",
    "def compute_flow_wide(df):\n",
    "    fw = df.pivot_table(index=df.index, columns=STATION_COL, values=FLOW_COL, aggfunc='mean')\n",
    "    return fw.reindex(sorted(fw.columns), axis=1).astype(np.float32)\n",
    "\n",
    "def select_neighbors(flow_wide, target, train_index, k=NEIGHBORS):\n",
    "    target_series = flow_wide[target].loc[train_index]\n",
    "    corrs = flow_wide.loc[train_index].corrwith(target_series).abs().sort_values(ascending=False)\n",
    "    return [s for s in corrs.index if s != target][:k]\n",
    "\n",
    "def build_slim_crosslags(flow_wide, neighbors, lags):\n",
    "    parts = []\n",
    "    for s in neighbors:\n",
    "        s_col = flow_wide[s]\n",
    "        for L in lags:\n",
    "            parts.append(s_col.shift(L).rename(f\"{s}_lag_{L}\"))\n",
    "    return pd.concat(parts, axis=1) if parts else pd.DataFrame(index=flow_wide.index)\n",
    "\n",
    "def build_XY_for_target_fast(df, flow_wide, target, train_idx):\n",
    "    neighbors = select_neighbors(flow_wide, target, train_idx, k=NEIGHBORS)\n",
    "    X_cross = build_slim_crosslags(flow_wide, neighbors, LAG_SET)\n",
    "    drop_cols = [c for c in ['Station', STATION_COL, FLOW_COL] if c in df.columns]\n",
    "    drop_cols += [c for c in df.columns if c.startswith('TotalFlow_lag_')]\n",
    "    X_target_feats = df[df[STATION_COL] == target].drop(columns=drop_cols, errors='ignore')\n",
    "    X = pd.concat([X_cross, X_target_feats], axis=1).sort_index()\n",
    "    Y = pd.concat({h: df.loc[df[STATION_COL] == target, FLOW_COL].shift(-h) for h in HORIZONS}, axis=1)\n",
    "    Y.columns = ORDERED_COLS\n",
    "    burn_in = max(LAG_SET) if len(LAG_SET) else 0\n",
    "    common_idx = X.index.intersection(Y.index)\n",
    "    X = X.loc[common_idx].iloc[burn_in:]\n",
    "    Y = Y.loc[common_idx].iloc[burn_in:]\n",
    "    mask = ~Y.isna().any(axis=1)\n",
    "    X = clean_numeric(X.loc[mask]); Y = Y.loc[mask]\n",
    "    return X, Y, neighbors\n",
    "\n",
    "def rank_features_gb(X_tr, y12_tr):\n",
    "    n_rows = len(X_tr)\n",
    "    subsz = min(IMP_SUBSAMP, n_rows)\n",
    "    sub_idx = np.random.choice(np.arange(n_rows), size=subsz, replace=False)\n",
    "    X_sub, y_sub = X_tr.iloc[sub_idx], y12_tr.iloc[sub_idx]\n",
    "    gbr = GradientBoostingRegressor(\n",
    "        n_estimators=GB_TREES, learning_rate=0.05,\n",
    "        max_depth=GB_MAX_DEPTH, subsample=GB_SUBSAMPLE, random_state=42\n",
    "    )\n",
    "    gbr.fit(X_sub, y_sub)\n",
    "    return pd.Series(gbr.feature_importances_, index=X_tr.columns).sort_values(ascending=False)\n",
    "\n",
    "# ---------------- resume/sampling utilities ----------------\n",
    "def list_trained_rf(base_dir=\"per_station_rf\"):\n",
    "    \"\"\"Stations considered done if metrics.csv exists (and model.joblib optionally).\"\"\"\n",
    "    if not os.path.exists(base_dir):\n",
    "        return []\n",
    "    done = []\n",
    "    for d in os.listdir(base_dir):\n",
    "        m1 = os.path.join(base_dir, d, \"metrics.csv\")\n",
    "        if os.path.exists(m1):\n",
    "            done.append(d)\n",
    "    return sorted(done)\n",
    "\n",
    "def rebuild_summary_rf(base_dir=\"per_station_rf\", outfile=\"summary_all_stations_rf.csv\"):\n",
    "    rows = []\n",
    "    if not os.path.exists(base_dir):\n",
    "        print(\"[summary_rf] base_dir not found; nothing to rebuild.\")\n",
    "        return None\n",
    "    for s in os.listdir(base_dir):\n",
    "        mpath = os.path.join(base_dir, s, \"metrics.csv\")\n",
    "        if os.path.exists(mpath):\n",
    "            try:\n",
    "                mdf = pd.read_csv(mpath)\n",
    "                row = {\"station\": s}\n",
    "                row.update({k: float(v) for k, v in zip(mdf[\"metric\"], mdf[\"value\"])})\n",
    "                rows.append(row)\n",
    "            except Exception:\n",
    "                pass\n",
    "    if rows:\n",
    "        sdf = pd.DataFrame(rows)\n",
    "        if \"MAE_mean\" in sdf.columns:\n",
    "            sdf = sdf.sort_values(\"MAE_mean\")\n",
    "        sdf.to_csv(outfile, index=False)\n",
    "        print(f\"[summary_rf] wrote {outfile} with {len(rows)} rows\")\n",
    "        return sdf\n",
    "    else:\n",
    "        print(\"[summary_rf] no metrics found to rebuild.\")\n",
    "        return None\n",
    "\n",
    "def sample_stations(df, method=\"stratified\", n=None, seed=42, include_list=None, exclude_set=None):\n",
    "    stations_all = sorted(df[STATION_COL].dropna().unique().tolist())\n",
    "    if exclude_set:\n",
    "        stations_all = [s for s in stations_all if s not in exclude_set]\n",
    "\n",
    "    if method == \"list\":\n",
    "        keep = [s for s in (include_list or []) if s in stations_all]\n",
    "        return keep if (n is None or n >= len(keep)) else keep[:n]\n",
    "\n",
    "    if (n is None) or (n >= len(stations_all)):\n",
    "        return stations_all\n",
    "\n",
    "    rng = np.random.default_rng(seed)\n",
    "\n",
    "    if method == \"random\":\n",
    "        return sorted(rng.choice(stations_all, size=n, replace=False).tolist())\n",
    "\n",
    "    # default: stratified by average flow deciles\n",
    "    stats = (\n",
    "        df[[STATION_COL, FLOW_COL]]\n",
    "        .dropna()\n",
    "        .groupby(STATION_COL)[FLOW_COL]\n",
    "        .mean()\n",
    "        .rename(\"avg_flow\")\n",
    "        .to_frame()\n",
    "        .loc[stations_all]\n",
    "    )\n",
    "    try:\n",
    "        stats[\"bin\"] = pd.qcut(stats[\"avg_flow\"], q=10, labels=False, duplicates=\"drop\")\n",
    "    except Exception:\n",
    "        stats[\"bin\"] = 0\n",
    "\n",
    "    bins = stats[\"bin\"].unique()\n",
    "    total = len(stats)\n",
    "    alloc = {}\n",
    "    for b in sorted(bins):\n",
    "        count_b = (stats[\"bin\"] == b).sum()\n",
    "        alloc[b] = max(1, round(n * (count_b / total)))\n",
    "\n",
    "    diff = n - sum(alloc.values())\n",
    "    order = sorted(alloc, key=lambda b: alloc[b], reverse=(diff > 0))\n",
    "    i = 0\n",
    "    while diff != 0 and order:\n",
    "        b = order[i % len(order)]\n",
    "        if diff > 0:\n",
    "            alloc[b] += 1; diff -= 1\n",
    "        else:\n",
    "            if alloc[b] > 1:\n",
    "                alloc[b] -= 1; diff += 1\n",
    "        i += 1\n",
    "\n",
    "    picked = []\n",
    "    for b in sorted(bins):\n",
    "        pool = stats[stats[\"bin\"] == b].index.tolist()\n",
    "        if not pool:\n",
    "            continue\n",
    "        k = min(alloc[b], len(pool))\n",
    "        sel = rng.choice(pool, size=k, replace=False).tolist()\n",
    "        picked.extend(sel)\n",
    "    return sorted(picked[:n])\n",
    "\n",
    "def compute_overall_metrics_rf(base_dir=\"per_station_rf\"):\n",
    "    macro_rows, pooled_abs, pooled_sq = [], [], []\n",
    "    n_total = 0\n",
    "    for s in os.listdir(base_dir) if os.path.exists(base_dir) else []:\n",
    "        mpath = os.path.join(base_dir, s, \"metrics.csv\")\n",
    "        ppath = os.path.join(base_dir, s, \"preds_test.csv\")\n",
    "        if os.path.exists(mpath):\n",
    "            mdf = pd.read_csv(mpath)\n",
    "            m = {k:v for k,v in zip(mdf[\"metric\"], mdf[\"value\"])}\n",
    "            m[\"station\"] = s\n",
    "            macro_rows.append(m)\n",
    "        if os.path.exists(ppath):\n",
    "            pdf = pd.read_csv(ppath, index_col=0)\n",
    "            for col in pdf.columns:\n",
    "                if col.startswith(\"ytrue_\"):\n",
    "                    h = col.replace(\"ytrue_\", \"\")\n",
    "                    y    = pdf[col].values.astype(np.float64)\n",
    "                    yhat = pdf.get(\"ypred_\" + h)\n",
    "                    if yhat is None: \n",
    "                        continue\n",
    "                    yhat = yhat.values.astype(np.float64)\n",
    "                    err = y - yhat\n",
    "                    pooled_abs.append(np.abs(err))\n",
    "                    pooled_sq.append(err**2)\n",
    "                    n_total += len(err)\n",
    "    macro, micro = {}, {}\n",
    "    if macro_rows:\n",
    "        mdf = pd.DataFrame(macro_rows)\n",
    "        if \"MAE_mean\" in mdf.columns:\n",
    "            macro[\"MAE_macro\"]  = float(mdf[\"MAE_mean\"].mean())\n",
    "        if \"RMSE_mean\" in mdf.columns:\n",
    "            macro[\"RMSE_macro\"] = float(mdf[\"RMSE_mean\"].mean())\n",
    "    if pooled_abs and pooled_sq:\n",
    "        pooled_abs = np.concatenate(pooled_abs)\n",
    "        pooled_sq  = np.concatenate(pooled_sq)\n",
    "        micro[\"MAE_micro\"]  = float(pooled_abs.mean())\n",
    "        micro[\"RMSE_micro\"] = float(np.sqrt(pooled_sq.mean()))\n",
    "        micro[\"n_samples\"]  = int(n_total)\n",
    "    return {\"macro\": macro, \"micro\": micro}\n",
    "\n",
    "# ---------------- per-station trainer (unchanged logic, now saves model + artifacts) -----------\n",
    "def train_eval_station_rf(df, flow_wide, target):\n",
    "    print(f\"\\n=== [RF] Station {target} ===\")\n",
    "    station_dir = f\"per_station_rf/{target}\"\n",
    "    os.makedirs(station_dir, exist_ok=True)\n",
    "\n",
    "    target_idx = df.loc[df[STATION_COL] == target].index.sort_values().unique()\n",
    "    tr_idx, va_idx, te_idx = time_split_index(target_idx)\n",
    "\n",
    "    X_all, Y_all, neighbors = build_XY_for_target_fast(df, flow_wide, target, train_idx=tr_idx)\n",
    "\n",
    "    X_tr = X_all.loc[tr_idx.intersection(X_all.index)]\n",
    "    X_va = X_all.loc[va_idx.intersection(X_all.index)]\n",
    "    X_te = X_all.loc[te_idx.intersection(X_all.index)]\n",
    "    Y_tr = Y_all.loc[X_tr.index]; Y_va = Y_all.loc[X_va.index]; Y_te = Y_all.loc[X_te.index]\n",
    "\n",
    "    print(f\"[GB] RF importances on {min(IMP_SUBSAMP, len(X_tr))} rows, {X_tr.shape[1]} feats\")\n",
    "    imp = rank_features_gb(X_tr, Y_tr['y_12h'])\n",
    "    keep_cols = imp.index[:min(TOP_K, len(imp))].tolist()\n",
    "    print(f\"[select] kept {len(keep_cols)} features\")\n",
    "\n",
    "    rf = RandomForestRegressor(**RF_PARAMS)\n",
    "    rf.fit(X_tr[keep_cols], Y_tr.values)\n",
    "\n",
    "    Yhat_te = rf.predict(X_te[keep_cols])\n",
    "    results = metrics_by_horizon(Y_te.values, Yhat_te)\n",
    "\n",
    "    Yte_df  = pd.DataFrame(Y_te.values, index=X_te.index, columns=ORDERED_COLS)\n",
    "    Yhat_df = pd.DataFrame(Yhat_te, index=X_te.index, columns=ORDERED_COLS)\n",
    "    baseline_res = lv_baseline_metrics(Yte_df, df.loc[df[STATION_COL]==target, FLOW_COL].sort_index())\n",
    "\n",
    "    final_metrics = {**results, **baseline_res,\n",
    "                     \"neighbors_used\": len(neighbors), \"features_used\": len(keep_cols)}\n",
    "    pd.DataFrame(list(final_metrics.items()), columns=[\"metric\", \"value\"]).to_csv(f\"{station_dir}/metrics.csv\", index=False)\n",
    "    pd.concat([Yte_df.add_prefix(\"ytrue_\"), Yhat_df.add_prefix(\"ypred_\")], axis=1).to_csv(f\"{station_dir}/preds_test.csv\")\n",
    "    pd.DataFrame({\"feature\": keep_cols}).to_csv(f\"{station_dir}/kept_features.csv\", index=False)\n",
    "\n",
    "    # save the trained model for resume/inspection\n",
    "    try:\n",
    "        joblib.dump({\"model\": rf, \"keep_cols\": keep_cols, \"params\": RF_PARAMS}, f\"{station_dir}/model.joblib\")\n",
    "    except Exception as e:\n",
    "        print(f\"[warn] could not save model.joblib: {e}\")\n",
    "\n",
    "    gc.collect()\n",
    "    row = {\"station\": target}; row.update(final_metrics)\n",
    "    return row\n",
    "\n",
    "# ---------------- main (resume-aware + sampling) ----------------\n",
    "def run_all_stations_rf_resume(df):\n",
    "    if not isinstance(df.index, pd.DatetimeIndex):\n",
    "        raise ValueError(\"df must have a DateTimeIndex\")\n",
    "    os.makedirs(\"per_station_rf\", exist_ok=True)\n",
    "\n",
    "    done = set(list_trained_rf(\"per_station_rf\"))\n",
    "    print(f\"[resume_rf] already-trained stations: {len(done)}\")\n",
    "    _ = rebuild_summary_rf(\"per_station_rf\", \"summary_all_stations_rf.csv\")\n",
    "\n",
    "    print(\"[prep] computing flow_wide...\")\n",
    "    flow_wide = compute_flow_wide(df)\n",
    "\n",
    "    stations_all = sorted(df[STATION_COL].dropna().unique())\n",
    "    remaining = [s for s in stations_all if s not in done]\n",
    "    print(f\"[stations] total: {len(stations_all)} | remaining to train: {len(remaining)}\")\n",
    "\n",
    "    stations = sample_stations(\n",
    "        df=df,\n",
    "        method=STATION_SAMPLE_METHOD,\n",
    "        n=STATION_SAMPLE_N,\n",
    "        seed=RANDOM_SEED,\n",
    "        include_list=INCLUDED_STATIONS_LIST,\n",
    "        exclude_set=done,\n",
    "    )\n",
    "    print(f\"[sampling] selected {len(stations)} stations to train \"\n",
    "          f\"(method='{STATION_SAMPLE_METHOD}', n={STATION_SAMPLE_N})\")\n",
    "\n",
    "    rows = []\n",
    "    for s in stations:\n",
    "        try:\n",
    "            station_dir = f\"per_station_rf/{s}\"\n",
    "            metrics_csv = f\"{station_dir}/metrics.csv\"\n",
    "            model_path  = f\"{station_dir}/model.joblib\"\n",
    "            if SKIP_IF_EXISTS and (os.path.exists(metrics_csv) or os.path.exists(model_path)):\n",
    "                print(f\"\\n=== [RF] Station {s} ===\")\n",
    "                print(\"[skip] found existing metrics/model\")\n",
    "                try:\n",
    "                    mdf = pd.read_csv(metrics_csv)\n",
    "                    row = {\"station\": s}\n",
    "                    row.update({k: float(v) for k, v in zip(mdf[\"metric\"], mdf[\"value\"])})\n",
    "                    rows.append(row)\n",
    "                except Exception:\n",
    "                    pass\n",
    "                continue\n",
    "\n",
    "            rows.append(train_eval_station_rf(df, flow_wide, s))\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"[RF {s}] ERROR: {e}\")\n",
    "\n",
    "    # write/update summary\n",
    "    if rows:\n",
    "        new_df = pd.DataFrame(rows)\n",
    "        try:\n",
    "            old_df = pd.read_csv(\"summary_all_stations_rf.csv\")\n",
    "        except Exception:\n",
    "            old_df = pd.DataFrame()\n",
    "        if not old_df.empty:\n",
    "            comb = pd.concat([old_df, new_df], ignore_index=True)\n",
    "            comb = comb.sort_values(by=[\"station\"]).drop_duplicates(subset=[\"station\"], keep=\"last\")\n",
    "        else:\n",
    "            comb = new_df\n",
    "        if \"MAE_mean\" in comb.columns:\n",
    "            comb = comb.sort_values(\"MAE_mean\")\n",
    "        comb.to_csv(\"summary_all_stations_rf.csv\", index=False)\n",
    "        print(\"Saved/updated summary_all_stations_rf.csv\")\n",
    "    else:\n",
    "        print(\"No new station results produced. Check inputs and schema.\")\n",
    "\n",
    "    # overall metrics\n",
    "    overall = compute_overall_metrics_rf(\"per_station_rf\")\n",
    "    print(\"Overall RF (macro avg of station means):\", overall[\"macro\"])\n",
    "    print(\"Overall RF (micro on pooled errors):    \", overall[\"micro\"])\n",
    "\n",
    "# ===== RUN =====\n",
    "# Expect df with DateTimeIndex and columns [STATION_COL, FLOW_COL, ... non-flow features ...]\n",
    "run_all_stations_rf_resume(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "71fafd0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[saved] per-horizon metrics → per_station_rf/overall_by_horizon_rf.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>horizon</th>\n",
       "      <th>MAE_macro</th>\n",
       "      <th>RMSE_macro</th>\n",
       "      <th>MAE_micro</th>\n",
       "      <th>RMSE_micro</th>\n",
       "      <th>n_samples</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12h</td>\n",
       "      <td>136.478621</td>\n",
       "      <td>203.573409</td>\n",
       "      <td>138.697249</td>\n",
       "      <td>274.522320</td>\n",
       "      <td>62975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>24h</td>\n",
       "      <td>135.917282</td>\n",
       "      <td>215.995645</td>\n",
       "      <td>139.199959</td>\n",
       "      <td>295.552752</td>\n",
       "      <td>62975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>48h</td>\n",
       "      <td>145.338181</td>\n",
       "      <td>229.958420</td>\n",
       "      <td>149.234480</td>\n",
       "      <td>316.024905</td>\n",
       "      <td>62975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>72h</td>\n",
       "      <td>153.723024</td>\n",
       "      <td>238.805045</td>\n",
       "      <td>156.986152</td>\n",
       "      <td>327.783125</td>\n",
       "      <td>62975</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  horizon   MAE_macro  RMSE_macro   MAE_micro  RMSE_micro  n_samples\n",
       "0     12h  136.478621  203.573409  138.697249  274.522320      62975\n",
       "1     24h  135.917282  215.995645  139.199959  295.552752      62975\n",
       "2     48h  145.338181  229.958420  149.234480  316.024905      62975\n",
       "3     72h  153.723024  238.805045  156.986152  327.783125      62975"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ================== RANDOM FOREST: OVERALL METRICS BY HORIZON (MACRO & MICRO) ==================\n",
    "import os, numpy as np, pandas as pd\n",
    "\n",
    "HORIZONS = [12, 24, 48, 72]\n",
    "BASE_DIR = \"per_station_rf\"   # RF outputs live here\n",
    "\n",
    "def compute_overall_by_horizon_rf(base_dir=BASE_DIR, horizons=HORIZONS):\n",
    "    macro_lists = {h: {\"mae\": [], \"rmse\": []} for h in horizons}\n",
    "    micro_abs, micro_sq, micro_n = {h: [] for h in horizons}, {h: [] for h in horizons}, {h: 0 for h in horizons}\n",
    "\n",
    "    if not os.path.exists(base_dir):\n",
    "        raise FileNotFoundError(f\"{base_dir} not found\")\n",
    "\n",
    "    stations = [d for d in os.listdir(base_dir) if os.path.isdir(os.path.join(base_dir, d))]\n",
    "    for s in stations:\n",
    "        ppath = os.path.join(base_dir, s, \"preds_test.csv\")\n",
    "        if not os.path.exists(ppath):\n",
    "            continue\n",
    "        pdf = pd.read_csv(ppath, index_col=0)\n",
    "\n",
    "        for h in horizons:\n",
    "            ytrue_col = f\"ytrue_y_{h}h\"\n",
    "            ypred_col = f\"ypred_y_{h}h\"\n",
    "            if ytrue_col not in pdf.columns or ypred_col not in pdf.columns:\n",
    "                continue\n",
    "            y, yhat = pdf[ytrue_col].values.astype(float), pdf[ypred_col].values.astype(float)\n",
    "            err = y - yhat\n",
    "            mae, rmse = np.abs(err).mean(), np.sqrt((err**2).mean())\n",
    "            macro_lists[h][\"mae\"].append(mae)\n",
    "            macro_lists[h][\"rmse\"].append(rmse)\n",
    "            micro_abs[h].append(np.abs(err))\n",
    "            micro_sq[h].append(err**2)\n",
    "            micro_n[h] += len(err)\n",
    "\n",
    "    rows = []\n",
    "    for h in horizons:\n",
    "        # macro = mean of station-level errors\n",
    "        mae_macro = np.mean(macro_lists[h][\"mae\"]) if macro_lists[h][\"mae\"] else np.nan\n",
    "        rmse_macro = np.mean(macro_lists[h][\"rmse\"]) if macro_lists[h][\"rmse\"] else np.nan\n",
    "\n",
    "        # micro = pooled error\n",
    "        if micro_abs[h]:\n",
    "            abs_all, sq_all = np.concatenate(micro_abs[h]), np.concatenate(micro_sq[h])\n",
    "            mae_micro = abs_all.mean()\n",
    "            rmse_micro = np.sqrt(sq_all.mean())\n",
    "            n_samp = micro_n[h]\n",
    "        else:\n",
    "            mae_micro, rmse_micro, n_samp = np.nan, np.nan, 0\n",
    "\n",
    "        rows.append({\n",
    "            \"horizon\": f\"{h}h\",\n",
    "            \"MAE_macro\": mae_macro, \"RMSE_macro\": rmse_macro,\n",
    "            \"MAE_micro\": mae_micro, \"RMSE_micro\": rmse_micro,\n",
    "            \"n_samples\": n_samp\n",
    "        })\n",
    "\n",
    "    df_out = pd.DataFrame(rows)\n",
    "    out_path = os.path.join(base_dir, \"overall_by_horizon_rf.csv\")\n",
    "    df_out.to_csv(out_path, index=False)\n",
    "    print(f\"[saved] per-horizon metrics → {out_path}\")\n",
    "    return df_out\n",
    "\n",
    "# -------- run --------\n",
    "rf_overall = compute_overall_by_horizon_rf()\n",
    "display(rf_overall)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "08863fc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[resume_ridge] already-trained stations: 116\n",
      "[summary_ridge] wrote summary_all_stations_ridge.csv with 116 rows\n",
      "[prep] computing flow_wide...]\n",
      "[stations] total: 1806 | remaining to train: 1690\n",
      "[sampling] selected 120 stations to train (method='stratified', n=120)\n",
      "\n",
      "=== [Ridge] Station S3008023 ===\n",
      "[GB] Ridge importances on 1019 rows, 1631 feats\n",
      "[select] kept 400 features\n",
      "\n",
      "=== [Ridge] Station S3009053 ===\n",
      "[GB] Ridge importances on 1376 rows, 1631 feats\n",
      "[select] kept 400 features\n",
      "\n",
      "=== [Ridge] Station S3011042 ===\n",
      "[GB] Ridge importances on 1377 rows, 1631 feats\n",
      "[select] kept 400 features\n",
      "\n",
      "=== [Ridge] Station S3016072 ===\n",
      "[GB] Ridge importances on 1377 rows, 1631 feats\n",
      "[select] kept 400 features\n",
      "\n",
      "=== [Ridge] Station S3016092 ===\n",
      "[GB] Ridge importances on 1377 rows, 1631 feats\n",
      "[select] kept 400 features\n",
      "\n",
      "=== [Ridge] Station S3017032 ===\n",
      "[GB] Ridge importances on 1377 rows, 1631 feats\n",
      "[select] kept 400 features\n",
      "\n",
      "=== [Ridge] Station S3024104 ===\n",
      "[GB] Ridge importances on 1132 rows, 1631 feats\n",
      "[select] kept 400 features\n",
      "\n",
      "=== [Ridge] Station S3025061 ===\n",
      "[GB] Ridge importances on 1377 rows, 1631 feats\n",
      "[select] kept 400 features\n",
      "\n",
      "=== [Ridge] Station S3025085 ===\n",
      "[GB] Ridge importances on 1376 rows, 1631 feats\n",
      "[select] kept 400 features\n",
      "\n",
      "=== [Ridge] Station S3026094 ===\n",
      "[GB] Ridge importances on 1360 rows, 1631 feats\n",
      "[select] kept 400 features\n",
      "\n",
      "=== [Ridge] Station S3027012 ===\n",
      "[GB] Ridge importances on 1288 rows, 1631 feats\n",
      "[select] kept 400 features\n",
      "\n",
      "=== [Ridge] Station S3028071 ===\n",
      "[GB] Ridge importances on 1377 rows, 1631 feats\n",
      "[select] kept 400 features\n",
      "\n",
      "=== [Ridge] Station S3028111 ===\n",
      "[GB] Ridge importances on 1377 rows, 1631 feats\n",
      "[select] kept 400 features\n",
      "\n",
      "=== [Ridge] Station S3029114 ===\n",
      "[GB] Ridge importances on 1377 rows, 1631 feats\n",
      "[select] kept 400 features\n",
      "\n",
      "=== [Ridge] Station S3031052 ===\n",
      "[GB] Ridge importances on 1377 rows, 1631 feats\n",
      "[select] kept 400 features\n",
      "\n",
      "=== [Ridge] Station S3033061 ===\n",
      "[GB] Ridge importances on 1377 rows, 1631 feats\n",
      "[select] kept 400 features\n",
      "\n",
      "=== [Ridge] Station S3036082 ===\n",
      "[GB] Ridge importances on 1377 rows, 1631 feats\n",
      "[select] kept 400 features\n",
      "\n",
      "=== [Ridge] Station S3036092 ===\n",
      "[GB] Ridge importances on 1377 rows, 1631 feats\n",
      "[select] kept 400 features\n",
      "\n",
      "=== [Ridge] Station S3038084 ===\n",
      "[GB] Ridge importances on 1376 rows, 1631 feats\n",
      "[select] kept 400 features\n",
      "\n",
      "=== [Ridge] Station S3039021 ===\n",
      "[GB] Ridge importances on 1082 rows, 1631 feats\n",
      "[select] kept 400 features\n",
      "\n",
      "=== [Ridge] Station S3043092 ===\n",
      "[GB] Ridge importances on 1376 rows, 1631 feats\n",
      "[select] kept 400 features\n",
      "\n",
      "=== [Ridge] Station S3049021 ===\n",
      "[GB] Ridge importances on 1377 rows, 1631 feats\n",
      "[select] kept 400 features\n",
      "\n",
      "=== [Ridge] Station S3050011 ===\n",
      "[GB] Ridge importances on 1377 rows, 1631 feats\n",
      "[select] kept 400 features\n",
      "\n",
      "=== [Ridge] Station S3052091 ===\n",
      "[GB] Ridge importances on 1377 rows, 1631 feats\n",
      "[select] kept 400 features\n",
      "\n",
      "=== [Ridge] Station S3053045 ===\n",
      "[GB] Ridge importances on 1376 rows, 1631 feats\n",
      "[select] kept 400 features\n",
      "\n",
      "=== [Ridge] Station S3054051 ===\n",
      "[GB] Ridge importances on 1377 rows, 1631 feats\n",
      "[select] kept 400 features\n",
      "\n",
      "=== [Ridge] Station S3055022 ===\n",
      "[GB] Ridge importances on 1377 rows, 1631 feats\n",
      "[select] kept 400 features\n",
      "\n",
      "=== [Ridge] Station S3056031 ===\n",
      "[GB] Ridge importances on 1377 rows, 1631 feats\n",
      "[select] kept 400 features\n",
      "\n",
      "=== [Ridge] Station S3069054 ===\n",
      "[GB] Ridge importances on 1376 rows, 1631 feats\n",
      "[select] kept 400 features\n",
      "\n",
      "=== [Ridge] Station S3070052 ===\n",
      "[GB] Ridge importances on 1377 rows, 1631 feats\n",
      "[select] kept 400 features\n",
      "\n",
      "=== [Ridge] Station S3070084 ===\n",
      "[GB] Ridge importances on 1377 rows, 1631 feats\n",
      "[select] kept 400 features\n",
      "\n",
      "=== [Ridge] Station S3072011 ===\n",
      "[GB] Ridge importances on 789 rows, 1631 feats\n",
      "[select] kept 400 features\n",
      "\n",
      "=== [Ridge] Station S3085054 ===\n",
      "[GB] Ridge importances on 1377 rows, 1631 feats\n",
      "[select] kept 400 features\n",
      "\n",
      "=== [Ridge] Station S3086022 ===\n",
      "[GB] Ridge importances on 1377 rows, 1631 feats\n",
      "[select] kept 400 features\n",
      "\n",
      "=== [Ridge] Station S3086032 ===\n",
      "[GB] Ridge importances on 1351 rows, 1631 feats\n",
      "[select] kept 400 features\n",
      "\n",
      "=== [Ridge] Station S3088033 ===\n",
      "[GB] Ridge importances on 1360 rows, 1631 feats\n",
      "[select] kept 400 features\n",
      "\n",
      "=== [Ridge] Station S3089011 ===\n",
      "[GB] Ridge importances on 1377 rows, 1631 feats\n",
      "[select] kept 400 features\n",
      "\n",
      "=== [Ridge] Station S3090074 ===\n",
      "[GB] Ridge importances on 1377 rows, 1631 feats\n",
      "[select] kept 400 features\n",
      "\n",
      "=== [Ridge] Station S3091021 ===\n",
      "[GB] Ridge importances on 1377 rows, 1631 feats\n",
      "[select] kept 400 features\n",
      "\n",
      "=== [Ridge] Station S3092041 ===\n",
      "[GB] Ridge importances on 1377 rows, 1631 feats\n",
      "[select] kept 400 features\n",
      "\n",
      "=== [Ridge] Station S3095041 ===\n",
      "[GB] Ridge importances on 1377 rows, 1631 feats\n",
      "[select] kept 400 features\n",
      "\n",
      "=== [Ridge] Station S3102012 ===\n",
      "[GB] Ridge importances on 1209 rows, 1631 feats\n",
      "[select] kept 400 features\n",
      "\n",
      "=== [Ridge] Station S311831 ===\n",
      "[GB] Ridge importances on 1376 rows, 1631 feats\n",
      "[select] kept 400 features\n",
      "\n",
      "=== [Ridge] Station S312009 ===\n",
      "[GB] Ridge importances on 1376 rows, 1631 feats\n",
      "[select] kept 400 features\n",
      "\n",
      "=== [Ridge] Station S312133 ===\n",
      "[GB] Ridge importances on 1376 rows, 1631 feats\n",
      "[select] kept 400 features\n",
      "\n",
      "=== [Ridge] Station S312139 ===\n",
      "[GB] Ridge importances on 1376 rows, 1631 feats\n",
      "[select] kept 400 features\n",
      "\n",
      "=== [Ridge] Station S312188 ===\n",
      "[GB] Ridge importances on 1376 rows, 1631 feats\n",
      "[select] kept 400 features\n",
      "\n",
      "=== [Ridge] Station S312420 ===\n",
      "[GB] Ridge importances on 1376 rows, 1631 feats\n",
      "[select] kept 400 features\n",
      "\n",
      "=== [Ridge] Station S312424 ===\n",
      "[GB] Ridge importances on 1376 rows, 1631 feats\n",
      "[select] kept 400 features\n",
      "\n",
      "=== [Ridge] Station S312648 ===\n",
      "[GB] Ridge importances on 1376 rows, 1631 feats\n",
      "[select] kept 400 features\n",
      "\n",
      "=== [Ridge] Station S312649 ===\n",
      "[GB] Ridge importances on 1376 rows, 1631 feats\n",
      "[select] kept 400 features\n",
      "\n",
      "=== [Ridge] Station S313036 ===\n",
      "[GB] Ridge importances on 1375 rows, 1631 feats\n",
      "[select] kept 400 features\n",
      "\n",
      "=== [Ridge] Station S313111 ===\n",
      "[GB] Ridge importances on 1376 rows, 1631 feats\n",
      "[select] kept 400 features\n",
      "\n",
      "=== [Ridge] Station S313114 ===\n",
      "[GB] Ridge importances on 1376 rows, 1631 feats\n",
      "[select] kept 400 features\n",
      "\n",
      "=== [Ridge] Station S313349 ===\n",
      "[GB] Ridge importances on 1376 rows, 1631 feats\n",
      "[select] kept 400 features\n",
      "\n",
      "=== [Ridge] Station S313386 ===\n",
      "[GB] Ridge importances on 1376 rows, 1631 feats\n",
      "[select] kept 400 features\n",
      "\n",
      "=== [Ridge] Station S313414 ===\n",
      "[GB] Ridge importances on 1376 rows, 1631 feats\n",
      "[select] kept 400 features\n",
      "\n",
      "=== [Ridge] Station S313552 ===\n",
      "[GB] Ridge importances on 1376 rows, 1631 feats\n",
      "[select] kept 400 features\n",
      "\n",
      "=== [Ridge] Station S313835 ===\n",
      "[GB] Ridge importances on 1376 rows, 1631 feats\n",
      "[select] kept 400 features\n",
      "\n",
      "=== [Ridge] Station S313980 ===\n",
      "[GB] Ridge importances on 1338 rows, 1631 feats\n",
      "[select] kept 400 features\n",
      "\n",
      "=== [Ridge] Station S314195 ===\n",
      "[GB] Ridge importances on 1376 rows, 1631 feats\n",
      "[select] kept 400 features\n",
      "\n",
      "=== [Ridge] Station S314355 ===\n",
      "[GB] Ridge importances on 1376 rows, 1631 feats\n",
      "[select] kept 400 features\n",
      "\n",
      "=== [Ridge] Station S314402 ===\n",
      "[GB] Ridge importances on 1376 rows, 1631 feats\n",
      "[select] kept 400 features\n",
      "\n",
      "=== [Ridge] Station S314434 ===\n",
      "[GB] Ridge importances on 1265 rows, 1631 feats\n",
      "[select] kept 400 features\n",
      "\n",
      "=== [Ridge] Station S314646 ===\n",
      "[GB] Ridge importances on 1376 rows, 1631 feats\n",
      "[select] kept 400 features\n",
      "\n",
      "=== [Ridge] Station S314934 ===\n",
      "[GB] Ridge importances on 1375 rows, 1631 feats\n",
      "[select] kept 400 features\n",
      "\n",
      "=== [Ridge] Station S314969 ===\n",
      "[GB] Ridge importances on 1376 rows, 1631 feats\n",
      "[select] kept 400 features\n",
      "\n",
      "=== [Ridge] Station S315006 ===\n",
      "[GB] Ridge importances on 1376 rows, 1631 feats\n",
      "[select] kept 400 features\n",
      "\n",
      "=== [Ridge] Station S315822 ===\n",
      "[GB] Ridge importances on 1377 rows, 1631 feats\n",
      "[select] kept 400 features\n",
      "\n",
      "=== [Ridge] Station S315864 ===\n",
      "[GB] Ridge importances on 1377 rows, 1631 feats\n",
      "[select] kept 400 features\n",
      "\n",
      "=== [Ridge] Station S315874 ===\n",
      "[GB] Ridge importances on 1377 rows, 1631 feats\n",
      "[select] kept 400 features\n",
      "\n",
      "=== [Ridge] Station S315892 ===\n",
      "[GB] Ridge importances on 1377 rows, 1631 feats\n",
      "[select] kept 400 features\n",
      "\n",
      "=== [Ridge] Station S315938 ===\n",
      "[GB] Ridge importances on 1377 rows, 1631 feats\n",
      "[select] kept 400 features\n",
      "\n",
      "=== [Ridge] Station S315955 ===\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[GB] Ridge importances on 1377 rows, 1631 feats\n",
      "[select] kept 400 features\n",
      "\n",
      "=== [Ridge] Station S316009 ===\n",
      "[GB] Ridge importances on 1377 rows, 1631 feats\n",
      "[select] kept 400 features\n",
      "\n",
      "=== [Ridge] Station S316033 ===\n",
      "[GB] Ridge importances on 1266 rows, 1631 feats\n",
      "[select] kept 400 features\n",
      "\n",
      "=== [Ridge] Station S316104 ===\n",
      "[GB] Ridge importances on 1375 rows, 1631 feats\n",
      "[select] kept 400 features\n",
      "\n",
      "=== [Ridge] Station S316110 ===\n",
      "[GB] Ridge importances on 1283 rows, 1631 feats\n",
      "[select] kept 400 features\n",
      "\n",
      "=== [Ridge] Station S316161 ===\n",
      "[GB] Ridge importances on 1377 rows, 1631 feats\n",
      "[select] kept 400 features\n",
      "\n",
      "=== [Ridge] Station S316166 ===\n",
      "[GB] Ridge importances on 1377 rows, 1631 feats\n",
      "[select] kept 400 features\n",
      "\n",
      "=== [Ridge] Station S316315 ===\n",
      "[GB] Ridge importances on 1266 rows, 1631 feats\n",
      "[select] kept 400 features\n",
      "\n",
      "=== [Ridge] Station S316416 ===\n",
      "[GB] Ridge importances on 1326 rows, 1631 feats\n",
      "[select] kept 400 features\n",
      "\n",
      "=== [Ridge] Station S316438 ===\n",
      "[GB] Ridge importances on 1377 rows, 1631 feats\n",
      "[select] kept 400 features\n",
      "\n",
      "=== [Ridge] Station S316670 ===\n",
      "[GB] Ridge importances on 1377 rows, 1631 feats\n",
      "[select] kept 400 features\n",
      "\n",
      "=== [Ridge] Station S316894 ===\n",
      "[GB] Ridge importances on 1377 rows, 1631 feats\n",
      "[select] kept 400 features\n",
      "\n",
      "=== [Ridge] Station S316940 ===\n",
      "[GB] Ridge importances on 1377 rows, 1631 feats\n",
      "[select] kept 400 features\n",
      "\n",
      "=== [Ridge] Station S317167 ===\n",
      "[GB] Ridge importances on 1012 rows, 1631 feats\n",
      "[select] kept 400 features\n",
      "\n",
      "=== [Ridge] Station S317796 ===\n",
      "[GB] Ridge importances on 1092 rows, 1631 feats\n",
      "[select] kept 400 features\n",
      "\n",
      "=== [Ridge] Station S317956 ===\n",
      "[GB] Ridge importances on 1377 rows, 1631 feats\n",
      "[select] kept 400 features\n",
      "\n",
      "=== [Ridge] Station S317959 ===\n",
      "[GB] Ridge importances on 1376 rows, 1631 feats\n",
      "[select] kept 400 features\n",
      "\n",
      "=== [Ridge] Station S318035 ===\n",
      "[GB] Ridge importances on 1377 rows, 1631 feats\n",
      "[select] kept 400 features\n",
      "\n",
      "=== [Ridge] Station S318373 ===\n",
      "[GB] Ridge importances on 287 rows, 1631 feats\n",
      "[select] kept 400 features\n",
      "\n",
      "=== [Ridge] Station S318383 ===\n",
      "[GB] Ridge importances on 1377 rows, 1631 feats\n",
      "[select] kept 400 features\n",
      "\n",
      "=== [Ridge] Station S318413 ===\n",
      "[GB] Ridge importances on 1376 rows, 1631 feats\n",
      "[select] kept 400 features\n",
      "\n",
      "=== [Ridge] Station S318434 ===\n",
      "[GB] Ridge importances on 1376 rows, 1631 feats\n",
      "[select] kept 400 features\n",
      "\n",
      "=== [Ridge] Station S318521 ===\n",
      "[GB] Ridge importances on 1377 rows, 1631 feats\n",
      "[select] kept 400 features\n",
      "\n",
      "=== [Ridge] Station S318711 ===\n",
      "[GB] Ridge importances on 1377 rows, 1631 feats\n",
      "[select] kept 400 features\n",
      "\n",
      "=== [Ridge] Station S319110 ===\n",
      "[GB] Ridge importances on 1377 rows, 1631 feats\n",
      "[select] kept 400 features\n",
      "\n",
      "=== [Ridge] Station S319119 ===\n",
      "[GB] Ridge importances on 1377 rows, 1631 feats\n",
      "[select] kept 400 features\n",
      "\n",
      "=== [Ridge] Station S319130 ===\n",
      "[GB] Ridge importances on 1376 rows, 1631 feats\n",
      "[select] kept 400 features\n",
      "\n",
      "=== [Ridge] Station S319250 ===\n",
      "[GB] Ridge importances on 1376 rows, 1631 feats\n",
      "[select] kept 400 features\n",
      "\n",
      "=== [Ridge] Station S319256 ===\n",
      "[GB] Ridge importances on 1376 rows, 1631 feats\n",
      "[select] kept 400 features\n",
      "\n",
      "=== [Ridge] Station S319344 ===\n",
      "[GB] Ridge importances on 1326 rows, 1631 feats\n",
      "[select] kept 400 features\n",
      "\n",
      "=== [Ridge] Station S319414 ===\n",
      "[GB] Ridge importances on 1341 rows, 1631 feats\n",
      "[select] kept 400 features\n",
      "\n",
      "=== [Ridge] Station S319482 ===\n",
      "[GB] Ridge importances on 1376 rows, 1631 feats\n",
      "[select] kept 400 features\n",
      "\n",
      "=== [Ridge] Station S320440 ===\n",
      "[GB] Ridge importances on 1111 rows, 1631 feats\n",
      "[select] kept 400 features\n",
      "\n",
      "=== [Ridge] Station S320501 ===\n",
      "[GB] Ridge importances on 1377 rows, 1631 feats\n",
      "[select] kept 400 features\n",
      "\n",
      "=== [Ridge] Station S320658 ===\n",
      "[GB] Ridge importances on 1377 rows, 1631 feats\n",
      "[select] kept 400 features\n",
      "\n",
      "=== [Ridge] Station S3412021 ===\n",
      "[GB] Ridge importances on 1377 rows, 1631 feats\n",
      "[select] kept 400 features\n",
      "\n",
      "=== [Ridge] Station S3412044 ===\n",
      "[GB] Ridge importances on 1377 rows, 1631 feats\n",
      "[select] kept 400 features\n",
      "\n",
      "=== [Ridge] Station S3413015 ===\n",
      "[GB] Ridge importances on 1376 rows, 1631 feats\n",
      "[select] kept 400 features\n",
      "\n",
      "=== [Ridge] Station S3413044 ===\n",
      "[GB] Ridge importances on 1377 rows, 1631 feats\n",
      "[select] kept 400 features\n",
      "\n",
      "=== [Ridge] Station S3414065 ===\n",
      "[GB] Ridge importances on 1358 rows, 1631 feats\n",
      "[select] kept 400 features\n",
      "\n",
      "=== [Ridge] Station S3415024 ===\n",
      "[GB] Ridge importances on 1377 rows, 1631 feats\n",
      "[select] kept 400 features\n",
      "\n",
      "=== [Ridge] Station S3415047 ===\n",
      "[GB] Ridge importances on 1377 rows, 1631 feats\n",
      "[select] kept 400 features\n",
      "\n",
      "=== [Ridge] Station S3420043 ===\n",
      "[GB] Ridge importances on 1332 rows, 1631 feats\n",
      "[select] kept 400 features\n",
      "\n",
      "=== [Ridge] Station S3420092 ===\n",
      "[GB] Ridge importances on 49 rows, 1631 feats\n",
      "[select] kept 400 features\n",
      "[Ridge S3420092] ERROR: Found array with 0 sample(s) (shape=(0, 400)) while a minimum of 1 is required by StandardScaler.\n",
      "\n",
      "=== [Ridge] Station S3422056 ===\n",
      "[GB] Ridge importances on 61 rows, 1631 feats\n",
      "[select] kept 400 features\n",
      "[Ridge S3422056] ERROR: Found array with 0 sample(s) (shape=(0, 400)) while a minimum of 1 is required by StandardScaler.\n",
      "\n",
      "=== [Ridge] Station S3422058 ===\n",
      "[GB] Ridge importances on 0 rows, 1631 feats\n",
      "[Ridge S3422058] ERROR: Found array with 0 sample(s) (shape=(0, 1631)) while a minimum of 1 is required by GradientBoostingRegressor.\n",
      "\n",
      "=== [Ridge] Station S3422059 ===\n",
      "[GB] Ridge importances on 59 rows, 1631 feats\n",
      "[select] kept 400 features\n",
      "[Ridge S3422059] ERROR: Found array with 0 sample(s) (shape=(0, 400)) while a minimum of 1 is required by StandardScaler.\n",
      "Saved/updated summary_all_stations_ridge.csv\n",
      "Overall Ridge (macro avg of station means): {'MAE_macro': 214.94247946083462, 'RMSE_macro': 283.29535715549054}\n",
      "Overall Ridge (micro on pooled errors):     {'MAE_micro': 215.4121253162175, 'RMSE_micro': 409.56024442988286, 'n_samples': 330168}\n"
     ]
    }
   ],
   "source": [
    "# ================= RIDGE: RESUME + REPRESENTATIVE SAMPLING + OVERALL METRICS =================\n",
    "import os, gc, warnings, joblib\n",
    "import numpy as np, pandas as pd\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# ---------------- CONFIG ----------------\n",
    "FLOW_COL        = \"Total Flow\"\n",
    "STATION_COL     = \"StationName\"\n",
    "HORIZONS        = [12, 24, 48, 72]\n",
    "ORDERED_COLS    = [f\"y_{h}h\" for h in HORIZONS]\n",
    "\n",
    "# Feature-building speed knobs\n",
    "NEIGHBORS       = 30\n",
    "LAG_SET         = list(range(1, 49)) + [72, 96, 120, 144, 168]\n",
    "TOP_K           = 400\n",
    "\n",
    "# GB importance (fast + shallow on subsample)\n",
    "GB_TREES        = 300\n",
    "GB_MAX_DEPTH    = 3\n",
    "GB_SUBSAMPLE    = 0.5\n",
    "IMP_SUBSAMP     = 10000\n",
    "\n",
    "# Ridge params\n",
    "RIDGE_ALPHA     = 1.0\n",
    "\n",
    "# ---- Sampling / resume knobs ----\n",
    "STATION_SAMPLE_N        = 120            # None → use all remaining\n",
    "STATION_SAMPLE_METHOD   = \"stratified\"   # \"random\" | \"stratified\" | \"list\"\n",
    "INCLUDED_STATIONS_LIST  = None           # only used if method == \"list\"\n",
    "RANDOM_SEED             = 42\n",
    "SKIP_IF_EXISTS          = True           # skip if metrics/model already saved\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
    "np.random.seed(42)\n",
    "\n",
    "# ---------------- helpers ----------------\n",
    "def time_split_index(idx, train_ratio=0.7, val_ratio=0.1):\n",
    "    n = len(idx); n_tr = int(n*train_ratio); n_va = int(n*val_ratio)\n",
    "    return idx[:n_tr], idx[n_tr:n_tr+n_va], idx[n_tr+n_va:]\n",
    "\n",
    "def metrics_by_horizon(y_true, y_pred):\n",
    "    res, maes, rmses = {}, [], []\n",
    "    for j, h in enumerate(HORIZONS):\n",
    "        mae  = mean_absolute_error(y_true[:, j], y_pred[:, j])\n",
    "        rmse = mean_squared_error(y_true[:, j], y_pred[:, j], squared=False)\n",
    "        res[f\"MAE_{h}h\"] = float(mae); res[f\"RMSE_{h}h\"] = float(rmse)\n",
    "        maes.append(mae); rmses.append(rmse)\n",
    "    res[\"MAE_mean\"]  = float(np.mean(maes)); res[\"RMSE_mean\"] = float(np.mean(rmses))\n",
    "    return res\n",
    "\n",
    "def lv_baseline_metrics(y_true_df, ref_series):\n",
    "    y_true = y_true_df.to_numpy()\n",
    "    ref_vals = ref_series.loc[y_true_df.index].values.astype(np.float32).reshape(-1, 1)\n",
    "    preds_lv = np.repeat(ref_vals, repeats=len(HORIZONS), axis=1)\n",
    "    res, maes, rmses = {}, [], []\n",
    "    for j, h in enumerate(HORIZONS):\n",
    "        mae  = mean_absolute_error(y_true[:, j], preds_lv[:, j])\n",
    "        rmse = mean_squared_error(y_true[:, j], preds_lv[:, j], squared=False)\n",
    "        res[f\"LV_MAE_{h}h\"] = float(mae); res[f\"LV_RMSE_{h}h\"] = float(rmse)\n",
    "        maes.append(mae); rmses.append(rmse)\n",
    "    res[\"LV_MAE_mean\"]  = float(np.mean(maes)); res[\"LV_RMSE_mean\"] = float(np.mean(rmses))\n",
    "    return res\n",
    "\n",
    "def clean_numeric(df_in):\n",
    "    X = df_in.copy()\n",
    "    bcols = X.select_dtypes(include=['bool']).columns\n",
    "    if len(bcols): X[bcols] = X[bcols].astype(np.int8)\n",
    "    for c in X.columns:\n",
    "        if X[c].dtype == object:\n",
    "            X[c] = pd.to_numeric(X[c], errors='coerce')\n",
    "    X = X.replace([np.inf, -np.inf], np.nan).fillna(0.0)\n",
    "    for c in X.columns:\n",
    "        if np.issubdtype(X[c].dtype, np.number):\n",
    "            X[c] = X[c].astype(np.float32)\n",
    "    return X\n",
    "\n",
    "# ---------------- neighbor + slim-lag builders ----------------\n",
    "def compute_flow_wide(df):\n",
    "    fw = df.pivot_table(index=df.index, columns=STATION_COL, values=FLOW_COL, aggfunc='mean')\n",
    "    return fw.reindex(sorted(fw.columns), axis=1).astype(np.float32)\n",
    "\n",
    "def select_neighbors(flow_wide, target, train_index, k=NEIGHBORS):\n",
    "    target_series = flow_wide[target].loc[train_index]\n",
    "    corrs = flow_wide.loc[train_index].corrwith(target_series).abs().sort_values(ascending=False)\n",
    "    return [s for s in corrs.index if s != target][:k]\n",
    "\n",
    "def build_slim_crosslags(flow_wide, neighbors, lags):\n",
    "    parts = []\n",
    "    for s in neighbors:\n",
    "        s_col = flow_wide[s]\n",
    "        for L in lags:\n",
    "            parts.append(s_col.shift(L).rename(f\"{s}_lag_{L}\"))\n",
    "    return pd.concat(parts, axis=1) if parts else pd.DataFrame(index=flow_wide.index)\n",
    "\n",
    "def build_XY_for_target_fast(df, flow_wide, target, train_idx):\n",
    "    neighbors = select_neighbors(flow_wide, target, train_idx, k=NEIGHBORS)\n",
    "    X_cross = build_slim_crosslags(flow_wide, neighbors, LAG_SET)\n",
    "    drop_cols = [c for c in ['Station', STATION_COL, FLOW_COL] if c in df.columns]\n",
    "    drop_cols += [c for c in df.columns if c.startswith('TotalFlow_lag_')]\n",
    "    X_target_feats = df[df[STATION_COL] == target].drop(columns=drop_cols, errors='ignore')\n",
    "    X = pd.concat([X_cross, X_target_feats], axis=1).sort_index()\n",
    "    Y = pd.concat({h: df.loc[df[STATION_COL] == target, FLOW_COL].shift(-h) for h in HORIZONS}, axis=1)\n",
    "    Y.columns = ORDERED_COLS\n",
    "    burn_in = max(LAG_SET) if len(LAG_SET) else 0\n",
    "    common_idx = X.index.intersection(Y.index)\n",
    "    X = X.loc[common_idx].iloc[burn_in:]\n",
    "    Y = Y.loc[common_idx].iloc[burn_in:]\n",
    "    mask = ~Y.isna().any(axis=1)\n",
    "    X = clean_numeric(X.loc[mask]); Y = Y.loc[mask]\n",
    "    return X, Y, neighbors\n",
    "\n",
    "def rank_features_gb(X_tr, y12_tr):\n",
    "    n_rows = len(X_tr)\n",
    "    subsz = min(IMP_SUBSAMP, n_rows)\n",
    "    sub_idx = np.random.choice(np.arange(n_rows), size=subsz, replace=False)\n",
    "    X_sub, y_sub = X_tr.iloc[sub_idx], y12_tr.iloc[sub_idx]\n",
    "    gbr = GradientBoostingRegressor(\n",
    "        n_estimators=GB_TREES, learning_rate=0.05,\n",
    "        max_depth=GB_MAX_DEPTH, subsample=GB_SUBSAMPLE, random_state=42\n",
    "    )\n",
    "    gbr.fit(X_sub, y_sub)\n",
    "    return pd.Series(gbr.feature_importances_, index=X_tr.columns).sort_values(ascending=False)\n",
    "\n",
    "# ---------------- resume/sampling utilities ----------------\n",
    "def list_trained_ridge(base_dir=\"per_station_ridge\"):\n",
    "    \"\"\"Stations considered done if metrics.csv exists (and model.joblib optionally).\"\"\"\n",
    "    if not os.path.exists(base_dir):\n",
    "        return []\n",
    "    done = []\n",
    "    for d in os.listdir(base_dir):\n",
    "        m1 = os.path.join(base_dir, d, \"metrics.csv\")\n",
    "        if os.path.exists(m1):\n",
    "            done.append(d)\n",
    "    return sorted(done)\n",
    "\n",
    "def rebuild_summary_ridge(base_dir=\"per_station_ridge\", outfile=\"summary_all_stations_ridge.csv\"):\n",
    "    rows = []\n",
    "    if not os.path.exists(base_dir):\n",
    "        print(\"[summary_ridge] base_dir not found; nothing to rebuild.\")\n",
    "        return None\n",
    "    for s in os.listdir(base_dir):\n",
    "        mpath = os.path.join(base_dir, s, \"metrics.csv\")\n",
    "        if os.path.exists(mpath):\n",
    "            try:\n",
    "                mdf = pd.read_csv(mpath)\n",
    "                row = {\"station\": s}\n",
    "                row.update({k: float(v) for k, v in zip(mdf[\"metric\"], mdf[\"value\"])})\n",
    "                rows.append(row)\n",
    "            except Exception:\n",
    "                pass\n",
    "    if rows:\n",
    "        sdf = pd.DataFrame(rows)\n",
    "        if \"MAE_mean\" in sdf.columns:\n",
    "            sdf = sdf.sort_values(\"MAE_mean\")\n",
    "        sdf.to_csv(outfile, index=False)\n",
    "        print(f\"[summary_ridge] wrote {outfile} with {len(rows)} rows\")\n",
    "        return sdf\n",
    "    else:\n",
    "        print(\"[summary_ridge] no metrics found to rebuild.\")\n",
    "        return None\n",
    "\n",
    "def sample_stations(df, method=\"stratified\", n=None, seed=42, include_list=None, exclude_set=None):\n",
    "    stations_all = sorted(df[STATION_COL].dropna().unique().tolist())\n",
    "    if exclude_set:\n",
    "        stations_all = [s for s in stations_all if s not in exclude_set]\n",
    "\n",
    "    if method == \"list\":\n",
    "        keep = [s for s in (include_list or []) if s in stations_all]\n",
    "        return keep if (n is None or n >= len(keep)) else keep[:n]\n",
    "\n",
    "    if (n is None) or (n >= len(stations_all)):\n",
    "        return stations_all\n",
    "\n",
    "    rng = np.random.default_rng(seed)\n",
    "\n",
    "    if method == \"random\":\n",
    "        return sorted(rng.choice(stations_all, size=n, replace=False).tolist())\n",
    "\n",
    "    # default: stratified by average flow deciles\n",
    "    stats = (\n",
    "        df[[STATION_COL, FLOW_COL]]\n",
    "        .dropna()\n",
    "        .groupby(STATION_COL)[FLOW_COL]\n",
    "        .mean()\n",
    "        .rename(\"avg_flow\")\n",
    "        .to_frame()\n",
    "        .loc[stations_all]\n",
    "    )\n",
    "    try:\n",
    "        stats[\"bin\"] = pd.qcut(stats[\"avg_flow\"], q=10, labels=False, duplicates=\"drop\")\n",
    "    except Exception:\n",
    "        stats[\"bin\"] = 0\n",
    "\n",
    "    bins = stats[\"bin\"].unique()\n",
    "    total = len(stats)\n",
    "    alloc = {}\n",
    "    for b in sorted(bins):\n",
    "        count_b = (stats[\"bin\"] == b).sum()\n",
    "        alloc[b] = max(1, round(n * (count_b / total)))\n",
    "\n",
    "    diff = n - sum(alloc.values())\n",
    "    order = sorted(alloc, key=lambda b: alloc[b], reverse=(diff > 0))\n",
    "    i = 0\n",
    "    while diff != 0 and order:\n",
    "        b = order[i % len(order)]\n",
    "        if diff > 0:\n",
    "            alloc[b] += 1; diff -= 1\n",
    "        else:\n",
    "            if alloc[b] > 1:\n",
    "                alloc[b] -= 1; diff += 1\n",
    "        i += 1\n",
    "\n",
    "    picked = []\n",
    "    for b in sorted(bins):\n",
    "        pool = stats[stats[\"bin\"] == b].index.tolist()\n",
    "        if not pool:\n",
    "            continue\n",
    "        k = min(alloc[b], len(pool))\n",
    "        sel = rng.choice(pool, size=k, replace=False).tolist()\n",
    "        picked.extend(sel)\n",
    "    return sorted(picked[:n])\n",
    "\n",
    "def compute_overall_metrics_ridge(base_dir=\"per_station_ridge\"):\n",
    "    macro_rows, pooled_abs, pooled_sq = [], [], []\n",
    "    n_total = 0\n",
    "    for s in os.listdir(base_dir) if os.path.exists(base_dir) else []:\n",
    "        mpath = os.path.join(base_dir, s, \"metrics.csv\")\n",
    "        ppath = os.path.join(base_dir, s, \"preds_test.csv\")\n",
    "        if os.path.exists(mpath):\n",
    "            mdf = pd.read_csv(mpath)\n",
    "            m = {k:v for k,v in zip(mdf[\"metric\"], mdf[\"value\"])}\n",
    "            m[\"station\"] = s\n",
    "            macro_rows.append(m)\n",
    "        if os.path.exists(ppath):\n",
    "            pdf = pd.read_csv(ppath, index_col=0)\n",
    "            for col in pdf.columns:\n",
    "                if col.startswith(\"ytrue_\"):\n",
    "                    h = col.replace(\"ytrue_\", \"\")\n",
    "                    y    = pdf[col].values.astype(np.float64)\n",
    "                    yhat = pdf.get(\"ypred_\" + h)\n",
    "                    if yhat is None: \n",
    "                        continue\n",
    "                    yhat = yhat.values.astype(np.float64)\n",
    "                    err = y - yhat\n",
    "                    pooled_abs.append(np.abs(err))\n",
    "                    pooled_sq.append(err**2)\n",
    "                    n_total += len(err)\n",
    "    macro, micro = {}, {}\n",
    "    if macro_rows:\n",
    "        mdf = pd.DataFrame(macro_rows)\n",
    "        if \"MAE_mean\" in mdf.columns:\n",
    "            macro[\"MAE_macro\"]  = float(mdf[\"MAE_mean\"].mean())\n",
    "        if \"RMSE_mean\" in mdf.columns:\n",
    "            macro[\"RMSE_macro\"] = float(mdf[\"RMSE_mean\"].mean())\n",
    "    if pooled_abs and pooled_sq:\n",
    "        pooled_abs = np.concatenate(pooled_abs)\n",
    "        pooled_sq  = np.concatenate(pooled_sq)\n",
    "        micro[\"MAE_micro\"]  = float(pooled_abs.mean())\n",
    "        micro[\"RMSE_micro\"] = float(np.sqrt(pooled_sq.mean()))\n",
    "        micro[\"n_samples\"]  = int(n_total)\n",
    "    return {\"macro\": macro, \"micro\": micro}\n",
    "\n",
    "# ---------------- per-station trainer (saves model + artifacts) ----------------\n",
    "def train_eval_station_ridge(df, flow_wide, target, alpha=RIDGE_ALPHA):\n",
    "    print(f\"\\n=== [Ridge] Station {target} ===\")\n",
    "    station_dir = f\"per_station_ridge/{target}\"\n",
    "    os.makedirs(station_dir, exist_ok=True)\n",
    "\n",
    "    target_idx = df.loc[df[STATION_COL] == target].index.sort_values().unique()\n",
    "    tr_idx, va_idx, te_idx = time_split_index(target_idx)\n",
    "\n",
    "    X_all, Y_all, neighbors = build_XY_for_target_fast(df, flow_wide, target, train_idx=tr_idx)\n",
    "\n",
    "    X_tr = X_all.loc[tr_idx.intersection(X_all.index)]\n",
    "    X_va = X_all.loc[va_idx.intersection(X_all.index)]\n",
    "    X_te = X_all.loc[te_idx.intersection(X_all.index)]\n",
    "    Y_tr = Y_all.loc[X_tr.index]; Y_va = Y_all.loc[X_va.index]; Y_te = Y_all.loc[X_te.index]\n",
    "\n",
    "    print(f\"[GB] Ridge importances on {min(IMP_SUBSAMP, len(X_tr))} rows, {X_tr.shape[1]} feats\")\n",
    "    imp = rank_features_gb(X_tr, Y_tr['y_12h'])\n",
    "    keep_cols = imp.index[:min(TOP_K, len(imp))].tolist()\n",
    "    print(f\"[select] kept {len(keep_cols)} features\")\n",
    "\n",
    "    ridge = Pipeline([\n",
    "        (\"scaler\", StandardScaler(with_mean=True, with_std=True)),\n",
    "        (\"model\", Ridge(alpha=alpha, random_state=42))\n",
    "    ])\n",
    "    ridge.fit(X_tr[keep_cols], Y_tr.values)\n",
    "\n",
    "    Yhat_te = ridge.predict(X_te[keep_cols])\n",
    "    results = metrics_by_horizon(Y_te.values, Yhat_te)\n",
    "\n",
    "    Yte_df  = pd.DataFrame(Y_te.values, index=X_te.index, columns=ORDERED_COLS)\n",
    "    Yhat_df = pd.DataFrame(Yhat_te, index=X_te.index, columns=ORDERED_COLS)\n",
    "    baseline_res = lv_baseline_metrics(Yte_df, df.loc[df[STATION_COL]==target, FLOW_COL].sort_index())\n",
    "\n",
    "    final_metrics = {**results, **baseline_res,\n",
    "                     \"neighbors_used\": len(neighbors), \"features_used\": len(keep_cols)}\n",
    "    pd.DataFrame(list(final_metrics.items()), columns=[\"metric\", \"value\"]).to_csv(f\"{station_dir}/metrics.csv\", index=False)\n",
    "    pd.concat([Yte_df.add_prefix(\"ytrue_\"), Yhat_df.add_prefix(\"ypred_\")], axis=1).to_csv(f\"{station_dir}/preds_test.csv\")\n",
    "    pd.DataFrame({\"feature\": keep_cols}).to_csv(f\"{station_dir}/kept_features.csv\", index=False)\n",
    "\n",
    "    # save the trained model for resume/inspection\n",
    "    try:\n",
    "        joblib.dump({\"model\": ridge, \"keep_cols\": keep_cols, \"alpha\": alpha}, f\"{station_dir}/model.joblib\")\n",
    "    except Exception as e:\n",
    "        print(f\"[warn] could not save model.joblib: {e}\")\n",
    "\n",
    "    gc.collect()\n",
    "    row = {\"station\": target}; row.update(final_metrics)\n",
    "    return row\n",
    "\n",
    "# ---------------- main (resume-aware + sampling) ----------------\n",
    "def run_all_stations_ridge_resume(df, alpha=RIDGE_ALPHA):\n",
    "    if not isinstance(df.index, pd.DatetimeIndex):\n",
    "        raise ValueError(\"df must have a DateTimeIndex\")\n",
    "    os.makedirs(\"per_station_ridge\", exist_ok=True)\n",
    "\n",
    "    done = set(list_trained_ridge(\"per_station_ridge\"))\n",
    "    print(f\"[resume_ridge] already-trained stations: {len(done)}\")\n",
    "    _ = rebuild_summary_ridge(\"per_station_ridge\", \"summary_all_stations_ridge.csv\")\n",
    "\n",
    "    print(\"[prep] computing flow_wide...]\")\n",
    "    flow_wide = compute_flow_wide(df)\n",
    "\n",
    "    stations_all = sorted(df[STATION_COL].dropna().unique())\n",
    "    remaining = [s for s in stations_all if s not in done]\n",
    "    print(f\"[stations] total: {len(stations_all)} | remaining to train: {len(remaining)}\")\n",
    "\n",
    "    stations = sample_stations(\n",
    "        df=df,\n",
    "        method=STATION_SAMPLE_METHOD,\n",
    "        n=STATION_SAMPLE_N,\n",
    "        seed=RANDOM_SEED,\n",
    "        include_list=INCLUDED_STATIONS_LIST,\n",
    "        exclude_set=done,\n",
    "    )\n",
    "    print(f\"[sampling] selected {len(stations)} stations to train \"\n",
    "          f\"(method='{STATION_SAMPLE_METHOD}', n={STATION_SAMPLE_N})\")\n",
    "\n",
    "    rows = []\n",
    "    for s in stations:\n",
    "        try:\n",
    "            station_dir = f\"per_station_ridge/{s}\"\n",
    "            metrics_csv = f\"{station_dir}/metrics.csv\"\n",
    "            model_path  = f\"{station_dir}/model.joblib\"\n",
    "            if SKIP_IF_EXISTS and (os.path.exists(metrics_csv) or os.path.exists(model_path)):\n",
    "                print(f\"\\n=== [Ridge] Station {s} ===\")\n",
    "                print(\"[skip] found existing metrics/model\")\n",
    "                try:\n",
    "                    mdf = pd.read_csv(metrics_csv)\n",
    "                    row = {\"station\": s}\n",
    "                    row.update({k: float(v) for k, v in zip(mdf[\"metric\"], mdf[\"value\"])})\n",
    "                    rows.append(row)\n",
    "                except Exception:\n",
    "                    pass\n",
    "                continue\n",
    "\n",
    "            rows.append(train_eval_station_ridge(df, flow_wide, s, alpha=alpha))\n",
    "\n",
    "        except Exception as e:\n",
    "            # FIXED: proper f-string\n",
    "            print(f\"[Ridge {s}] ERROR: {e}\")\n",
    "\n",
    "    # write/update summary\n",
    "    if rows:\n",
    "        new_df = pd.DataFrame(rows)\n",
    "        try:\n",
    "            old_df = pd.read_csv(\"summary_all_stations_ridge.csv\")\n",
    "        except Exception:\n",
    "            old_df = pd.DataFrame()\n",
    "        if not old_df.empty:\n",
    "            comb = pd.concat([old_df, new_df], ignore_index=True)\n",
    "            comb = comb.sort_values(by=[\"station\"]).drop_duplicates(subset=[\"station\"], keep=\"last\")\n",
    "        else:\n",
    "            comb = new_df\n",
    "        if \"MAE_mean\" in comb.columns:\n",
    "            comb = comb.sort_values(\"MAE_mean\")\n",
    "        comb.to_csv(\"summary_all_stations_ridge.csv\", index=False)\n",
    "        print(\"Saved/updated summary_all_stations_ridge.csv\")\n",
    "    else:\n",
    "        print(\"No new station results produced. Check inputs and schema.\")\n",
    "\n",
    "    # overall metrics\n",
    "    overall = compute_overall_metrics_ridge(\"per_station_ridge\")\n",
    "    print(\"Overall Ridge (macro avg of station means):\", overall[\"macro\"])\n",
    "    print(\"Overall Ridge (micro on pooled errors):    \", overall[\"micro\"])\n",
    "\n",
    "# ===== RUN =====\n",
    "# Expect df with DateTimeIndex and columns [STATION_COL, FLOW_COL, ... non-flow features ...]\n",
    "run_all_stations_ridge_resume(df, alpha=RIDGE_ALPHA)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "ebf6e807",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[saved] per-horizon Ridge metrics → per_station_ridge/overall_by_horizon_ridge.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>horizon</th>\n",
       "      <th>MAE_macro</th>\n",
       "      <th>RMSE_macro</th>\n",
       "      <th>MAE_micro</th>\n",
       "      <th>RMSE_micro</th>\n",
       "      <th>n_samples</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12h</td>\n",
       "      <td>232.966203</td>\n",
       "      <td>295.881037</td>\n",
       "      <td>230.831570</td>\n",
       "      <td>408.567135</td>\n",
       "      <td>82542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>24h</td>\n",
       "      <td>193.394581</td>\n",
       "      <td>254.373624</td>\n",
       "      <td>195.073163</td>\n",
       "      <td>380.959832</td>\n",
       "      <td>82542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>48h</td>\n",
       "      <td>211.428556</td>\n",
       "      <td>282.781773</td>\n",
       "      <td>213.836231</td>\n",
       "      <td>414.430225</td>\n",
       "      <td>82542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>72h</td>\n",
       "      <td>221.980577</td>\n",
       "      <td>300.144994</td>\n",
       "      <td>221.907537</td>\n",
       "      <td>432.606595</td>\n",
       "      <td>82542</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  horizon   MAE_macro  RMSE_macro   MAE_micro  RMSE_micro  n_samples\n",
       "0     12h  232.966203  295.881037  230.831570  408.567135      82542\n",
       "1     24h  193.394581  254.373624  195.073163  380.959832      82542\n",
       "2     48h  211.428556  282.781773  213.836231  414.430225      82542\n",
       "3     72h  221.980577  300.144994  221.907537  432.606595      82542"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ================== RIDGE (LINEAR REGRESSION): OVERALL METRICS BY HORIZON (MACRO & MICRO) ==================\n",
    "import os, numpy as np, pandas as pd\n",
    "\n",
    "HORIZONS = [12, 24, 48, 72]\n",
    "BASE_DIR = \"per_station_ridge\"   # Ridge model results directory\n",
    "\n",
    "def compute_overall_by_horizon_ridge(base_dir=BASE_DIR, horizons=HORIZONS):\n",
    "    macro_lists = {h: {\"mae\": [], \"rmse\": []} for h in horizons}\n",
    "    micro_abs, micro_sq, micro_n = {h: [] for h in horizons}, {h: [] for h in horizons}, {h: 0 for h in horizons}\n",
    "\n",
    "    if not os.path.exists(base_dir):\n",
    "        raise FileNotFoundError(f\"{base_dir} not found\")\n",
    "\n",
    "    stations = [d for d in os.listdir(base_dir) if os.path.isdir(os.path.join(base_dir, d))]\n",
    "    for s in stations:\n",
    "        ppath = os.path.join(base_dir, s, \"preds_test.csv\")\n",
    "        if not os.path.exists(ppath):\n",
    "            continue\n",
    "        pdf = pd.read_csv(ppath, index_col=0)\n",
    "\n",
    "        for h in horizons:\n",
    "            ytrue_col = f\"ytrue_y_{h}h\"\n",
    "            ypred_col = f\"ypred_y_{h}h\"\n",
    "            if ytrue_col not in pdf.columns or ypred_col not in pdf.columns:\n",
    "                continue\n",
    "            y, yhat = pdf[ytrue_col].values.astype(float), pdf[ypred_col].values.astype(float)\n",
    "            err = y - yhat\n",
    "            mae, rmse = np.abs(err).mean(), np.sqrt((err**2).mean())\n",
    "            macro_lists[h][\"mae\"].append(mae)\n",
    "            macro_lists[h][\"rmse\"].append(rmse)\n",
    "            micro_abs[h].append(np.abs(err))\n",
    "            micro_sq[h].append(err**2)\n",
    "            micro_n[h] += len(err)\n",
    "\n",
    "    rows = []\n",
    "    for h in horizons:\n",
    "        # macro = mean of per-station means\n",
    "        mae_macro = np.mean(macro_lists[h][\"mae\"]) if macro_lists[h][\"mae\"] else np.nan\n",
    "        rmse_macro = np.mean(macro_lists[h][\"rmse\"]) if macro_lists[h][\"rmse\"] else np.nan\n",
    "\n",
    "        # micro = pooled across all samples\n",
    "        if micro_abs[h]:\n",
    "            abs_all, sq_all = np.concatenate(micro_abs[h]), np.concatenate(micro_sq[h])\n",
    "            mae_micro = abs_all.mean()\n",
    "            rmse_micro = np.sqrt(sq_all.mean())\n",
    "            n_samp = micro_n[h]\n",
    "        else:\n",
    "            mae_micro, rmse_micro, n_samp = np.nan, np.nan, 0\n",
    "\n",
    "        rows.append({\n",
    "            \"horizon\": f\"{h}h\",\n",
    "            \"MAE_macro\": mae_macro, \"RMSE_macro\": rmse_macro,\n",
    "            \"MAE_micro\": mae_micro, \"RMSE_micro\": rmse_micro,\n",
    "            \"n_samples\": n_samp\n",
    "        })\n",
    "\n",
    "    df_out = pd.DataFrame(rows)\n",
    "    out_path = os.path.join(base_dir, \"overall_by_horizon_ridge.csv\")\n",
    "    df_out.to_csv(out_path, index=False)\n",
    "    print(f\"[saved] per-horizon Ridge metrics → {out_path}\")\n",
    "    return df_out\n",
    "\n",
    "# -------- run --------\n",
    "ridge_overall = compute_overall_by_horizon_ridge()\n",
    "display(ridge_overall)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "00fa05e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[saved] common index (667 rows) → fair_eval/common_test_index.csv\n"
     ]
    }
   ],
   "source": [
    "import os, pandas as pd\n",
    "\n",
    "def build_common_test_index(model_dirs, out_csv=\"fair_eval/common_test_index.csv\"):\n",
    "    os.makedirs(\"fair_eval\", exist_ok=True)\n",
    "    sets = []\n",
    "    for base in model_dirs:\n",
    "        ts = set()\n",
    "        if not os.path.exists(base): \n",
    "            continue\n",
    "        for s in os.listdir(base):\n",
    "            f = os.path.join(base, s, \"preds_test.csv\")\n",
    "            if os.path.exists(f):\n",
    "                dfp = pd.read_csv(f, index_col=0)\n",
    "                ts.update(dfp.index.astype(str).tolist())\n",
    "        if ts:\n",
    "            sets.append(ts)\n",
    "    common = sorted(set.intersection(*sets))\n",
    "    pd.DataFrame({\"timestamp\": common}).to_csv(out_csv, index=False)\n",
    "    print(f\"[saved] common index ({len(common)} rows) → {out_csv}\")\n",
    "    return out_csv\n",
    "\n",
    "common_csv = build_common_test_index(\n",
    "    [\"per_station\", \"per_station_rf\", \"per_station_ridge\"]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "8b49e0e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[saved] per-horizon LSTM (common) → per_station/overall_by_horizon_lstm_common.csv\n"
     ]
    }
   ],
   "source": [
    "def compute_overall_by_horizon_lstm_common(base_dir=\"per_station\", horizons=[12,24,48,72], common_csv=\"fair_eval/common_test_index.csv\"):\n",
    "    import numpy as np, pandas as pd, os\n",
    "    common = set(pd.read_csv(common_csv)[\"timestamp\"].astype(str))\n",
    "    macro = {h: {\"mae\":[], \"rmse\":[]} for h in horizons}\n",
    "    micro_abs = {h:[] for h in horizons}; micro_sq = {h:[] for h in horizons}; micro_n={h:0 for h in horizons}\n",
    "    for s in os.listdir(base_dir):\n",
    "        f = os.path.join(base_dir, s, \"preds_test.csv\")\n",
    "        if not os.path.exists(f): continue\n",
    "        pdf = pd.read_csv(f, index_col=0); pdf.index = pdf.index.astype(str)\n",
    "        pdf = pdf.loc[pdf.index.isin(common)]\n",
    "        if pdf.empty: continue\n",
    "        for h in horizons:\n",
    "            ytrue = f\"ytrue_y_{h}h\"; ypred = f\"ypred_y_{h}h\"\n",
    "            if ytrue not in pdf or ypred not in pdf: continue\n",
    "            y = pdf[ytrue].values.astype(float); yhat = pdf[ypred].values.astype(float)\n",
    "            err = y - yhat\n",
    "            mae = np.abs(err).mean(); rmse = np.sqrt((err**2).mean())\n",
    "            macro[h][\"mae\"].append(mae); macro[h][\"rmse\"].append(rmse)\n",
    "            micro_abs[h].append(np.abs(err)); micro_sq[h].append(err**2); micro_n[h]+=len(err)\n",
    "    rows=[]\n",
    "    for h in horizons:\n",
    "        mae_macro = float(np.mean(macro[h][\"mae\"])) if macro[h][\"mae\"] else np.nan\n",
    "        rmse_macro= float(np.mean(macro[h][\"rmse\"])) if macro[h][\"rmse\"] else np.nan\n",
    "        if micro_abs[h]:\n",
    "            import numpy as np\n",
    "            abs_all=np.concatenate(micro_abs[h]); sq_all=np.concatenate(micro_sq[h])\n",
    "            mae_micro=float(abs_all.mean()); rmse_micro=float(np.sqrt(sq_all.mean())); n=int(micro_n[h])\n",
    "        else:\n",
    "            mae_micro=rmse_micro=np.nan; n=0\n",
    "        rows.append({\"horizon\":f\"{h}h\",\"MAE_macro\":mae_macro,\"RMSE_macro\":rmse_macro,\"MAE_micro\":mae_micro,\"RMSE_micro\":rmse_micro,\"n_samples\":n})\n",
    "    out = pd.DataFrame(rows)\n",
    "    out.to_csv(os.path.join(base_dir,\"overall_by_horizon_lstm_common.csv\"), index=False)\n",
    "    print(\"[saved] per-horizon LSTM (common) →\", os.path.join(base_dir,\"overall_by_horizon_lstm_common.csv\"))\n",
    "    return out\n",
    "\n",
    "lstm_common = compute_overall_by_horizon_lstm_common()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "9083fb26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- PATCHED FUNCTION (drop this below your existing imports and rerun) ---\n",
    "import os, numpy as np, pandas as pd\n",
    "\n",
    "def compute_overall_by_horizon_rf(base_dir=\"per_station_rf\",\n",
    "                                  horizons=[12,24,48,72],\n",
    "                                  use_common_index=False,\n",
    "                                  common_index_path=\"fair_eval/common_test_index.csv\"):\n",
    "    \"\"\"Compute per-horizon MAE/RMSE (macro + micro). \n",
    "       If use_common_index=True, restricts to timestamps in the given CSV.\"\"\"\n",
    "    macro_lists = {h: {\"mae\": [], \"rmse\": []} for h in horizons}\n",
    "    micro_abs, micro_sq, micro_n = {h: [] for h in horizons}, {h: [] for h in horizons}, {h: 0 for h in horizons}\n",
    "\n",
    "    # Load the common timestamps if requested\n",
    "    common_idx = None\n",
    "    if use_common_index and os.path.exists(common_index_path):\n",
    "        common_idx = set(pd.read_csv(common_index_path)[\"timestamp\"].astype(str))\n",
    "        print(f\"[info] restricting evaluation to {len(common_idx)} common timestamps\")\n",
    "    elif use_common_index:\n",
    "        raise FileNotFoundError(f\"{common_index_path} not found\")\n",
    "\n",
    "    if not os.path.exists(base_dir):\n",
    "        raise FileNotFoundError(f\"{base_dir} not found\")\n",
    "\n",
    "    stations = [d for d in os.listdir(base_dir) if os.path.isdir(os.path.join(base_dir, d))]\n",
    "    for s in stations:\n",
    "        ppath = os.path.join(base_dir, s, \"preds_test.csv\")\n",
    "        if not os.path.exists(ppath):\n",
    "            continue\n",
    "        pdf = pd.read_csv(ppath, index_col=0)\n",
    "        pdf.index = pdf.index.astype(str)\n",
    "        if use_common_index and common_idx is not None:\n",
    "            pdf = pdf.loc[pdf.index.isin(common_idx)]\n",
    "            if pdf.empty:\n",
    "                continue\n",
    "\n",
    "        for h in horizons:\n",
    "            ytrue_col = f\"ytrue_y_{h}h\"\n",
    "            ypred_col = f\"ypred_y_{h}h\"\n",
    "            if ytrue_col not in pdf.columns or ypred_col not in pdf.columns:\n",
    "                continue\n",
    "            y, yhat = pdf[ytrue_col].values.astype(float), pdf[ypred_col].values.astype(float)\n",
    "            err = y - yhat\n",
    "            mae, rmse = np.abs(err).mean(), np.sqrt((err**2).mean())\n",
    "            macro_lists[h][\"mae\"].append(mae)\n",
    "            macro_lists[h][\"rmse\"].append(rmse)\n",
    "            micro_abs[h].append(np.abs(err))\n",
    "            micro_sq[h].append(err**2)\n",
    "            micro_n[h] += len(err)\n",
    "\n",
    "    rows = []\n",
    "    for h in horizons:\n",
    "        mae_macro = float(np.mean(macro_lists[h][\"mae\"])) if macro_lists[h][\"mae\"] else np.nan\n",
    "        rmse_macro= float(np.mean(macro_lists[h][\"rmse\"])) if macro_lists[h][\"rmse\"] else np.nan\n",
    "        if micro_abs[h]:\n",
    "            abs_all=np.concatenate(micro_abs[h]); sq_all=np.concatenate(micro_sq[h])\n",
    "            mae_micro=float(abs_all.mean()); rmse_micro=float(np.sqrt(sq_all.mean())); n=int(micro_n[h])\n",
    "        else:\n",
    "            mae_micro=rmse_micro=np.nan; n=0\n",
    "        rows.append({\n",
    "            \"horizon\":f\"{h}h\",\n",
    "            \"MAE_macro\":mae_macro,\"RMSE_macro\":rmse_macro,\n",
    "            \"MAE_micro\":mae_micro,\"RMSE_micro\":rmse_micro,\n",
    "            \"n_samples\":n\n",
    "        })\n",
    "\n",
    "    df_out = pd.DataFrame(rows)\n",
    "    suffix = \"_common\" if use_common_index else \"\"\n",
    "    out_path = os.path.join(base_dir, f\"overall_by_horizon_rf{suffix}.csv\")\n",
    "    df_out.to_csv(out_path, index=False)\n",
    "    print(f\"[saved] per-horizon RF metrics → {out_path}\")\n",
    "    return df_out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "75fa8f5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] restricting evaluation to 667 common timestamps\n",
      "[saved] per-horizon RF metrics → per_station_rf/overall_by_horizon_rf_common.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>horizon</th>\n",
       "      <th>MAE_macro</th>\n",
       "      <th>RMSE_macro</th>\n",
       "      <th>MAE_micro</th>\n",
       "      <th>RMSE_micro</th>\n",
       "      <th>n_samples</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12h</td>\n",
       "      <td>137.337276</td>\n",
       "      <td>204.942804</td>\n",
       "      <td>138.778931</td>\n",
       "      <td>274.684928</td>\n",
       "      <td>62856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>24h</td>\n",
       "      <td>136.352326</td>\n",
       "      <td>216.672993</td>\n",
       "      <td>139.334011</td>\n",
       "      <td>295.799619</td>\n",
       "      <td>62856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>48h</td>\n",
       "      <td>145.867882</td>\n",
       "      <td>230.891525</td>\n",
       "      <td>149.409867</td>\n",
       "      <td>316.303122</td>\n",
       "      <td>62856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>72h</td>\n",
       "      <td>154.720925</td>\n",
       "      <td>240.349655</td>\n",
       "      <td>157.138336</td>\n",
       "      <td>328.045507</td>\n",
       "      <td>62856</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  horizon   MAE_macro  RMSE_macro   MAE_micro  RMSE_micro  n_samples\n",
       "0     12h  137.337276  204.942804  138.778931  274.684928      62856\n",
       "1     24h  136.352326  216.672993  139.334011  295.799619      62856\n",
       "2     48h  145.867882  230.891525  149.409867  316.303122      62856\n",
       "3     72h  154.720925  240.349655  157.138336  328.045507      62856"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rf_common = compute_overall_by_horizon_rf(\n",
    "    use_common_index=True,\n",
    "    common_index_path=\"fair_eval/common_test_index.csv\"\n",
    ")\n",
    "display(rf_common)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "b738704f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[saved] per-horizon Ridge (common) → per_station_ridge/overall_by_horizon_ridge_common.csv\n"
     ]
    }
   ],
   "source": [
    "def compute_overall_by_horizon_ridge_common(base_dir=\"per_station_ridge\", horizons=[12,24,48,72], common_csv=\"fair_eval/common_test_index.csv\"):\n",
    "    import numpy as np, pandas as pd, os\n",
    "    common = set(pd.read_csv(common_csv)[\"timestamp\"].astype(str))\n",
    "    macro = {h: {\"mae\":[], \"rmse\":[]} for h in horizons}\n",
    "    micro_abs = {h:[] for h in horizons}; micro_sq = {h:[] for h in horizons}; micro_n={h:0 for h in horizons}\n",
    "    for s in os.listdir(base_dir):\n",
    "        f = os.path.join(base_dir, s, \"preds_test.csv\")\n",
    "        if not os.path.exists(f): continue\n",
    "        pdf = pd.read_csv(f, index_col=0); pdf.index = pdf.index.astype(str)\n",
    "        pdf = pdf.loc[pdf.index.isin(common)]\n",
    "        if pdf.empty: continue\n",
    "        for h in horizons:\n",
    "            ytrue = f\"ytrue_y_{h}h\"; ypred = f\"ypred_y_{h}h\"\n",
    "            if ytrue not in pdf or ypred not in pdf: continue\n",
    "            y = pdf[ytrue].values.astype(float); yhat = pdf[ypred].values.astype(float)\n",
    "            err = y - yhat\n",
    "            mae = np.abs(err).mean(); rmse = np.sqrt((err**2).mean())\n",
    "            macro[h][\"mae\"].append(mae); macro[h][\"rmse\"].append(rmse)\n",
    "            micro_abs[h].append(np.abs(err)); micro_sq[h].append(err**2); micro_n[h]+=len(err)\n",
    "    rows=[]\n",
    "    for h in horizons:\n",
    "        mae_macro = float(np.mean(macro[h][\"mae\"])) if macro[h][\"mae\"] else np.nan\n",
    "        rmse_macro= float(np.mean(macro[h][\"rmse\"])) if macro[h][\"rmse\"] else np.nan\n",
    "        if micro_abs[h]:\n",
    "            import numpy as np\n",
    "            abs_all=np.concatenate(micro_abs[h]); sq_all=np.concatenate(micro_sq[h])\n",
    "            mae_micro=float(abs_all.mean()); rmse_micro=float(np.sqrt(sq_all.mean())); n=int(micro_n[h])\n",
    "        else:\n",
    "            mae_micro=rmse_micro=np.nan; n=0\n",
    "        rows.append({\"horizon\":f\"{h}h\",\"MAE_macro\":mae_macro,\"RMSE_macro\":rmse_macro,\"MAE_micro\":mae_micro,\"RMSE_micro\":rmse_micro,\"n_samples\":n})\n",
    "    out = pd.DataFrame(rows)\n",
    "    out.to_csv(os.path.join(base_dir,\"overall_by_horizon_ridge_common.csv\"), index=False)\n",
    "    print(\"[saved] per-horizon Ridge (common) →\", os.path.join(base_dir,\"overall_by_horizon_ridge_common.csv\"))\n",
    "    return out\n",
    "\n",
    "ridge_common = compute_overall_by_horizon_ridge_common()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "4bbec530",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[saved] COMMON per-station index → fair_eval/common_index_by_station.csv (rows=13670)\n",
      "[saved] BALANCED per-station×horizon index → fair_eval/balanced_index_by_station.csv (rows=54680)\n",
      "[saved] per-horizon metrics → per_station/overall_by_horizon_common.csv\n",
      "[saved] per-horizon metrics → per_station_rf/overall_by_horizon_common.csv\n",
      "[saved] per-horizon metrics → per_station_ridge/overall_by_horizon_common.csv\n",
      "[saved] per-horizon metrics → per_station/overall_by_horizon_balanced.csv\n",
      "[saved] per-horizon metrics → per_station_rf/overall_by_horizon_balanced.csv\n",
      "[saved] per-horizon metrics → per_station_ridge/overall_by_horizon_balanced.csv\n",
      "[saved] side-by-side comparison → fair_eval/comparison_common.csv\n",
      "[saved] side-by-side comparison → fair_eval/comparison_balanced.csv\n"
     ]
    }
   ],
   "source": [
    "# ================= FAIR EVAL TOOLKIT: common per-station index + (optional) balanced sampling + per-horizon metrics =================\n",
    "import os, numpy as np, pandas as pd\n",
    "\n",
    "HORIZONS = [12, 24, 48, 72]\n",
    "MODEL_DIRS = {\n",
    "    \"LSTM\":  \"per_station\",\n",
    "    \"RF\":    \"per_station_rf\",\n",
    "    \"Ridge\": \"per_station_ridge\",\n",
    "}\n",
    "FAIR_DIR = \"fair_eval\"\n",
    "os.makedirs(FAIR_DIR, exist_ok=True)\n",
    "\n",
    "\n",
    "# -------- 1) Build COMMON per-station timestamp index (intersection across all provided model dirs) --------\n",
    "def build_common_index_by_station(model_dirs=MODEL_DIRS.values(), out_csv=f\"{FAIR_DIR}/common_index_by_station.csv\"):\n",
    "    \"\"\"\n",
    "    For each STATION, find the intersection of timestamps present in preds_test.csv across all models.\n",
    "    Output: CSV with columns [station, timestamp]\n",
    "    \"\"\"\n",
    "    # Collect per model: dict(station -> set(timestamps))\n",
    "    per_model = []\n",
    "    for base in model_dirs:\n",
    "        if not os.path.exists(base):\n",
    "            continue\n",
    "        station_to_ts = {}\n",
    "        for s in os.listdir(base):\n",
    "            p = os.path.join(base, s, \"preds_test.csv\")\n",
    "            if not os.path.exists(p): \n",
    "                continue\n",
    "            dfp = pd.read_csv(p, index_col=0)\n",
    "            dfp.index = dfp.index.astype(str)\n",
    "            station_to_ts[s] = set(dfp.index.tolist())\n",
    "        if station_to_ts:\n",
    "            per_model.append(station_to_ts)\n",
    "\n",
    "    # Stations common to all models\n",
    "    if not per_model:\n",
    "        raise RuntimeError(\"No preds_test.csv found in provided model directories.\")\n",
    "    common_stations = set(per_model[0].keys())\n",
    "    for d in per_model[1:]:\n",
    "        common_stations &= set(d.keys())\n",
    "\n",
    "    rows = []\n",
    "    for s in sorted(common_stations):\n",
    "        # Intersect timestamps across models for this station\n",
    "        ts_sets = [m[s] for m in per_model if s in m]\n",
    "        if not ts_sets:\n",
    "            continue\n",
    "        ts_common = sorted(set.intersection(*ts_sets))\n",
    "        for t in ts_common:\n",
    "            rows.append({\"station\": s, \"timestamp\": t})\n",
    "\n",
    "    out = pd.DataFrame(rows)\n",
    "    out.to_csv(out_csv, index=False)\n",
    "    print(f\"[saved] COMMON per-station index → {out_csv} (rows={len(out)})\")\n",
    "    return out_csv\n",
    "\n",
    "\n",
    "# -------- 2) (Optional) Build BALANCED per-station×horizon index (downsample to min N across models) --------\n",
    "def build_balanced_index_by_station(\n",
    "    model_dirs=MODEL_DIRS.values(),\n",
    "    horizons=HORIZONS,\n",
    "    base_common_csv=f\"{FAIR_DIR}/common_index_by_station.csv\",\n",
    "    out_csv=f\"{FAIR_DIR}/balanced_index_by_station.csv\",\n",
    "    seed=42\n",
    "):\n",
    "    \"\"\"\n",
    "    For each station & horizon, count how many rows each model has in the common index,\n",
    "    find the minimum count across models, and randomly sample that many timestamps so each model\n",
    "    is evaluated on the exact same N per station×horizon.\n",
    "    Assumes preds_test.csv have columns ytrue_y_{h}h / ypred_y_{h}h.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(base_common_csv):\n",
    "        raise FileNotFoundError(f\"{base_common_csv} not found; run build_common_index_by_station first.\")\n",
    "\n",
    "    rng = np.random.default_rng(seed)\n",
    "    common = pd.read_csv(base_common_csv)\n",
    "    common[\"timestamp\"] = common[\"timestamp\"].astype(str)\n",
    "\n",
    "    # For fast membership tests, load all preds into dict[(model, station)] = df\n",
    "    cache = {}\n",
    "    for model_name, base in MODEL_DIRS.items():\n",
    "        if not os.path.exists(base):\n",
    "            continue\n",
    "        for s in os.listdir(base):\n",
    "            p = os.path.join(base, s, \"preds_test.csv\")\n",
    "            if os.path.exists(p):\n",
    "                dfp = pd.read_csv(p, index_col=0)\n",
    "                dfp.index = dfp.index.astype(str)\n",
    "                cache[(model_name, s)] = dfp\n",
    "\n",
    "    rows = []\n",
    "    for s in sorted(common[\"station\"].unique()):\n",
    "        ts_common_s = common.loc[common[\"station\"]==s, \"timestamp\"].tolist()\n",
    "        if not ts_common_s:\n",
    "            continue\n",
    "        ts_set_s = set(ts_common_s)\n",
    "\n",
    "        # For each horizon, find min available N across models\n",
    "        for h in horizons:\n",
    "            ytrue_col = f\"ytrue_y_{h}h\"\n",
    "            ypred_col = f\"ypred_y_{h}h\"\n",
    "\n",
    "            counts = {}\n",
    "            usable_ts_per_model = {}\n",
    "            for model_name in MODEL_DIRS.keys():\n",
    "                dfp = cache.get((model_name, s))\n",
    "                if dfp is None:\n",
    "                    counts[model_name] = 0\n",
    "                    usable_ts_per_model[model_name] = []\n",
    "                    continue\n",
    "                # restrict to common timestamps\n",
    "                dfp_s = dfp.loc[dfp.index.isin(ts_set_s)]\n",
    "                # only rows with both ytrue and ypred present\n",
    "                if ytrue_col in dfp_s.columns and ypred_col in dfp_s.columns:\n",
    "                    idx_ok = dfp_s.index[ dfp_s[ytrue_col].notna() & dfp_s[ypred_col].notna() ]\n",
    "                    usable = idx_ok.tolist()\n",
    "                else:\n",
    "                    usable = []\n",
    "                counts[model_name] = len(usable)\n",
    "                usable_ts_per_model[model_name] = usable\n",
    "\n",
    "            if not counts:\n",
    "                continue\n",
    "            min_n = min(counts.values())\n",
    "            if min_n == 0:\n",
    "                # no fair comparison possible for this station×horizon\n",
    "                continue\n",
    "\n",
    "            # choose a shared subset of timestamps of size min_n\n",
    "            # pick from the intersection across models' usable ts\n",
    "            # if intersection < min_n, fallback to random sample on each model's own set (still keeps counts equal)\n",
    "            intersect_ts = set.intersection(*[set(usable_ts_per_model[m]) for m in MODEL_DIRS.keys() if counts[m]>0])\n",
    "            if len(intersect_ts) >= min_n:\n",
    "                chosen = sorted(rng.choice(list(intersect_ts), size=min_n, replace=False).tolist())\n",
    "            else:\n",
    "                # fallback: sample per model's own usable set, but we only need a unified list\n",
    "                # union and sample min_n from there (ensures all have at least min_n, but might not be identical per model)\n",
    "                # For strict fairness, we prefer intersection; union fallback is last resort.\n",
    "                union_ts = set().union(*[set(usable_ts_per_model[m]) for m in MODEL_DIRS.keys()])\n",
    "                chosen = sorted(rng.choice(list(union_ts), size=min_n, replace=False).tolist())\n",
    "\n",
    "            for t in chosen:\n",
    "                rows.append({\"station\": s, \"timestamp\": t, \"horizon\": f\"{h}h\"})\n",
    "\n",
    "    out = pd.DataFrame(rows)\n",
    "    out.to_csv(out_csv, index=False)\n",
    "    print(f\"[saved] BALANCED per-station×horizon index → {out_csv} (rows={len(out)})\")\n",
    "    return out_csv\n",
    "\n",
    "\n",
    "# -------- 3) Generic per-horizon metrics using an index (common or balanced) --------\n",
    "def compute_overall_by_horizon_with_index(\n",
    "    base_dir, horizons=HORIZONS, index_csv=f\"{FAIR_DIR}/common_index_by_station.csv\", balanced=False\n",
    "):\n",
    "    \"\"\"\n",
    "    Reads base_dir/<station>/preds_test.csv and filters rows to those in index_csv.\n",
    "    If balanced=True and index_csv has a 'horizon' column, it filters per horizon accordingly.\n",
    "    Returns DataFrame with per-horizon MAE/RMSE (macro + micro) and saves a CSV.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(index_csv):\n",
    "        raise FileNotFoundError(f\"{index_csv} not found\")\n",
    "\n",
    "    idx_df = pd.read_csv(index_csv)\n",
    "    idx_df[\"timestamp\"] = idx_df[\"timestamp\"].astype(str)\n",
    "    has_h_col = (\"horizon\" in idx_df.columns)\n",
    "\n",
    "    # Build mapping: station -> {all timestamps} or {horizon -> timestamps}\n",
    "    if balanced and has_h_col:\n",
    "        map_s_h = {}\n",
    "        for s, g in idx_df.groupby(\"station\"):\n",
    "            map_s_h[s] = {h: set(g.loc[g[\"horizon\"]==h, \"timestamp\"].tolist()) for h in g[\"horizon\"].unique()}\n",
    "    else:\n",
    "        map_s = {s: set(g[\"timestamp\"].tolist()) for s, g in idx_df.groupby(\"station\")}\n",
    "\n",
    "    macro_lists = {h: {\"mae\": [], \"rmse\": []} for h in horizons}\n",
    "    micro_abs   = {h: [] for h in horizons}\n",
    "    micro_sq    = {h: [] for h in horizons}\n",
    "    micro_n     = {h: 0  for h in horizons}\n",
    "\n",
    "    if not os.path.exists(base_dir):\n",
    "        raise FileNotFoundError(f\"{base_dir} not found\")\n",
    "\n",
    "    stations = [d for d in os.listdir(base_dir) if os.path.isdir(os.path.join(base_dir, d))]\n",
    "    for s in stations:\n",
    "        p = os.path.join(base_dir, s, \"preds_test.csv\")\n",
    "        if not os.path.exists(p): \n",
    "            continue\n",
    "        pdf = pd.read_csv(p, index_col=0)\n",
    "        pdf.index = pdf.index.astype(str)\n",
    "\n",
    "        for h in horizons:\n",
    "            ytrue_col = f\"ytrue_y_{h}h\"; ypred_col = f\"ypred_y_{h}h\"\n",
    "            if ytrue_col not in pdf.columns or ypred_col not in pdf.columns:\n",
    "                continue\n",
    "\n",
    "            if balanced and has_h_col:\n",
    "                ts_keep = map_s_h.get(s, {}).get(f\"{h}h\", set())\n",
    "            else:\n",
    "                ts_keep = map_s.get(s, set())\n",
    "\n",
    "            if not ts_keep:\n",
    "                continue\n",
    "\n",
    "            sub = pdf.loc[pdf.index.isin(ts_keep)]\n",
    "            if sub.empty: \n",
    "                continue\n",
    "\n",
    "            y = sub[ytrue_col].values.astype(float)\n",
    "            yhat = sub[ypred_col].values.astype(float)\n",
    "            err = y - yhat\n",
    "            mae = np.abs(err).mean()\n",
    "            rmse = np.sqrt((err**2).mean())\n",
    "\n",
    "            macro_lists[h][\"mae\"].append(mae)\n",
    "            macro_lists[h][\"rmse\"].append(rmse)\n",
    "            micro_abs[h].append(np.abs(err))\n",
    "            micro_sq[h].append(err**2)\n",
    "            micro_n[h] += len(err)\n",
    "\n",
    "    rows = []\n",
    "    for h in horizons:\n",
    "        mae_macro = float(np.mean(macro_lists[h][\"mae\"])) if macro_lists[h][\"mae\"] else np.nan\n",
    "        rmse_macro= float(np.mean(macro_lists[h][\"rmse\"])) if macro_lists[h][\"rmse\"] else np.nan\n",
    "\n",
    "        if micro_abs[h]:\n",
    "            abs_all = np.concatenate(micro_abs[h]); sq_all = np.concatenate(micro_sq[h])\n",
    "            mae_micro = float(abs_all.mean()); rmse_micro = float(np.sqrt(sq_all.mean())); n = int(micro_n[h])\n",
    "        else:\n",
    "            mae_micro = rmse_micro = np.nan; n = 0\n",
    "\n",
    "        rows.append({\n",
    "            \"horizon\": f\"{h}h\",\n",
    "            \"MAE_macro\": mae_macro, \"RMSE_macro\": rmse_macro,\n",
    "            \"MAE_micro\": mae_micro, \"RMSE_micro\": rmse_micro,\n",
    "            \"n_samples\": n\n",
    "        })\n",
    "\n",
    "    out = pd.DataFrame(rows)\n",
    "    suffix = \"_balanced\" if (balanced and has_h_col) else \"_common\"\n",
    "    out_csv = os.path.join(base_dir, f\"overall_by_horizon{suffix}.csv\")\n",
    "    out.to_csv(out_csv, index=False)\n",
    "    print(f\"[saved] per-horizon metrics → {out_csv}\")\n",
    "    return out\n",
    "\n",
    "\n",
    "# ================= HOW TO USE =================\n",
    "# 1) Build the common per-station index (intersection across models):\n",
    "common_csv = build_common_index_by_station(list(MODEL_DIRS.values()))\n",
    "#    This makes fair_eval/common_index_by_station.csv\n",
    "\n",
    "# 2) (Optional) Build the BALANCED per-station×horizon index (downsample to min N across models):\n",
    "balanced_csv = build_balanced_index_by_station(list(MODEL_DIRS.values()), HORIZONS, base_common_csv=common_csv)\n",
    "\n",
    "# 3a) Recompute per-horizon metrics on the COMMON index (same timestamps for all models; counts may still differ per horizon/station):\n",
    "lstm_common  = compute_overall_by_horizon_with_index(MODEL_DIRS[\"LSTM\"],  HORIZONS, index_csv=common_csv,  balanced=False)\n",
    "rf_common    = compute_overall_by_horizon_with_index(MODEL_DIRS[\"RF\"],    HORIZONS, index_csv=common_csv,  balanced=False)\n",
    "ridge_common = compute_overall_by_horizon_with_index(MODEL_DIRS[\"Ridge\"], HORIZONS, index_csv=common_csv,  balanced=False)\n",
    "\n",
    "# 3b) (Best apples-to-apples) Recompute per-horizon metrics on the BALANCED index (exact same N per station×horizon across models):\n",
    "lstm_bal  = compute_overall_by_horizon_with_index(MODEL_DIRS[\"LSTM\"],  HORIZONS, index_csv=balanced_csv, balanced=True)\n",
    "rf_bal    = compute_overall_by_horizon_with_index(MODEL_DIRS[\"RF\"],    HORIZONS, index_csv=balanced_csv, balanced=True)\n",
    "ridge_bal = compute_overall_by_horizon_with_index(MODEL_DIRS[\"Ridge\"], HORIZONS, index_csv=balanced_csv, balanced=True)\n",
    "\n",
    "# 4) (Optional) Merge into one side-by-side table for reporting:\n",
    "def merge_side_by_side(lstm_df, rf_df, ridge_df, label_suffix):\n",
    "    t = lstm_df.merge(rf_df, on=\"horizon\", suffixes=(\"_LSTM\", \"_RF\"))\n",
    "    # Ridge columns will collide; add suffix manually\n",
    "    rid = ridge_df.add_suffix(\"_Ridge\"); rid = rid.rename(columns={\"horizon_Ridge\":\"horizon\"})\n",
    "    t = t.merge(rid, on=\"horizon\")\n",
    "    out = os.path.join(FAIR_DIR, f\"comparison_{label_suffix}.csv\")\n",
    "    t.to_csv(out, index=False)\n",
    "    print(f\"[saved] side-by-side comparison → {out}\")\n",
    "    return t\n",
    "\n",
    "_ = merge_side_by_side(lstm_common, rf_common, ridge_common, \"common\")\n",
    "_ = merge_side_by_side(lstm_bal,    rf_bal,    ridge_bal,    \"balanced\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "d8286e24",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, numpy as np, pandas as pd\n",
    "\n",
    "def lv_baseline_from_preds(preds_df, horizons=(12,24,48,72)):\n",
    "    out = {}\n",
    "    for h in horizons:\n",
    "        y = preds_df[f\"ytrue_y_{h}h\"].values.astype(float)\n",
    "        # naive: predict y(t) for y(t+h) ⇒ shift ytrue by 0 (same as repeat last observed),\n",
    "        # BUT since we only have future targets here, use y_{12h} as a proxy check:\n",
    "        # better: compare against ytrue_y_{h}h shifted by (h-1) etc. — we’ll rely on model-specific LV files for rigor.\n",
    "        # For a quick flag, compute MAE/RMSE between y and its 1-step lag if available:\n",
    "        out[h] = dict(mae=np.nan, rmse=np.nan)\n",
    "    return out\n",
    "\n",
    "def audit_station(model_dir, station, horizons=(12,24,48,72), common_csv=None, balanced_csv=None, use_balanced=False):\n",
    "    path = os.path.join(model_dir, station, \"preds_test.csv\")\n",
    "    if not os.path.exists(path):\n",
    "        print(f\"[audit] missing: {path}\")\n",
    "        return None\n",
    "    df = pd.read_csv(path, index_col=0)\n",
    "    df.index = df.index.astype(str)\n",
    "\n",
    "    # restrict to fair indices if provided\n",
    "    if use_balanced and balanced_csv:\n",
    "        idx = pd.read_csv(balanced_csv)\n",
    "        keep = set(idx[(idx[\"station\"]==station)][\"timestamp\"].astype(str))\n",
    "        df = df.loc[df.index.isin(keep)]\n",
    "    elif common_csv:\n",
    "        keep = set(pd.read_csv(common_csv)[\"timestamp\"].astype(str))\n",
    "        df = df.loc[df.index.isin(keep)]\n",
    "\n",
    "    rows=[]\n",
    "    for h in horizons:\n",
    "        ycol=f\"ytrue_y_{h}h\"; pcol=f\"ypred_y_{h}h\"\n",
    "        if ycol not in df or pcol not in df: \n",
    "            continue\n",
    "        y = df[ycol].values.astype(float)\n",
    "        p = df[pcol].values.astype(float)\n",
    "        e = y - p\n",
    "        rows.append([h, np.mean(np.abs(e)), np.sqrt((e**2).mean()), len(e), np.mean(y), np.std(y), np.mean(p), np.std(p)])\n",
    "    if not rows:\n",
    "        print(f\"[audit] no rows after filtering for {station}\")\n",
    "        return None\n",
    "    out = pd.DataFrame(rows, columns=[\"h\",\"MAE\",\"RMSE\",\"n\",\"y_mean\",\"y_std\",\"p_mean\",\"p_std\"])\n",
    "    print(f\"\\n[audit:{model_dir}/{station}]\")\n",
    "    print(out)\n",
    "    return out\n",
    "\n",
    "# Example usage (pick one station you know has plenty of data):\n",
    "# audit_station(\"per_station\", \"S3001021\", common_csv=\"fair_eval/common_index_by_station.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "f28a8e2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np, pandas as pd, os\n",
    "\n",
    "def best_shift_mae(preds_df, horizon, max_shift=3):\n",
    "    y = preds_df[f\"ytrue_y_{horizon}h\"].values.astype(float)\n",
    "    p = preds_df[f\"ypred_y_{horizon}h\"].values.astype(float)\n",
    "    best = {\"shift\":0,\"mae\":np.mean(np.abs(y-p))}\n",
    "    for s in range(-max_shift, max_shift+1):\n",
    "        if s==0: continue\n",
    "        if s > 0:\n",
    "            y_s, p_s = y[s:], p[:-s]\n",
    "        else:\n",
    "            y_s, p_s = y[:s], p[-s:]\n",
    "        if len(y_s)==0: continue\n",
    "        mae = np.mean(np.abs(y_s - p_s))\n",
    "        if mae < best[\"mae\"]:\n",
    "            best = {\"shift\": s, \"mae\": mae}\n",
    "    return best\n",
    "\n",
    "def audit_alignment(model_dir, station, horizons=(12,24,48,72), common_csv=None):\n",
    "    path = os.path.join(model_dir, station, \"preds_test.csv\")\n",
    "    if not os.path.exists(path):\n",
    "        print(f\"[align] missing: {path}\"); return\n",
    "    df = pd.read_csv(path, index_col=0); df.index = df.index.astype(str)\n",
    "    if common_csv:\n",
    "        keep = set(pd.read_csv(common_csv)[\"timestamp\"].astype(str))\n",
    "        df = df.loc[df.index.isin(keep)]\n",
    "    for h in horizons:\n",
    "        ycol=f\"ytrue_y_{h}h\"; pcol=f\"ypred_y_{h}h\"\n",
    "        if ycol not in df or pcol not in df: continue\n",
    "        best = best_shift_mae(df[[ycol,pcol]], h)\n",
    "        print(f\"[align] {station} h={h}: best_shift={best['shift']}  best_mae={best['mae']:.3f}\")\n",
    "        \n",
    "# Example:\n",
    "# audit_alignment(\"per_station\", \"S3001021\", common_csv=\"fair_eval/common_index_by_station.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "bb965f0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_scale(model_dir, station, horizon=12):\n",
    "    import os, pandas as pd, numpy as np\n",
    "    f = os.path.join(model_dir, station, \"preds_test.csv\")\n",
    "    if not os.path.exists(f): \n",
    "        print(\"missing\", f); return\n",
    "    df = pd.read_csv(f, index_col=0)\n",
    "    y = df[f\"ytrue_y_{horizon}h\"].values.astype(float)\n",
    "    p = df[f\"ypred_y_{horizon}h\"].values.astype(float)\n",
    "    print(f\"[scale] {station} h={horizon}: y_mean={y.mean():.1f}, p_mean={p.mean():.1f}, y_std={y.std():.1f}, p_std={p.std():.1f}\")\n",
    "    print(f\"         MAE={np.mean(np.abs(y-p)):.1f}, RMSE={np.sqrt(((y-p)**2).mean()):.1f}\")\n",
    "\n",
    "# Example:\n",
    "# check_scale(\"per_station\", \"S3001021\", horizon=24)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "270c67a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM n: 0\n",
      "RF n: 0\n",
      "Ridge n: 0\n"
     ]
    }
   ],
   "source": [
    "# pick a station and compare n_samples across all three models on the balanced index\n",
    "station = \"S3001021\"\n",
    "balanced = pd.read_csv(\"fair_eval/balanced_index_by_station.csv\")\n",
    "need = set(balanced[balanced[\"station\"]==station][\"timestamp\"].astype(str))\n",
    "\n",
    "def count_rows(model_dir, station):\n",
    "    p = os.path.join(model_dir, station, \"preds_test.csv\")\n",
    "    if not os.path.exists(p): return 0\n",
    "    df = pd.read_csv(p, index_col=0); df.index = df.index.astype(str)\n",
    "    return int(df.index.isin(need).sum())\n",
    "\n",
    "print(\"LSTM n:\",  count_rows(\"per_station\", station))\n",
    "print(\"RF n:\",    count_rows(\"per_station_rf\", station))\n",
    "print(\"Ridge n:\", count_rows(\"per_station_ridge\", station))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13ae156b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
